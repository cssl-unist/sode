MAINTAINERS:F:	drivers/cpufreq/sun50i-cpufreq-nvmem.c
MAINTAINERS:F:	drivers/devfreq/devfreq-event.c
MAINTAINERS:F:	include/linux/devfreq-event.h
MAINTAINERS:F:	drivers/cpufreq/qcom-cpufreq-nvmem.c
fs/f2fs/checkpoint.c:		diff = (u64)ktime_ms_delta(ktime_get(), req->queue_time);
fs/f2fs/checkpoint.c:		req->ret = ret;
fs/f2fs/checkpoint.c:		complete(&req->wait);
fs/f2fs/checkpoint.c:			wait_for_completion(&wait_req->wait);
fs/f2fs/checkpoint.c:	init_completion(&req->wait);
fs/f2fs/checkpoint.c:	req->queue_time = ktime_get();
fs/ubifs/debug.c:	       req->new_ino, req->dirtied_ino);
fs/ubifs/debug.c:	       req->new_ino_d, req->dirtied_ino_d);
fs/ubifs/debug.c:	       req->new_page, req->dirtied_page);
fs/ubifs/debug.c:	       req->new_dent, req->mod_dent);
fs/ubifs/debug.c:	pr_err("\tidx_growth  %d\n", req->idx_growth);
fs/ubifs/debug.c:	       req->data_growth, req->dd_growth);
fs/ubifs/budget.c:	znodes = req->new_ino + (req->new_page << UBIFS_BLOCKS_PER_PAGE_SHIFT) +
fs/ubifs/budget.c:		 req->new_dent;
fs/ubifs/budget.c:	data_growth = req->new_ino  ? c->bi.inode_budget : 0;
fs/ubifs/budget.c:	if (req->new_page)
fs/ubifs/budget.c:	if (req->new_dent)
fs/ubifs/budget.c:	data_growth += req->new_ino_d;
fs/ubifs/budget.c:	dd_growth = req->dirtied_page ? c->bi.page_budget : 0;
fs/ubifs/budget.c:	if (req->dirtied_ino)
fs/ubifs/budget.c:		dd_growth += c->bi.inode_budget << (req->dirtied_ino - 1);
fs/ubifs/budget.c:	if (req->mod_dent)
fs/ubifs/budget.c:	dd_growth += req->dirtied_ino_d;
fs/ubifs/budget.c:	ubifs_assert(c, req->new_page <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_page <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_dent <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->mod_dent <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_ino <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_ino_d <= UBIFS_MAX_INO_DATA);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_ino <= 4);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_ino_d <= UBIFS_MAX_INO_DATA * 4);
fs/ubifs/budget.c:	ubifs_assert(c, !(req->new_ino_d & 7));
fs/ubifs/budget.c:	ubifs_assert(c, !(req->dirtied_ino_d & 7));
fs/ubifs/budget.c:		req->idx_growth = idx_growth;
fs/ubifs/budget.c:		req->data_growth = data_growth;
fs/ubifs/budget.c:		req->dd_growth = dd_growth;
fs/ubifs/budget.c:	if (req->fast) {
fs/ubifs/budget.c: * since the index changes (which were budgeted for in @req->idx_growth) will
fs/ubifs/budget.c:	ubifs_assert(c, req->new_page <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_page <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_dent <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->mod_dent <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_ino <= 1);
fs/ubifs/budget.c:	ubifs_assert(c, req->new_ino_d <= UBIFS_MAX_INO_DATA);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_ino <= 4);
fs/ubifs/budget.c:	ubifs_assert(c, req->dirtied_ino_d <= UBIFS_MAX_INO_DATA * 4);
fs/ubifs/budget.c:	ubifs_assert(c, !(req->new_ino_d & 7));
fs/ubifs/budget.c:	ubifs_assert(c, !(req->dirtied_ino_d & 7));
fs/ubifs/budget.c:	if (!req->recalculate) {
fs/ubifs/budget.c:		ubifs_assert(c, req->idx_growth >= 0);
fs/ubifs/budget.c:		ubifs_assert(c, req->data_growth >= 0);
fs/ubifs/budget.c:		ubifs_assert(c, req->dd_growth >= 0);
fs/ubifs/budget.c:	if (req->recalculate) {
fs/ubifs/budget.c:		req->data_growth = calc_data_growth(c, req);
fs/ubifs/budget.c:		req->dd_growth = calc_dd_growth(c, req);
fs/ubifs/budget.c:		req->idx_growth = calc_idx_growth(c, req);
fs/ubifs/budget.c:	if (!req->data_growth && !req->dd_growth)
fs/ubifs/budget.c:	c->bi.idx_growth -= req->idx_growth;
fs/ubifs/budget.c:	c->bi.uncommitted_idx += req->idx_growth;
fs/ubifs/budget.c:	c->bi.data_growth -= req->data_growth;
fs/ubifs/budget.c:	c->bi.dd_growth -= req->dd_growth;
fs/cifs/smb2pdu.c:	req->NegotiateContextOffset = cpu_to_le32(*total_len);
fs/cifs/smb2pdu.c:		req->NegotiateContextCount = cpu_to_le16(5);
fs/cifs/smb2pdu.c:		req->NegotiateContextCount = cpu_to_le16(4);
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset = cpu_to_le32(
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, sizeof(struct create_posix));
fs/cifs/smb2pdu.c:	req->sync_hdr.SessionId = 0;
fs/cifs/smb2pdu.c:		req->Dialects[0] = cpu_to_le16(SMB30_PROT_ID);
fs/cifs/smb2pdu.c:		req->Dialects[1] = cpu_to_le16(SMB302_PROT_ID);
fs/cifs/smb2pdu.c:		req->Dialects[2] = cpu_to_le16(SMB311_PROT_ID);
fs/cifs/smb2pdu.c:		req->DialectCount = cpu_to_le16(3);
fs/cifs/smb2pdu.c:		req->Dialects[0] = cpu_to_le16(SMB21_PROT_ID);
fs/cifs/smb2pdu.c:		req->Dialects[1] = cpu_to_le16(SMB30_PROT_ID);
fs/cifs/smb2pdu.c:		req->Dialects[2] = cpu_to_le16(SMB302_PROT_ID);
fs/cifs/smb2pdu.c:		req->Dialects[3] = cpu_to_le16(SMB311_PROT_ID);
fs/cifs/smb2pdu.c:		req->DialectCount = cpu_to_le16(4);
fs/cifs/smb2pdu.c:		req->Dialects[0] = cpu_to_le16(server->vals->protocol_id);
fs/cifs/smb2pdu.c:		req->DialectCount = cpu_to_le16(1);
fs/cifs/smb2pdu.c:		req->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_REQUIRED);
fs/cifs/smb2pdu.c:		req->SecurityMode = cpu_to_le16(SMB2_NEGOTIATE_SIGNING_ENABLED);
fs/cifs/smb2pdu.c:		req->SecurityMode = 0;
fs/cifs/smb2pdu.c:	req->Capabilities = cpu_to_le32(server->vals->req_capabilities);
fs/cifs/smb2pdu.c:		memset(req->ClientGUID, 0, SMB2_CLIENT_GUID_SIZE);
fs/cifs/smb2pdu.c:		memcpy(req->ClientGUID, server->client_guid,
fs/cifs/smb2pdu.c:		req->sync_hdr.SessionId = sess_data->ses->Suid;
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_SIGNED;
fs/cifs/smb2pdu.c:		req->PreviousSessionId = 0;
fs/cifs/smb2pdu.c:		req->Flags = SMB2_SESSION_REQ_FLAG_BINDING;
fs/cifs/smb2pdu.c:		req->sync_hdr.SessionId = 0;
fs/cifs/smb2pdu.c:		req->PreviousSessionId = sess_data->previous_session;
fs/cifs/smb2pdu.c:		req->Flags = 0; /* MBZ */
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditRequest = cpu_to_le16(130);
fs/cifs/smb2pdu.c:		req->SecurityMode = SMB2_NEGOTIATE_SIGNING_REQUIRED;
fs/cifs/smb2pdu.c:		req->SecurityMode = SMB2_NEGOTIATE_SIGNING_ENABLED;
fs/cifs/smb2pdu.c:		req->SecurityMode = 0;
fs/cifs/smb2pdu.c:	req->Capabilities = cpu_to_le32(SMB2_GLOBAL_CAP_DFS);
fs/cifs/smb2pdu.c:	req->Capabilities = 0;
fs/cifs/smb2pdu.c:	req->Channel = 0; /* MBZ */
fs/cifs/smb2pdu.c:	req->SecurityBufferOffset =
fs/cifs/smb2pdu.c:	req->SecurityBufferLength = cpu_to_le16(sess_data->iov[1].iov_len);
fs/cifs/smb2pdu.c:	req->sync_hdr.SessionId = ses->Suid;
fs/cifs/smb2pdu.c:	req->sync_hdr.SessionId = ses->Suid;
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_SIGNED;
fs/cifs/smb2pdu.c:	req->PathOffset = cpu_to_le16(sizeof(struct smb2_tree_connect_req)
fs/cifs/smb2pdu.c:	req->PathLength = cpu_to_le16(unc_path_len - 2);
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_SIGNED;
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditRequest = cpu_to_le16(64);
fs/cifs/smb2pdu.c:	req->RequestedOplockLevel = SMB2_OPLOCK_LEVEL_LEASE;
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset = cpu_to_le32(
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength,
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset =
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, sizeof(struct create_durable_v2));
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset =
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength,
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset =
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, sizeof(struct create_durable));
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset = cpu_to_le32(
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, sizeof(struct crt_twarp_ctxt));
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset = cpu_to_le32(
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, len);
fs/cifs/smb2pdu.c:	if (!req->CreateContextsOffset)
fs/cifs/smb2pdu.c:		req->CreateContextsOffset = cpu_to_le32(
fs/cifs/smb2pdu.c:	le32_add_cpu(&req->CreateContextsLength, sizeof(struct crt_query_id_ctxt));
fs/cifs/smb2pdu.c:	req->ImpersonationLevel = IL_IMPERSONATION;
fs/cifs/smb2pdu.c:	req->DesiredAccess = cpu_to_le32(FILE_WRITE_ATTRIBUTES);
fs/cifs/smb2pdu.c:	req->FileAttributes = cpu_to_le32(file_attributes);
fs/cifs/smb2pdu.c:	req->ShareAccess = FILE_SHARE_ALL_LE;
fs/cifs/smb2pdu.c:	req->CreateDisposition = cpu_to_le32(FILE_CREATE);
fs/cifs/smb2pdu.c:	req->CreateOptions = cpu_to_le32(CREATE_NOT_FILE);
fs/cifs/smb2pdu.c:	req->NameOffset = cpu_to_le16(sizeof(struct smb2_create_req));
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_DFS_OPERATIONS;
fs/cifs/smb2pdu.c:		req->NameLength = cpu_to_le16(name_len * 2);
fs/cifs/smb2pdu.c:		req->NameLength = cpu_to_le16(uni_path_len - 2);
fs/cifs/smb2pdu.c:	req->RequestedOplockLevel = SMB2_OPLOCK_LEVEL_NONE;
fs/cifs/smb2pdu.c:	req->ImpersonationLevel = IL_IMPERSONATION;
fs/cifs/smb2pdu.c:	req->DesiredAccess = cpu_to_le32(oparms->desired_access);
fs/cifs/smb2pdu.c:	req->FileAttributes = cpu_to_le32(file_attributes);
fs/cifs/smb2pdu.c:	req->ShareAccess = FILE_SHARE_ALL_LE;
fs/cifs/smb2pdu.c:	req->CreateDisposition = cpu_to_le32(oparms->disposition);
fs/cifs/smb2pdu.c:	req->CreateOptions = cpu_to_le32(oparms->create_options & CREATE_OPTIONS_MASK);
fs/cifs/smb2pdu.c:	req->NameOffset = cpu_to_le16(sizeof(struct smb2_create_req));
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_DFS_OPERATIONS;
fs/cifs/smb2pdu.c:		req->NameLength = cpu_to_le16(name_len * 2);
fs/cifs/smb2pdu.c:		req->NameLength = cpu_to_le16(uni_path_len - 2);
fs/cifs/smb2pdu.c:		req->RequestedOplockLevel = *oplock;
fs/cifs/smb2pdu.c:		req->RequestedOplockLevel = *oplock; /* no srv lease support */
fs/cifs/smb2pdu.c:	req->CtlCode = cpu_to_le32(opcode);
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:		req->InputCount = cpu_to_le32(indatalen);
fs/cifs/smb2pdu.c:		req->InputOffset =
fs/cifs/smb2pdu.c:	req->OutputOffset = 0;
fs/cifs/smb2pdu.c:	req->OutputCount = 0; /* MBZ */
fs/cifs/smb2pdu.c:	req->MaxOutputResponse = cpu_to_le32(max_response_size);
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditCharge =
fs/cifs/smb2pdu.c:		req->Flags = cpu_to_le32(SMB2_0_IOCTL_IS_FSCTL);
fs/cifs/smb2pdu.c:		req->Flags = 0;
fs/cifs/smb2pdu.c:		req->sync_hdr.Flags |= SMB2_FLAGS_SIGNED;
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:		req->Flags = SMB2_CLOSE_FLAG_POSTQUERY_ATTRIB;
fs/cifs/smb2pdu.c:		req->Flags = 0;
fs/cifs/smb2pdu.c:	req->InfoType = info_type;
fs/cifs/smb2pdu.c:	req->FileInfoClass = info_class;
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	req->AdditionalInformation = cpu_to_le32(additional_info);
fs/cifs/smb2pdu.c:	req->OutputBufferLength = cpu_to_le32(output_len);
fs/cifs/smb2pdu.c:		req->InputBufferLength = cpu_to_le32(input_len);
fs/cifs/smb2pdu.c:		req->InputBufferOffset = cpu_to_le16(total_len - 1);
fs/cifs/smb2pdu.c:		memcpy(req->Buffer, input, input_len);
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	req->OutputBufferLength =
fs/cifs/smb2pdu.c:	req->CompletionFilter = cpu_to_le32(completion_filter);
fs/cifs/smb2pdu.c:		req->Flags = cpu_to_le16(SMB2_WATCH_TREE);
fs/cifs/smb2pdu.c:		req->Flags = 0;
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditRequest = cpu_to_le16(1);
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	shdr = &req->sync_hdr;
fs/cifs/smb2pdu.c:	req->PersistentFileId = io_parms->persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = io_parms->volatile_fid;
fs/cifs/smb2pdu.c:	req->ReadChannelInfoOffset = 0; /* reserved */
fs/cifs/smb2pdu.c:	req->ReadChannelInfoLength = 0; /* reserved */
fs/cifs/smb2pdu.c:	req->Channel = 0; /* reserved */
fs/cifs/smb2pdu.c:	req->MinimumCount = 0;
fs/cifs/smb2pdu.c:	req->Length = cpu_to_le32(io_parms->length);
fs/cifs/smb2pdu.c:	req->Offset = cpu_to_le64(io_parms->offset);
fs/cifs/smb2pdu.c:		req->Channel = SMB2_CHANNEL_RDMA_V1_INVALIDATE;
fs/cifs/smb2pdu.c:			req->Channel = SMB2_CHANNEL_RDMA_V1;
fs/cifs/smb2pdu.c:		req->ReadChannelInfoOffset =
fs/cifs/smb2pdu.c:		req->ReadChannelInfoLength =
fs/cifs/smb2pdu.c:		v1 = (struct smbd_buffer_descriptor_v1 *) &req->Buffer[0];
fs/cifs/smb2pdu.c:			req->PersistentFileId = 0xFFFFFFFF;
fs/cifs/smb2pdu.c:			req->VolatileFileId = 0xFFFFFFFF;
fs/cifs/smb2pdu.c:		req->RemainingBytes = cpu_to_le32(remaining_bytes);
fs/cifs/smb2pdu.c:		req->RemainingBytes = 0;
fs/cifs/smb2pdu.c:			trace_smb3_read_err(xid, req->PersistentFileId,
fs/cifs/smb2pdu.c:			trace_smb3_read_done(xid, req->PersistentFileId,
fs/cifs/smb2pdu.c:		trace_smb3_read_done(xid, req->PersistentFileId,
fs/cifs/smb2pdu.c:	req->PersistentFileId = wdata->cfile->fid.persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = wdata->cfile->fid.volatile_fid;
fs/cifs/smb2pdu.c:	req->WriteChannelInfoOffset = 0;
fs/cifs/smb2pdu.c:	req->WriteChannelInfoLength = 0;
fs/cifs/smb2pdu.c:	req->Channel = 0;
fs/cifs/smb2pdu.c:	req->Offset = cpu_to_le64(wdata->offset);
fs/cifs/smb2pdu.c:	req->DataOffset = cpu_to_le16(
fs/cifs/smb2pdu.c:	req->RemainingBytes = 0;
fs/cifs/smb2pdu.c:		req->Length = 0;
fs/cifs/smb2pdu.c:		req->DataOffset = 0;
fs/cifs/smb2pdu.c:			req->RemainingBytes =
fs/cifs/smb2pdu.c:			req->RemainingBytes = cpu_to_le32(wdata->tailsz);
fs/cifs/smb2pdu.c:		req->Channel = SMB2_CHANNEL_RDMA_V1_INVALIDATE;
fs/cifs/smb2pdu.c:			req->Channel = SMB2_CHANNEL_RDMA_V1;
fs/cifs/smb2pdu.c:		req->WriteChannelInfoOffset =
fs/cifs/smb2pdu.c:		req->WriteChannelInfoLength =
fs/cifs/smb2pdu.c:		v1 = (struct smbd_buffer_descriptor_v1 *) &req->Buffer[0];
fs/cifs/smb2pdu.c:		req->Length = cpu_to_le32(wdata->bytes);
fs/cifs/smb2pdu.c:	req->Length = cpu_to_le32(wdata->bytes);
fs/cifs/smb2pdu.c:		trace_smb3_write_err(0 /* no xid */, req->PersistentFileId,
fs/cifs/smb2pdu.c:	req->sync_hdr.ProcessId = cpu_to_le32(io_parms->pid);
fs/cifs/smb2pdu.c:	req->PersistentFileId = io_parms->persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = io_parms->volatile_fid;
fs/cifs/smb2pdu.c:	req->WriteChannelInfoOffset = 0;
fs/cifs/smb2pdu.c:	req->WriteChannelInfoLength = 0;
fs/cifs/smb2pdu.c:	req->Channel = 0;
fs/cifs/smb2pdu.c:	req->Length = cpu_to_le32(io_parms->length);
fs/cifs/smb2pdu.c:	req->Offset = cpu_to_le64(io_parms->offset);
fs/cifs/smb2pdu.c:	req->DataOffset = cpu_to_le16(
fs/cifs/smb2pdu.c:	req->RemainingBytes = 0;
fs/cifs/smb2pdu.c:		trace_smb3_write_err(xid, req->PersistentFileId,
fs/cifs/smb2pdu.c:		trace_smb3_write_done(xid, req->PersistentFileId,
fs/cifs/smb2pdu.c:		req->FileInformationClass = FILE_DIRECTORY_INFORMATION;
fs/cifs/smb2pdu.c:		req->FileInformationClass = FILEID_FULL_DIRECTORY_INFORMATION;
fs/cifs/smb2pdu.c:		req->FileInformationClass = SMB_FIND_FILE_POSIX_INFO;
fs/cifs/smb2pdu.c:	req->FileIndex = cpu_to_le32(index);
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	bufptr = req->Buffer;
fs/cifs/smb2pdu.c:	req->FileNameOffset =
fs/cifs/smb2pdu.c:	req->FileNameLength = cpu_to_le16(len);
fs/cifs/smb2pdu.c:	req->OutputBufferLength = cpu_to_le32(output_size);
fs/cifs/smb2pdu.c:	iov[1].iov_base = (char *)(req->Buffer);
fs/cifs/smb2pdu.c:	req->sync_hdr.ProcessId = cpu_to_le32(pid);
fs/cifs/smb2pdu.c:	req->InfoType = info_type;
fs/cifs/smb2pdu.c:	req->FileInfoClass = info_class;
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	req->AdditionalInformation = cpu_to_le32(additional_info);
fs/cifs/smb2pdu.c:	req->BufferOffset =
fs/cifs/smb2pdu.c:	req->BufferLength = cpu_to_le32(*size);
fs/cifs/smb2pdu.c:	memcpy(req->Buffer, *data, *size);
fs/cifs/smb2pdu.c:		le32_add_cpu(&req->BufferLength, size[i]);
fs/cifs/smb2pdu.c:	req->VolatileFid = volatile_fid;
fs/cifs/smb2pdu.c:	req->PersistentFid = persistent_fid;
fs/cifs/smb2pdu.c:	req->OplockLevel = oplock_level;
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditRequest = cpu_to_le16(1);
fs/cifs/smb2pdu.c:	req->InfoType = SMB2_O_INFO_FILESYSTEM;
fs/cifs/smb2pdu.c:	req->FileInfoClass = level;
fs/cifs/smb2pdu.c:	req->PersistentFileId = persistent_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	req->InputBufferOffset =
fs/cifs/smb2pdu.c:	req->OutputBufferLength = cpu_to_le32(
fs/cifs/smb2pdu.c:	req->sync_hdr.ProcessId = cpu_to_le32(pid);
fs/cifs/smb2pdu.c:	req->LockCount = cpu_to_le16(num_lock);
fs/cifs/smb2pdu.c:	req->PersistentFileId = persist_fid;
fs/cifs/smb2pdu.c:	req->VolatileFileId = volatile_fid;
fs/cifs/smb2pdu.c:	req->sync_hdr.CreditRequest = cpu_to_le16(1);
fs/cifs/smb2pdu.c:	req->StructureSize = cpu_to_le16(36);
fs/cifs/smb2pdu.c:	memcpy(req->LeaseKey, lease_key, 16);
fs/cifs/smb2pdu.c:	req->LeaseState = lease_state;
fs/cifs/smb2ops.c:	dfs_req->MaxReferralLevel = DFS_VERSION;
fs/cifs/smb2ops.c:	memcpy(dfs_req->RequestFileName, utf16_path, utf16_path_len);
fs/cifs/cifssmb.c:	req->AndXCommand = 0xFF;
fs/cifs/cifssmb.c:	if (req->hdr.Flags2 & SMBFLG2_UNICODE) {
fs/cifs/cifssmb.c:		name_len = cifsConvertToUTF16((__le16 *)(req->fileName + 1),
fs/cifs/cifssmb.c:		req->NameLength = cpu_to_le16(name_len);
fs/cifs/cifssmb.c:		name_len = copy_path_name(req->fileName, path);
fs/cifs/cifssmb.c:		req->NameLength = cpu_to_le16(name_len);
fs/cifs/cifssmb.c:		req->OpenFlags = cpu_to_le32(REQ_OPLOCK);
fs/cifs/cifssmb.c:		req->OpenFlags = cpu_to_le32(REQ_BATCHOPLOCK);
fs/cifs/cifssmb.c:	req->DesiredAccess = cpu_to_le32(desired_access);
fs/cifs/cifssmb.c:	req->AllocationSize = 0;
fs/cifs/cifssmb.c:		req->FileAttributes = cpu_to_le32(ATTR_SYSTEM);
fs/cifs/cifssmb.c:		req->FileAttributes = cpu_to_le32(ATTR_NORMAL);
fs/cifs/cifssmb.c:		req->FileAttributes |= cpu_to_le32(ATTR_POSIX_SEMANTICS);
fs/cifs/cifssmb.c:		req->FileAttributes |= cpu_to_le32(ATTR_READONLY);
fs/cifs/cifssmb.c:	req->ShareAccess = cpu_to_le32(FILE_SHARE_ALL);
fs/cifs/cifssmb.c:	req->CreateDisposition = cpu_to_le32(disposition);
fs/cifs/cifssmb.c:	req->CreateOptions = cpu_to_le32(create_options & CREATE_OPTIONS_MASK);
fs/cifs/cifssmb.c:	req->ImpersonationLevel = cpu_to_le32(SECURITY_IMPERSONATION);
fs/cifs/cifssmb.c:	req->SecurityFlags = SECURITY_CONTEXT_TRACKING|SECURITY_EFFECTIVE_ONLY;
fs/cifs/cifssmb.c:	req->ByteCount = cpu_to_le16(count);
fs/overlayfs/file.c:	struct kiocb *iocb = &aio_req->iocb;
fs/overlayfs/file.c:	struct kiocb *orig_iocb = aio_req->orig_iocb;
fs/overlayfs/file.c:	fdput(aio_req->fd);
fs/overlayfs/file.c:	struct kiocb *orig_iocb = aio_req->orig_iocb;
fs/overlayfs/file.c:		aio_req->fd = real;
fs/overlayfs/file.c:		aio_req->orig_iocb = iocb;
fs/overlayfs/file.c:		kiocb_clone(&aio_req->iocb, iocb, real.file);
fs/overlayfs/file.c:		aio_req->iocb.ki_complete = ovl_aio_rw_complete;
fs/overlayfs/file.c:		ret = vfs_iocb_iter_read(real.file, &aio_req->iocb, iter);
fs/overlayfs/file.c:		aio_req->fd = real;
fs/overlayfs/file.c:		aio_req->orig_iocb = iocb;
fs/overlayfs/file.c:		kiocb_clone(&aio_req->iocb, iocb, real.file);
fs/overlayfs/file.c:		aio_req->iocb.ki_flags = ifl;
fs/overlayfs/file.c:		aio_req->iocb.ki_complete = ovl_aio_rw_complete;
fs/overlayfs/file.c:		ret = vfs_iocb_iter_write(real.file, &aio_req->iocb, iter);
fs/nfs/nfs42xdr.c:	if (len > req->rq_rcv_buf.page_len)
fs/nfs/flexfilelayout/flexfilelayout.c:					   req->wb_bytes,
fs/nfs/flexfilelayout/flexfilelayout.c:						   req->wb_bytes,
fs/nfs/flexfilelayout/flexfilelayout.c:						   req->wb_bytes,
fs/nfs/flexfilelayout/flexfilelayout.c:			count += req->wb_bytes;
fs/nfs/nfs2xdr.c:	req->rq_rcv_buf.flags |= XDRBUF_READ;
fs/nfs/pagelist.c:	struct nfs_page *head = req->wb_head;
fs/nfs/pagelist.c:	if (!kref_get_unless_zero(&subreq->wb_kref))
fs/nfs/pagelist.c:			subreq = subreq->wb_this_page) {
fs/nfs/pagelist.c: * this lock must be held when modifying req->wb_head
fs/nfs/pagelist.c:	if (!test_and_set_bit(PG_HEADLOCK, &req->wb_flags))
fs/nfs/pagelist.c:	set_bit(PG_CONTENDED1, &req->wb_flags);
fs/nfs/pagelist.c:	return wait_on_bit_lock(&req->wb_flags, PG_HEADLOCK,
fs/nfs/pagelist.c:	clear_bit(PG_HEADLOCK, &req->wb_flags);
fs/nfs/pagelist.c:	if (!test_bit(PG_CONTENDED1, &req->wb_flags))
fs/nfs/pagelist.c:	wake_up_bit(&req->wb_flags, PG_HEADLOCK);
fs/nfs/pagelist.c:	if (ret || req->wb_head == req)
fs/nfs/pagelist.c:	return nfs_page_set_headlock(req->wb_head);
fs/nfs/pagelist.c:	if (req != req->wb_head)
fs/nfs/pagelist.c:		nfs_page_clear_headlock(req->wb_head);
fs/nfs/pagelist.c:	struct nfs_page *head = req->wb_head;
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_and_set_bit(bit, &req->wb_flags));
fs/nfs/pagelist.c:	tmp = req->wb_this_page;
fs/nfs/pagelist.c:		req->wb_head = req;
fs/nfs/pagelist.c:		req->wb_this_page = req;
fs/nfs/pagelist.c:		req->wb_head = prev->wb_head;
fs/nfs/pagelist.c:		req->wb_this_page = prev->wb_this_page;
fs/nfs/pagelist.c:		kref_get(&req->wb_head->wb_kref);
fs/nfs/pagelist.c:			inode = page_file_mapping(req->wb_page)->host;
fs/nfs/pagelist.c:			set_bit(PG_INODE_REF, &req->wb_flags);
fs/nfs/pagelist.c:			kref_get(&req->wb_kref);
fs/nfs/pagelist.c:	struct nfs_page *head = req->wb_head;
fs/nfs/pagelist.c:	req->wb_lock_context = l_ctx;
fs/nfs/pagelist.c:	req->wb_page    = page;
fs/nfs/pagelist.c:		req->wb_index = page_index(page);
fs/nfs/pagelist.c:	req->wb_offset  = offset;
fs/nfs/pagelist.c:	req->wb_pgbase	= pgbase;
fs/nfs/pagelist.c:	req->wb_bytes   = count;
fs/nfs/pagelist.c:	kref_init(&req->wb_kref);
fs/nfs/pagelist.c:	req->wb_nio = 0;
fs/nfs/pagelist.c:	ret = __nfs_create_request(req->wb_lock_context, req->wb_page,
fs/nfs/pagelist.c:		for (last = req->wb_head;
fs/nfs/pagelist.c:		     last->wb_this_page != req->wb_head;
fs/nfs/pagelist.c:		ret->wb_index = req->wb_index;
fs/nfs/pagelist.c:		ret->wb_nio = req->wb_nio;
fs/nfs/pagelist.c:	clear_bit(PG_BUSY, &req->wb_flags);
fs/nfs/pagelist.c:	if (!test_bit(PG_CONTENDED2, &req->wb_flags))
fs/nfs/pagelist.c:	wake_up_bit(&req->wb_flags, PG_BUSY);
fs/nfs/pagelist.c:	struct page *page = req->wb_page;
fs/nfs/pagelist.c:	struct nfs_lock_context *l_ctx = req->wb_lock_context;
fs/nfs/pagelist.c:		req->wb_page = NULL;
fs/nfs/pagelist.c:		req->wb_lock_context = NULL;
fs/nfs/pagelist.c:	WARN_ON_ONCE(req->wb_this_page != req);
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_bit(PG_TEARDOWN, &req->wb_flags));
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_bit(PG_UNLOCKPAGE, &req->wb_flags));
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_bit(PG_UPTODATE, &req->wb_flags));
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_bit(PG_WB_END, &req->wb_flags));
fs/nfs/pagelist.c:	WARN_ON_ONCE(test_bit(PG_REMOVE, &req->wb_flags));
fs/nfs/pagelist.c:	kref_put(&req->wb_kref, nfs_page_group_destroy);
fs/nfs/pagelist.c:	if (!test_bit(PG_BUSY, &req->wb_flags))
fs/nfs/pagelist.c:	set_bit(PG_CONTENDED2, &req->wb_flags);
fs/nfs/pagelist.c:	return wait_on_bit_io(&req->wb_flags, PG_BUSY,
fs/nfs/pagelist.c:	if (((mirror->pg_count + req->wb_bytes) >> PAGE_SHIFT) *
fs/nfs/pagelist.c:	return min(mirror->pg_bsize - mirror->pg_count, (size_t)req->wb_bytes);
fs/nfs/pagelist.c:	hdr->args.pgbase = req->wb_pgbase;
fs/nfs/pagelist.c:	hdr->args.lock_context = req->wb_lock_context;
fs/nfs/pagelist.c:		if (!last_page || last_page != req->wb_page) {
fs/nfs/pagelist.c:			*pages++ = last_page = req->wb_page;
fs/nfs/pagelist.c:		    !nfs_match_lock_context(req->wb_lock_context,
fs/nfs/pagelist.c:		if (req->wb_page == prev->wb_page) {
fs/nfs/pagelist.c:			if (req->wb_pgbase != prev->wb_pgbase + prev->wb_bytes)
fs/nfs/pagelist.c:			if (req->wb_pgbase != 0 ||
fs/nfs/pagelist.c:		mirror->pg_base = req->wb_pgbase;
fs/nfs/pagelist.c:	if (desc->pg_maxretrans && req->wb_nio > desc->pg_maxretrans) {
fs/nfs/pagelist.c:	if (size < req->wb_bytes)
fs/nfs/pagelist.c:	mirror->pg_count += req->wb_bytes;
fs/nfs/pagelist.c:	return req->wb_bytes;
fs/nfs/pagelist.c:	subreq_size = subreq->wb_bytes;
fs/nfs/pagelist.c:			req->wb_pgbase += size;
fs/nfs/pagelist.c:			req->wb_bytes -= size;
fs/nfs/pagelist.c:			req->wb_offset += size;
fs/nfs/pagelist.c:			subreq_size = req->wb_bytes;
fs/nfs/pagelist.c:			subreq_size = req->wb_bytes;
fs/nfs/pagelist.c:		subreq = nfs_create_subreq(req, req->wb_pgbase,
fs/nfs/pagelist.c:				req->wb_offset, size);
fs/nfs/pagelist.c:	pgbase = req->wb_pgbase;
fs/nfs/pagelist.c:	offset = req->wb_offset;
fs/nfs/pagelist.c:	bytes = req->wb_bytes;
fs/nfs/filelayout/filelayout.c: * of bytes (maximum @req->wb_bytes) that can be coalesced.
fs/nfs/direct.c:	atomic_inc(&dreq->io_count);
fs/nfs/direct.c:	return atomic_dec_and_test(&dreq->io_count);
fs/nfs/direct.c:	if (dreq->max_count >= dreq_len) {
fs/nfs/direct.c:		dreq->max_count = dreq_len;
fs/nfs/direct.c:		if (dreq->count > dreq_len)
fs/nfs/direct.c:			dreq->count = dreq_len;
fs/nfs/direct.c:			dreq->error = hdr->error;
fs/nfs/direct.c:			dreq->error = 0;
fs/nfs/direct.c:	if (hdr_end > dreq->io_start)
fs/nfs/direct.c:		dreq_len = hdr_end - dreq->io_start;
fs/nfs/direct.c:	if (dreq_len > dreq->max_count)
fs/nfs/direct.c:		dreq_len = dreq->max_count;
fs/nfs/direct.c:	if (dreq->count < dreq_len)
fs/nfs/direct.c:		dreq->count = dreq_len;
fs/nfs/direct.c:	cinfo->inode = dreq->inode;
fs/nfs/direct.c:	cinfo->mds = &dreq->mds_cinfo;
fs/nfs/direct.c:	cinfo->ds = &dreq->ds_cinfo;
fs/nfs/direct.c:	kref_init(&dreq->kref);
fs/nfs/direct.c:	kref_get(&dreq->kref);
fs/nfs/direct.c:	init_completion(&dreq->completion);
fs/nfs/direct.c:	INIT_LIST_HEAD(&dreq->mds_cinfo.list);
fs/nfs/direct.c:	pnfs_init_ds_commit_info(&dreq->ds_cinfo);
fs/nfs/direct.c:	INIT_WORK(&dreq->work, nfs_direct_write_schedule_work);
fs/nfs/direct.c:	spin_lock_init(&dreq->lock);
fs/nfs/direct.c:	pnfs_release_ds_info(&dreq->ds_cinfo, dreq->inode);
fs/nfs/direct.c:	if (dreq->l_ctx != NULL)
fs/nfs/direct.c:		nfs_put_lock_context(dreq->l_ctx);
fs/nfs/direct.c:	if (dreq->ctx != NULL)
fs/nfs/direct.c:		put_nfs_open_context(dreq->ctx);
fs/nfs/direct.c:	kref_put(&dreq->kref, nfs_direct_req_free);
fs/nfs/direct.c:	return dreq->bytes_left;
fs/nfs/direct.c:	if (dreq->iocb)
fs/nfs/direct.c:	result = wait_for_completion_killable(&dreq->completion);
fs/nfs/direct.c:		result = dreq->count;
fs/nfs/direct.c:		WARN_ON_ONCE(dreq->count < 0);
fs/nfs/direct.c:		result = dreq->error;
fs/nfs/direct.c:	struct inode *inode = dreq->inode;
fs/nfs/direct.c:	if (dreq->iocb) {
fs/nfs/direct.c:		long res = (long) dreq->error;
fs/nfs/direct.c:		if (dreq->count != 0) {
fs/nfs/direct.c:			res = (long) dreq->count;
fs/nfs/direct.c:			WARN_ON_ONCE(dreq->count < 0);
fs/nfs/direct.c:		dreq->iocb->ki_complete(dreq->iocb, res, 0);
fs/nfs/direct.c:	complete(&dreq->completion);
fs/nfs/direct.c:	spin_lock(&dreq->lock);
fs/nfs/direct.c:		spin_unlock(&dreq->lock);
fs/nfs/direct.c:	spin_unlock(&dreq->lock);
fs/nfs/direct.c:		struct page *page = req->wb_page;
fs/nfs/direct.c:		    (dreq->flags == NFS_ODIRECT_SHOULD_DIRTY))
fs/nfs/direct.c:		bytes += req->wb_bytes;
fs/nfs/direct.c:	struct inode *inode = dreq->inode;
fs/nfs/direct.c:	nfs_pageio_init_read(&desc, dreq->inode, false,
fs/nfs/direct.c:			req = nfs_create_request(dreq->ctx, pagevec[i],
fs/nfs/direct.c:			req->wb_index = pos >> PAGE_SHIFT;
fs/nfs/direct.c:			req->wb_offset = pos & ~PAGE_MASK;
fs/nfs/direct.c:			dreq->bytes_left -= req_len;
fs/nfs/direct.c:	dreq->inode = inode;
fs/nfs/direct.c:	dreq->bytes_left = dreq->max_count = count;
fs/nfs/direct.c:	dreq->io_start = iocb->ki_pos;
fs/nfs/direct.c:	dreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));
fs/nfs/direct.c:	l_ctx = nfs_get_lock_context(dreq->ctx);
fs/nfs/direct.c:	dreq->l_ctx = l_ctx;
fs/nfs/direct.c:		dreq->iocb = iocb;
fs/nfs/direct.c:		dreq->flags = NFS_ODIRECT_SHOULD_DIRTY;
fs/nfs/direct.c:		if (req->wb_head != req || req->wb_this_page == req)
fs/nfs/direct.c:		for (next = req->wb_this_page;
fs/nfs/direct.c:				next != req->wb_head;
fs/nfs/direct.c:	nfs_direct_write_scan_commit_list(dreq->inode, &reqs, &cinfo);
fs/nfs/direct.c:	nfs_direct_join_group(&reqs, dreq->inode);
fs/nfs/direct.c:	dreq->count = 0;
fs/nfs/direct.c:	dreq->max_count = 0;
fs/nfs/direct.c:		dreq->max_count += req->wb_bytes;
fs/nfs/direct.c:	nfs_clear_pnfs_ds_commit_verifiers(&dreq->ds_cinfo);
fs/nfs/direct.c:	nfs_pageio_init_write(&desc, dreq->inode, FLUSH_STABLE, false,
fs/nfs/direct.c:		req->wb_nio++;
fs/nfs/direct.c:			dreq->flags = 0;
fs/nfs/direct.c:				dreq->error = desc.pg_error;
fs/nfs/direct.c:				dreq->error = -EIO;
fs/nfs/direct.c:		dreq->error = status;
fs/nfs/direct.c:		dreq->max_count = 0;
fs/nfs/direct.c:		dreq->count = 0;
fs/nfs/direct.c:		dreq->flags = NFS_ODIRECT_DONE;
fs/nfs/direct.c:	} else if (dreq->flags == NFS_ODIRECT_DONE)
fs/nfs/direct.c:		status = dreq->error;
fs/nfs/direct.c:			dreq->flags = NFS_ODIRECT_RESCHED_WRITES;
fs/nfs/direct.c:			req->wb_nio = 0;
fs/nfs/direct.c:	spin_lock(&dreq->lock);
fs/nfs/direct.c:	if (dreq->flags != NFS_ODIRECT_DONE)
fs/nfs/direct.c:		dreq->flags = NFS_ODIRECT_RESCHED_WRITES;
fs/nfs/direct.c:	spin_unlock(&dreq->lock);
fs/nfs/direct.c:	nfs_scan_commit(dreq->inode, &mds_list, &cinfo);
fs/nfs/direct.c:	res = nfs_generic_commit_list(dreq->inode, &mds_list, 0, &cinfo);
fs/nfs/direct.c:	nfs_direct_write_scan_commit_list(dreq->inode, &reqs, &cinfo);
fs/nfs/direct.c:	int flags = dreq->flags;
fs/nfs/direct.c:	dreq->flags = 0;
fs/nfs/direct.c:			nfs_zap_mapping(dreq->inode, dreq->inode->i_mapping);
fs/nfs/direct.c:	queue_work(nfsiod_workqueue, &dreq->work); /* Calls nfs_direct_write_schedule_work */
fs/nfs/direct.c:	spin_lock(&dreq->lock);
fs/nfs/direct.c:		spin_unlock(&dreq->lock);
fs/nfs/direct.c:		switch (dreq->flags) {
fs/nfs/direct.c:			dreq->flags = NFS_ODIRECT_DO_COMMIT;
fs/nfs/direct.c:	spin_unlock(&dreq->lock);
fs/nfs/direct.c:			kref_get(&req->wb_kref);
fs/nfs/direct.c:			memcpy(&req->wb_verf, &hdr->verf.verifier,
fs/nfs/direct.c:			       sizeof(req->wb_verf));
fs/nfs/direct.c:	spin_lock(&dreq->lock);
fs/nfs/direct.c:	if (dreq->error == 0) {
fs/nfs/direct.c:		dreq->flags = NFS_ODIRECT_RESCHED_WRITES;
fs/nfs/direct.c:	spin_unlock(&dreq->lock);
fs/nfs/direct.c:	struct inode *inode = dreq->inode;
fs/nfs/direct.c:			req = nfs_create_request(dreq->ctx, pagevec[i],
fs/nfs/direct.c:			req->wb_index = pos >> PAGE_SHIFT;
fs/nfs/direct.c:			req->wb_offset = pos & ~PAGE_MASK;
fs/nfs/direct.c:			dreq->bytes_left -= req_len;
fs/nfs/direct.c:	dreq->inode = inode;
fs/nfs/direct.c:	dreq->bytes_left = dreq->max_count = count;
fs/nfs/direct.c:	dreq->io_start = pos;
fs/nfs/direct.c:	dreq->ctx = get_nfs_open_context(nfs_file_open_context(iocb->ki_filp));
fs/nfs/direct.c:	l_ctx = nfs_get_lock_context(dreq->ctx);
fs/nfs/direct.c:	dreq->l_ctx = l_ctx;
fs/nfs/direct.c:		dreq->iocb = iocb;
fs/nfs/direct.c:	pnfs_init_ds_commit_info_ops(&dreq->ds_cinfo, inode);
fs/nfs/nfstrace.h:			__entry->index = req->wb_index;
fs/nfs/nfstrace.h:			__entry->offset = req->wb_offset;
fs/nfs/nfstrace.h:			__entry->pgbase = req->wb_pgbase;
fs/nfs/nfstrace.h:			__entry->bytes = req->wb_bytes;
fs/nfs/internal.h:		!nfs_write_verifier_cmp(&req->wb_verf, &verf->verifier);
fs/nfs/blocklayout/blocklayout.c:	if (!IS_ALIGNED(req->wb_offset, alignment))
fs/nfs/blocklayout/blocklayout.c:	if (IS_ALIGNED(req->wb_bytes, alignment))
fs/nfs/blocklayout/blocklayout.c:	    (req_offset(req) + req->wb_bytes == i_size_read(pgio->pg_inode))) {
fs/nfs/blocklayout/blocklayout.c: * of bytes (maximum @req->wb_bytes) that can be coalesced.
fs/nfs/blocklayout/blocklayout.c:					      req->wb_index);
fs/nfs/blocklayout/blocklayout.c: * of bytes (maximum @req->wb_bytes) that can be coalesced.
fs/nfs/cache_lib.c:	if (refcount_dec_and_test(&dreq->count))
fs/nfs/cache_lib.c:	complete(&dreq->completion);
fs/nfs/cache_lib.c:	dreq->deferred_req.revisit = nfs_dns_cache_revisit;
fs/nfs/cache_lib.c:	refcount_inc(&dreq->count);
fs/nfs/cache_lib.c:	return &dreq->deferred_req;
fs/nfs/cache_lib.c:		init_completion(&dreq->completion);
fs/nfs/cache_lib.c:		refcount_set(&dreq->count, 1);
fs/nfs/cache_lib.c:		dreq->req.defer = nfs_dns_cache_defer;
fs/nfs/cache_lib.c:	if (wait_for_completion_timeout(&dreq->completion,
fs/nfs/pnfs.h:	u64 req_last = req_offset(req) + req->wb_bytes;
fs/nfs/nfs4xdr.c:	req->rq_rcv_buf.flags |= XDRBUF_READ;
fs/nfs/nfs4xdr.c:	req->rq_snd_buf.flags |= XDRBUF_WRITE;
fs/nfs/nfs4xdr.c:	struct xdr_buf *rcvbuf = &req->rq_rcv_buf;
fs/nfs/write.c:	if (!test_and_set_bit(PG_INODE_REF, &req->wb_flags)) {
fs/nfs/write.c:		kref_get(&req->wb_kref);
fs/nfs/write.c:	if (!test_bit(PG_REMOVE, &req->wb_flags))
fs/nfs/write.c:	if (test_and_clear_bit(PG_REMOVE, &req->wb_flags))
fs/nfs/write.c:		WARN_ON_ONCE(req->wb_head != req);
fs/nfs/write.c:		kref_get(&req->wb_kref);
fs/nfs/write.c:			WARN_ON_ONCE(req->wb_head != req);
fs/nfs/write.c:			kref_get(&req->wb_kref);
fs/nfs/write.c:		if (page_offset >= req->wb_pgbase &&
fs/nfs/write.c:		    page_offset < (req->wb_pgbase + req->wb_bytes))
fs/nfs/write.c:		req = req->wb_this_page;
fs/nfs/write.c:	unsigned int len = nfs_page_length(req->wb_page);
fs/nfs/write.c:		tmp = nfs_page_group_search_locked(req->wb_head, pos);
fs/nfs/write.c:	if (PageUptodate(req->wb_page))
fs/nfs/write.c:	SetPageUptodate(req->wb_page);
fs/nfs/write.c:	struct inode *inode = page_file_mapping(req->wb_page)->host;
fs/nfs/write.c:	end_page_writeback(req->wb_page);
fs/nfs/write.c:		destroy_list = (subreq->wb_this_page == old_head) ?
fs/nfs/write.c:				   NULL : subreq->wb_this_page;
fs/nfs/write.c:		/* Note: lock subreq in order to change subreq->wb_head */
fs/nfs/write.c:		WARN_ON_ONCE(old_head != subreq->wb_head);
fs/nfs/write.c:		subreq->wb_this_page = subreq;
fs/nfs/write.c:		subreq->wb_head = subreq;
fs/nfs/write.c:		clear_bit(PG_REMOVE, &subreq->wb_flags);
fs/nfs/write.c:		if (!kref_read(&subreq->wb_kref)) {
fs/nfs/write.c:			if (test_and_clear_bit(PG_TEARDOWN, &subreq->wb_flags)) {
fs/nfs/write.c:		if (test_and_clear_bit(PG_INODE_REF, &subreq->wb_flags)) {
fs/nfs/write.c:			subreq = subreq->wb_this_page) {
fs/nfs/write.c:		if (pgbase > subreq->wb_pgbase) {
fs/nfs/write.c:			off -= pgbase - subreq->wb_pgbase;
fs/nfs/write.c:			bytes += pgbase - subreq->wb_pgbase;
fs/nfs/write.c:			pgbase = subreq->wb_pgbase;
fs/nfs/write.c:		bytes = max(subreq->wb_pgbase + subreq->wb_bytes
fs/nfs/write.c:		subreq = subreq->wb_this_page;
fs/nfs/write.c:	nfs_mapping_set_error(req->wb_page, error);
fs/nfs/write.c:	WARN_ON_ONCE(test_bit(PG_CLEAN, &req->wb_flags));
fs/nfs/write.c:	struct address_space *mapping = page_file_mapping(req->wb_page);
fs/nfs/write.c:	WARN_ON_ONCE(req->wb_this_page != req);
fs/nfs/write.c:	if (likely(!PageSwapCache(req->wb_page))) {
fs/nfs/write.c:		set_bit(PG_MAPPED, &req->wb_flags);
fs/nfs/write.c:		SetPagePrivate(req->wb_page);
fs/nfs/write.c:		set_page_private(req->wb_page, (unsigned long)req);
fs/nfs/write.c:	WARN_ON(test_and_set_bit(PG_INODE_REF, &req->wb_flags));
fs/nfs/write.c:	kref_get(&req->wb_kref);
fs/nfs/write.c:	struct address_space *mapping = page_file_mapping(req->wb_page);
fs/nfs/write.c:		head = req->wb_head;
fs/nfs/write.c:	if (test_and_clear_bit(PG_INODE_REF, &req->wb_flags)) {
fs/nfs/write.c:	if (req->wb_page)
fs/nfs/write.c:		__set_page_dirty_nobuffers(req->wb_page);
fs/nfs/write.c:		return freq->wb_head;
fs/nfs/write.c:		if (freq->wb_page == page)
fs/nfs/write.c:			return freq->wb_head;
fs/nfs/write.c:	set_bit(PG_CLEAN, &req->wb_flags);
fs/nfs/write.c:	if (req->wb_page)
fs/nfs/write.c:		nfs_mark_page_unstable(req->wb_page, cinfo);
fs/nfs/write.c:	if (test_bit(PG_CLEAN, &req->wb_flags)) {
fs/nfs/write.c:		nfs_clear_page_commit(req->wb_page);
fs/nfs/write.c:		bytes += req->wb_bytes;
fs/nfs/write.c:			nfs_mapping_set_error(req->wb_page, hdr->error);
fs/nfs/write.c:			req->wb_nio = 0;
fs/nfs/write.c:			memcpy(&req->wb_verf, &hdr->verf.verifier, sizeof(req->wb_verf));
fs/nfs/write.c:		kref_get(&req->wb_kref);
fs/nfs/write.c:		clear_bit(PG_COMMIT_TO_DS, &req->wb_flags);
fs/nfs/write.c:	rqend = req->wb_offset + req->wb_bytes;
fs/nfs/write.c:	if (offset > rqend || end < req->wb_offset)
fs/nfs/write.c:	if (offset < req->wb_offset) {
fs/nfs/write.c:		req->wb_offset = offset;
fs/nfs/write.c:		req->wb_pgbase = offset;
fs/nfs/write.c:		req->wb_bytes = end - req->wb_offset;
fs/nfs/write.c:		req->wb_bytes = rqend - req->wb_offset;
fs/nfs/write.c:	req->wb_nio = 0;
fs/nfs/write.c:		l_ctx = req->wb_lock_context;
fs/nfs/write.c:		do_flush = req->wb_page != page ||
fs/nfs/write.c:	req->wb_nio++;
fs/nfs/write.c:		if (lwb < (req_offset(req) + req->wb_bytes))
fs/nfs/write.c:			lwb = req_offset(req) + req->wb_bytes;
fs/nfs/write.c:			nfs_clear_page_commit(req->wb_page);
fs/nfs/write.c:	__set_page_dirty_nobuffers(req->wb_page);
fs/nfs/write.c:		if (req->wb_page)
fs/nfs/write.c:			nfs_clear_page_commit(req->wb_page);
fs/nfs/write.c:			req->wb_bytes,
fs/nfs/write.c:			if (req->wb_page) {
fs/nfs/write.c:				nfs_mapping_set_error(req->wb_page, status);
fs/nfs/write.c:			if (req->wb_page)
fs/nfs/read.c:	struct page *page = req->wb_page;
fs/nfs/read.c:		(unsigned long long)NFS_FILEID(inode), req->wb_bytes,
fs/nfs/read.c:		SetPageUptodate(req->wb_page);
fs/nfs/read.c:		struct page *page = req->wb_page;
fs/nfs/read.c:		unsigned long start = req->wb_pgbase;
fs/nfs/read.c:		unsigned long end = req->wb_pgbase + req->wb_bytes;
fs/nfs/read.c:			} else if (hdr->good_bytes - bytes < req->wb_bytes) {
fs/nfs/read.c:				WARN_ON(start < req->wb_pgbase);
fs/nfs/read.c:		bytes += req->wb_bytes;
fs/nfs/callback.c:			list_del(&req->rq_bc_list);
fs/nfs/pnfs_nfs.c:	if (!test_and_clear_bit(PG_COMMIT_TO_DS, &req->wb_flags))
fs/nfs/pnfs_nfs.c:	if (list_is_singular(&req->wb_list))
fs/nfs/pnfs_nfs.c:		bucket = list_first_entry(&req->wb_list,
fs/nfs/pnfs_nfs.c:			if (req->wb_page == page)
fs/nfs/pnfs_nfs.c:				return req->wb_head;
fs/nfs/pnfs_nfs.c:			if (req->wb_page == page)
fs/nfs/pnfs_nfs.c:				return req->wb_head;
fs/nfs/pnfs_nfs.c:	set_bit(PG_COMMIT_TO_DS, &req->wb_flags);
fs/nfs/pnfs_nfs.c:	nfs_mark_page_unstable(req->wb_page, cinfo);
fs/nfs/nfs3xdr.c:	req->rq_rcv_buf.flags |= XDRBUF_READ;
fs/nfs/nfs3xdr.c:		req->rq_rcv_buf.flags |= XDRBUF_SPARSE_PAGES;
fs/nfs/nfs3xdr.c:	base = req->rq_slen;
fs/nfs/dns_resolve.c:		ret = cache_check(cd, &(*item)->h, &dreq->req);
fs/nfs/pnfs.c:	u64 rd_size = req->wb_bytes;
fs/nfs/pnfs.c: * of bytes (maximum @req->wb_bytes) that can be coalesced.
fs/nfs/pnfs.c:	 * to the original size asked for in @req->wb_bytes).
fs/ocfs2/ioctl.c:	kreq->ir_flags |= OCFS2_INFO_FL_ERROR;
fs/ocfs2/ioctl.c:	(void)put_user(kreq->ir_flags, (__u32 __user *)&(req->ir_flags));
fs/ocfs2/ioctl.c:	req->ir_flags |= OCFS2_INFO_FL_FILLED;
fs/ocfs2/ioctl.c:	req->ir_flags &= ~OCFS2_INFO_FL_FILLED;
fs/ocfs2/ioctl.c:	return (!(req->ir_flags & OCFS2_INFO_FL_NON_COHERENT));
fs/ocfs2/dlm/dlmrecovery.c:	hash = dlm_lockid_hash(req->name, req->namelen);
fs/ocfs2/dlm/dlmrecovery.c:	res = __dlm_lookup_lockres(dlm, req->name, req->namelen, hash);
fs/ocfs2/cluster/tcp.c:	o2net_keep_req->magic = cpu_to_be16(O2NET_MSG_KEEP_REQ_MAGIC);
fs/ecryptfs/kthread.c:			list_del(&req->kthread_ctl_list);
fs/ecryptfs/kthread.c:			*req->lower_file = dentry_open(&req->path,
fs/ecryptfs/kthread.c:			complete(&req->done);
fs/ecryptfs/kthread.c:		list_del(&req->kthread_ctl_list);
fs/ecryptfs/kthread.c:		*req->lower_file = ERR_PTR(-EIO);
fs/ecryptfs/kthread.c:		complete(&req->done);
fs/ecryptfs/crypto.c:	struct extent_crypt_result *ecr = req->data;
fs/ecryptfs/crypto.c:		struct extent_crypt_result *ecr = req->base.data;
fs/nfsd/blocklayout.c:	req->cmd[0] = INQUIRY;
fs/nfsd/blocklayout.c:	req->cmd[1] = 1;
fs/nfsd/blocklayout.c:	req->cmd[2] = 0x83;
fs/nfsd/blocklayout.c:	req->cmd[3] = bufflen >> 8;
fs/nfsd/blocklayout.c:	req->cmd[4] = bufflen & 0xff;
fs/nfsd/blocklayout.c:	req->cmd_len = COMMAND_SIZE(INQUIRY);
fs/nfsd/blocklayout.c:	if (req->result) {
fs/nfsd/blocklayout.c:			req->result);
fs/aio.c:	struct kioctx *ctx = req->ki_ctx;
fs/aio.c:	if (WARN_ON_ONCE(!list_empty(&req->ki_list)))
fs/aio.c:	list_add_tail(&req->ki_list, &ctx->active_reqs);
fs/aio.c:	req->ki_cancel = cancel;
fs/aio.c:		req->ki_cancel(&req->rw);
fs/aio.c:		list_del_init(&req->ki_list);
fs/aio.c:	req->ki_ctx = ctx;
fs/aio.c:	INIT_LIST_HEAD(&req->ki_list);
fs/aio.c:	refcount_set(&req->ki_refcnt, 2);
fs/aio.c:	req->ki_eventfd = NULL;
fs/aio.c:	req->ki_complete = aio_complete_rw;
fs/aio.c:	req->private = NULL;
fs/aio.c:	req->ki_pos = iocb->aio_offset;
fs/aio.c:	req->ki_flags = iocb_flags(req->ki_filp);
fs/aio.c:		req->ki_flags |= IOCB_EVENTFD;
fs/aio.c:	req->ki_hint = ki_hint_validate(file_write_hint(req->ki_filp));
fs/aio.c:		req->ki_ioprio = iocb->aio_reqprio;
fs/aio.c:		req->ki_ioprio = get_current_ioprio();
fs/aio.c:	req->ki_flags &= ~IOCB_HIPRI; /* no one is going to poll for this I/O */
fs/aio.c:		req->ki_complete(req, ret, 0);
fs/aio.c:	file = req->ki_filp;
fs/aio.c:	ret = rw_verify_area(READ, file, &req->ki_pos, iov_iter_count(&iter));
fs/aio.c:	file = req->ki_filp;
fs/aio.c:	ret = rw_verify_area(WRITE, file, &req->ki_pos, iov_iter_count(&iter));
fs/aio.c:		req->ki_flags |= IOCB_WRITE;
fs/aio.c:	if (unlikely(!req->file->f_op->fsync))
fs/aio.c:	req->creds = prepare_creds();
fs/aio.c:	if (!req->creds)
fs/aio.c:	req->datasync = datasync;
fs/aio.c:	INIT_WORK(&req->work, aio_fsync_work);
fs/aio.c:	schedule_work(&req->work);
fs/aio.c:	struct poll_table_struct pt = { ._key = req->events };
fs/aio.c:	if (!READ_ONCE(req->cancelled))
fs/aio.c:		mask = vfs_poll(req->file, &pt) & req->events;
fs/aio.c:	if (!mask && !READ_ONCE(req->cancelled)) {
fs/aio.c:		add_wait_queue(req->head, &req->wait);
fs/aio.c:	req->done = true;
fs/aio.c:	spin_lock(&req->head->lock);
fs/aio.c:	WRITE_ONCE(req->cancelled, true);
fs/aio.c:	if (!list_empty(&req->wait.entry)) {
fs/aio.c:		list_del_init(&req->wait.entry);
fs/aio.c:	spin_unlock(&req->head->lock);
fs/aio.c:	if (mask && !(mask & req->events))
fs/aio.c:	list_del_init(&req->wait.entry);
fs/aio.c:		req->done = true;
fs/aio.c:			INIT_WORK(&req->work, aio_poll_put_work);
fs/aio.c:			schedule_work(&req->work);
fs/aio.c:		schedule_work(&req->work);
fs/aio.c:	INIT_WORK(&req->work, aio_poll_complete_work);
fs/aio.c:	req->events = demangle_poll(iocb->aio_buf) | EPOLLERR | EPOLLHUP;
fs/aio.c:	req->head = NULL;
fs/aio.c:	req->done = false;
fs/aio.c:	req->cancelled = false;
fs/aio.c:	apt.pt._key = req->events;
fs/aio.c:	INIT_LIST_HEAD(&req->wait.entry);
fs/aio.c:	init_waitqueue_func_entry(&req->wait, aio_poll_wake);
fs/aio.c:	mask = vfs_poll(req->file, &apt.pt) & req->events;
fs/aio.c:	if (likely(req->head)) {
fs/aio.c:		spin_lock(&req->head->lock);
fs/aio.c:		if (unlikely(list_empty(&req->wait.entry))) {
fs/aio.c:			list_del_init(&req->wait.entry);
fs/aio.c:			WRITE_ONCE(req->cancelled, true);
fs/aio.c:		} else if (!req->done) { /* actually waiting for an event */
fs/aio.c:		spin_unlock(&req->head->lock);
fs/aio.c:	req->ki_filp = fget(iocb->aio_fildes);
fs/aio.c:	if (unlikely(!req->ki_filp))
fs/aio.c:		req->ki_eventfd = eventfd;
fs/aio.c:	req->ki_res.obj = (u64)(unsigned long)user_iocb;
fs/aio.c:	req->ki_res.data = iocb->aio_data;
fs/aio.c:	req->ki_res.res = 0;
fs/aio.c:	req->ki_res.res2 = 0;
fs/aio.c:		return aio_read(&req->rw, iocb, false, compat);
fs/aio.c:		return aio_write(&req->rw, iocb, false, compat);
fs/aio.c:		return aio_read(&req->rw, iocb, true, compat);
fs/aio.c:		return aio_write(&req->rw, iocb, true, compat);
fs/aio.c:		return aio_fsync(&req->fsync, iocb, false);
fs/aio.c:		return aio_fsync(&req->fsync, iocb, true);
fs/dlm/user.c:	if (req->version[0] != DLM_DEVICE_VERSION_MAJOR ||
fs/dlm/user.c:	    (req->version[0] == DLM_DEVICE_VERSION_MAJOR &&
fs/dlm/user.c:	     req->version[1] > DLM_DEVICE_VERSION_MINOR)) {
fs/dlm/user.c:		       req->version[0],
fs/dlm/user.c:		       req->version[1],
fs/dlm/user.c:		       req->version[2],
fs/io_uring.c:	/* needs req->file assigned */
fs/io_uring.c:	if (req->flags & (REQ_F_NEED_CLEANUP | REQ_F_BUFFER_SELECTED))
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!req->fixed_rsrc_refs) {
fs/io_uring.c:		req->fixed_rsrc_refs = &ctx->file_data->node->refs;
fs/io_uring.c:		percpu_ref_get(req->fixed_rsrc_refs);
fs/io_uring.c:		if (req->flags & REQ_F_INFLIGHT)
fs/io_uring.c:	if ((req->flags & (REQ_F_LINK | REQ_F_HARDLINK)) == REQ_F_LINK)
fs/io_uring.c:		req->flags |= REQ_F_FAIL_LINK;
fs/io_uring.c:	return !req->timeout.off;
fs/io_uring.c:	if (unlikely(req->flags & REQ_F_IO_DRAIN)) {
fs/io_uring.c:		struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!(req->flags & REQ_F_INFLIGHT)) {
fs/io_uring.c:		req->flags |= REQ_F_INFLIGHT;
fs/io_uring.c:		list_add(&req->inflight_entry, &ctx->inflight_list);
fs/io_uring.c:	const struct io_op_def *def = &io_op_defs[req->opcode];
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!req->work.creds)
fs/io_uring.c:		req->work.creds = get_current_cred();
fs/io_uring.c:	if (req->flags & REQ_F_FORCE_ASYNC)
fs/io_uring.c:		req->work.flags |= IO_WQ_WORK_CONCURRENT;
fs/io_uring.c:	if (req->flags & REQ_F_ISREG) {
fs/io_uring.c:			io_wq_hash_work(&req->work, file_inode(req->file));
fs/io_uring.c:	} else if (!req->file || !S_ISBLK(file_inode(req->file)->i_mode)) {
fs/io_uring.c:			req->work.flags |= IO_WQ_WORK_UNBOUND;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_uring_task *tctx = req->task->io_uring;
fs/io_uring.c:	trace_io_uring_queue_async_work(ctx, io_wq_is_hashed(&req->work), req,
fs/io_uring.c:					&req->work, req->flags);
fs/io_uring.c:	io_wq_enqueue(tctx->io_wq, &req->work);
fs/io_uring.c:	struct io_timeout_data *io = req->async_data;
fs/io_uring.c:		atomic_set(&req->ctx->cq_timeouts,
fs/io_uring.c:			atomic_read(&req->ctx->cq_timeouts) + 1);
fs/io_uring.c:		list_del_init(&req->timeout.list);
fs/io_uring.c:		events_needed = req->timeout.target_seq - ctx->cq_last_tm_flush;
fs/io_uring.c:		list_del_init(&req->timeout.list);
fs/io_uring.c:		list_move(&req->compl.list, &list);
fs/io_uring.c:			WRITE_ONCE(cqe->user_data, req->user_data);
fs/io_uring.c:			WRITE_ONCE(cqe->res, req->result);
fs/io_uring.c:			WRITE_ONCE(cqe->flags, req->compl.cflags);
fs/io_uring.c:		list_del(&req->compl.list);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	trace_io_uring_complete(ctx, req->user_data, res);
fs/io_uring.c:		WRITE_ONCE(cqe->user_data, req->user_data);
fs/io_uring.c:		   atomic_read(&req->task->io_uring->in_idle)) {
fs/io_uring.c:		req->result = res;
fs/io_uring.c:		req->compl.cflags = cflags;
fs/io_uring.c:		refcount_inc(&req->refs);
fs/io_uring.c:		list_add_tail(&req->compl.list, &ctx->cq_overflow_list);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (refcount_dec_and_test(&req->refs)) {
fs/io_uring.c:		if (req->flags & (REQ_F_LINK | REQ_F_HARDLINK)) {
fs/io_uring.c:			if (req->flags & (REQ_F_LINK_TIMEOUT | REQ_F_FAIL_LINK))
fs/io_uring.c:			if (req->link) {
fs/io_uring.c:				io_req_task_queue(req->link);
fs/io_uring.c:				req->link = NULL;
fs/io_uring.c:		io_put_task(req->task, 1);
fs/io_uring.c:		list_add(&req->compl.list, &cs->locked_free_list);
fs/io_uring.c:	req->result = res;
fs/io_uring.c:	req->compl.cflags = cflags;
fs/io_uring.c:	req->flags |= REQ_F_COMPLETE_INLINE;
fs/io_uring.c:		list_del(&req->compl.list);
fs/io_uring.c:	if (req->async_data)
fs/io_uring.c:		kfree(req->async_data);
fs/io_uring.c:	if (req->file)
fs/io_uring.c:		io_put_file(req, req->file, (req->flags & REQ_F_FIXED_FILE));
fs/io_uring.c:	if (req->fixed_rsrc_refs)
fs/io_uring.c:		percpu_ref_put(req->fixed_rsrc_refs);
fs/io_uring.c:	if (req->work.creds) {
fs/io_uring.c:		put_cred(req->work.creds);
fs/io_uring.c:		req->work.creds = NULL;
fs/io_uring.c:	if (req->flags & REQ_F_INFLIGHT) {
fs/io_uring.c:		struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:		list_del(&req->inflight_entry);
fs/io_uring.c:		req->flags &= ~REQ_F_INFLIGHT;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	io_put_task(req->task, 1);
fs/io_uring.c:	struct io_kiocb *nxt = req->link;
fs/io_uring.c:	req->link = nxt->link;
fs/io_uring.c:	__must_hold(&req->ctx->completion_lock)
fs/io_uring.c:	struct io_kiocb *link = req->link;
fs/io_uring.c:	req->flags &= ~REQ_F_LINK_TIMEOUT;
fs/io_uring.c:	__must_hold(&req->ctx->completion_lock)
fs/io_uring.c:	struct io_kiocb *nxt, *link = req->link;
fs/io_uring.c:	req->link = NULL;
fs/io_uring.c:	__must_hold(&req->ctx->completion_lock)
fs/io_uring.c:	if (likely(req->flags & REQ_F_LINK_TIMEOUT))
fs/io_uring.c:	if (unlikely(req->flags & REQ_F_FAIL_LINK)) {
fs/io_uring.c:		posted |= (req->link != NULL);
fs/io_uring.c:	if (req->flags & (REQ_F_LINK_TIMEOUT | REQ_F_FAIL_LINK)) {
fs/io_uring.c:		struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:			io_commit_cqring(req->ctx);
fs/io_uring.c:	nxt = req->link;
fs/io_uring.c:	req->link = NULL;
fs/io_uring.c:	if (likely(!(req->flags & (REQ_F_LINK|REQ_F_HARDLINK))))
fs/io_uring.c:		if (req->ctx != ctx) {
fs/io_uring.c:			ctx = req->ctx;
fs/io_uring.c:		req->task_work.func(&req->task_work);
fs/io_uring.c:	wq_list_add_tail(&req->io_task_work.node, &tctx->task_list);
fs/io_uring.c:		if (&req->io_task_work.node == node) {
fs/io_uring.c:	struct task_struct *tsk = req->task;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	init_task_work(&req->task_work, cb);
fs/io_uring.c:	io_task_work_add_head(&req->ctx->exit_task_work, &req->task_work);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	__io_req_task_cancel(req, req->result);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	req->task_work.func = io_req_task_submit;
fs/io_uring.c:		req->result = -ECANCELED;
fs/io_uring.c:		percpu_ref_get(&req->ctx->refs);
fs/io_uring.c:	percpu_ref_get(&req->ctx->refs);
fs/io_uring.c:	req->result = ret;
fs/io_uring.c:	req->task_work.func = io_req_task_cancel;
fs/io_uring.c:	if (req->task != rb->task) {
fs/io_uring.c:		rb->task = req->task;
fs/io_uring.c:		list_add(&req->compl.list, &state->comp.free_list);
fs/io_uring.c:		__io_cqring_fill_event(req, req->result, req->compl.cflags);
fs/io_uring.c:		if (refcount_sub_and_test(2, &req->refs))
fs/io_uring.c:	if (refcount_dec_and_test(&req->refs)) {
fs/io_uring.c:	if (refcount_dec_and_test(&req->refs))
fs/io_uring.c:	req->task_work.func = io_put_req_deferred_cb;
fs/io_uring.c:	if (refcount_sub_and_test(refs, &req->refs))
fs/io_uring.c:	if (refcount_sub_and_test(2, &req->refs))
fs/io_uring.c:	req->flags &= ~REQ_F_BUFFER_SELECTED;
fs/io_uring.c:	kbuf = (struct io_buffer *) (unsigned long) req->rw.addr;
fs/io_uring.c:		list_del(&req->inflight_entry);
fs/io_uring.c:		if (READ_ONCE(req->result) == -EAGAIN) {
fs/io_uring.c:			req->iopoll_completed = 0;
fs/io_uring.c:		if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:		__io_cqring_fill_event(req, req->result, cflags);
fs/io_uring.c:		if (refcount_dec_and_test(&req->refs))
fs/io_uring.c:		struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:		if (READ_ONCE(req->iopoll_completed)) {
fs/io_uring.c:			list_move_tail(&req->inflight_entry, &done);
fs/io_uring.c:		if (READ_ONCE(req->iopoll_completed))
fs/io_uring.c:			list_move_tail(&req->inflight_entry, &done);
fs/io_uring.c:	if (req->flags & REQ_F_ISREG) {
fs/io_uring.c:		struct inode *inode = file_inode(req->file);
fs/io_uring.c:	file_end_write(req->file);
fs/io_uring.c:	if (req->async_data)
fs/io_uring.c:	switch (req->opcode) {
fs/io_uring.c:				req->opcode);
fs/io_uring.c:	umode_t mode = file_inode(req->file)->i_mode;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if ((req->flags & REQ_F_NOWAIT) || (io_wq_current_is_worker() &&
fs/io_uring.c:	lockdep_assert_held(&req->ctx->uring_lock);
fs/io_uring.c:		refcount_inc(&req->refs);
fs/io_uring.c:	if (req->rw.kiocb.ki_flags & IOCB_WRITE)
fs/io_uring.c:		req->flags |= REQ_F_REISSUE;
fs/io_uring.c:	if (res != req->result)
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:		struct io_async_rw *rw = req->async_data;
fs/io_uring.c:					req->result - iov_iter_count(&rw->iter));
fs/io_uring.c:	if (res != -EAGAIN && res != req->result)
fs/io_uring.c:	WRITE_ONCE(req->result, res);
fs/io_uring.c:	WRITE_ONCE(req->iopoll_completed, 1);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:		if (list_req->file != req->file)
fs/io_uring.c:	if (READ_ONCE(req->iopoll_completed))
fs/io_uring.c:		list_add(&req->inflight_entry, &ctx->iopoll_list);
fs/io_uring.c:		list_add_tail(&req->inflight_entry, &ctx->iopoll_list);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:	struct file *file = req->file;
fs/io_uring.c:		req->flags |= REQ_F_ISREG;
fs/io_uring.c:		req->flags |= REQ_F_CUR_POS;
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:		req->iopoll_completed = 0;
fs/io_uring.c:	req->rw.addr = READ_ONCE(sqe->addr);
fs/io_uring.c:	req->rw.len = READ_ONCE(sqe->len);
fs/io_uring.c:	req->buf_index = READ_ONCE(sqe->buf_index);
fs/io_uring.c:	struct io_async_rw *io = req->async_data;
fs/io_uring.c:	if (req->flags & REQ_F_CUR_POS)
fs/io_uring.c:		req->file->f_pos = kiocb->ki_pos;
fs/io_uring.c:	if (check_reissue && req->flags & REQ_F_REISSUE) {
fs/io_uring.c:		req->flags &= ~REQ_F_REISSUE;
fs/io_uring.c:			if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	size_t len = req->rw.len;
fs/io_uring.c:	u16 index, buf_index = req->buf_index;
fs/io_uring.c:	buf_addr = req->rw.addr;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:	io_ring_submit_lock(req->ctx, needs_lock);
fs/io_uring.c:	lockdep_assert_held(&req->ctx->uring_lock);
fs/io_uring.c:	head = xa_load(&req->ctx->io_buffers, bgid);
fs/io_uring.c:			xa_erase(&req->ctx->io_buffers, bgid);
fs/io_uring.c:	io_ring_submit_unlock(req->ctx, needs_lock);
fs/io_uring.c:	kbuf = (struct io_buffer *) (unsigned long) req->rw.addr;
fs/io_uring.c:	bgid = req->buf_index;
fs/io_uring.c:	req->rw.addr = (u64) (unsigned long) kbuf;
fs/io_uring.c:	req->flags |= REQ_F_BUFFER_SELECTED;
fs/io_uring.c:	uiov = u64_to_user_ptr(req->rw.addr);
fs/io_uring.c:	struct iovec __user *uiov = u64_to_user_ptr(req->rw.addr);
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED) {
fs/io_uring.c:		kbuf = (struct io_buffer *) (unsigned long) req->rw.addr;
fs/io_uring.c:	if (req->rw.len != 1)
fs/io_uring.c:	if (req->ctx->compat)
fs/io_uring.c:	void __user *buf = u64_to_user_ptr(req->rw.addr);
fs/io_uring.c:	size_t sqe_len = req->rw.len;
fs/io_uring.c:	u8 opcode = req->opcode;
fs/io_uring.c:	if (req->buf_index && !(req->flags & REQ_F_BUFFER_SELECT))
fs/io_uring.c:		if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:			req->rw.len = sqe_len;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:			      req->ctx->compat);
fs/io_uring.c:	struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:	struct file *file = req->file;
fs/io_uring.c:			iovec.iov_base = u64_to_user_ptr(req->rw.addr);
fs/io_uring.c:			iovec.iov_len = req->rw.len;
fs/io_uring.c:		req->rw.len -= nr;
fs/io_uring.c:		req->rw.addr += nr;
fs/io_uring.c:	struct io_async_rw *rw = req->async_data;
fs/io_uring.c:		req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	WARN_ON_ONCE(!io_op_defs[req->opcode].async_size);
fs/io_uring.c:	req->async_data = kmalloc(io_op_defs[req->opcode].async_size, GFP_KERNEL);
fs/io_uring.c:	return req->async_data == NULL;
fs/io_uring.c:	if (!io_op_defs[req->opcode].needs_async_data)
fs/io_uring.c:	if (!force && !io_op_defs[req->opcode].needs_async_data)
fs/io_uring.c:	if (!req->async_data) {
fs/io_uring.c:	struct io_async_rw *iorw = req->async_data;
fs/io_uring.c:		req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	if (unlikely(!(req->file->f_mode & FMODE_READ)))
fs/io_uring.c:	req->rw.kiocb.ki_flags &= ~IOCB_WAITQ;
fs/io_uring.c:	refcount_inc(&req->refs);
fs/io_uring.c:	struct io_async_rw *rw = req->async_data;
fs/io_uring.c:	struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:	if (req->flags & REQ_F_NOWAIT)
fs/io_uring.c:	if (file_can_poll(req->file) || !(req->file->f_mode & FMODE_BUF_RASYNC))
fs/io_uring.c:	if (req->file->f_op->read_iter)
fs/io_uring.c:		return call_read_iter(req->file, &req->rw.kiocb, iter);
fs/io_uring.c:	else if (req->file->f_op->read)
fs/io_uring.c:	struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:	struct io_async_rw *rw = req->async_data;
fs/io_uring.c:	req->result = io_size;
fs/io_uring.c:	if (force_nonblock && !io_file_supports_async(req->file, READ)) {
fs/io_uring.c:	ret = rw_verify_area(READ, req->file, io_kiocb_ppos(kiocb), io_size);
fs/io_uring.c:	if (ret == -EAGAIN || (req->flags & REQ_F_REISSUE)) {
fs/io_uring.c:		req->flags &= ~REQ_F_REISSUE;
fs/io_uring.c:		if (!force_nonblock && !(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:		if (req->flags & REQ_F_NOWAIT)
fs/io_uring.c:		   (req->flags & REQ_F_NOWAIT) || !(req->flags & REQ_F_ISREG)) {
fs/io_uring.c:	rw = req->async_data;
fs/io_uring.c:	if (unlikely(!(req->file->f_mode & FMODE_WRITE)))
fs/io_uring.c:	struct kiocb *kiocb = &req->rw.kiocb;
fs/io_uring.c:	struct io_async_rw *rw = req->async_data;
fs/io_uring.c:	req->result = io_size;
fs/io_uring.c:	if (force_nonblock && !io_file_supports_async(req->file, WRITE))
fs/io_uring.c:	    (req->flags & REQ_F_ISREG))
fs/io_uring.c:	ret = rw_verify_area(WRITE, req->file, io_kiocb_ppos(kiocb), io_size);
fs/io_uring.c:	if (req->flags & REQ_F_ISREG) {
fs/io_uring.c:		sb_start_write(file_inode(req->file)->i_sb);
fs/io_uring.c:		__sb_writers_release(file_inode(req->file)->i_sb,
fs/io_uring.c:	if (req->file->f_op->write_iter)
fs/io_uring.c:		ret2 = call_write_iter(req->file, kiocb, iter);
fs/io_uring.c:	else if (req->file->f_op->write)
fs/io_uring.c:	if (req->flags & REQ_F_REISSUE) {
fs/io_uring.c:		req->flags &= ~REQ_F_REISSUE;
fs/io_uring.c:	if (ret2 == -EAGAIN && (req->flags & REQ_F_NOWAIT))
fs/io_uring.c:		if ((req->ctx->flags & IORING_SETUP_IOPOLL) && ret2 == -EAGAIN)
fs/io_uring.c:	struct io_rename *ren = &req->rename;
fs/io_uring.c:	if (unlikely(req->flags & REQ_F_FIXED_FILE))
fs/io_uring.c:	req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_rename *ren = &req->rename;
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_unlink *un = &req->unlink;
fs/io_uring.c:	if (unlikely(req->flags & REQ_F_FIXED_FILE))
fs/io_uring.c:	req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_unlink *un = &req->unlink;
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->shutdown.how = READ_ONCE(sqe->len);
fs/io_uring.c:	sock = sock_from_file(req->file);
fs/io_uring.c:	ret = __sys_shutdown_sock(sock, req->shutdown.how);
fs/io_uring.c:	struct io_splice* sp = &req->splice;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:		req->work.flags |= IO_WQ_WORK_UNBOUND;
fs/io_uring.c:	struct io_splice *sp = &req->splice;
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_splice* sp = &req->splice;
fs/io_uring.c:	struct io_splice *sp = &req->splice;
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!req->file)
fs/io_uring.c:	req->sync.flags = READ_ONCE(sqe->fsync_flags);
fs/io_uring.c:	if (unlikely(req->sync.flags & ~IORING_FSYNC_DATASYNC))
fs/io_uring.c:	req->sync.off = READ_ONCE(sqe->off);
fs/io_uring.c:	req->sync.len = READ_ONCE(sqe->len);
fs/io_uring.c:	loff_t end = req->sync.off + req->sync.len;
fs/io_uring.c:	ret = vfs_fsync_range(req->file, req->sync.off,
fs/io_uring.c:				req->sync.flags & IORING_FSYNC_DATASYNC);
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->sync.off = READ_ONCE(sqe->off);
fs/io_uring.c:	req->sync.len = READ_ONCE(sqe->addr);
fs/io_uring.c:	req->sync.mode = READ_ONCE(sqe->len);
fs/io_uring.c:	ret = vfs_fallocate(req->file, req->sync.mode, req->sync.off,
fs/io_uring.c:				req->sync.len);
fs/io_uring.c:	if (unlikely(req->flags & REQ_F_FIXED_FILE))
fs/io_uring.c:	if (!(req->open.how.flags & O_PATH) && force_o_largefile())
fs/io_uring.c:		req->open.how.flags |= O_LARGEFILE;
fs/io_uring.c:	req->open.dfd = READ_ONCE(sqe->fd);
fs/io_uring.c:	req->open.filename = getname(fname);
fs/io_uring.c:	if (IS_ERR(req->open.filename)) {
fs/io_uring.c:		ret = PTR_ERR(req->open.filename);
fs/io_uring.c:		req->open.filename = NULL;
fs/io_uring.c:	req->open.nofile = rlimit(RLIMIT_NOFILE);
fs/io_uring.c:	req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->open.how = build_open_how(flags, mode);
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	ret = copy_struct_from_user(&req->open.how, sizeof(req->open.how), how,
fs/io_uring.c:	ret = build_open_flags(&req->open.how, &op);
fs/io_uring.c:	resolve_nonblock = req->open.how.resolve & RESOLVE_CACHED;
fs/io_uring.c:		if (req->open.how.flags & (O_TRUNC | O_CREAT | O_TMPFILE))
fs/io_uring.c:	ret = __get_unused_fd_flags(req->open.how.flags, req->open.nofile);
fs/io_uring.c:	file = do_filp_open(req->open.dfd, req->open.filename, &op);
fs/io_uring.c:	putname(req->open.filename);
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_provide_buf *p = &req->pbuf;
fs/io_uring.c:	struct io_provide_buf *p = &req->pbuf;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_provide_buf *p = &req->pbuf;
fs/io_uring.c:	struct io_provide_buf *p = &req->pbuf;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (unlikely(req->ctx->flags & (IORING_SETUP_IOPOLL | IORING_SETUP_SQPOLL)))
fs/io_uring.c:	req->epoll.epfd = READ_ONCE(sqe->fd);
fs/io_uring.c:	req->epoll.op = READ_ONCE(sqe->len);
fs/io_uring.c:	req->epoll.fd = READ_ONCE(sqe->off);
fs/io_uring.c:	if (ep_op_has_event(req->epoll.op)) {
fs/io_uring.c:		if (copy_from_user(&req->epoll.event, ev, sizeof(*ev)))
fs/io_uring.c:	struct io_epoll *ie = &req->epoll;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->madvise.addr = READ_ONCE(sqe->addr);
fs/io_uring.c:	req->madvise.len = READ_ONCE(sqe->len);
fs/io_uring.c:	req->madvise.advice = READ_ONCE(sqe->fadvise_advice);
fs/io_uring.c:	struct io_madvise *ma = &req->madvise;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->fadvise.offset = READ_ONCE(sqe->off);
fs/io_uring.c:	req->fadvise.len = READ_ONCE(sqe->len);
fs/io_uring.c:	req->fadvise.advice = READ_ONCE(sqe->fadvise_advice);
fs/io_uring.c:	struct io_fadvise *fa = &req->fadvise;
fs/io_uring.c:	ret = vfs_fadvise(req->file, fa->offset, fa->len, fa->advice);
fs/io_uring.c:	if (unlikely(req->ctx->flags & (IORING_SETUP_IOPOLL | IORING_SETUP_SQPOLL)))
fs/io_uring.c:	if (req->flags & REQ_F_FIXED_FILE)
fs/io_uring.c:	req->statx.dfd = READ_ONCE(sqe->fd);
fs/io_uring.c:	req->statx.mask = READ_ONCE(sqe->len);
fs/io_uring.c:	req->statx.filename = u64_to_user_ptr(READ_ONCE(sqe->addr));
fs/io_uring.c:	req->statx.buffer = u64_to_user_ptr(READ_ONCE(sqe->addr2));
fs/io_uring.c:	req->statx.flags = READ_ONCE(sqe->statx_flags);
fs/io_uring.c:	struct io_statx *ctx = &req->statx;
fs/io_uring.c:			req->flags |= REQ_F_NO_FILE_TABLE;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (req->flags & REQ_F_FIXED_FILE)
fs/io_uring.c:	req->close.fd = READ_ONCE(sqe->fd);
fs/io_uring.c:	struct io_close *close = &req->close;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	req->sync.off = READ_ONCE(sqe->off);
fs/io_uring.c:	req->sync.len = READ_ONCE(sqe->len);
fs/io_uring.c:	req->sync.flags = READ_ONCE(sqe->sync_range_flags);
fs/io_uring.c:	ret = sync_file_range(req->file, req->sync.off, req->sync.len,
fs/io_uring.c:				req->sync.flags);
fs/io_uring.c:	struct io_async_msghdr *async_msg = req->async_data;
fs/io_uring.c:	async_msg = req->async_data;
fs/io_uring.c:	req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	return sendmsg_copy_msghdr(&iomsg->msg, req->sr_msg.umsg,
fs/io_uring.c:				   req->sr_msg.msg_flags, &iomsg->free_iov);
fs/io_uring.c:	if (!io_op_defs[req->opcode].needs_async_data)
fs/io_uring.c:	ret = io_sendmsg_copy_hdr(req, req->async_data);
fs/io_uring.c:		req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (req->ctx->compat)
fs/io_uring.c:	sock = sock_from_file(req->file);
fs/io_uring.c:	kmsg = req->async_data;
fs/io_uring.c:	flags = req->sr_msg.msg_flags | MSG_NOSIGNAL;
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	sock = sock_from_file(req->file);
fs/io_uring.c:	flags = req->sr_msg.msg_flags | MSG_NOSIGNAL;
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:	if (req->ctx->compat)
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	req->flags |= REQ_F_BUFFER_SELECTED;
fs/io_uring.c:	return io_put_kbuf(req, req->sr_msg.kbuf);
fs/io_uring.c:	if (!io_op_defs[req->opcode].needs_async_data)
fs/io_uring.c:	ret = io_recvmsg_copy_hdr(req, req->async_data);
fs/io_uring.c:		req->flags |= REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (req->ctx->compat)
fs/io_uring.c:	sock = sock_from_file(req->file);
fs/io_uring.c:	kmsg = req->async_data;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:		kmsg->fast_iov[0].iov_len = req->sr_msg.len;
fs/io_uring.c:				1, req->sr_msg.len);
fs/io_uring.c:	flags = req->sr_msg.msg_flags | MSG_NOSIGNAL;
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:	ret = __sys_recvmsg_sock(sock, &kmsg->msg, req->sr_msg.umsg,
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:	req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_sr_msg *sr = &req->sr_msg;
fs/io_uring.c:	sock = sock_from_file(req->file);
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECT) {
fs/io_uring.c:	flags = req->sr_msg.msg_flags | MSG_NOSIGNAL;
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED)
fs/io_uring.c:	struct io_accept *accept = &req->accept;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	struct io_accept *accept = &req->accept;
fs/io_uring.c:	if (req->file->f_flags & O_NONBLOCK)
fs/io_uring.c:		req->flags |= REQ_F_NOWAIT;
fs/io_uring.c:	ret = __sys_accept4_file(req->file, file_flags, accept->addr,
fs/io_uring.c:	struct io_async_connect *io = req->async_data;
fs/io_uring.c:	struct io_connect *conn = &req->connect;
fs/io_uring.c:	struct io_connect *conn = &req->connect;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (req->async_data) {
fs/io_uring.c:		io = req->async_data;
fs/io_uring.c:		ret = move_addr_to_kernel(req->connect.addr,
fs/io_uring.c:						req->connect.addr_len,
fs/io_uring.c:	ret = __sys_connect_file(req->file, &io->address,
fs/io_uring.c:					req->connect.addr_len, file_flags);
fs/io_uring.c:		if (req->async_data)
fs/io_uring.c:		memcpy(req->async_data, &__io, sizeof(__io));
fs/io_uring.c:	trace_io_uring_task_add(req->ctx, req->opcode, req->user_data, mask);
fs/io_uring.c:	req->result = mask;
fs/io_uring.c:	req->task_work.func = func;
fs/io_uring.c:	percpu_ref_get(&req->ctx->refs);
fs/io_uring.c:	__acquires(&req->ctx->completion_lock)
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!req->result && !READ_ONCE(poll->canceled)) {
fs/io_uring.c:		req->result = vfs_poll(req->file, &pt) & poll->events;
fs/io_uring.c:	if (!req->result && !READ_ONCE(poll->canceled)) {
fs/io_uring.c:	if (req->opcode == IORING_OP_POLL_ADD)
fs/io_uring.c:		return req->async_data;
fs/io_uring.c:	return req->apoll->double_poll;
fs/io_uring.c:	if (req->opcode == IORING_OP_POLL_ADD)
fs/io_uring.c:		return &req->poll;
fs/io_uring.c:	return &req->apoll->poll;
fs/io_uring.c:	lockdep_assert_held(&req->ctx->completion_lock);
fs/io_uring.c:			refcount_dec(&req->refs);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	req->poll.done = true;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (io_poll_rewait(req, &req->poll)) {
fs/io_uring.c:		hash_del(&req->hash_node);
fs/io_uring.c:		io_poll_complete(req, req->result, 0);
fs/io_uring.c:	refcount_dec(&req->refs);
fs/io_uring.c:		refcount_inc(&req->refs);
fs/io_uring.c:	struct async_poll *apoll = pt->req->apoll;
fs/io_uring.c:	struct async_poll *apoll = req->apoll;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	trace_io_uring_task_run(req->ctx, req->opcode, req->user_data);
fs/io_uring.c:	if (hash_hashed(&req->hash_node))
fs/io_uring.c:		hash_del(&req->hash_node);
fs/io_uring.c:	struct io_poll_iocb *poll = &req->apoll->poll;
fs/io_uring.c:	trace_io_uring_poll_wake(req->ctx, req->opcode, req->user_data,
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	list = &ctx->cancel_hash[hash_long(req->user_data, ctx->cancel_hash_bits)];
fs/io_uring.c:	hlist_add_head(&req->hash_node, list);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	INIT_HLIST_NODE(&req->hash_node);
fs/io_uring.c:	poll->file = req->file;
fs/io_uring.c:	mask = vfs_poll(req->file, &ipt->pt) & poll->events;
fs/io_uring.c:	const struct io_op_def *def = &io_op_defs[req->opcode];
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!req->file || !file_can_poll(req->file))
fs/io_uring.c:	if (req->flags & REQ_F_POLLED)
fs/io_uring.c:	if (!io_file_supports_async(req->file, rw))
fs/io_uring.c:	req->flags |= REQ_F_POLLED;
fs/io_uring.c:	req->apoll = apoll;
fs/io_uring.c:	if ((req->opcode == IORING_OP_RECVMSG) &&
fs/io_uring.c:	    (req->sr_msg.msg_flags & MSG_ERRQUEUE))
fs/io_uring.c:	trace_io_uring_poll_arm(ctx, req->opcode, req->user_data, mask,
fs/io_uring.c:	hash_del(&req->hash_node);
fs/io_uring.c:	if (req->opcode == IORING_OP_POLL_ADD) {
fs/io_uring.c:		do_complete = __io_poll_remove_one(req, &req->poll);
fs/io_uring.c:		struct async_poll *apoll = req->apoll;
fs/io_uring.c:		io_commit_cqring(req->ctx);
fs/io_uring.c:		if (sqe_addr != req->user_data)
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->poll_remove.addr = READ_ONCE(sqe->addr);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	ret = io_poll_cancel(ctx, req->poll_remove.addr);
fs/io_uring.c:	struct io_poll_iocb *poll = &req->poll;
fs/io_uring.c:	__io_queue_proc(&pt->req->poll, pt, head, (struct io_poll_iocb **) &pt->req->async_data);
fs/io_uring.c:	struct io_poll_iocb *poll = &req->poll;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	struct io_poll_iocb *poll = &req->poll;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	mask = __io_arm_poll_handler(req, &req->poll, &ipt, poll->events,
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	list_del_init(&req->timeout.list);
fs/io_uring.c:	atomic_set(&req->ctx->cq_timeouts,
fs/io_uring.c:		atomic_read(&req->ctx->cq_timeouts) + 1);
fs/io_uring.c:		if (user_data == req->user_data) {
fs/io_uring.c:	io = req->async_data;
fs/io_uring.c:	list_del_init(&req->timeout.list);
fs/io_uring.c:	req->timeout.off = 0; /* noseq */
fs/io_uring.c:	data = req->async_data;
fs/io_uring.c:	list_add_tail(&req->timeout.list, &ctx->timeout_list);
fs/io_uring.c:	struct io_timeout_rem *tr = &req->timeout_rem;
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (unlikely(req->flags & (REQ_F_FIXED_FILE | REQ_F_BUFFER_SELECT)))
fs/io_uring.c:	struct io_timeout_rem *tr = &req->timeout_rem;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (!(req->timeout_rem.flags & IORING_TIMEOUT_UPDATE))
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	req->timeout.off = off;
fs/io_uring.c:	if (!req->async_data && io_alloc_async_data(req))
fs/io_uring.c:	data = req->async_data;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_timeout_data *data = req->async_data;
fs/io_uring.c:	u32 tail, off = req->timeout.off;
fs/io_uring.c:	req->timeout.target_seq = tail + off;
fs/io_uring.c:	list_add(&req->timeout.list, entry);
fs/io_uring.c:	return req->ctx == cd->ctx && req->user_data == cd->user_data;
fs/io_uring.c:	ret = io_async_cancel_one(req->task->io_uring, sqe_addr, ctx);
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_IOPOLL))
fs/io_uring.c:	if (unlikely(req->flags & (REQ_F_FIXED_FILE | REQ_F_BUFFER_SELECT)))
fs/io_uring.c:	req->cancel.addr = READ_ONCE(sqe->addr);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	u64 sqe_addr = req->cancel.addr;
fs/io_uring.c:	ret = io_async_cancel_one(req->task->io_uring, sqe_addr, ctx);
fs/io_uring.c:		ret = io_async_cancel_one(tctx, req->cancel.addr, ctx);
fs/io_uring.c:	if (unlikely(req->ctx->flags & IORING_SETUP_SQPOLL))
fs/io_uring.c:	if (unlikely(req->flags & (REQ_F_FIXED_FILE | REQ_F_BUFFER_SELECT)))
fs/io_uring.c:	req->rsrc_update.offset = READ_ONCE(sqe->off);
fs/io_uring.c:	req->rsrc_update.nr_args = READ_ONCE(sqe->len);
fs/io_uring.c:	if (!req->rsrc_update.nr_args)
fs/io_uring.c:	req->rsrc_update.arg = READ_ONCE(sqe->addr);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	up.offset = req->rsrc_update.offset;
fs/io_uring.c:	up.data = req->rsrc_update.arg;
fs/io_uring.c:	ret = __io_sqe_files_update(ctx, &up, req->rsrc_update.nr_args);
fs/io_uring.c:	switch (req->opcode) {
fs/io_uring.c:			req->opcode);
fs/io_uring.c:	switch (req->opcode) {
fs/io_uring.c:	if (!io_op_defs[req->opcode].needs_async_data)
fs/io_uring.c:	if (req->async_data)
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:		!(req->flags & REQ_F_IO_DRAIN)))
fs/io_uring.c:	trace_io_uring_defer(ctx, req, req->user_data);
fs/io_uring.c:	if (req->flags & REQ_F_BUFFER_SELECTED) {
fs/io_uring.c:		switch (req->opcode) {
fs/io_uring.c:			kfree((void *)(unsigned long)req->rw.addr);
fs/io_uring.c:			kfree(req->sr_msg.kbuf);
fs/io_uring.c:		req->flags &= ~REQ_F_BUFFER_SELECTED;
fs/io_uring.c:	if (req->flags & REQ_F_NEED_CLEANUP) {
fs/io_uring.c:		switch (req->opcode) {
fs/io_uring.c:			struct io_async_rw *io = req->async_data;
fs/io_uring.c:			struct io_async_msghdr *io = req->async_data;
fs/io_uring.c:			io_put_file(req, req->splice.file_in,
fs/io_uring.c:				    (req->splice.flags & SPLICE_F_FD_IN_FIXED));
fs/io_uring.c:			if (req->open.filename)
fs/io_uring.c:				putname(req->open.filename);
fs/io_uring.c:			putname(req->rename.oldpath);
fs/io_uring.c:			putname(req->rename.newpath);
fs/io_uring.c:			putname(req->unlink.filename);
fs/io_uring.c:		req->flags &= ~REQ_F_NEED_CLEANUP;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	if (req->work.creds && req->work.creds != current_cred())
fs/io_uring.c:		creds = override_creds(req->work.creds);
fs/io_uring.c:	switch (req->opcode) {
fs/io_uring.c:	if ((ctx->flags & IORING_SETUP_IOPOLL) && req->file) {
fs/io_uring.c:		refcount_inc(&req->refs);
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	prev = req->timeout.head;
fs/io_uring.c:	req->timeout.head = NULL;
fs/io_uring.c:	if (req->timeout.head) {
fs/io_uring.c:		struct io_timeout_data *data = req->async_data;
fs/io_uring.c:	struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	struct io_kiocb *nxt = req->link;
fs/io_uring.c:	if (!nxt || (req->flags & REQ_F_LINK_TIMEOUT) ||
fs/io_uring.c:	req->flags |= REQ_F_LINK_TIMEOUT;
fs/io_uring.c:	if (ret == -EAGAIN && !(req->flags & REQ_F_NOWAIT)) {
fs/io_uring.c:		if (req->flags & REQ_F_COMPLETE_INLINE) {
fs/io_uring.c:			struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	} else if (req->flags & REQ_F_FORCE_ASYNC) {
fs/io_uring.c:	if (!test_bit(req->opcode, ctx->restrictions.sqe_op))
fs/io_uring.c:	req->opcode = READ_ONCE(sqe->opcode);
fs/io_uring.c:	req->flags = sqe_flags = READ_ONCE(sqe->flags);
fs/io_uring.c:	req->user_data = READ_ONCE(sqe->user_data);
fs/io_uring.c:	req->async_data = NULL;
fs/io_uring.c:	req->file = NULL;
fs/io_uring.c:	req->ctx = ctx;
fs/io_uring.c:	req->link = NULL;
fs/io_uring.c:	req->fixed_rsrc_refs = NULL;
fs/io_uring.c:	refcount_set(&req->refs, 2);
fs/io_uring.c:	req->task = current;
fs/io_uring.c:	req->result = 0;
fs/io_uring.c:	req->work.list.next = NULL;
fs/io_uring.c:	req->work.creds = NULL;
fs/io_uring.c:	req->work.flags = 0;
fs/io_uring.c:		req->flags = 0;
fs/io_uring.c:	if (unlikely(req->opcode >= IORING_OP_LAST))
fs/io_uring.c:	    !io_op_defs[req->opcode].buffer_select)
fs/io_uring.c:		req->work.creds = xa_load(&ctx->personalities, personality);
fs/io_uring.c:		if (!req->work.creds)
fs/io_uring.c:		get_cred(req->work.creds);
fs/io_uring.c:	    io_op_defs[req->opcode].plug) {
fs/io_uring.c:	if (io_op_defs[req->opcode].needs_file) {
fs/io_uring.c:		bool fixed = req->flags & REQ_F_FIXED_FILE;
fs/io_uring.c:		req->file = io_file_get(state, req, READ_ONCE(sqe->fd), fixed);
fs/io_uring.c:		if (unlikely(!req->file))
fs/io_uring.c:	trace_io_uring_submit_sqe(ctx, req->opcode, req->user_data,
fs/io_uring.c:		if (req->flags & REQ_F_IO_DRAIN) {
fs/io_uring.c:		if (!(req->flags & (REQ_F_LINK | REQ_F_HARDLINK))) {
fs/io_uring.c:			req->flags |= REQ_F_IO_DRAIN;
fs/io_uring.c:		if (req->flags & (REQ_F_LINK | REQ_F_HARDLINK)) {
fs/io_uring.c:	return req ? &req->work : NULL;
fs/io_uring.c:		if (tsk && req->task != tsk)
fs/io_uring.c:		list_del(&req->compl.list);
fs/io_uring.c:	if (cancel->files && (req->flags & REQ_F_LINK_TIMEOUT)) {
fs/io_uring.c:		struct io_ring_ctx *ctx = req->ctx;
fs/io_uring.c:	return req->ctx == data;
fs/io_uring.c:			seq_printf(m, "  op=%d, task_works=%d\n", req->opcode,
fs/io_uring.c:					req->task->task_works != NULL);
fs/fuse/file.c: * fully completed (req->out.args[0].size == 32K) resulting in pos == -1. The
fs/fuse/dev.c:	INIT_LIST_HEAD(&req->list);
fs/fuse/dev.c:	INIT_LIST_HEAD(&req->intr_entry);
fs/fuse/dev.c:	init_waitqueue_head(&req->waitq);
fs/fuse/dev.c:	refcount_set(&req->count, 1);
fs/fuse/dev.c:	__set_bit(FR_PENDING, &req->flags);
fs/fuse/dev.c:	req->fm = fm;
fs/fuse/dev.c:	refcount_inc(&req->count);
fs/fuse/dev.c:	refcount_dec(&req->count);
fs/fuse/dev.c:	req->in.h.uid = from_kuid(fc->user_ns, current_fsuid());
fs/fuse/dev.c:	req->in.h.gid = from_kgid(fc->user_ns, current_fsgid());
fs/fuse/dev.c:	req->in.h.pid = pid_nr_ns(task_pid(current), fc->pid_ns);
fs/fuse/dev.c:	__set_bit(FR_WAITING, &req->flags);
fs/fuse/dev.c:		__set_bit(FR_BACKGROUND, &req->flags);
fs/fuse/dev.c:	if (unlikely(req->in.h.uid == ((uid_t)-1) ||
fs/fuse/dev.c:		     req->in.h.gid == ((gid_t)-1))) {
fs/fuse/dev.c:	struct fuse_conn *fc = req->fm->fc;
fs/fuse/dev.c:	if (refcount_dec_and_test(&req->count)) {
fs/fuse/dev.c:		if (test_bit(FR_BACKGROUND, &req->flags)) {
fs/fuse/dev.c:		if (test_bit(FR_WAITING, &req->flags)) {
fs/fuse/dev.c:			__clear_bit(FR_WAITING, &req->flags);
fs/fuse/dev.c:	req->in.h.len = sizeof(struct fuse_in_header) +
fs/fuse/dev.c:		fuse_len_args(req->args->in_numargs,
fs/fuse/dev.c:			      (struct fuse_arg *) req->args->in_args);
fs/fuse/dev.c:	list_add_tail(&req->list, &fiq->pending);
fs/fuse/dev.c:		list_del(&req->list);
fs/fuse/dev.c:		req->in.h.unique = fuse_get_unique(fiq);
fs/fuse/dev.c:	struct fuse_mount *fm = req->fm;
fs/fuse/dev.c:	if (test_and_set_bit(FR_FINISHED, &req->flags))
fs/fuse/dev.c:	if (!list_empty(&req->intr_entry)) {
fs/fuse/dev.c:		list_del_init(&req->intr_entry);
fs/fuse/dev.c:	WARN_ON(test_bit(FR_PENDING, &req->flags));
fs/fuse/dev.c:	WARN_ON(test_bit(FR_SENT, &req->flags));
fs/fuse/dev.c:	if (test_bit(FR_BACKGROUND, &req->flags)) {
fs/fuse/dev.c:		clear_bit(FR_BACKGROUND, &req->flags);
fs/fuse/dev.c:		wake_up(&req->waitq);
fs/fuse/dev.c:	if (test_bit(FR_ASYNC, &req->flags))
fs/fuse/dev.c:		req->args->end(fm, req->args, req->out.h.error);
fs/fuse/dev.c:	struct fuse_iqueue *fiq = &req->fm->fc->iq;
fs/fuse/dev.c:	if (unlikely(!test_bit(FR_INTERRUPTED, &req->flags))) {
fs/fuse/dev.c:	if (list_empty(&req->intr_entry)) {
fs/fuse/dev.c:		list_add_tail(&req->intr_entry, &fiq->interrupts);
fs/fuse/dev.c:		if (test_bit(FR_FINISHED, &req->flags)) {
fs/fuse/dev.c:			list_del_init(&req->intr_entry);
fs/fuse/dev.c:	struct fuse_conn *fc = req->fm->fc;
fs/fuse/dev.c:		err = wait_event_interruptible(req->waitq,
fs/fuse/dev.c:					test_bit(FR_FINISHED, &req->flags));
fs/fuse/dev.c:		set_bit(FR_INTERRUPTED, &req->flags);
fs/fuse/dev.c:		if (test_bit(FR_SENT, &req->flags))
fs/fuse/dev.c:	if (!test_bit(FR_FORCE, &req->flags)) {
fs/fuse/dev.c:		err = wait_event_killable(req->waitq,
fs/fuse/dev.c:					test_bit(FR_FINISHED, &req->flags));
fs/fuse/dev.c:		if (test_bit(FR_PENDING, &req->flags)) {
fs/fuse/dev.c:			list_del(&req->list);
fs/fuse/dev.c:			req->out.h.error = -EINTR;
fs/fuse/dev.c:	wait_event(req->waitq, test_bit(FR_FINISHED, &req->flags));
fs/fuse/dev.c:	struct fuse_iqueue *fiq = &req->fm->fc->iq;
fs/fuse/dev.c:	BUG_ON(test_bit(FR_BACKGROUND, &req->flags));
fs/fuse/dev.c:		req->out.h.error = -ENOTCONN;
fs/fuse/dev.c:		req->in.h.unique = fuse_get_unique(fiq);
fs/fuse/dev.c:	struct fuse_conn *fc = req->fm->fc;
fs/fuse/dev.c:	req->in.h.uid = from_kuid_munged(fc->user_ns, current_fsuid());
fs/fuse/dev.c:	req->in.h.gid = from_kgid_munged(fc->user_ns, current_fsgid());
fs/fuse/dev.c:	req->in.h.pid = pid_nr_ns(task_pid(current), fc->pid_ns);
fs/fuse/dev.c:	req->in.h.opcode = args->opcode;
fs/fuse/dev.c:	req->in.h.nodeid = args->nodeid;
fs/fuse/dev.c:	req->args = args;
fs/fuse/dev.c:		__set_bit(FR_ASYNC, &req->flags);
fs/fuse/dev.c:		__set_bit(FR_WAITING, &req->flags);
fs/fuse/dev.c:		__set_bit(FR_FORCE, &req->flags);
fs/fuse/dev.c:		__set_bit(FR_ISREPLY, &req->flags);
fs/fuse/dev.c:	ret = req->out.h.error;
fs/fuse/dev.c:	struct fuse_mount *fm = req->fm;
fs/fuse/dev.c:	WARN_ON(!test_bit(FR_BACKGROUND, &req->flags));
fs/fuse/dev.c:	if (!test_bit(FR_WAITING, &req->flags)) {
fs/fuse/dev.c:		__set_bit(FR_WAITING, &req->flags);
fs/fuse/dev.c:	__set_bit(FR_ISREPLY, &req->flags);
fs/fuse/dev.c:		list_add_tail(&req->list, &fc->bg_queue);
fs/fuse/dev.c:		__set_bit(FR_BACKGROUND, &req->flags);
fs/fuse/dev.c:	__clear_bit(FR_ISREPLY, &req->flags);
fs/fuse/dev.c:	req->in.h.unique = unique;
fs/fuse/dev.c:		spin_lock(&req->waitq.lock);
fs/fuse/dev.c:		if (test_bit(FR_ABORTED, &req->flags))
fs/fuse/dev.c:			set_bit(FR_LOCKED, &req->flags);
fs/fuse/dev.c:		spin_unlock(&req->waitq.lock);
fs/fuse/dev.c:		spin_lock(&req->waitq.lock);
fs/fuse/dev.c:		if (test_bit(FR_ABORTED, &req->flags))
fs/fuse/dev.c:			clear_bit(FR_LOCKED, &req->flags);
fs/fuse/dev.c:		spin_unlock(&req->waitq.lock);
fs/fuse/dev.c:	spin_lock(&cs->req->waitq.lock);
fs/fuse/dev.c:	if (test_bit(FR_ABORTED, &cs->req->flags))
fs/fuse/dev.c:	spin_unlock(&cs->req->waitq.lock);
fs/fuse/dev.c:	struct fuse_args_pages *ap = container_of(req->args, typeof(*ap), args);
fs/fuse/dev.c:	list_del_init(&req->intr_entry);
fs/fuse/dev.c:	ih.unique = (req->in.h.unique | FUSE_INT_REQ_BIT);
fs/fuse/dev.c:	arg.unique = req->in.h.unique;
fs/fuse/dev.c:	clear_bit(FR_PENDING, &req->flags);
fs/fuse/dev.c:	list_del_init(&req->list);
fs/fuse/dev.c:	args = req->args;
fs/fuse/dev.c:	reqsize = req->in.h.len;
fs/fuse/dev.c:		req->out.h.error = -EIO;
fs/fuse/dev.c:			req->out.h.error = -E2BIG;
fs/fuse/dev.c:	list_add(&req->list, &fpq->io);
fs/fuse/dev.c:	err = fuse_copy_one(cs, &req->in.h, sizeof(req->in.h));
fs/fuse/dev.c:	clear_bit(FR_LOCKED, &req->flags);
fs/fuse/dev.c:		req->out.h.error = -EIO;
fs/fuse/dev.c:	if (!test_bit(FR_ISREPLY, &req->flags)) {
fs/fuse/dev.c:	hash = fuse_req_hash(req->in.h.unique);
fs/fuse/dev.c:	list_move_tail(&req->list, &fpq->processing[hash]);
fs/fuse/dev.c:	set_bit(FR_SENT, &req->flags);
fs/fuse/dev.c:	if (test_bit(FR_INTERRUPTED, &req->flags))
fs/fuse/dev.c:	if (!test_bit(FR_PRIVATE, &req->flags))
fs/fuse/dev.c:		list_del_init(&req->list);
fs/fuse/dev.c:		if (req->in.h.unique == unique)
fs/fuse/dev.c:	clear_bit(FR_SENT, &req->flags);
fs/fuse/dev.c:	list_move(&req->list, &fpq->io);
fs/fuse/dev.c:	req->out.h = oh;
fs/fuse/dev.c:	set_bit(FR_LOCKED, &req->flags);
fs/fuse/dev.c:	if (!req->args->page_replace)
fs/fuse/dev.c:		err = copy_out_args(cs, req->args, nbytes);
fs/fuse/dev.c:	clear_bit(FR_LOCKED, &req->flags);
fs/fuse/dev.c:		req->out.h.error = -EIO;
fs/fuse/dev.c:	if (!test_bit(FR_PRIVATE, &req->flags))
fs/fuse/dev.c:		list_del_init(&req->list);
fs/fuse/dev.c:		req->out.h.error = -ECONNABORTED;
fs/fuse/dev.c:		clear_bit(FR_SENT, &req->flags);
fs/fuse/dev.c:		list_del_init(&req->list);
fs/fuse/dev.c:				req->out.h.error = -ECONNABORTED;
fs/fuse/dev.c:				spin_lock(&req->waitq.lock);
fs/fuse/dev.c:				set_bit(FR_ABORTED, &req->flags);
fs/fuse/dev.c:				if (!test_bit(FR_LOCKED, &req->flags)) {
fs/fuse/dev.c:					set_bit(FR_PRIVATE, &req->flags);
fs/fuse/dev.c:					list_move(&req->list, &to_end);
fs/fuse/dev.c:				spin_unlock(&req->waitq.lock);
fs/fuse/dev.c:			clear_bit(FR_PENDING, &req->flags);
fs/fuse/virtio_fs.c:		list_del_init(&req->list);
fs/fuse/virtio_fs.c:		list_del_init(&req->list);
fs/fuse/virtio_fs.c:				list_add_tail(&req->list, &fsvq->queued_reqs);
fs/fuse/virtio_fs.c:			req->out.h.error = ret;
fs/fuse/virtio_fs.c:/* Allocate and copy args into req->argbuf */
fs/fuse/virtio_fs.c:	struct fuse_args *args = req->args;
fs/fuse/virtio_fs.c:	req->argbuf = kmalloc(len, GFP_ATOMIC);
fs/fuse/virtio_fs.c:	if (!req->argbuf)
fs/fuse/virtio_fs.c:		memcpy(req->argbuf + offset,
fs/fuse/virtio_fs.c:/* Copy args out of and free req->argbuf */
fs/fuse/virtio_fs.c:	remaining = req->out.h.len - sizeof(req->out.h);
fs/fuse/virtio_fs.c:		memcpy(args->out_args[i].value, req->argbuf + offset, argsize);
fs/fuse/virtio_fs.c:	kfree(req->argbuf);
fs/fuse/virtio_fs.c:	req->argbuf = NULL;
fs/fuse/virtio_fs.c:	args = req->args;
fs/fuse/virtio_fs.c:	clear_bit(FR_SENT, &req->flags);
fs/fuse/virtio_fs.c:			list_move_tail(&req->list, &reqs);
fs/fuse/virtio_fs.c:		list_del_init(&req->list);
fs/fuse/virtio_fs.c:		if (req->args->may_block) {
fs/fuse/virtio_fs.c:	req->ih = (struct fuse_in_header){
fs/fuse/virtio_fs.c:	req->arg = (struct fuse_forget_in){
fs/fuse/virtio_fs.c:	struct fuse_args *args = req->args;
fs/fuse/virtio_fs.c:	if (!test_bit(FR_ISREPLY, &req->flags))
fs/fuse/virtio_fs.c:	struct fuse_args_pages *ap = container_of(req->args, typeof(*ap), args);
fs/fuse/virtio_fs.c:	struct fuse_args *args = req->args;
fs/fuse/virtio_fs.c:	sg_init_one(&sg[out_sgs++], &req->in.h, sizeof(req->in.h));
fs/fuse/virtio_fs.c:				     req->argbuf, &argbuf_used);
fs/fuse/virtio_fs.c:	if (test_bit(FR_ISREPLY, &req->flags)) {
fs/fuse/virtio_fs.c:			    &req->out.h, sizeof(req->out.h));
fs/fuse/virtio_fs.c:					    req->argbuf + argbuf_used, NULL);
fs/fuse/virtio_fs.c:	list_add_tail(&req->list, fpq->processing);
fs/fuse/virtio_fs.c:	set_bit(FR_SENT, &req->flags);
fs/fuse/virtio_fs.c:	if (ret < 0 && req->argbuf) {
fs/fuse/virtio_fs.c:		kfree(req->argbuf);
fs/fuse/virtio_fs.c:		req->argbuf = NULL;
fs/fuse/virtio_fs.c:	clear_bit(FR_PENDING, &req->flags);
fs/fuse/virtio_fs.c:	list_del_init(&req->list);
fs/fuse/virtio_fs.c:		  __func__, req->in.h.opcode, req->in.h.unique,
fs/fuse/virtio_fs.c:		 req->in.h.nodeid, req->in.h.len,
fs/fuse/virtio_fs.c:		 fuse_len_args(req->args->out_numargs, req->args->out_args));
fs/fuse/virtio_fs.c:			list_add_tail(&req->list, &fsvq->queued_reqs);
fs/fuse/virtio_fs.c:		req->out.h.error = ret;
fs/fuse/virtio_fs.c:		list_add_tail(&req->list, &fsvq->end_reqs);
fs/xfs/xfs_itable.h:	char __user		*b = breq->ubuffer;
fs/xfs/xfs_itable.h:	breq->ubuffer = b + bytes;
fs/xfs/xfs_itable.h:	breq->ocount++;
fs/xfs/xfs_itable.h:	return breq->ocount == breq->icount ? -ECANCELED : 0;
fs/xfs/xfs_ioctl.c:		f = fdget(hreq->fd);
fs/xfs/xfs_ioctl.c:		error = user_path_at(AT_FDCWD, hreq->path, 0, &path);
fs/xfs/xfs_ioctl.c:	if (copy_to_user(hreq->ohandle, &handle, hsize) ||
fs/xfs/xfs_ioctl.c:	    copy_to_user(hreq->ohandlen, &hsize, sizeof(__s32)))
fs/xfs/xfs_ioctl.c:	return xfs_handle_to_dentry(parfilp, hreq->ihandle, hreq->ihandlen);
fs/xfs/xfs_ioctl.c:	hreq->oflags |= O_LARGEFILE;
fs/xfs/xfs_ioctl.c:	permflag = hreq->oflags;
fs/xfs/xfs_ioctl.c:	filp = dentry_open(&path, hreq->oflags, cred);
fs/xfs/xfs_ioctl.c:	if (copy_from_user(&olen, hreq->ohandlen, sizeof(__u32))) {
fs/xfs/xfs_ioctl.c:	error = vfs_readlink(dentry, hreq->ohandle, olen);
fs/xfs/xfs_ioctl.c:	xfs_bulkstat_to_bstat(breq->mp, &bs1, bstat);
fs/xfs/xfs_ioctl.c:	if (copy_to_user(breq->ubuffer, &bs1, sizeof(bs1)))
fs/xfs/xfs_ioctl.c:	if (copy_to_user(breq->ubuffer, &ig1, sizeof(struct xfs_inogrp)))
fs/xfs/xfs_ioctl.c:	if (copy_to_user(breq->ubuffer, bstat, sizeof(struct xfs_bulkstat)))
fs/xfs/xfs_ioctl.c:	breq->startino = hdr->ino;
fs/xfs/xfs_ioctl.c:	breq->ubuffer = ubuffer;
fs/xfs/xfs_ioctl.c:	breq->icount = hdr->icount;
fs/xfs/xfs_ioctl.c:	breq->ocount = 0;
fs/xfs/xfs_ioctl.c:	breq->flags = 0;
fs/xfs/xfs_ioctl.c:		breq->icount = 1;
fs/xfs/xfs_ioctl.c:		if (breq->startino == 0)
fs/xfs/xfs_ioctl.c:			breq->startino = XFS_AGINO_TO_INO(mp, hdr->agno, 0);
fs/xfs/xfs_ioctl.c:		else if (XFS_INO_TO_AGNO(mp, breq->startino) < hdr->agno)
fs/xfs/xfs_ioctl.c:		breq->flags |= XFS_IBULK_SAME_AG;
fs/xfs/xfs_ioctl.c:		if (XFS_INO_TO_AGNO(mp, breq->startino) > hdr->agno)
fs/xfs/xfs_ioctl.c:	if (XFS_INO_TO_AGNO(mp, breq->startino) >= mp->m_sb.sb_agcount)
fs/xfs/xfs_ioctl.c:	hdr->ino = breq->startino;
fs/xfs/xfs_ioctl.c:	hdr->ocount = breq->ocount;
fs/xfs/xfs_ioctl.c:	if (copy_to_user(breq->ubuffer, igrp, sizeof(struct xfs_inumbers)))
fs/xfs/xfs_ioctl32.c:	struct compat_xfs_inogrp __user	*p32 = breq->ubuffer;
fs/xfs/xfs_ioctl32.c:	struct compat_xfs_bstat	__user	*p32 = breq->ubuffer;
fs/xfs/xfs_ioctl32.c:	xfs_bulkstat_to_bstat(breq->mp, &bs1, bstat);
fs/xfs/xfs_ioctl32.c:	hreq->fd = hreq32.fd;
fs/xfs/xfs_ioctl32.c:	hreq->path = compat_ptr(hreq32.path);
fs/xfs/xfs_ioctl32.c:	hreq->oflags = hreq32.oflags;
fs/xfs/xfs_ioctl32.c:	hreq->ihandle = compat_ptr(hreq32.ihandle);
fs/xfs/xfs_ioctl32.c:	hreq->ihandlen = hreq32.ihandlen;
fs/xfs/xfs_ioctl32.c:	hreq->ohandle = compat_ptr(hreq32.ohandle);
fs/xfs/xfs_ioctl32.c:	hreq->ohandlen = compat_ptr(hreq32.ohandlen);
fs/xfs/xfs_ioctl32.c:			compat_ptr(hreq->ihandle), hreq->ihandlen);
fs/xfs/xfs_itable.c: * bc->breq->lastino is effectively the inode cursor as we walk through the
fs/xfs/xfs_itable.c:	bc->breq->startino = ino + 1;
fs/xfs/xfs_itable.c:	if (breq->mnt_userns != &init_user_ns) {
fs/xfs/xfs_itable.c:		xfs_warn_ratelimited(breq->mp,
fs/xfs/xfs_itable.c:	ASSERT(breq->icount == 1);
fs/xfs/xfs_itable.c:	error = xfs_bulkstat_one_int(breq->mp, breq->mnt_userns, NULL,
fs/xfs/xfs_itable.c:				     breq->startino, &bc);
fs/xfs/xfs_itable.c:	error = xfs_bulkstat_one_int(mp, bc->breq->mnt_userns, tp, ino, data);
fs/xfs/xfs_itable.c:	if (breq->mnt_userns != &init_user_ns) {
fs/xfs/xfs_itable.c:		xfs_warn_ratelimited(breq->mp,
fs/xfs/xfs_itable.c:	if (xfs_bulkstat_already_done(breq->mp, breq->startino))
fs/xfs/xfs_itable.c:	error = xfs_iwalk(breq->mp, NULL, breq->startino, breq->flags,
fs/xfs/xfs_itable.c:			xfs_bulkstat_iwalk, breq->icount, &bc);
fs/xfs/xfs_itable.c:	if (breq->ocount > 0)
fs/xfs/xfs_itable.c:	ic->breq->startino = XFS_AGINO_TO_INO(mp, agno, irec->ir_startino) +
fs/xfs/xfs_itable.c:	if (xfs_bulkstat_already_done(breq->mp, breq->startino))
fs/xfs/xfs_itable.c:	error = xfs_inobt_walk(breq->mp, NULL, breq->startino, breq->flags,
fs/xfs/xfs_itable.c:			xfs_inumbers_walk, breq->icount, &ic);
fs/xfs/xfs_itable.c:	if (breq->ocount > 0)
fs/ceph/xattr.c:	if (req && req->r_target_inode == in) {
fs/ceph/xattr.c:		if (req->r_op == CEPH_MDS_OP_LOOKUP ||
fs/ceph/xattr.c:		    req->r_op == CEPH_MDS_OP_LOOKUPINO ||
fs/ceph/xattr.c:		    req->r_op == CEPH_MDS_OP_LOOKUPPARENT ||
fs/ceph/xattr.c:		    req->r_op == CEPH_MDS_OP_GETATTR) {
fs/ceph/xattr.c:			mask = le32_to_cpu(req->r_args.getattr.mask);
fs/ceph/xattr.c:		} else if (req->r_op == CEPH_MDS_OP_OPEN ||
fs/ceph/xattr.c:			   req->r_op == CEPH_MDS_OP_CREATE) {
fs/ceph/xattr.c:			mask = le32_to_cpu(req->r_args.open.mask);
fs/ceph/xattr.c:	req->r_path2 = kstrdup(name, GFP_NOFS);
fs/ceph/xattr.c:	if (!req->r_path2) {
fs/ceph/xattr.c:		req->r_args.setxattr.flags = cpu_to_le32(flags);
fs/ceph/xattr.c:		req->r_args.setxattr.osdmap_epoch =
fs/ceph/xattr.c:		req->r_pagelist = pagelist;
fs/ceph/xattr.c:	req->r_inode = inode;
fs/ceph/xattr.c:	req->r_num_caps = 1;
fs/ceph/xattr.c:	req->r_inode_drop = CEPH_CAP_XATTR_SHARED;
fs/ceph/mds_client.h:	kref_get(&req->r_kref);
fs/ceph/mds_client.h:	kref_put(&req->r_kref, ceph_mdsc_release_request);
fs/ceph/export.c:		req->r_args.lookupino.mask = cpu_to_le32(mask);
fs/ceph/export.c:		req->r_ino1 = vino;
fs/ceph/export.c:		req->r_num_caps = 1;
fs/ceph/export.c:		inode = req->r_target_inode;
fs/ceph/export.c:	req->r_args.lookupino.mask = cpu_to_le32(mask);
fs/ceph/export.c:		req->r_args.lookupino.snapid = cpu_to_le64(vino.snap);
fs/ceph/export.c:			req->r_args.lookupino.parent =
fs/ceph/export.c:			req->r_args.lookupino.hash =
fs/ceph/export.c:	req->r_ino1 = vino;
fs/ceph/export.c:	req->r_num_caps = 1;
fs/ceph/export.c:	inode = req->r_target_inode;
fs/ceph/export.c:		req->r_inode = d_inode(child);
fs/ceph/export.c:		req->r_ino1 = (struct ceph_vino) {
fs/ceph/export.c:	req->r_args.getattr.mask = cpu_to_le32(mask);
fs/ceph/export.c:	req->r_num_caps = 1;
fs/ceph/export.c:	inode = req->r_target_inode;
fs/ceph/export.c:		req->r_direct_mode = USE_AUTH_MDS;
fs/ceph/export.c:		req->r_readdir_offset = next_offset;
fs/ceph/export.c:		req->r_args.readdir.flags =
fs/ceph/export.c:			req->r_path2 = last_name;
fs/ceph/export.c:		req->r_inode = dir;
fs/ceph/export.c:		req->r_dentry = dget(parent);
fs/ceph/export.c:		rinfo = &req->r_reply_info;
fs/ceph/export.c:	req->r_inode = inode;
fs/ceph/export.c:	req->r_ino2 = ceph_vino(d_inode(parent));
fs/ceph/export.c:	req->r_parent = d_inode(parent);
fs/ceph/export.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/export.c:	req->r_num_caps = 2;
fs/ceph/export.c:		struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
fs/ceph/ioctl.c:	req->r_inode = inode;
fs/ceph/ioctl.c:	req->r_num_caps = 1;
fs/ceph/ioctl.c:	req->r_inode_drop = CEPH_CAP_FILE_SHARED | CEPH_CAP_FILE_EXCL;
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_stripe_unit =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_stripe_count =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_object_size =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_pg_pool = cpu_to_le32(l.data_pool);
fs/ceph/ioctl.c:	req->r_inode = inode;
fs/ceph/ioctl.c:	req->r_num_caps = 1;
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_stripe_unit =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_stripe_count =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_object_size =
fs/ceph/ioctl.c:	req->r_args.setlayout.layout.fl_pg_pool =
fs/ceph/mds_client.c:	if (req->r_session) {
fs/ceph/mds_client.c:		ceph_put_mds_session(req->r_session);
fs/ceph/mds_client.c:		req->r_session = NULL;
fs/ceph/mds_client.c:	destroy_reply_info(&req->r_reply_info);
fs/ceph/mds_client.c:	if (req->r_request)
fs/ceph/mds_client.c:		ceph_msg_put(req->r_request);
fs/ceph/mds_client.c:	if (req->r_reply)
fs/ceph/mds_client.c:		ceph_msg_put(req->r_reply);
fs/ceph/mds_client.c:	if (req->r_inode) {
fs/ceph/mds_client.c:		ceph_put_cap_refs(ceph_inode(req->r_inode), CEPH_CAP_PIN);
fs/ceph/mds_client.c:		ceph_async_iput(req->r_inode);
fs/ceph/mds_client.c:	if (req->r_parent) {
fs/ceph/mds_client.c:		ceph_put_cap_refs(ceph_inode(req->r_parent), CEPH_CAP_PIN);
fs/ceph/mds_client.c:		ceph_async_iput(req->r_parent);
fs/ceph/mds_client.c:	ceph_async_iput(req->r_target_inode);
fs/ceph/mds_client.c:	if (req->r_dentry)
fs/ceph/mds_client.c:		dput(req->r_dentry);
fs/ceph/mds_client.c:	if (req->r_old_dentry)
fs/ceph/mds_client.c:		dput(req->r_old_dentry);
fs/ceph/mds_client.c:	if (req->r_old_dentry_dir) {
fs/ceph/mds_client.c:		ceph_put_cap_refs(ceph_inode(req->r_old_dentry_dir),
fs/ceph/mds_client.c:		ceph_async_iput(req->r_old_dentry_dir);
fs/ceph/mds_client.c:	kfree(req->r_path1);
fs/ceph/mds_client.c:	kfree(req->r_path2);
fs/ceph/mds_client.c:	put_cred(req->r_cred);
fs/ceph/mds_client.c:	if (req->r_pagelist)
fs/ceph/mds_client.c:		ceph_pagelist_release(req->r_pagelist);
fs/ceph/mds_client.c:	ceph_unreserve_caps(req->r_mdsc, &req->r_caps_reservation);
fs/ceph/mds_client.c:	WARN_ON_ONCE(!list_empty(&req->r_wait));
fs/ceph/mds_client.c:	req->r_tid = ++mdsc->last_tid;
fs/ceph/mds_client.c:	if (req->r_num_caps) {
fs/ceph/mds_client.c:		ret = ceph_reserve_caps(mdsc, &req->r_caps_reservation,
fs/ceph/mds_client.c:					req->r_num_caps);
fs/ceph/mds_client.c:			/* set req->r_err to fail early from __do_request */
fs/ceph/mds_client.c:			req->r_err = ret;
fs/ceph/mds_client.c:	dout("__register_request %p tid %lld\n", req, req->r_tid);
fs/ceph/mds_client.c:	req->r_cred = get_current_cred();
fs/ceph/mds_client.c:	if (mdsc->oldest_tid == 0 && req->r_op != CEPH_MDS_OP_SETFILELOCK)
fs/ceph/mds_client.c:		mdsc->oldest_tid = req->r_tid;
fs/ceph/mds_client.c:		req->r_unsafe_dir = dir;
fs/ceph/mds_client.c:		list_add_tail(&req->r_unsafe_dir_item, &ci->i_unsafe_dirops);
fs/ceph/mds_client.c:	dout("__unregister_request %p tid %lld\n", req, req->r_tid);
fs/ceph/mds_client.c:	list_del_init(&req->r_unsafe_item);
fs/ceph/mds_client.c:	if (req->r_tid == mdsc->oldest_tid) {
fs/ceph/mds_client.c:		struct rb_node *p = rb_next(&req->r_node);
fs/ceph/mds_client.c:			if (next_req->r_op != CEPH_MDS_OP_SETFILELOCK) {
fs/ceph/mds_client.c:				mdsc->oldest_tid = next_req->r_tid;
fs/ceph/mds_client.c:	if (req->r_unsafe_dir) {
fs/ceph/mds_client.c:		struct ceph_inode_info *ci = ceph_inode(req->r_unsafe_dir);
fs/ceph/mds_client.c:		list_del_init(&req->r_unsafe_dir_item);
fs/ceph/mds_client.c:	if (req->r_target_inode &&
fs/ceph/mds_client.c:	    test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags)) {
fs/ceph/mds_client.c:		struct ceph_inode_info *ci = ceph_inode(req->r_target_inode);
fs/ceph/mds_client.c:		list_del_init(&req->r_unsafe_target_item);
fs/ceph/mds_client.c:	if (req->r_unsafe_dir) {
fs/ceph/mds_client.c:		ceph_async_iput(req->r_unsafe_dir);
fs/ceph/mds_client.c:		req->r_unsafe_dir = NULL;
fs/ceph/mds_client.c:	complete_all(&req->r_safe_completion);
fs/ceph/mds_client.c:	int mode = req->r_direct_mode;
fs/ceph/mds_client.c:	u32 hash = req->r_direct_hash;
fs/ceph/mds_client.c:	bool is_hash = test_bit(CEPH_MDS_R_DIRECT_IS_HASH, &req->r_req_flags);
fs/ceph/mds_client.c:	if (req->r_resend_mds >= 0 &&
fs/ceph/mds_client.c:	    (__have_session(mdsc, req->r_resend_mds) ||
fs/ceph/mds_client.c:	     ceph_mdsmap_get_state(mdsc->mdsmap, req->r_resend_mds) > 0)) {
fs/ceph/mds_client.c:		     req->r_resend_mds);
fs/ceph/mds_client.c:		return req->r_resend_mds;
fs/ceph/mds_client.c:	if (req->r_inode) {
fs/ceph/mds_client.c:		if (ceph_snap(req->r_inode) != CEPH_SNAPDIR) {
fs/ceph/mds_client.c:			inode = req->r_inode;
fs/ceph/mds_client.c:			/* req->r_dentry is non-null for LSSNAP request */
fs/ceph/mds_client.c:			inode = get_nonsnap_parent(req->r_dentry);
fs/ceph/mds_client.c:	} else if (req->r_dentry) {
fs/ceph/mds_client.c:		parent = READ_ONCE(req->r_dentry->d_parent);
fs/ceph/mds_client.c:		dir = req->r_parent ? : d_inode_rcu(parent);
fs/ceph/mds_client.c:			inode = d_inode(req->r_dentry);
fs/ceph/mds_client.c:			inode = d_inode(req->r_dentry);
fs/ceph/mds_client.c:				hash = ceph_dentry_hash(dir, req->r_dentry);
fs/ceph/mds_client.c:				    req->r_tid);
fs/ceph/mds_client.c:		if (req->r_target_inode) {
fs/ceph/mds_client.c:			ci = ceph_inode(req->r_target_inode);
fs/ceph/mds_client.c:		if (req->r_unsafe_dir) {
fs/ceph/mds_client.c:			ci = ceph_inode(req->r_unsafe_dir);
fs/ceph/mds_client.c:		if (req->r_session &&
fs/ceph/mds_client.c:		    req->r_session->s_mds == session->s_mds)
fs/ceph/mds_client.c:			req->r_attempts = 0;
fs/ceph/mds_client.c:	struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
fs/ceph/mds_client.c:	struct ceph_mount_options *opt = req->r_mdsc->fsc->mount_options;
fs/ceph/mds_client.c:	req->r_num_caps = num_entries + 1;
fs/ceph/mds_client.c:	req->r_args.readdir.max_entries = cpu_to_le32(num_entries);
fs/ceph/mds_client.c:	req->r_args.readdir.max_bytes = cpu_to_le32(opt->max_readdir_bytes);
fs/ceph/mds_client.c:	mutex_init(&req->r_fill_mutex);
fs/ceph/mds_client.c:	req->r_mdsc = mdsc;
fs/ceph/mds_client.c:	req->r_started = jiffies;
fs/ceph/mds_client.c:	req->r_start_latency = ktime_get();
fs/ceph/mds_client.c:	req->r_resend_mds = -1;
fs/ceph/mds_client.c:	INIT_LIST_HEAD(&req->r_unsafe_dir_item);
fs/ceph/mds_client.c:	INIT_LIST_HEAD(&req->r_unsafe_target_item);
fs/ceph/mds_client.c:	req->r_fmode = -1;
fs/ceph/mds_client.c:	kref_init(&req->r_kref);
fs/ceph/mds_client.c:	RB_CLEAR_NODE(&req->r_node);
fs/ceph/mds_client.c:	INIT_LIST_HEAD(&req->r_wait);
fs/ceph/mds_client.c:	init_completion(&req->r_completion);
fs/ceph/mds_client.c:	init_completion(&req->r_safe_completion);
fs/ceph/mds_client.c:	INIT_LIST_HEAD(&req->r_unsafe_item);
fs/ceph/mds_client.c:	ktime_get_coarse_real_ts64(&req->r_stamp);
fs/ceph/mds_client.c:	req->r_op = op;
fs/ceph/mds_client.c:	req->r_direct_mode = mode;
fs/ceph/mds_client.c:	ceph_encode_timespec64(&ts, &req->r_stamp);
fs/ceph/mds_client.c:	ceph_encode_32(p, req->r_cred->group_info->ngroups);
fs/ceph/mds_client.c:	for (i = 0; i < req->r_cred->group_info->ngroups; i++)
fs/ceph/mds_client.c:					    req->r_cred->group_info->gid[i]));
fs/ceph/mds_client.c:	ret = set_request_path_attr(req->r_inode, req->r_dentry,
fs/ceph/mds_client.c:			      req->r_parent, req->r_path1, req->r_ino1.ino,
fs/ceph/mds_client.c:					&req->r_req_flags));
fs/ceph/mds_client.c:	ret = set_request_path_attr(NULL, req->r_old_dentry,
fs/ceph/mds_client.c:			      req->r_old_dentry_dir,
fs/ceph/mds_client.c:			      req->r_path2, req->r_ino2.ino,
fs/ceph/mds_client.c:	len += sizeof(u32) + (sizeof(u64) * req->r_cred->group_info->ngroups);
fs/ceph/mds_client.c:		(!!req->r_inode_drop + !!req->r_dentry_drop +
fs/ceph/mds_client.c:		 !!req->r_old_inode_drop + !!req->r_old_dentry_drop);
fs/ceph/mds_client.c:	if (req->r_dentry_drop)
fs/ceph/mds_client.c:	if (req->r_old_dentry_drop)
fs/ceph/mds_client.c:	msg->hdr.tid = cpu_to_le64(req->r_tid);
fs/ceph/mds_client.c:	head->op = cpu_to_le32(req->r_op);
fs/ceph/mds_client.c:						 req->r_cred->fsuid));
fs/ceph/mds_client.c:						 req->r_cred->fsgid));
fs/ceph/mds_client.c:	head->ino = cpu_to_le64(req->r_deleg_ino);
fs/ceph/mds_client.c:	head->args = req->r_args;
fs/ceph/mds_client.c:	req->r_request_release_offset = p - msg->front.iov_base;
fs/ceph/mds_client.c:	if (req->r_inode_drop)
fs/ceph/mds_client.c:		      req->r_inode ? req->r_inode : d_inode(req->r_dentry),
fs/ceph/mds_client.c:		      mds, req->r_inode_drop, req->r_inode_unless,
fs/ceph/mds_client.c:		      req->r_op == CEPH_MDS_OP_READDIR);
fs/ceph/mds_client.c:	if (req->r_dentry_drop)
fs/ceph/mds_client.c:		releases += ceph_encode_dentry_release(&p, req->r_dentry,
fs/ceph/mds_client.c:				req->r_parent, mds, req->r_dentry_drop,
fs/ceph/mds_client.c:				req->r_dentry_unless);
fs/ceph/mds_client.c:	if (req->r_old_dentry_drop)
fs/ceph/mds_client.c:		releases += ceph_encode_dentry_release(&p, req->r_old_dentry,
fs/ceph/mds_client.c:				req->r_old_dentry_dir, mds,
fs/ceph/mds_client.c:				req->r_old_dentry_drop,
fs/ceph/mds_client.c:				req->r_old_dentry_unless);
fs/ceph/mds_client.c:	if (req->r_old_inode_drop)
fs/ceph/mds_client.c:		      d_inode(req->r_old_dentry),
fs/ceph/mds_client.c:		      mds, req->r_old_inode_drop, req->r_old_inode_unless, 0);
fs/ceph/mds_client.c:		p = msg->front.iov_base + req->r_request_release_offset;
fs/ceph/mds_client.c:	if (req->r_pagelist) {
fs/ceph/mds_client.c:		struct ceph_pagelist *pagelist = req->r_pagelist;
fs/ceph/mds_client.c:	req->r_end_latency = ktime_get();
fs/ceph/mds_client.c:	if (req->r_callback)
fs/ceph/mds_client.c:		req->r_callback(mdsc, req);
fs/ceph/mds_client.c:	complete_all(&req->r_completion);
fs/ceph/mds_client.c:	req->r_attempts++;
fs/ceph/mds_client.c:	if (req->r_inode) {
fs/ceph/mds_client.c:			ceph_get_cap_for_mds(ceph_inode(req->r_inode), mds);
fs/ceph/mds_client.c:			req->r_sent_on_mseq = cap->mseq;
fs/ceph/mds_client.c:			req->r_sent_on_mseq = -1;
fs/ceph/mds_client.c:	     req->r_tid, ceph_mds_op_name(req->r_op), req->r_attempts);
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags)) {
fs/ceph/mds_client.c:		msg = req->r_request;
fs/ceph/mds_client.c:		if (req->r_target_inode)
fs/ceph/mds_client.c:			rhead->ino = cpu_to_le64(ceph_ino(req->r_target_inode));
fs/ceph/mds_client.c:		rhead->num_retry = req->r_attempts - 1;
fs/ceph/mds_client.c:		p = msg->front.iov_base + req->r_request_release_offset;
fs/ceph/mds_client.c:	if (req->r_request) {
fs/ceph/mds_client.c:		ceph_msg_put(req->r_request);
fs/ceph/mds_client.c:		req->r_request = NULL;
fs/ceph/mds_client.c:		req->r_err = PTR_ERR(msg);
fs/ceph/mds_client.c:	req->r_request = msg;
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags))
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags))
fs/ceph/mds_client.c:	if (req->r_parent)
fs/ceph/mds_client.c:	rhead->num_fwd = req->r_num_fwd;
fs/ceph/mds_client.c:	rhead->num_retry = req->r_attempts - 1;
fs/ceph/mds_client.c:	dout(" r_parent = %p\n", req->r_parent);
fs/ceph/mds_client.c:		ceph_msg_get(req->r_request);
fs/ceph/mds_client.c:		ceph_con_send(&session->s_con, req->r_request);
fs/ceph/mds_client.c:	if (req->r_err || test_bit(CEPH_MDS_R_GOT_RESULT, &req->r_req_flags)) {
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags))
fs/ceph/mds_client.c:	if (req->r_timeout &&
fs/ceph/mds_client.c:	    time_after_eq(jiffies, req->r_started + req->r_timeout)) {
fs/ceph/mds_client.c:			list_add(&req->r_wait, &mdsc->waiting_for_map);
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags)) {
fs/ceph/mds_client.c:		list_add(&req->r_wait, &mdsc->waiting_for_map);
fs/ceph/mds_client.c:	req->r_session = ceph_get_mds_session(session);
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags)) {
fs/ceph/mds_client.c:				list_add(&req->r_wait, &mdsc->waiting_for_map);
fs/ceph/mds_client.c:				req->r_resend_mds = mds;
fs/ceph/mds_client.c:		list_add(&req->r_wait, &session->s_waiting);
fs/ceph/mds_client.c:	req->r_resend_mds = -1;   /* forget any previous mds hint */
fs/ceph/mds_client.c:	if (req->r_request_started == 0)   /* note request start time */
fs/ceph/mds_client.c:		req->r_request_started = jiffies;
fs/ceph/mds_client.c:		req->r_err = err;
fs/ceph/mds_client.c:		list_del_init(&req->r_wait);
fs/ceph/mds_client.c:		dout(" wake request %p tid %llu\n", req, req->r_tid);
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags))
fs/ceph/mds_client.c:		if (req->r_attempts > 0)
fs/ceph/mds_client.c:		if (req->r_session &&
fs/ceph/mds_client.c:		    req->r_session->s_mds == mds) {
fs/ceph/mds_client.c:			dout(" kicking tid %llu\n", req->r_tid);
fs/ceph/mds_client.c:			list_del_init(&req->r_wait);
fs/ceph/mds_client.c:	if (req->r_inode)
fs/ceph/mds_client.c:		ceph_get_cap_refs(ceph_inode(req->r_inode), CEPH_CAP_PIN);
fs/ceph/mds_client.c:	if (req->r_parent) {
fs/ceph/mds_client.c:		struct ceph_inode_info *ci = ceph_inode(req->r_parent);
fs/ceph/mds_client.c:		int fmode = (req->r_op & CEPH_MDS_OP_WRITE) ?
fs/ceph/mds_client.c:		ihold(req->r_parent);
fs/ceph/mds_client.c:	if (req->r_old_dentry_dir)
fs/ceph/mds_client.c:		ceph_get_cap_refs(ceph_inode(req->r_old_dentry_dir),
fs/ceph/mds_client.c:	if (req->r_inode) {
fs/ceph/mds_client.c:		err = ceph_wait_on_async_create(req->r_inode);
fs/ceph/mds_client.c:	if (!err && req->r_old_inode) {
fs/ceph/mds_client.c:		err = ceph_wait_on_async_create(req->r_old_inode);
fs/ceph/mds_client.c:	err = req->r_err;
fs/ceph/mds_client.c:	if (!req->r_timeout && req->r_wait_for_completion) {
fs/ceph/mds_client.c:		err = req->r_wait_for_completion(mdsc, req);
fs/ceph/mds_client.c:					&req->r_completion,
fs/ceph/mds_client.c:					ceph_timeout_jiffies(req->r_timeout));
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_GOT_RESULT, &req->r_req_flags)) {
fs/ceph/mds_client.c:		err = le32_to_cpu(req->r_reply_info.head->result);
fs/ceph/mds_client.c:		dout("aborted request %lld with %d\n", req->r_tid, err);
fs/ceph/mds_client.c:		mutex_lock(&req->r_fill_mutex);
fs/ceph/mds_client.c:		req->r_err = err;
fs/ceph/mds_client.c:		set_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags);
fs/ceph/mds_client.c:		mutex_unlock(&req->r_fill_mutex);
fs/ceph/mds_client.c:		if (req->r_parent &&
fs/ceph/mds_client.c:		    (req->r_op & CEPH_MDS_OP_WRITE))
fs/ceph/mds_client.c:		err = req->r_err;
fs/ceph/mds_client.c:	struct inode *dir = req->r_parent;
fs/ceph/mds_client.c:	struct inode *old_dir = req->r_old_dentry_dir;
fs/ceph/mds_client.c:	if (req->r_dentry)
fs/ceph/mds_client.c:		ceph_invalidate_dentry_lease(req->r_dentry);
fs/ceph/mds_client.c:	if (req->r_old_dentry)
fs/ceph/mds_client.c:		ceph_invalidate_dentry_lease(req->r_old_dentry);
fs/ceph/mds_client.c:	if (req->r_session != session) {
fs/ceph/mds_client.c:		       req->r_session ? req->r_session->s_mds : -1);
fs/ceph/mds_client.c:	if ((test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags) && !head->safe) ||
fs/ceph/mds_client.c:	    (test_bit(CEPH_MDS_R_GOT_SAFE, &req->r_req_flags) && head->safe)) {
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_GOT_SAFE, &req->r_req_flags)) {
fs/ceph/mds_client.c:		dout("got ESTALE on request %llu\n", req->r_tid);
fs/ceph/mds_client.c:		req->r_resend_mds = -1;
fs/ceph/mds_client.c:		if (req->r_direct_mode != USE_AUTH_MDS) {
fs/ceph/mds_client.c:			req->r_direct_mode = USE_AUTH_MDS;
fs/ceph/mds_client.c:			if (mds >= 0 && mds != req->r_session->s_mds) {
fs/ceph/mds_client.c:		dout("have to return ESTALE on request %llu\n", req->r_tid);
fs/ceph/mds_client.c:		set_bit(CEPH_MDS_R_GOT_SAFE, &req->r_req_flags);
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags)) {
fs/ceph/mds_client.c:		set_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags);
fs/ceph/mds_client.c:		list_add_tail(&req->r_unsafe_item, &req->r_session->s_unsafe);
fs/ceph/mds_client.c:	rinfo = &req->r_reply_info;
fs/ceph/mds_client.c:		req->r_target_inode = in;
fs/ceph/mds_client.c:	mutex_lock(&req->r_fill_mutex);
fs/ceph/mds_client.c:		if (result == 0 && (req->r_op == CEPH_MDS_OP_READDIR ||
fs/ceph/mds_client.c:				    req->r_op == CEPH_MDS_OP_LSSNAP))
fs/ceph/mds_client.c:			ceph_readdir_prepopulate(req, req->r_session);
fs/ceph/mds_client.c:	mutex_unlock(&req->r_fill_mutex);
fs/ceph/mds_client.c:		if (req->r_target_inode &&
fs/ceph/mds_client.c:		    test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags)) {
fs/ceph/mds_client.c:				ceph_inode(req->r_target_inode);
fs/ceph/mds_client.c:			list_add_tail(&req->r_unsafe_target_item,
fs/ceph/mds_client.c:		ceph_unreserve_caps(mdsc, &req->r_caps_reservation);
fs/ceph/mds_client.c:	if (!test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags)) {
fs/ceph/mds_client.c:			req->r_err = err;
fs/ceph/mds_client.c:			req->r_reply =  ceph_msg_get(msg);
fs/ceph/mds_client.c:			set_bit(CEPH_MDS_R_GOT_RESULT, &req->r_req_flags);
fs/ceph/mds_client.c:	ceph_update_metadata_latency(&mdsc->metric, req->r_start_latency,
fs/ceph/mds_client.c:				     req->r_end_latency, err);
fs/ceph/mds_client.c:	if (test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags)) {
fs/ceph/mds_client.c:	} else if (fwd_seq <= req->r_num_fwd) {
fs/ceph/mds_client.c:		     tid, next_mds, req->r_num_fwd, fwd_seq);
fs/ceph/mds_client.c:		BUG_ON(req->r_err);
fs/ceph/mds_client.c:		BUG_ON(test_bit(CEPH_MDS_R_GOT_RESULT, &req->r_req_flags));
fs/ceph/mds_client.c:		req->r_attempts = 0;
fs/ceph/mds_client.c:		req->r_num_fwd = fwd_seq;
fs/ceph/mds_client.c:		req->r_resend_mds = next_mds;
fs/ceph/mds_client.c:	dcaps = xchg(&req->r_dir_caps, 0);
fs/ceph/mds_client.c:		ceph_put_cap_refs(ceph_inode(req->r_parent), dcaps);
fs/ceph/mds_client.c:	dcaps = xchg(&req->r_dir_caps, 0);
fs/ceph/mds_client.c:		ceph_put_cap_refs_no_check_caps(ceph_inode(req->r_parent),
fs/ceph/mds_client.c:		if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags))
fs/ceph/mds_client.c:		if (req->r_attempts == 0)
fs/ceph/mds_client.c:		if (!req->r_session)
fs/ceph/mds_client.c:		if (req->r_session->s_mds != session->s_mds)
fs/ceph/mds_client.c:			     req->r_tid);
fs/ceph/mds_client.c:			list_del_init(&req->r_wait);
fs/ceph/mds_client.c:	while (req && req->r_tid <= want_tid) {
fs/ceph/mds_client.c:		n = rb_next(&req->r_node);
fs/ceph/mds_client.c:		if (req->r_op != CEPH_MDS_OP_SETFILELOCK &&
fs/ceph/mds_client.c:		    (req->r_op & CEPH_MDS_OP_WRITE)) {
fs/ceph/mds_client.c:			     req->r_tid, want_tid);
fs/ceph/mds_client.c:			wait_for_completion(&req->r_safe_completion);
fs/ceph/mds_client.c:			if (RB_EMPTY_NODE(&nextreq->r_node)) {
fs/ceph/file.c:	req->r_fmode = ceph_flags_to_mode(flags);
fs/ceph/file.c:	req->r_args.open.flags = ceph_flags_sys2wire(flags);
fs/ceph/file.c:	req->r_args.open.mode = cpu_to_le32(create_mode);
fs/ceph/file.c:	req->r_inode = inode;
fs/ceph/file.c:	req->r_num_caps = 1;
fs/ceph/file.c:	req->r_inode = inode;
fs/ceph/file.c:	req->r_num_caps = 1;
fs/ceph/file.c:		err = ceph_init_file(inode, file, req->r_fmode);
fs/ceph/file.c:	int result = req->r_err ? req->r_err :
fs/ceph/file.c:			le32_to_cpu(req->r_reply_info.head->result);
fs/ceph/file.c:	mapping_set_error(req->r_parent->i_mapping, result);
fs/ceph/file.c:		struct dentry *dentry = req->r_dentry;
fs/ceph/file.c:		char *path = ceph_mdsc_build_path(req->r_dentry, &pathlen,
fs/ceph/file.c:		ceph_dir_clear_complete(req->r_parent);
fs/ceph/file.c:	if (req->r_target_inode) {
fs/ceph/file.c:		struct ceph_inode_info *ci = ceph_inode(req->r_target_inode);
fs/ceph/file.c:		u64 ino = ceph_vino(req->r_target_inode).ino;
fs/ceph/file.c:		if (req->r_deleg_ino != ino)
fs/ceph/file.c:				__func__, req->r_err, req->r_deleg_ino, ino);
fs/ceph/file.c:		mapping_set_error(req->r_target_inode->i_mapping, result);
fs/ceph/file.c:		ceph_kick_flushing_inode_caps(req->r_session, ci);
fs/ceph/file.c:		pr_warn("%s: no req->r_target_inode for 0x%llx\n", __func__,
fs/ceph/file.c:			req->r_deleg_ino);
fs/ceph/file.c:	struct ceph_vino vino = { .ino = req->r_deleg_ino,
fs/ceph/file.c:	ret = ceph_fill_inode(inode, NULL, &iinfo, NULL, req->r_session,
fs/ceph/file.c:			      req->r_fmode, NULL);
fs/ceph/file.c:	req->r_dentry = dget(dentry);
fs/ceph/file.c:	req->r_num_caps = 2;
fs/ceph/file.c:	req->r_args.open.mask = cpu_to_le32(mask);
fs/ceph/file.c:	req->r_parent = dir;
fs/ceph/file.c:		req->r_dentry_drop = CEPH_CAP_FILE_SHARED | CEPH_CAP_AUTH_EXCL;
fs/ceph/file.c:		req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/file.c:			req->r_pagelist = as_ctx.pagelist;
fs/ceph/file.c:		    (req->r_dir_caps =
fs/ceph/file.c:					    &req->r_deleg_ino))) {
fs/ceph/file.c:			set_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags);
fs/ceph/file.c:			req->r_args.open.flags |= cpu_to_le32(CEPH_O_EXCL);
fs/ceph/file.c:			req->r_callback = ceph_async_create_cb;
fs/ceph/file.c:				restore_deleg_ino(dir, req->r_deleg_ino);
fs/ceph/file.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/file.c:	if ((flags & O_CREAT) && !req->r_reply_info.head->is_dentry)
fs/ceph/file.c:		if (req->r_op == CEPH_MDS_OP_CREATE && req->r_reply_info.has_create_ino) {
fs/ceph/file.c:					 req->r_start_latency,
fs/ceph/file.c:					 req->r_end_latency,
fs/ceph/file.c:	if (!atomic_dec_and_test(&aio_req->pending_reqs))
fs/ceph/file.c:	if (aio_req->iocb->ki_flags & IOCB_DIRECT)
fs/ceph/file.c:	ret = aio_req->error;
fs/ceph/file.c:		ret = aio_req->total_len;
fs/ceph/file.c:	if (ret >= 0 && aio_req->write) {
fs/ceph/file.c:		loff_t endoff = aio_req->iocb->ki_pos + aio_req->total_len;
fs/ceph/file.c:					       &aio_req->prealloc_cf);
fs/ceph/file.c:	ceph_put_cap_refs(ci, (aio_req->write ? CEPH_CAP_FILE_WR :
fs/ceph/file.c:	aio_req->iocb->ki_complete(aio_req->iocb, ret, 0);
fs/ceph/file.c:	ceph_free_cap_flush(aio_req->prealloc_cf);
fs/ceph/file.c:	int rc = req->r_result;
fs/ceph/file.c:	struct inode *inode = req->r_inode;
fs/ceph/file.c:	struct ceph_aio_request *aio_req = req->r_priv;
fs/ceph/file.c:	if (req->r_start_latency) {
fs/ceph/file.c:		if (aio_req->write)
fs/ceph/file.c:			ceph_update_write_latency(metric, req->r_start_latency,
fs/ceph/file.c:						  req->r_end_latency, rc);
fs/ceph/file.c:			ceph_update_read_latency(metric, req->r_start_latency,
fs/ceph/file.c:						 req->r_end_latency, rc);
fs/ceph/file.c:		BUG_ON(!aio_req->write);
fs/ceph/file.c:	} else if (!aio_req->write) {
fs/ceph/file.c:			if (aio_req->num_reqs == 1) {
fs/ceph/file.c:				loff_t endoff = aio_req->iocb->ki_pos + rc;
fs/ceph/file.c:				aio_req->total_len = rc + zlen;
fs/ceph/file.c:		  aio_req->should_dirty);
fs/ceph/file.c:		cmpxchg(&aio_req->error, 0, rc);
fs/ceph/file.c:	struct ceph_aio_request *aio_req = orig_req->r_priv;
fs/ceph/file.c:	struct inode *inode = orig_req->r_inode;
fs/ceph/file.c:	req = ceph_osdc_alloc_request(orig_req->r_osdc, snapc, 1,
fs/ceph/file.c:	req->r_flags = /* CEPH_OSD_FLAG_ORDERSNAP | */ CEPH_OSD_FLAG_WRITE;
fs/ceph/file.c:	ceph_oloc_copy(&req->r_base_oloc, &orig_req->r_base_oloc);
fs/ceph/file.c:	ceph_oid_copy(&req->r_base_oid, &orig_req->r_base_oid);
fs/ceph/file.c:	req->r_ops[0] = orig_req->r_ops[0];
fs/ceph/file.c:	req->r_mtime = aio_req->mtime;
fs/ceph/file.c:	req->r_data_offset = req->r_ops[0].extent.offset;
fs/ceph/file.c:	req->r_callback = ceph_aio_complete_req;
fs/ceph/file.c:	req->r_inode = inode;
fs/ceph/file.c:	req->r_priv = aio_req;
fs/ceph/file.c:	ret = ceph_osdc_start_request(req->r_osdc, req, false);
fs/ceph/file.c:		req->r_result = ret;
fs/ceph/file.c:				aio_req->iocb = iocb;
fs/ceph/file.c:				aio_req->write = write;
fs/ceph/file.c:				aio_req->should_dirty = should_dirty;
fs/ceph/file.c:				INIT_LIST_HEAD(&aio_req->osd_reqs);
fs/ceph/file.c:					aio_req->mtime = mtime;
fs/ceph/file.c:					swap(aio_req->prealloc_cf, *pcf);
fs/ceph/file.c:			req->r_mtime = mtime;
fs/ceph/file.c:			aio_req->total_len += len;
fs/ceph/file.c:			aio_req->num_reqs++;
fs/ceph/file.c:			atomic_inc(&aio_req->pending_reqs);
fs/ceph/file.c:			req->r_callback = ceph_aio_complete_req;
fs/ceph/file.c:			req->r_inode = inode;
fs/ceph/file.c:			req->r_priv = aio_req;
fs/ceph/file.c:			list_add_tail(&req->r_private_item, &aio_req->osd_reqs);
fs/ceph/file.c:		ret = ceph_osdc_start_request(req->r_osdc, req, false);
fs/ceph/file.c:			ceph_update_write_latency(metric, req->r_start_latency,
fs/ceph/file.c:						  req->r_end_latency, ret);
fs/ceph/file.c:			ceph_update_read_latency(metric, req->r_start_latency,
fs/ceph/file.c:						 req->r_end_latency, ret);
fs/ceph/file.c:		if (aio_req->num_reqs == 0) {
fs/ceph/file.c:		list_splice(&aio_req->osd_reqs, &osd_reqs);
fs/ceph/file.c:			list_del_init(&req->r_private_item);
fs/ceph/file.c:				ret = ceph_osdc_start_request(req->r_osdc,
fs/ceph/file.c:				req->r_result = ret;
fs/ceph/file.c:		req->r_inode = inode;
fs/ceph/file.c:		req->r_mtime = mtime;
fs/ceph/file.c:		ceph_update_write_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/file.c:					  req->r_end_latency, ret);
fs/ceph/file.c:	req->r_mtime = inode->i_mtime;
fs/ceph/dir.c:		req->r_direct_mode = USE_AUTH_MDS;
fs/ceph/dir.c:			req->r_direct_hash = ceph_frag_value(frag);
fs/ceph/dir.c:			__set_bit(CEPH_MDS_R_DIRECT_IS_HASH, &req->r_req_flags);
fs/ceph/dir.c:			req->r_inode_drop = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:			req->r_path2 = kstrdup(dfi->last_name, GFP_KERNEL);
fs/ceph/dir.c:			if (!req->r_path2) {
fs/ceph/dir.c:			req->r_args.readdir.offset_hash =
fs/ceph/dir.c:		req->r_dir_release_cnt = dfi->dir_release_count;
fs/ceph/dir.c:		req->r_dir_ordered_cnt = dfi->dir_ordered_count;
fs/ceph/dir.c:		req->r_readdir_cache_idx = dfi->readdir_cache_idx;
fs/ceph/dir.c:		req->r_readdir_offset = dfi->next_offset;
fs/ceph/dir.c:		req->r_args.readdir.frag = cpu_to_le32(frag);
fs/ceph/dir.c:		req->r_args.readdir.flags =
fs/ceph/dir.c:		req->r_inode = inode;
fs/ceph/dir.c:		req->r_dentry = dget(file->f_path.dentry);
fs/ceph/dir.c:		     (int)req->r_reply_info.dir_end,
fs/ceph/dir.c:		     (int)req->r_reply_info.dir_complete,
fs/ceph/dir.c:		     (int)req->r_reply_info.hash_order);
fs/ceph/dir.c:		rinfo = &req->r_reply_info;
fs/ceph/dir.c:				dfi->next_offset = req->r_readdir_offset;
fs/ceph/dir.c:		if (test_bit(CEPH_MDS_R_DID_PREPOPULATE, &req->r_req_flags)) {
fs/ceph/dir.c:			dfi->readdir_cache_idx = req->r_readdir_cache_idx;
fs/ceph/dir.c:				dfi->dir_release_count = req->r_dir_release_cnt;
fs/ceph/dir.c:				dfi->dir_ordered_count = req->r_dir_ordered_cnt;
fs/ceph/dir.c:			unsigned next_offset = req->r_reply_info.dir_end ?
fs/ceph/dir.c:		} else if (req->r_reply_info.dir_end) {
fs/ceph/dir.c: * Mainly, make sure we return the final req->r_dentry (if it already
fs/ceph/dir.c:		if (!req->r_reply_info.head->is_dentry) {
fs/ceph/dir.c:	else if (dentry != req->r_dentry)
fs/ceph/dir.c:		dentry = dget(req->r_dentry);   /* we got spliced */
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_args.getattr.mask = cpu_to_le32(mask);
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_args.mknod.mode = cpu_to_le32(mode);
fs/ceph/dir.c:	req->r_args.mknod.rdev = cpu_to_le32(rdev);
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED | CEPH_CAP_AUTH_EXCL;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:		req->r_pagelist = as_ctx.pagelist;
fs/ceph/dir.c:	if (!err && !req->r_reply_info.head->is_dentry)
fs/ceph/dir.c:	req->r_path2 = kstrdup(dest, GFP_KERNEL);
fs/ceph/dir.c:	if (!req->r_path2) {
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED | CEPH_CAP_AUTH_EXCL;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:		req->r_pagelist = as_ctx.pagelist;
fs/ceph/dir.c:	if (!err && !req->r_reply_info.head->is_dentry)
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_args.mkdir.mode = cpu_to_le32(mode);
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED | CEPH_CAP_AUTH_EXCL;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:		req->r_pagelist = as_ctx.pagelist;
fs/ceph/dir.c:	    !req->r_reply_info.head->is_target &&
fs/ceph/dir.c:	    !req->r_reply_info.head->is_dentry)
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_old_dentry = dget(old_dentry);
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:	req->r_old_inode_drop = CEPH_CAP_LINK_SHARED | CEPH_CAP_LINK_EXCL;
fs/ceph/dir.c:	} else if (!req->r_reply_info.head->is_dentry) {
fs/ceph/dir.c:	int result = req->r_err ? req->r_err :
fs/ceph/dir.c:			le32_to_cpu(req->r_reply_info.head->result);
fs/ceph/dir.c:		char *path = ceph_mdsc_build_path(req->r_dentry, &pathlen,
fs/ceph/dir.c:		mapping_set_error(req->r_parent->i_mapping, result);
fs/ceph/dir.c:		ceph_dir_clear_complete(req->r_parent);
fs/ceph/dir.c:		if (!d_unhashed(req->r_dentry))
fs/ceph/dir.c:			d_drop(req->r_dentry);
fs/ceph/dir.c:		mapping_set_error(req->r_old_inode->i_mapping, result);
fs/ceph/dir.c:	iput(req->r_old_inode);
fs/ceph/dir.c:	req->r_dentry = dget(dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_parent = dir;
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:	req->r_inode_drop = ceph_drop_caps_for_unlink(inode);
fs/ceph/dir.c:	    (req->r_dir_caps = get_caps_for_async_unlink(dir, dentry))) {
fs/ceph/dir.c:		     ceph_cap_string(req->r_dir_caps));
fs/ceph/dir.c:		set_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags);
fs/ceph/dir.c:		req->r_callback = ceph_async_unlink_cb;
fs/ceph/dir.c:		req->r_old_inode = d_inode(dentry);
fs/ceph/dir.c:		ihold(req->r_old_inode);
fs/ceph/dir.c:		set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:		if (!err && !req->r_reply_info.head->is_dentry)
fs/ceph/dir.c:	req->r_dentry = dget(new_dentry);
fs/ceph/dir.c:	req->r_num_caps = 2;
fs/ceph/dir.c:	req->r_old_dentry = dget(old_dentry);
fs/ceph/dir.c:	req->r_old_dentry_dir = old_dir;
fs/ceph/dir.c:	req->r_parent = new_dir;
fs/ceph/dir.c:	set_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags);
fs/ceph/dir.c:	req->r_old_dentry_drop = CEPH_CAP_FILE_SHARED;
fs/ceph/dir.c:	req->r_old_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:	req->r_dentry_drop = CEPH_CAP_FILE_SHARED;
fs/ceph/dir.c:	req->r_dentry_unless = CEPH_CAP_FILE_EXCL;
fs/ceph/dir.c:	req->r_old_inode_drop = CEPH_CAP_LINK_SHARED | CEPH_CAP_LINK_EXCL;
fs/ceph/dir.c:		req->r_inode_drop =
fs/ceph/dir.c:	if (!err && !req->r_reply_info.head->is_dentry) {
fs/ceph/dir.c:			req->r_dentry = dget(dentry);
fs/ceph/dir.c:			req->r_num_caps = 2;
fs/ceph/dir.c:			req->r_parent = dir;
fs/ceph/dir.c:			req->r_args.getattr.mask = cpu_to_le32(mask);
fs/ceph/dir.c:				    d_inode(dentry) == req->r_target_inode)
fs/ceph/locks.c:	req->r_inode = inode;
fs/ceph/locks.c:	req->r_num_caps = 1;
fs/ceph/locks.c:	req->r_args.filelock_change.rule = lock_type;
fs/ceph/locks.c:	req->r_args.filelock_change.type = cmd;
fs/ceph/locks.c:	req->r_args.filelock_change.owner = cpu_to_le64(owner);
fs/ceph/locks.c:	req->r_args.filelock_change.pid = cpu_to_le64((u64)fl->fl_pid);
fs/ceph/locks.c:	req->r_args.filelock_change.start = cpu_to_le64(fl->fl_start);
fs/ceph/locks.c:	req->r_args.filelock_change.length = cpu_to_le64(length);
fs/ceph/locks.c:	req->r_args.filelock_change.wait = wait;
fs/ceph/locks.c:		req->r_wait_for_completion = ceph_lock_wait_for_completion;
fs/ceph/locks.c:		fl->fl_pid = -le64_to_cpu(req->r_reply_info.filelock_reply->pid);
fs/ceph/locks.c:		if (CEPH_LOCK_SHARED == req->r_reply_info.filelock_reply->type)
fs/ceph/locks.c:		else if (CEPH_LOCK_EXCL == req->r_reply_info.filelock_reply->type)
fs/ceph/locks.c:		fl->fl_start = le64_to_cpu(req->r_reply_info.filelock_reply->start);
fs/ceph/locks.c:		length = le64_to_cpu(req->r_reply_info.filelock_reply->start) +
fs/ceph/locks.c:						 le64_to_cpu(req->r_reply_info.filelock_reply->length);
fs/ceph/locks.c:	struct inode *inode = req->r_inode;
fs/ceph/locks.c:	BUG_ON(req->r_op != CEPH_MDS_OP_SETFILELOCK);
fs/ceph/locks.c:	if (req->r_args.filelock_change.rule == CEPH_LOCK_FCNTL)
fs/ceph/locks.c:	else if (req->r_args.filelock_change.rule == CEPH_LOCK_FLOCK)
fs/ceph/locks.c:	BUG_ON(req->r_args.filelock_change.type == CEPH_LOCK_UNLOCK);
fs/ceph/locks.c:	err = wait_for_completion_interruptible(&req->r_completion);
fs/ceph/locks.c:	     req->r_tid);
fs/ceph/locks.c:	if (test_bit(CEPH_MDS_R_GOT_RESULT, &req->r_req_flags)) {
fs/ceph/locks.c:		mutex_lock(&req->r_fill_mutex);
fs/ceph/locks.c:		req->r_err = err;
fs/ceph/locks.c:		set_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags);
fs/ceph/locks.c:		mutex_unlock(&req->r_fill_mutex);
fs/ceph/locks.c:		if (!req->r_session) {
fs/ceph/locks.c:	intr_req->r_inode = inode;
fs/ceph/locks.c:	intr_req->r_num_caps = 1;
fs/ceph/locks.c:	intr_req->r_args.filelock_change = req->r_args.filelock_change;
fs/ceph/locks.c:	intr_req->r_args.filelock_change.rule = lock_type;
fs/ceph/locks.c:	intr_req->r_args.filelock_change.type = CEPH_LOCK_UNLOCK;
fs/ceph/locks.c:	wait_for_completion_killable(&req->r_safe_completion);
fs/ceph/addr.c:	ceph_update_read_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/addr.c:				 req->r_end_latency, err);
fs/ceph/addr.c:	struct inode *inode = req->r_inode;
fs/ceph/addr.c:	int rc = req->r_result <= 0 ? req->r_result : 0;
fs/ceph/addr.c:	int bytes = req->r_result >= 0 ? req->r_result : 0;
fs/ceph/addr.c:	ceph_update_read_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/addr.c:				 req->r_end_latency, rc);
fs/ceph/addr.c:	req->r_callback = finish_read;
fs/ceph/addr.c:	req->r_inode = inode;
fs/ceph/addr.c:	req->r_mtime = inode->i_mtime;
fs/ceph/addr.c:	ceph_update_write_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/addr.c:				  req->r_end_latency, err);
fs/ceph/addr.c:	struct inode *inode = req->r_inode;
fs/ceph/addr.c:	int rc = req->r_result;
fs/ceph/addr.c:	struct ceph_snap_context *snapc = req->r_snapc;
fs/ceph/addr.c:	ceph_update_write_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/addr.c:				  req->r_end_latency, rc);
fs/ceph/addr.c:	for (i = 0; i < req->r_num_ops; i++) {
fs/ceph/addr.c:		if (req->r_ops[i].op != CEPH_OSD_OP_WRITE)
fs/ceph/addr.c:		req->r_callback = writepages_finish;
fs/ceph/addr.c:		req->r_inode = inode;
fs/ceph/addr.c:				if (op_idx + 1 == req->r_num_ops)
fs/ceph/addr.c:		BUG_ON(op_idx + 1 != req->r_num_ops);
fs/ceph/addr.c:			BUG_ON(num_ops <= req->r_num_ops);
fs/ceph/addr.c:			num_ops -= req->r_num_ops;
fs/ceph/addr.c:			BUG_ON(num_ops != req->r_num_ops);
fs/ceph/addr.c:		req->r_mtime = inode->i_mtime;
fs/ceph/addr.c:	req->r_mtime = inode->i_mtime;
fs/ceph/addr.c:	req->r_mtime = inode->i_mtime;
fs/ceph/addr.c:	ceph_update_write_latency(&fsc->mdsc->metric, req->r_start_latency,
fs/ceph/addr.c:				  req->r_end_latency, err);
fs/ceph/addr.c:	rd_req->r_flags = CEPH_OSD_FLAG_READ;
fs/ceph/addr.c:	rd_req->r_base_oloc.pool = pool;
fs/ceph/addr.c:		rd_req->r_base_oloc.pool_ns = ceph_get_string(pool_ns);
fs/ceph/addr.c:	ceph_oid_printf(&rd_req->r_base_oid, "%llx.00000000", ci->i_vino.ino);
fs/ceph/addr.c:	wr_req->r_flags = CEPH_OSD_FLAG_WRITE;
fs/ceph/addr.c:	ceph_oloc_copy(&wr_req->r_base_oloc, &rd_req->r_base_oloc);
fs/ceph/addr.c:	ceph_oid_copy(&wr_req->r_base_oid, &rd_req->r_base_oid);
fs/ceph/addr.c:	wr_req->r_mtime = ci->vfs_inode.i_mtime;
fs/ceph/super.c:	req->r_path1 = kstrdup(path, GFP_NOFS);
fs/ceph/super.c:	if (!req->r_path1) {
fs/ceph/super.c:	req->r_ino1.ino = CEPH_INO_ROOT;
fs/ceph/super.c:	req->r_ino1.snap = CEPH_NOSNAP;
fs/ceph/super.c:	req->r_started = started;
fs/ceph/super.c:	req->r_timeout = fsc->client->options->mount_timeout;
fs/ceph/super.c:	req->r_args.getattr.mask = cpu_to_le32(CEPH_STAT_CAP_INODE);
fs/ceph/super.c:	req->r_num_caps = 2;
fs/ceph/super.c:		struct inode *inode = req->r_target_inode;
fs/ceph/super.c:		req->r_target_inode = NULL;
fs/ceph/inode.c:	struct ceph_mds_session *session = req->r_session;
fs/ceph/inode.c:	struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
fs/ceph/inode.c:		if (rinfo->head->result == 0 && req->r_parent)
fs/ceph/inode.c:		struct inode *dir = req->r_parent;
fs/ceph/inode.c:					      &req->r_caps_reservation);
fs/ceph/inode.c:		if (dir && req->r_op == CEPH_MDS_OP_LOOKUPNAME &&
fs/ceph/inode.c:		    test_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags) &&
fs/ceph/inode.c:		    !test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags)) {
fs/ceph/inode.c:			BUG_ON(req->r_dentry);
fs/ceph/inode.c:			req->r_dentry = dn;
fs/ceph/inode.c:		BUG_ON(!req->r_target_inode);
fs/ceph/inode.c:		in = req->r_target_inode;
fs/ceph/inode.c:		err = ceph_fill_inode(in, req->r_locked_page, &rinfo->targeti,
fs/ceph/inode.c:				(!test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags) &&
fs/ceph/inode.c:				 !test_bit(CEPH_MDS_R_ASYNC, &req->r_req_flags) &&
fs/ceph/inode.c:				 rinfo->head->result == 0) ?  req->r_fmode : -1,
fs/ceph/inode.c:				&req->r_caps_reservation);
fs/ceph/inode.c:			req->r_target_inode = NULL;
fs/ceph/inode.c:            !test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags) &&
fs/ceph/inode.c:	    test_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags) &&
fs/ceph/inode.c:	    (rinfo->head->is_target || strncmp(req->r_dentry->d_name.name,
fs/ceph/inode.c:					       req->r_dentry->d_name.len))) {
fs/ceph/inode.c:		struct inode *dir = req->r_parent;
fs/ceph/inode.c:		struct dentry *dn = req->r_dentry;
fs/ceph/inode.c:		if (req->r_old_dentry && req->r_op == CEPH_MDS_OP_RENAME) {
fs/ceph/inode.c:			struct inode *olddir = req->r_old_dentry_dir;
fs/ceph/inode.c:			     req->r_old_dentry,
fs/ceph/inode.c:			     req->r_old_dentry,
fs/ceph/inode.c:			     req->r_old_dentry, dn);
fs/ceph/inode.c:			d_move(req->r_old_dentry, dn);
fs/ceph/inode.c:			     req->r_old_dentry,
fs/ceph/inode.c:			     req->r_old_dentry,
fs/ceph/inode.c:			dout("dn %p gets new offset %lld\n", req->r_old_dentry,
fs/ceph/inode.c:			     ceph_dentry(req->r_old_dentry)->offset);
fs/ceph/inode.c:			req->r_dentry = req->r_old_dentry;
fs/ceph/inode.c:			req->r_old_dentry = dn;
fs/ceph/inode.c:			dn = req->r_dentry;
fs/ceph/inode.c:						    req->r_request_started);
fs/ceph/inode.c:			err = splice_dentry(&req->r_dentry, in);
fs/ceph/inode.c:			dn = req->r_dentry;  /* may have spliced */
fs/ceph/inode.c:					    req->r_request_started);
fs/ceph/inode.c:	} else if ((req->r_op == CEPH_MDS_OP_LOOKUPSNAP ||
fs/ceph/inode.c:		    req->r_op == CEPH_MDS_OP_MKSNAP) &&
fs/ceph/inode.c:	           test_bit(CEPH_MDS_R_PARENT_LOCKED, &req->r_req_flags) &&
fs/ceph/inode.c:		   !test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags)) {
fs/ceph/inode.c:		struct inode *dir = req->r_parent;
fs/ceph/inode.c:		BUG_ON(!req->r_dentry);
fs/ceph/inode.c:		dout(" linking snapped dir %p to dn %p\n", in, req->r_dentry);
fs/ceph/inode.c:		err = splice_dentry(&req->r_dentry, in);
fs/ceph/inode.c:	} else if (rinfo->head->is_dentry && req->r_dentry) {
fs/ceph/inode.c:		update_dentry_lease_careful(req->r_dentry, rinfo->dlease,
fs/ceph/inode.c:					    session, req->r_request_started,
fs/ceph/inode.c:	struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
fs/ceph/inode.c:		in = ceph_get_inode(req->r_dentry->d_sb, vino);
fs/ceph/inode.c:				     -1, &req->r_caps_reservation);
fs/ceph/inode.c:	if (req->r_dir_release_cnt == atomic64_read(&ci->i_release_count) &&
fs/ceph/inode.c:	    req->r_dir_ordered_cnt == atomic64_read(&ci->i_ordered_count)) {
fs/ceph/inode.c:	struct dentry *parent = req->r_dentry;
fs/ceph/inode.c:	struct ceph_mds_reply_info_parsed *rinfo = &req->r_reply_info;
fs/ceph/inode.c:	u32 frag = le32_to_cpu(req->r_args.readdir.frag);
fs/ceph/inode.c:	if (test_bit(CEPH_MDS_R_ABORTED, &req->r_req_flags))
fs/ceph/inode.c:		if (req->r_path2) {
fs/ceph/inode.c:						  req->r_path2,
fs/ceph/inode.c:						  strlen(req->r_path2));
fs/ceph/inode.c:			WARN_ON_ONCE(req->r_readdir_offset != 2);
fs/ceph/inode.c:			last_hash = le32_to_cpu(req->r_args.readdir.offset_hash);
fs/ceph/inode.c:			req->r_readdir_offset = 2;
fs/ceph/inode.c:		    req->r_readdir_offset == 2 &&
fs/ceph/inode.c:			req->r_dir_release_cnt =
fs/ceph/inode.c:			req->r_dir_ordered_cnt =
fs/ceph/inode.c:			req->r_readdir_cache_idx = 0;
fs/ceph/inode.c:	cache_ctl.index = req->r_readdir_cache_idx;
fs/ceph/inode.c:	fpos_offset = req->r_readdir_offset;
fs/ceph/inode.c:				      -1, &req->r_caps_reservation);
fs/ceph/inode.c:				    rde->lease, req->r_session,
fs/ceph/inode.c:				    req->r_request_started);
fs/ceph/inode.c:		set_bit(CEPH_MDS_R_DID_PREPOPULATE, &req->r_req_flags);
fs/ceph/inode.c:		req->r_readdir_cache_idx = cache_ctl.index;
fs/ceph/inode.c:			req->r_args.setattr.uid = cpu_to_le32(
fs/ceph/inode.c:			req->r_args.setattr.gid = cpu_to_le32(
fs/ceph/inode.c:			req->r_args.setattr.mode = cpu_to_le32(attr->ia_mode);
fs/ceph/inode.c:			ceph_encode_timespec64(&req->r_args.setattr.atime,
fs/ceph/inode.c:			req->r_args.setattr.size = cpu_to_le64(attr->ia_size);
fs/ceph/inode.c:			req->r_args.setattr.old_size =
fs/ceph/inode.c:			ceph_encode_timespec64(&req->r_args.setattr.mtime,
fs/ceph/inode.c:		req->r_inode = inode;
fs/ceph/inode.c:		req->r_inode_drop = release;
fs/ceph/inode.c:		req->r_args.setattr.mask = cpu_to_le32(mask);
fs/ceph/inode.c:		req->r_num_caps = 1;
fs/ceph/inode.c:		req->r_stamp = attr->ia_ctime;
fs/ceph/inode.c:	req->r_inode = inode;
fs/ceph/inode.c:	req->r_num_caps = 1;
fs/ceph/inode.c:	req->r_args.getattr.mask = cpu_to_le32(mask);
fs/ceph/inode.c:	req->r_locked_page = locked_page;
fs/ceph/inode.c:		u64 inline_version = req->r_reply_info.targeti.inline_version;
fs/ceph/inode.c:			err = req->r_reply_info.targeti.inline_len;
fs/ceph/debugfs.c:		if (req->r_request && req->r_session)
fs/ceph/debugfs.c:			seq_printf(s, "%lld\tmds%d\t", req->r_tid,
fs/ceph/debugfs.c:				   req->r_session->s_mds);
fs/ceph/debugfs.c:		else if (!req->r_request)
fs/ceph/debugfs.c:			seq_printf(s, "%lld\t(no request)\t", req->r_tid);
fs/ceph/debugfs.c:			seq_printf(s, "%lld\t(no session)\t", req->r_tid);
fs/ceph/debugfs.c:		seq_printf(s, "%s", ceph_mds_op_name(req->r_op));
fs/ceph/debugfs.c:		if (test_bit(CEPH_MDS_R_GOT_UNSAFE, &req->r_req_flags))
fs/ceph/debugfs.c:		if (req->r_inode) {
fs/ceph/debugfs.c:			seq_printf(s, " #%llx", ceph_ino(req->r_inode));
fs/ceph/debugfs.c:		} else if (req->r_dentry) {
fs/ceph/debugfs.c:			path = ceph_mdsc_build_path(req->r_dentry, &pathlen,
fs/ceph/debugfs.c:			spin_lock(&req->r_dentry->d_lock);
fs/ceph/debugfs.c:				   ceph_ino(d_inode(req->r_dentry->d_parent)),
fs/ceph/debugfs.c:				   req->r_dentry,
fs/ceph/debugfs.c:			spin_unlock(&req->r_dentry->d_lock);
fs/ceph/debugfs.c:		} else if (req->r_path1) {
fs/ceph/debugfs.c:			seq_printf(s, " #%llx/%s", req->r_ino1.ino,
fs/ceph/debugfs.c:				   req->r_path1);
fs/ceph/debugfs.c:			seq_printf(s, " #%llx", req->r_ino1.ino);
fs/ceph/debugfs.c:		if (req->r_old_dentry) {
fs/ceph/debugfs.c:			path = ceph_mdsc_build_path(req->r_old_dentry, &pathlen,
fs/ceph/debugfs.c:			spin_lock(&req->r_old_dentry->d_lock);
fs/ceph/debugfs.c:				   req->r_old_dentry_dir ?
fs/ceph/debugfs.c:				   ceph_ino(req->r_old_dentry_dir) : 0,
fs/ceph/debugfs.c:				   req->r_old_dentry,
fs/ceph/debugfs.c:			spin_unlock(&req->r_old_dentry->d_lock);
fs/ceph/debugfs.c:		} else if (req->r_path2 && req->r_op != CEPH_MDS_OP_SYMLINK) {
fs/ceph/debugfs.c:			if (req->r_ino2.ino)
fs/ceph/debugfs.c:				seq_printf(s, " #%llx/%s", req->r_ino2.ino,
fs/ceph/debugfs.c:					   req->r_path2);
fs/ceph/debugfs.c:				seq_printf(s, " %s", req->r_path2);
fs/afs/yfsclient.c:	       call->unmarshall, iov_iter_count(call->iter), req->actual_len);
fs/afs/yfsclient.c:		req->actual_len = 0;
fs/afs/yfsclient.c:		req->index = 0;
fs/afs/yfsclient.c:		req->offset = req->pos & (PAGE_SIZE - 1);
fs/afs/yfsclient.c:		req->actual_len = be64_to_cpu(call->tmp64);
fs/afs/yfsclient.c:		_debug("DATA length: %llu", req->actual_len);
fs/afs/yfsclient.c:		req->remain = min(req->len, req->actual_len);
fs/afs/yfsclient.c:		if (req->remain == 0)
fs/afs/yfsclient.c:		ASSERTCMP(req->index, <, req->nr_pages);
fs/afs/yfsclient.c:		if (req->remain > PAGE_SIZE - req->offset)
fs/afs/yfsclient.c:			size = PAGE_SIZE - req->offset;
fs/afs/yfsclient.c:			size = req->remain;
fs/afs/yfsclient.c:		call->bvec[0].bv_offset = req->offset;
fs/afs/yfsclient.c:		call->bvec[0].bv_page = req->pages[req->index];
fs/afs/yfsclient.c:		       iov_iter_count(call->iter), req->remain);
fs/afs/yfsclient.c:		req->remain -= call->bvec[0].bv_len;
fs/afs/yfsclient.c:		req->offset += call->bvec[0].bv_len;
fs/afs/yfsclient.c:		ASSERTCMP(req->offset, <=, PAGE_SIZE);
fs/afs/yfsclient.c:		if (req->offset == PAGE_SIZE) {
fs/afs/yfsclient.c:			req->offset = 0;
fs/afs/yfsclient.c:			req->index++;
fs/afs/yfsclient.c:			if (req->remain > 0)
fs/afs/yfsclient.c:		ASSERTCMP(req->remain, ==, 0);
fs/afs/yfsclient.c:		if (req->actual_len <= req->len)
fs/afs/yfsclient.c:		afs_extract_discard(call, req->actual_len - req->len);
fs/afs/yfsclient.c:		       iov_iter_count(call->iter), req->actual_len - req->len);
fs/afs/yfsclient.c:		req->data_version = vp->scb.status.data_version;
fs/afs/yfsclient.c:		req->file_size = vp->scb.status.size;
fs/afs/yfsclient.c:	for (; req->index < req->nr_pages; req->index++) {
fs/afs/yfsclient.c:		if (req->offset < PAGE_SIZE)
fs/afs/yfsclient.c:			zero_user_segment(req->pages[req->index],
fs/afs/yfsclient.c:					  req->offset, PAGE_SIZE);
fs/afs/yfsclient.c:		req->offset = 0;
fs/afs/yfsclient.c:	if (req->page_done)
fs/afs/yfsclient.c:		for (req->index = 0; req->index < req->nr_pages; req->index++)
fs/afs/yfsclient.c:			req->page_done(req);
fs/afs/yfsclient.c:	       req->pos, req->len);
fs/afs/yfsclient.c:	bp = xdr_encode_u64(bp, req->pos);
fs/afs/yfsclient.c:	bp = xdr_encode_u64(bp, req->len);
fs/afs/file.c:	if (refcount_dec_and_test(&req->usage)) {
fs/afs/file.c:		if (req->pages) {
fs/afs/file.c:			for (i = 0; i < req->nr_pages; i++)
fs/afs/file.c:				if (req->pages[i])
fs/afs/file.c:					put_page(req->pages[i]);
fs/afs/file.c:			if (req->pages != req->array)
fs/afs/file.c:				kfree(req->pages);
fs/afs/file.c:	atomic_long_add(op->fetch.req->actual_len, &op->net->n_fetch_bytes);
fs/afs/file.c:		refcount_set(&req->usage, 1);
fs/afs/file.c:		req->pos = (loff_t)page->index << PAGE_SHIFT;
fs/afs/file.c:		req->len = PAGE_SIZE;
fs/afs/file.c:		req->nr_pages = 1;
fs/afs/file.c:		req->pages = req->array;
fs/afs/file.c:		req->pages[0] = page;
fs/afs/file.c:	struct afs_vnode *vnode = req->vnode;
fs/afs/file.c:	struct page *page = req->pages[req->index];
fs/afs/file.c:	req->pages[req->index] = NULL;
fs/afs/file.c:	refcount_set(&req->usage, 1);
fs/afs/file.c:	req->vnode = vnode;
fs/afs/file.c:	req->page_done = afs_readpages_page_done;
fs/afs/file.c:	req->pos = first->index;
fs/afs/file.c:	req->pos <<= PAGE_SHIFT;
fs/afs/file.c:	req->pages = req->array;
fs/afs/file.c:		req->pages[req->nr_pages++] = page;
fs/afs/file.c:		req->len += PAGE_SIZE;
fs/afs/file.c:	} while (req->nr_pages < n);
fs/afs/file.c:	if (req->nr_pages == 0) {
fs/afs/file.c:	task_io_account_read(PAGE_SIZE * req->nr_pages);
fs/afs/file.c:	for (i = 0; i < req->nr_pages; i++) {
fs/afs/file.c:		page = req->pages[i];
fs/afs/internal.h:	refcount_inc(&req->usage);
fs/afs/dir.c:	for (i = 0; i < req->nr_pages; i++)
fs/afs/dir.c:		if (!afs_dir_check_page(dvnode, req->pages[i], req->actual_len))
fs/afs/dir.c:		req->file_size, req->len, req->actual_len, req->remain);
fs/afs/dir.c:		req->pos, req->index, req->nr_pages, req->offset);
fs/afs/dir.c:	for (i = 0; i < req->nr_pages; i++) {
fs/afs/dir.c:		dbuf = kmap(req->pages[i]);
fs/afs/dir.c:		kunmap(req->pages[i]);
fs/afs/dir.c:	refcount_set(&req->usage, 1);
fs/afs/dir.c:	req->nr_pages = nr_pages;
fs/afs/dir.c:	req->actual_len = i_size; /* May change */
fs/afs/dir.c:	req->len = nr_pages * PAGE_SIZE; /* We can ask for more than there is */
fs/afs/dir.c:	req->data_version = dvnode->status.data_version; /* May change */
fs/afs/dir.c:		req->pages = req->array;
fs/afs/dir.c:		req->pages = kcalloc(nr_pages, sizeof(struct page *),
fs/afs/dir.c:		if (!req->pages)
fs/afs/dir.c:					  req->nr_pages - i,
fs/afs/dir.c:					  req->pages + i);
fs/afs/dir.c:		_debug("find %u at %u/%u", n, i, req->nr_pages);
fs/afs/dir.c:			req->pages[i] = __page_cache_alloc(gfp);
fs/afs/dir.c:			if (!req->pages[i])
fs/afs/dir.c:			ret = add_to_page_cache_lru(req->pages[i],
fs/afs/dir.c:			attach_page_private(req->pages[i], (void *)1);
fs/afs/dir.c:			unlock_page(req->pages[i]);
fs/afs/dir.c:	} while (i < req->nr_pages);
fs/afs/dir.c:		task_io_account_read(PAGE_SIZE * req->nr_pages);
fs/afs/dir.c:		if (req->len < req->file_size)
fs/afs/dir.c:	*_dir_version = req->data_version;
fs/afs/dir.c:	while (ctx->pos < req->actual_len) {
fs/afs/dir.c:		page = req->pages[blkoff / PAGE_SIZE];
fs/afs/write.c:	refcount_set(&req->usage, 1);
fs/afs/write.c:	req->pos = pos;
fs/afs/write.c:	req->len = len;
fs/afs/write.c:	req->nr_pages = 1;
fs/afs/write.c:	req->pages = req->array;
fs/afs/write.c:	req->pages[0] = page;
fs/afs/fsclient.c:	       call->unmarshall, iov_iter_count(call->iter), req->actual_len);
fs/afs/fsclient.c:		req->actual_len = 0;
fs/afs/fsclient.c:		req->index = 0;
fs/afs/fsclient.c:		req->offset = req->pos & (PAGE_SIZE - 1);
fs/afs/fsclient.c:		req->actual_len = be64_to_cpu(call->tmp64);
fs/afs/fsclient.c:		_debug("DATA length: %llu", req->actual_len);
fs/afs/fsclient.c:		req->remain = min(req->len, req->actual_len);
fs/afs/fsclient.c:		if (req->remain == 0)
fs/afs/fsclient.c:		ASSERTCMP(req->index, <, req->nr_pages);
fs/afs/fsclient.c:		if (req->remain > PAGE_SIZE - req->offset)
fs/afs/fsclient.c:			size = PAGE_SIZE - req->offset;
fs/afs/fsclient.c:			size = req->remain;
fs/afs/fsclient.c:		call->bvec[0].bv_offset = req->offset;
fs/afs/fsclient.c:		call->bvec[0].bv_page = req->pages[req->index];
fs/afs/fsclient.c:		       iov_iter_count(call->iter), req->remain);
fs/afs/fsclient.c:		req->remain -= call->bvec[0].bv_len;
fs/afs/fsclient.c:		req->offset += call->bvec[0].bv_len;
fs/afs/fsclient.c:		ASSERTCMP(req->offset, <=, PAGE_SIZE);
fs/afs/fsclient.c:		if (req->offset == PAGE_SIZE) {
fs/afs/fsclient.c:			req->offset = 0;
fs/afs/fsclient.c:			req->index++;
fs/afs/fsclient.c:			if (req->remain > 0)
fs/afs/fsclient.c:		ASSERTCMP(req->remain, ==, 0);
fs/afs/fsclient.c:		if (req->actual_len <= req->len)
fs/afs/fsclient.c:		afs_extract_discard(call, req->actual_len - req->len);
fs/afs/fsclient.c:		       iov_iter_count(call->iter), req->actual_len - req->len);
fs/afs/fsclient.c:		req->data_version = vp->scb.status.data_version;
fs/afs/fsclient.c:		req->file_size = vp->scb.status.size;
fs/afs/fsclient.c:	for (; req->index < req->nr_pages; req->index++) {
fs/afs/fsclient.c:		if (req->offset < PAGE_SIZE)
fs/afs/fsclient.c:			zero_user_segment(req->pages[req->index],
fs/afs/fsclient.c:					  req->offset, PAGE_SIZE);
fs/afs/fsclient.c:		req->offset = 0;
fs/afs/fsclient.c:	if (req->page_done)
fs/afs/fsclient.c:		for (req->index = 0; req->index < req->nr_pages; req->index++)
fs/afs/fsclient.c:			req->page_done(req);
fs/afs/fsclient.c:	bp[4] = htonl(upper_32_bits(req->pos));
fs/afs/fsclient.c:	bp[5] = htonl(lower_32_bits(req->pos));
fs/afs/fsclient.c:	bp[7] = htonl(lower_32_bits(req->len));
fs/afs/fsclient.c:	if (upper_32_bits(req->pos) ||
fs/afs/fsclient.c:	    upper_32_bits(req->len) ||
fs/afs/fsclient.c:	    upper_32_bits(req->pos + req->len))
fs/afs/fsclient.c:	bp[4] = htonl(lower_32_bits(req->pos));
fs/afs/fsclient.c:	bp[5] = htonl(lower_32_bits(req->len));
fs/lockd/clntproc.c:	struct nlm_args	*argp = &req->a_args;
fs/lockd/clntproc.c:	char *nodename = req->a_host->h_rpcclnt->cl_nodename;
fs/lockd/clntproc.c:	lock->oh.data = req->a_owner;
fs/lockd/clntproc.c:	lock->oh.len  = snprintf(req->a_owner, sizeof(req->a_owner), "%u@%s",
fs/lockd/clntproc.c:	WARN_ON_ONCE(req->a_args.lock.fl.fl_ops != NULL);
fs/lockd/clntproc.c:	struct nlm_host	*host = req->a_host;
fs/lockd/clntproc.c:	struct nlm_args	*argp = &req->a_args;
fs/lockd/clntproc.c:	struct nlm_res	*resp = &req->a_res;
fs/lockd/clntproc.c:	struct nlm_host	*host = req->a_host;
fs/lockd/clntproc.c:		.rpc_argp	= &req->a_args,
fs/lockd/clntproc.c:		.rpc_resp	= &req->a_res,
fs/lockd/clntproc.c:		.rpc_argp	= &req->a_res,
fs/lockd/clntproc.c:		.rpc_argp	= &req->a_args,
fs/lockd/clntproc.c:		.rpc_resp	= &req->a_res,
fs/lockd/clntproc.c:	switch (req->a_res.status) {
fs/lockd/clntproc.c:			fl->fl_start = req->a_res.lock.fl.fl_start;
fs/lockd/clntproc.c:			fl->fl_end = req->a_res.lock.fl.fl_end;
fs/lockd/clntproc.c:			fl->fl_type = req->a_res.lock.fl.fl_type;
fs/lockd/clntproc.c:			fl->fl_pid = -req->a_res.lock.fl.fl_pid;
fs/lockd/clntproc.c:			status = nlm_stat_to_errno(req->a_res.status);
fs/lockd/clntproc.c:	struct nlm_host	*host = req->a_host;
fs/lockd/clntproc.c:	struct nlm_res	*resp = &req->a_res;
fs/lockd/clntproc.c:	req->a_args.state = nsm_local_state;
fs/lockd/clntproc.c:		if (!req->a_args.block)
fs/lockd/clntproc.c:		if (nlmclnt_cancel(host, req->a_args.block, fl) == 0)
fs/lockd/clntproc.c:	locks_init_lock(&req->a_args.lock.fl);
fs/lockd/clntproc.c:	locks_init_lock(&req->a_res.lock.fl);
fs/lockd/clntproc.c:	req->a_host  = host;
fs/lockd/clntproc.c:	req->a_args.reclaim = 1;
fs/lockd/clntproc.c:	if (status >= 0 && req->a_res.status == nlm_granted)
fs/lockd/clntproc.c:				status, ntohl(req->a_res.status));
fs/lockd/clntproc.c:	struct nlm_host	*host = req->a_host;
fs/lockd/clntproc.c:	struct nlm_res	*resp = &req->a_res;
fs/lockd/clntproc.c:	refcount_inc(&req->a_count);
fs/lockd/clntproc.c:	const struct nlmclnt_operations *nlmclnt_ops = req->a_host->h_nlmclnt_ops;
fs/lockd/clntproc.c:		defer_call = nlmclnt_ops->nlmclnt_unlock_prepare(task, req->a_callback_data);
fs/lockd/clntproc.c:	u32 status = ntohl(req->a_res.status);
fs/lockd/clntproc.c:	nlm_rebind_host(req->a_host);
fs/lockd/clntproc.c:	req->a_flags = RPC_TASK_ASYNC;
fs/lockd/clntproc.c:	req->a_args.block = block;
fs/lockd/clntproc.c:	refcount_inc(&req->a_count);
fs/lockd/clntproc.c:	if (status == 0 && req->a_res.status == nlm_lck_denied)
fs/lockd/clntproc.c:	u32 status = ntohl(req->a_res.status);
fs/lockd/clntproc.c:	if (req->a_retries++ >= NLMCLNT_MAX_RETRIES)
fs/lockd/clntproc.c:	nlm_rebind_host(req->a_host);
fs/lockd/clntlock.c:	req->a_res.status = block->b_status;
fs/lockd/svclock.c:		block->b_deferred_req->revisit(block->b_deferred_req, 0);
fs/coda/upcall.c:	add_wait_queue(&req->uc_sleep, &wait);
fs/coda/upcall.c:		if (req->uc_flags & (CODA_REQ_WRITE | CODA_REQ_ABORT))
fs/coda/upcall.c:			list_del(&req->uc_chain);
fs/coda/upcall.c:	remove_wait_queue(&req->uc_sleep, &wait);
fs/coda/upcall.c:	req->uc_data = (void *)buffer;
fs/coda/upcall.c:	req->uc_flags = outSize ? 0 : CODA_REQ_ASYNC;
fs/coda/upcall.c:	req->uc_inSize = inSize;
fs/coda/upcall.c:	req->uc_outSize = (outSize && *outSize) ? *outSize : inSize;
fs/coda/upcall.c:	req->uc_opcode = buffer->ih.opcode;
fs/coda/upcall.c:	req->uc_unique = buffer->ih.unique;
fs/coda/upcall.c:	init_waitqueue_head(&req->uc_sleep);
fs/coda/upcall.c:	list_add_tail(&req->uc_chain, &vcp->vc_pending);
fs/coda/upcall.c:	if (req->uc_flags & CODA_REQ_ASYNC) {
fs/coda/upcall.c:	if (req->uc_flags & CODA_REQ_WRITE) {
fs/coda/upcall.c:		out = (union outputArgs *)req->uc_data;
fs/coda/upcall.c:		*outSize = req->uc_outSize;
fs/coda/upcall.c:	if ((req->uc_flags & CODA_REQ_ABORT) || !signal_pending(current)) {
fs/coda/upcall.c:	if (!(req->uc_flags & CODA_REQ_READ))
fs/coda/upcall.c:	sig_inputArgs->ih.unique = req->uc_unique;
fs/coda/upcall.c:	sig_req->uc_flags = CODA_REQ_ASYNC;
fs/coda/upcall.c:	sig_req->uc_opcode = sig_inputArgs->ih.opcode;
fs/coda/upcall.c:	sig_req->uc_unique = sig_inputArgs->ih.unique;
fs/coda/upcall.c:	sig_req->uc_data = (void *)sig_inputArgs;
fs/coda/upcall.c:	sig_req->uc_inSize = sizeof(struct coda_in_hdr);
fs/coda/upcall.c:	sig_req->uc_outSize = sizeof(struct coda_in_hdr);
fs/coda/upcall.c:	list_add(&(sig_req->uc_chain), &vcp->vc_pending);
fs/coda/psdev.c:			list_del(&req->uc_chain);
fs/coda/psdev.c:	if (req->uc_outSize < nbytes) {
fs/coda/psdev.c:			__func__, req->uc_outSize, (long)nbytes,
fs/coda/psdev.c:		nbytes = req->uc_outSize; /* don't have more space! */
fs/coda/psdev.c:        if (copy_from_user(req->uc_data, buf, nbytes)) {
fs/coda/psdev.c:		req->uc_flags |= CODA_REQ_ABORT;
fs/coda/psdev.c:		wake_up(&req->uc_sleep);
fs/coda/psdev.c:	req->uc_outSize = nbytes;
fs/coda/psdev.c:	req->uc_flags |= CODA_REQ_WRITE;
fs/coda/psdev.c:	if (req->uc_opcode == CODA_OPEN_BY_FD) {
fs/coda/psdev.c:			(struct coda_open_by_fd_out *)req->uc_data;
fs/coda/psdev.c:        wake_up(&req->uc_sleep);
fs/coda/psdev.c:	list_del(&req->uc_chain);
fs/coda/psdev.c:	count = req->uc_inSize;
fs/coda/psdev.c:	if (nbytes < req->uc_inSize) {
fs/coda/psdev.c:			__func__, (long)nbytes, req->uc_inSize);
fs/coda/psdev.c:	if (copy_to_user(buf, req->uc_data, count))
fs/coda/psdev.c:	if (!(req->uc_flags & CODA_REQ_ASYNC)) {
fs/coda/psdev.c:		req->uc_flags |= CODA_REQ_READ;
fs/coda/psdev.c:		list_add_tail(&(req->uc_chain), &vcp->vc_processing);
fs/coda/psdev.c:	kvfree(req->uc_data);
fs/coda/psdev.c:		list_del(&req->uc_chain);
fs/coda/psdev.c:		if (req->uc_flags & CODA_REQ_ASYNC) {
fs/coda/psdev.c:			kvfree(req->uc_data);
fs/coda/psdev.c:		req->uc_flags |= CODA_REQ_ABORT;
fs/coda/psdev.c:		wake_up(&req->uc_sleep);
fs/coda/psdev.c:		list_del(&req->uc_chain);
fs/coda/psdev.c:		req->uc_flags |= CODA_REQ_ABORT;
fs/coda/psdev.c:		wake_up(&req->uc_sleep);
fs/nilfs2/bmap.h:		return nilfs_dat_prepare_alloc(dat, &req->bpr_req);
fs/nilfs2/bmap.h:	req->bpr_ptr = bmap->b_last_allocated_ptr++;
fs/nilfs2/bmap.h:		nilfs_dat_commit_alloc(dat, &req->bpr_req);
fs/nilfs2/bmap.h:		nilfs_dat_abort_alloc(dat, &req->bpr_req);
fs/nilfs2/bmap.h:	return dat ? nilfs_dat_prepare_end(dat, &req->bpr_req) : 0;
fs/nilfs2/bmap.h:		nilfs_dat_commit_end(dat, &req->bpr_req,
fs/nilfs2/bmap.h:		nilfs_dat_abort_end(dat, &req->bpr_req);
fs/nilfs2/dat.c:	return nilfs_palloc_get_entry_block(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					    create, &req->pr_entry_bh);
fs/nilfs2/dat.c:	mark_buffer_dirty(req->pr_entry_bh);
fs/nilfs2/dat.c:	brelse(req->pr_entry_bh);
fs/nilfs2/dat.c:	brelse(req->pr_entry_bh);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/dat.c:	kaddr = kmap_atomic(req->pr_entry_bh->b_page);
fs/nilfs2/dat.c:	entry = nilfs_palloc_block_get_entry(dat, req->pr_entry_nr,
fs/nilfs2/dat.c:					     req->pr_entry_bh, kaddr);
fs/nilfs2/alloc.c:	group = nilfs_palloc_group(inode, req->pr_entry_nr, &group_offset);
fs/nilfs2/alloc.c:			maxgroup = nilfs_palloc_group(inode, req->pr_entry_nr,
fs/nilfs2/alloc.c:					req->pr_entry_nr =
fs/nilfs2/alloc.c:					req->pr_desc_bh = desc_bh;
fs/nilfs2/alloc.c:					req->pr_bitmap_bh = bitmap_bh;
fs/nilfs2/alloc.c:	mark_buffer_dirty(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	mark_buffer_dirty(req->pr_desc_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_desc_bh);
fs/nilfs2/alloc.c:	group = nilfs_palloc_group(inode, req->pr_entry_nr, &group_offset);
fs/nilfs2/alloc.c:	desc_kaddr = kmap(req->pr_desc_bh->b_page);
fs/nilfs2/alloc.c:						 req->pr_desc_bh, desc_kaddr);
fs/nilfs2/alloc.c:	bitmap_kaddr = kmap(req->pr_bitmap_bh->b_page);
fs/nilfs2/alloc.c:	bitmap = bitmap_kaddr + bh_offset(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:			   (unsigned long long)req->pr_entry_nr);
fs/nilfs2/alloc.c:	kunmap(req->pr_bitmap_bh->b_page);
fs/nilfs2/alloc.c:	kunmap(req->pr_desc_bh->b_page);
fs/nilfs2/alloc.c:	mark_buffer_dirty(req->pr_desc_bh);
fs/nilfs2/alloc.c:	mark_buffer_dirty(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_desc_bh);
fs/nilfs2/alloc.c:	group = nilfs_palloc_group(inode, req->pr_entry_nr, &group_offset);
fs/nilfs2/alloc.c:	desc_kaddr = kmap(req->pr_desc_bh->b_page);
fs/nilfs2/alloc.c:						 req->pr_desc_bh, desc_kaddr);
fs/nilfs2/alloc.c:	bitmap_kaddr = kmap(req->pr_bitmap_bh->b_page);
fs/nilfs2/alloc.c:	bitmap = bitmap_kaddr + bh_offset(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:			   (unsigned long long)req->pr_entry_nr);
fs/nilfs2/alloc.c:	kunmap(req->pr_bitmap_bh->b_page);
fs/nilfs2/alloc.c:	kunmap(req->pr_desc_bh->b_page);
fs/nilfs2/alloc.c:	brelse(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_desc_bh);
fs/nilfs2/alloc.c:	req->pr_entry_nr = 0;
fs/nilfs2/alloc.c:	req->pr_bitmap_bh = NULL;
fs/nilfs2/alloc.c:	req->pr_desc_bh = NULL;
fs/nilfs2/alloc.c:	group = nilfs_palloc_group(inode, req->pr_entry_nr, &group_offset);
fs/nilfs2/alloc.c:	req->pr_desc_bh = desc_bh;
fs/nilfs2/alloc.c:	req->pr_bitmap_bh = bitmap_bh;
fs/nilfs2/alloc.c:	brelse(req->pr_bitmap_bh);
fs/nilfs2/alloc.c:	brelse(req->pr_desc_bh);
fs/nilfs2/alloc.c:	req->pr_entry_nr = 0;
fs/nilfs2/alloc.c:	req->pr_bitmap_bh = NULL;
fs/nilfs2/alloc.c:	req->pr_desc_bh = NULL;
fs/nilfs2/btree.c:		dreq->bpr_ptr = nilfs_btree_find_target_v(btree, NULL, key);
fs/nilfs2/btree.c:		nreq->bpr_ptr = dreq->bpr_ptr + 1;
fs/nilfs2/btree.c:		ret = nilfs_btree_get_new_block(btree, nreq->bpr_ptr, &bh);
fs/nilfs2/btree.c:		nilfs_btree_node_insert(node, n, key, dreq->bpr_ptr, ncblk);
fs/nilfs2/btree.c:		tmpptr = nreq->bpr_ptr;
fs/nilfs2/btree.c:		nilfs_btree_node_insert(node, n, key, dreq->bpr_ptr,
fs/nilfs2/btree.c:		nilfs_bmap_set_target_v(btree, key, dreq->bpr_ptr);
crypto/testmgr.c:	testmgr_poison(req->__ctx, crypto_ahash_reqsize(tfm));
crypto/testmgr.c:			testmgr_poison(req->__ctx, crypto_ahash_reqsize(tfm));
crypto/testmgr.c:	testmgr_poison(req->__ctx, crypto_aead_reqsize(tfm));
crypto/testmgr.c:	if (req->cryptlen != (enc ? vec->plen : vec->clen) ||
crypto/testmgr.c:	    req->assoclen != vec->alen ||
crypto/testmgr.c:	    req->iv != iv ||
crypto/testmgr.c:	    req->src != tsgls->src.sgl_ptr ||
crypto/testmgr.c:	    req->dst != tsgls->dst.sgl_ptr ||
crypto/testmgr.c:	    req->base.complete != crypto_req_done ||
crypto/testmgr.c:	    req->base.flags != req_flags ||
crypto/testmgr.c:	    req->base.data != &wait) {
crypto/testmgr.c:		if (req->cryptlen != (enc ? vec->plen : vec->clen))
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->cryptlen'\n");
crypto/testmgr.c:		if (req->assoclen != vec->alen)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->assoclen'\n");
crypto/testmgr.c:		if (req->iv != iv)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->iv'\n");
crypto/testmgr.c:		if (req->src != tsgls->src.sgl_ptr)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->src'\n");
crypto/testmgr.c:		if (req->dst != tsgls->dst.sgl_ptr)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->dst'\n");
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->base.tfm'\n");
crypto/testmgr.c:		if (req->base.complete != crypto_req_done)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->base.complete'\n");
crypto/testmgr.c:		if (req->base.flags != req_flags)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->base.flags'\n");
crypto/testmgr.c:		if (req->base.data != &wait)
crypto/testmgr.c:			pr_err("alg: aead: changed 'req->base.data'\n");
crypto/testmgr.c:	testmgr_poison(req->__ctx, crypto_skcipher_reqsize(tfm));
crypto/testmgr.c:	if (req->cryptlen != vec->len ||
crypto/testmgr.c:	    req->iv != iv ||
crypto/testmgr.c:	    req->src != tsgls->src.sgl_ptr ||
crypto/testmgr.c:	    req->dst != tsgls->dst.sgl_ptr ||
crypto/testmgr.c:	    req->base.complete != crypto_req_done ||
crypto/testmgr.c:	    req->base.flags != req_flags ||
crypto/testmgr.c:	    req->base.data != &wait) {
crypto/testmgr.c:		if (req->cryptlen != vec->len)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->cryptlen'\n");
crypto/testmgr.c:		if (req->iv != iv)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->iv'\n");
crypto/testmgr.c:		if (req->src != tsgls->src.sgl_ptr)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->src'\n");
crypto/testmgr.c:		if (req->dst != tsgls->dst.sgl_ptr)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->dst'\n");
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->base.tfm'\n");
crypto/testmgr.c:		if (req->base.complete != crypto_req_done)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->base.complete'\n");
crypto/testmgr.c:		if (req->base.flags != req_flags)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->base.flags'\n");
crypto/testmgr.c:		if (req->base.data != &wait)
crypto/testmgr.c:			pr_err("alg: skcipher: changed 'req->base.data'\n");
crypto/testmgr.c:		ilen = req->dlen;
crypto/testmgr.c:		if (req->dlen != ctemplate[i].inlen) {
crypto/testmgr.c:			       i + 1, algo, req->dlen);
crypto/testmgr.c:		if (memcmp(input_vec, decomp_out, req->dlen)) {
crypto/testmgr.c:			hexdump(output, req->dlen);
crypto/testmgr.c:		if (req->dlen != dtemplate[i].outlen) {
crypto/testmgr.c:			       i + 1, algo, req->dlen);
crypto/testmgr.c:		if (memcmp(output, dtemplate[i].output, req->dlen)) {
crypto/testmgr.c:			hexdump(output, req->dlen);
crypto/testmgr.c:		a_public = kmemdup(sg_virt(req->dst), out_len_max, GFP_KERNEL);
crypto/testmgr.c:		if (memcmp(vec->expected_a_public, sg_virt(req->dst),
crypto/testmgr.c:		a_ss = kmemdup(sg_virt(req->dst), vec->expected_ss_size, GFP_KERNEL);
crypto/testmgr.c:	if (memcmp(shared_secret, sg_virt(req->dst),
crypto/testmgr.c:		if (req->dst_len != c_size) {
crypto/testmgr.c:		c_size = req->dst_len;
crypto/testmgr.c:	out_len = req->dst_len;
crypto/seqiv.c:	memcpy(req->iv, subreq->iv, crypto_aead_ivsize(geniv));
crypto/seqiv.c:	kfree_sensitive(subreq->iv);
crypto/seqiv.c:	if (req->cryptlen < ivsize)
crypto/seqiv.c:	compl = req->base.complete;
crypto/seqiv.c:	data = req->base.data;
crypto/seqiv.c:	info = req->iv;
crypto/seqiv.c:	if (req->src != req->dst) {
crypto/seqiv.c:		skcipher_request_set_callback(nreq, req->base.flags,
crypto/seqiv.c:		skcipher_request_set_crypt(nreq, req->src, req->dst,
crypto/seqiv.c:					   req->assoclen + req->cryptlen,
crypto/seqiv.c:		info = kmemdup(req->iv, ivsize, req->base.flags &
crypto/seqiv.c:	aead_request_set_callback(subreq, req->base.flags, compl, data);
crypto/seqiv.c:	aead_request_set_crypt(subreq, req->dst, req->dst,
crypto/seqiv.c:			       req->cryptlen - ivsize, info);
crypto/seqiv.c:	aead_request_set_ad(subreq, req->assoclen + ivsize);
crypto/seqiv.c:	scatterwalk_map_and_copy(info, req->dst, req->assoclen, ivsize, 1);
crypto/seqiv.c:	if (unlikely(info != req->iv))
crypto/seqiv.c:	if (req->cryptlen < ivsize + crypto_aead_authsize(geniv))
crypto/seqiv.c:	compl = req->base.complete;
crypto/seqiv.c:	data = req->base.data;
crypto/seqiv.c:	aead_request_set_callback(subreq, req->base.flags, compl, data);
crypto/seqiv.c:	aead_request_set_crypt(subreq, req->src, req->dst,
crypto/seqiv.c:			       req->cryptlen - ivsize, req->iv);
crypto/seqiv.c:	aead_request_set_ad(subreq, req->assoclen + ivsize);
crypto/seqiv.c:	scatterwalk_map_and_copy(req->iv, req->src, req->assoclen, ivsize, 0);
crypto/authencesn.c:	unsigned int assoclen = req->assoclen;
crypto/authencesn.c:	unsigned int cryptlen = req->cryptlen;
crypto/authencesn.c:	struct scatterlist *dst = req->dst;
crypto/authencesn.c:	struct aead_request *req = areq->data;
crypto/authencesn.c:	unsigned int assoclen = req->assoclen;
crypto/authencesn.c:	unsigned int cryptlen = req->cryptlen;
crypto/authencesn.c:	struct scatterlist *dst = req->dst;
crypto/authencesn.c:	struct aead_request *areq = req->data;
crypto/authencesn.c:	skcipher_request_set_crypt(skreq, req->src, req->dst, len, NULL);
crypto/authencesn.c:	unsigned int assoclen = req->assoclen;
crypto/authencesn.c:	unsigned int cryptlen = req->cryptlen;
crypto/authencesn.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, assoclen);
crypto/authencesn.c:	if (req->src != req->dst) {
crypto/authencesn.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, assoclen);
crypto/authencesn.c:	skcipher_request_set_crypt(skreq, src, dst, cryptlen, req->iv);
crypto/authencesn.c:	unsigned int cryptlen = req->cryptlen - authsize;
crypto/authencesn.c:	unsigned int assoclen = req->assoclen;
crypto/authencesn.c:	struct scatterlist *dst = req->dst;
crypto/authencesn.c:				      req->base.complete, req->base.data);
crypto/authencesn.c:	skcipher_request_set_crypt(skreq, dst, dst, cryptlen, req->iv);
crypto/authencesn.c:	struct aead_request *req = areq->data;
crypto/authencesn.c:	unsigned int assoclen = req->assoclen;
crypto/authencesn.c:	unsigned int cryptlen = req->cryptlen;
crypto/authencesn.c:	struct scatterlist *dst = req->dst;
crypto/authencesn.c:	if (req->src != dst) {
crypto/authencesn.c:	scatterwalk_map_and_copy(ihash, req->src, assoclen + cryptlen,
crypto/crypto_engine.c:		enginectx = crypto_tfm_ctx(req->tfm);
crypto/crypto_engine.c:	req->complete(req, err);
crypto/crypto_engine.c:	enginectx = crypto_tfm_ctx(async_req->tfm);
crypto/crypto_engine.c:	async_req->complete(async_req, ret);
crypto/crypto_engine.c:	return crypto_transfer_request_to_engine(engine, &req->base);
crypto/crypto_engine.c:	return crypto_transfer_request_to_engine(engine, &req->base);
crypto/crypto_engine.c:	return crypto_transfer_request_to_engine(engine, &req->base);
crypto/crypto_engine.c:	return crypto_transfer_request_to_engine(engine, &req->base);
crypto/crypto_engine.c:	return crypto_finalize_request(engine, &req->base, err);
crypto/crypto_engine.c:	return crypto_finalize_request(engine, &req->base, err);
crypto/crypto_engine.c:	return crypto_finalize_request(engine, &req->base, err);
crypto/crypto_engine.c:	return crypto_finalize_request(engine, &req->base, err);
crypto/ccm.c:	unsigned int lp = req->iv[0];
crypto/ccm.c:	memcpy(info, req->iv, 16);
crypto/ccm.c:	if (req->assoclen)
crypto/ccm.c:	unsigned int assoclen = req->assoclen;
crypto/ccm.c:		sg_chain(sg, 3, req->src);
crypto/ccm.c:		sg_chain(sg, 2, req->src);
crypto/ccm.c:	struct aead_request *req = areq->data;
crypto/ccm.c:		scatterwalk_map_and_copy(odata, req->dst,
crypto/ccm.c:					 req->assoclen + req->cryptlen,
crypto/ccm.c:	u8 *iv = req->iv;
crypto/ccm.c:	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
crypto/ccm.c:	if (req->src != req->dst) {
crypto/ccm.c:		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
crypto/ccm.c:	unsigned int cryptlen = req->cryptlen;
crypto/ccm.c:	u8 *iv = req->iv;
crypto/ccm.c:	if (req->src != req->dst)
crypto/ccm.c:	struct aead_request *req = areq->data;
crypto/ccm.c:	unsigned int cryptlen = req->cryptlen - authsize;
crypto/ccm.c:	dst = sg_next(req->src == req->dst ? pctx->src : pctx->dst);
crypto/ccm.c:	unsigned int cryptlen = req->cryptlen;
crypto/ccm.c:	if (req->src != req->dst)
crypto/ccm.c:	memcpy(iv, req->iv, 16);
crypto/ccm.c:	memcpy(iv + 4, req->iv, 8);
crypto/ccm.c:	scatterwalk_map_and_copy(iv + 16, req->src, 0, req->assoclen - 8, 0);
crypto/ccm.c:	sg_set_buf(rctx->src, iv + 16, req->assoclen - 8);
crypto/ccm.c:	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
crypto/ccm.c:	if (req->src != req->dst) {
crypto/ccm.c:		sg_set_buf(rctx->dst, iv + 16, req->assoclen - 8);
crypto/ccm.c:		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
crypto/ccm.c:	aead_request_set_callback(subreq, req->base.flags, req->base.complete,
crypto/ccm.c:				  req->base.data);
crypto/ccm.c:			       req->src == req->dst ? rctx->src : rctx->dst,
crypto/ccm.c:			       req->cryptlen, iv);
crypto/ccm.c:	aead_request_set_ad(subreq, req->assoclen - 8);
crypto/ccm.c:	if (req->assoclen != 16 && req->assoclen != 20)
crypto/ccm.c:	if (req->assoclen != 16 && req->assoclen != 20)
crypto/lrw.c:	struct skcipher_request *req = areq->data;
crypto/lrw.c:	skcipher_request_set_callback(subreq, req->base.flags, lrw_crypt_done,
crypto/lrw.c:	/* pass req->iv as IV (will be used by xor_tweak, ECB will ignore it) */
crypto/lrw.c:	skcipher_request_set_crypt(subreq, req->dst, req->dst,
crypto/lrw.c:				   req->cryptlen, req->iv);
crypto/lrw.c:	memcpy(&rctx->t, req->iv, sizeof(rctx->t));
crypto/keywrap.c:	u64 t = 6 * ((req->cryptlen) >> 3);
crypto/keywrap.c:	if (req->cryptlen < (2 * SEMIBSIZE) || req->cryptlen % SEMIBSIZE)
crypto/keywrap.c:	memcpy(&block.A, req->iv, SEMIBSIZE);
crypto/keywrap.c:	 * first loop, src points to req->src and dst to req->dst. For any
crypto/keywrap.c:	 * subsequent round, the code operates on req->dst only.
crypto/keywrap.c:	src = req->src;
crypto/keywrap.c:	dst = req->dst;
crypto/keywrap.c:		unsigned int nbytes = req->cryptlen;
crypto/keywrap.c:		src = req->dst;
crypto/keywrap.c:		dst = req->dst;
crypto/keywrap.c:	if (req->cryptlen < (2 * SEMIBSIZE) || req->cryptlen % SEMIBSIZE)
crypto/keywrap.c:	 * first loop, src points to req->src and dst to req->dst. For any
crypto/keywrap.c:	 * subsequent round, the code operates on req->dst only.
crypto/keywrap.c:	src = req->src;
crypto/keywrap.c:	dst = req->dst;
crypto/keywrap.c:		unsigned int nbytes = req->cryptlen;
crypto/keywrap.c:		src = req->dst;
crypto/keywrap.c:		dst = req->dst;
crypto/keywrap.c:	memcpy(req->iv, &block.A, SEMIBSIZE);
crypto/aegis128-core.c:	unsigned int cryptlen = req->cryptlen;
crypto/aegis128-core.c:	crypto_aegis128_init(&state, &ctx->key, req->iv);
crypto/aegis128-core.c:	crypto_aegis128_process_ad(&state, req->src, req->assoclen, false);
crypto/aegis128-core.c:	crypto_aegis128_final(&state, &tag, req->assoclen, cryptlen);
crypto/aegis128-core.c:	scatterwalk_map_and_copy(tag.bytes, req->dst, req->assoclen + cryptlen,
crypto/aegis128-core.c:	unsigned int cryptlen = req->cryptlen - authsize;
crypto/aegis128-core.c:	scatterwalk_map_and_copy(tag.bytes, req->src, req->assoclen + cryptlen,
crypto/aegis128-core.c:	crypto_aegis128_init(&state, &ctx->key, req->iv);
crypto/aegis128-core.c:	crypto_aegis128_process_ad(&state, req->src, req->assoclen, false);
crypto/aegis128-core.c:	crypto_aegis128_final(&state, &tag, req->assoclen, cryptlen);
crypto/aegis128-core.c:	unsigned int cryptlen = req->cryptlen;
crypto/aegis128-core.c:	crypto_aegis128_init_simd(&state, &ctx->key, req->iv);
crypto/aegis128-core.c:	crypto_aegis128_process_ad(&state, req->src, req->assoclen, true);
crypto/aegis128-core.c:	crypto_aegis128_final_simd(&state, &tag, req->assoclen, cryptlen, 0);
crypto/aegis128-core.c:	scatterwalk_map_and_copy(tag.bytes, req->dst, req->assoclen + cryptlen,
crypto/aegis128-core.c:	unsigned int cryptlen = req->cryptlen - authsize;
crypto/aegis128-core.c:	scatterwalk_map_and_copy(tag.bytes, req->src, req->assoclen + cryptlen,
crypto/aegis128-core.c:	crypto_aegis128_init_simd(&state, &ctx->key, req->iv);
crypto/aegis128-core.c:	crypto_aegis128_process_ad(&state, req->src, req->assoclen, true);
crypto/aegis128-core.c:	if (unlikely(crypto_aegis128_final_simd(&state, &tag, req->assoclen,
crypto/asymmetric_keys/asym_tpm.c:		ret = req->dst_len;
crypto/asymmetric_keys/public_key.c:		ret = req->dst_len;
crypto/tcrypt.c:	struct crypto_wait *wait = req->base.data;
crypto/tcrypt.c:	struct crypto_wait *wait = req->base.data;
crypto/tcrypt.c:	struct crypto_wait *wait = req->base.data;
crypto/cryptd.c: * req->complete) and reschedule itself if there are more work to
crypto/cryptd.c:	req->complete(req, 0);
crypto/cryptd.c:	rctx->complete(&req->base, err);
crypto/cryptd.c:	skcipher_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
crypto/cryptd.c:				   req->iv);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	skcipher_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
crypto/cryptd.c:				   req->iv);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	req->base.complete = compl;
crypto/cryptd.c:	return cryptd_enqueue_request(queue, &req->base);
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	req->base.complete = compl;
crypto/cryptd.c:	return cryptd_enqueue_request(queue, &req->base);
crypto/cryptd.c:	rctx->complete(&req->base, err);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	err = crypto_shash_final(&rctx->desc, req->result);
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	req->base.complete = rctx->complete;
crypto/cryptd.c:	compl(&req->base, err);
crypto/cryptd.c:	struct cryptd_aead_ctx *ctx = crypto_tfm_ctx(areq->tfm);
crypto/cryptd.c:	struct cryptd_aead_ctx *ctx = crypto_tfm_ctx(areq->tfm);
crypto/cryptd.c:	rctx->complete = req->base.complete;
crypto/cryptd.c:	req->base.complete = compl;
crypto/cryptd.c:	return cryptd_enqueue_request(queue, &req->base);
crypto/ecdh.c:	if (req->src) {
crypto/ecdh.c:		if (public_key_sz != req->src_len)
crypto/ecdh.c:		copied = sg_copy_to_buffer(req->src,
crypto/ecdh.c:					   sg_nents_for_len(req->src,
crypto/ecdh.c:	nbytes = min_t(size_t, nbytes, req->dst_len);
crypto/ecdh.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst,
crypto/ahash.c:	walk->total = req->nbytes;
crypto/ahash.c:	walk->sg = req->src;
crypto/ahash.c:	walk->flags = req->base.flags;
crypto/ahash.c:		       (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
crypto/ahash.c:	priv->result = req->result;
crypto/ahash.c:	priv->complete = req->base.complete;
crypto/ahash.c:	priv->data = req->base.data;
crypto/ahash.c:	priv->flags = req->base.flags;
crypto/ahash.c:	 * WARNING: We do not backup req->priv here! The req->priv
crypto/ahash.c:	req->result = PTR_ALIGN((u8 *)priv->ubuf, alignmask + 1);
crypto/ahash.c:	req->base.complete = cplt;
crypto/ahash.c:	req->base.data = req;
crypto/ahash.c:	req->priv = priv;
crypto/ahash.c:	struct ahash_request_priv *priv = req->priv;
crypto/ahash.c:		memcpy(priv->result, req->result,
crypto/ahash.c:	req->result = priv->result;
crypto/ahash.c:	req->priv = NULL;
crypto/ahash.c:	/* Free the req->priv.priv from the ADJUSTED request. */
crypto/ahash.c:	struct ahash_request_priv *priv = req->priv;
crypto/ahash.c:	struct ahash_request *areq = req->data;
crypto/ahash.c:	/* First copy req->result into req->priv.result */
crypto/ahash.c:	areq->base.complete(&areq->base, err);
crypto/ahash.c:	if ((unsigned long)req->result & alignmask)
crypto/ahash.c:	unsigned int nbytes = req->nbytes;
crypto/ahash.c:	unsigned int nbytes = req->nbytes;
crypto/ahash.c:	unsigned int nbytes = req->nbytes;
crypto/ahash.c:	struct ahash_request *areq = req->data;
crypto/ahash.c:	areq->base.complete(&areq->base, err);
crypto/ahash.c:	req->base.complete = ahash_def_finup_done2;
crypto/ahash.c:	struct ahash_request *areq = req->data;
crypto/ahash.c:	areq->base.flags &= ~CRYPTO_TFM_REQ_MAY_SLEEP;
crypto/ahash.c:	if (areq->priv)
crypto/ahash.c:	areq->base.complete(&areq->base, err);
crypto/sm2.c:	buffer = kmalloc(req->src_len + req->dst_len, GFP_KERNEL);
crypto/sm2.c:	sg_pcopy_to_buffer(req->src,
crypto/sm2.c:		sg_nents_for_len(req->src, req->src_len + req->dst_len),
crypto/sm2.c:		buffer, req->src_len + req->dst_len, 0);
crypto/sm2.c:				buffer, req->src_len);
crypto/sm2.c:	hash = mpi_read_raw_data(buffer + req->src_len, req->dst_len);
crypto/authenc.c:	struct aead_request *req = areq->data;
crypto/authenc.c:	scatterwalk_map_and_copy(ahreq->result, req->dst,
crypto/authenc.c:				 req->assoclen + req->cryptlen,
crypto/authenc.c:	ahash_request_set_crypt(ahreq, req->dst, hash,
crypto/authenc.c:				req->assoclen + req->cryptlen);
crypto/authenc.c:	scatterwalk_map_and_copy(hash, req->dst, req->assoclen + req->cryptlen,
crypto/authenc.c:	struct aead_request *areq = req->data;
crypto/authenc.c:	skcipher_request_set_crypt(skreq, req->src, req->dst, req->assoclen,
crypto/authenc.c:	unsigned int cryptlen = req->cryptlen;
crypto/authenc.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, req->assoclen);
crypto/authenc.c:	if (req->src != req->dst) {
crypto/authenc.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, req->assoclen);
crypto/authenc.c:	skcipher_request_set_crypt(skreq, src, dst, cryptlen, req->iv);
crypto/authenc.c:	u8 *ihash = ahreq->result + authsize;
crypto/authenc.c:	scatterwalk_map_and_copy(ihash, req->src, ahreq->nbytes, authsize, 0);
crypto/authenc.c:	if (crypto_memneq(ihash, ahreq->result, authsize))
crypto/authenc.c:	src = scatterwalk_ffwd(areq_ctx->src, req->src, req->assoclen);
crypto/authenc.c:	if (req->src != req->dst)
crypto/authenc.c:		dst = scatterwalk_ffwd(areq_ctx->dst, req->dst, req->assoclen);
crypto/authenc.c:				      req->base.complete, req->base.data);
crypto/authenc.c:				   req->cryptlen - authsize, req->iv);
crypto/authenc.c:	struct aead_request *req = areq->data;
crypto/authenc.c:	ahash_request_set_crypt(ahreq, req->src, hash,
crypto/authenc.c:				req->assoclen + req->cryptlen - authsize);
crypto/rsa.c:	m = mpi_read_raw_from_sgl(req->src, req->src_len);
crypto/rsa.c:	ret = mpi_write_to_sgl(c, req->dst, req->dst_len, &sign);
crypto/rsa.c:	c = mpi_read_raw_from_sgl(req->src, req->src_len);
crypto/rsa.c:	ret = mpi_write_to_sgl(m, req->dst, req->dst_len, &sign);
crypto/skcipher.c:	walk->total = req->cryptlen;
crypto/skcipher.c:	walk->iv = req->iv;
crypto/skcipher.c:	walk->oiv = req->iv;
crypto/skcipher.c:	scatterwalk_start(&walk->in, req->src);
crypto/skcipher.c:	scatterwalk_start(&walk->out, req->dst);
crypto/skcipher.c:	walk->flags |= req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
crypto/skcipher.c:	might_sleep_if(req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
crypto/skcipher.c:	walk->iv = req->iv;
crypto/skcipher.c:	walk->oiv = req->iv;
crypto/skcipher.c:	scatterwalk_start(&walk->in, req->src);
crypto/skcipher.c:	scatterwalk_start(&walk->out, req->dst);
crypto/skcipher.c:	scatterwalk_copychunks(NULL, &walk->in, req->assoclen, 2);
crypto/skcipher.c:	scatterwalk_copychunks(NULL, &walk->out, req->assoclen, 2);
crypto/skcipher.c:	if (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP)
crypto/skcipher.c:	walk->total = req->cryptlen;
crypto/skcipher.c:	walk->total = req->cryptlen - crypto_aead_authsize(tfm);
crypto/skcipher.c:	unsigned int cryptlen = req->cryptlen;
crypto/skcipher.c:	unsigned int cryptlen = req->cryptlen;
crypto/ecrdsa.c:	unsigned int ndigits = req->dst_len / sizeof(u64);
crypto/ecrdsa.c:	    !req->src ||
crypto/ecrdsa.c:	    req->dst_len != ctx->digest_len ||
crypto/ecrdsa.c:	    req->dst_len != ctx->curve->g.ndigits * sizeof(u64) ||
crypto/ecrdsa.c:	    req->dst_len * 2 != req->src_len ||
crypto/ecrdsa.c:	    WARN_ON(req->src_len > sizeof(sig)) ||
crypto/ecrdsa.c:	    WARN_ON(req->dst_len > sizeof(digest)))
crypto/ecrdsa.c:	sg_copy_to_buffer(req->src, sg_nents_for_len(req->src, req->src_len),
crypto/ecrdsa.c:			  sig, req->src_len);
crypto/ecrdsa.c:	sg_pcopy_to_buffer(req->src,
crypto/ecrdsa.c:			   sg_nents_for_len(req->src,
crypto/ecrdsa.c:					    req->src_len + req->dst_len),
crypto/ecrdsa.c:			   digest, req->dst_len, req->src_len);
crypto/curve25519-generic.c:	if (req->src) {
crypto/curve25519-generic.c:		copied = sg_copy_to_buffer(req->src,
crypto/curve25519-generic.c:					   sg_nents_for_len(req->src,
crypto/curve25519-generic.c:	nbytes = min_t(size_t, CURVE25519_KEY_SIZE, req->dst_len);
crypto/curve25519-generic.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst,
crypto/aead.c:	unsigned int cryptlen = req->cryptlen;
crypto/aead.c:	unsigned int cryptlen = req->cryptlen;
crypto/aead.c:	else if (req->cryptlen < crypto_aead_authsize(aead))
crypto/xts.c:	const bool cts = (req->cryptlen % XTS_BLOCK_SIZE);
crypto/xts.c:	struct skcipher_request *req = areq->data;
crypto/xts.c:	int offset = req->cryptlen & ~(XTS_BLOCK_SIZE - 1);
crypto/xts.c:	int tail = req->cryptlen % XTS_BLOCK_SIZE;
crypto/xts.c:	rctx->tail = scatterwalk_ffwd(rctx->sg, req->dst,
crypto/xts.c:	scatterwalk_map_and_copy(b, req->src, offset, tail, 0);
crypto/xts.c:	skcipher_request_set_callback(subreq, req->base.flags, xts_cts_done,
crypto/xts.c:	struct skcipher_request *req = areq->data;
crypto/xts.c:		if (!err && unlikely(req->cryptlen % XTS_BLOCK_SIZE)) {
crypto/xts.c:	struct skcipher_request *req = areq->data;
crypto/xts.c:		if (!err && unlikely(req->cryptlen % XTS_BLOCK_SIZE)) {
crypto/xts.c:	if (req->cryptlen < XTS_BLOCK_SIZE)
crypto/xts.c:	skcipher_request_set_callback(subreq, req->base.flags, compl, req);
crypto/xts.c:	skcipher_request_set_crypt(subreq, req->dst, req->dst,
crypto/xts.c:				   req->cryptlen & ~(XTS_BLOCK_SIZE - 1), NULL);
crypto/xts.c:	crypto_cipher_encrypt_one(ctx->tweak, (u8 *)&rctx->t, req->iv);
crypto/xts.c:	if (err || likely((req->cryptlen % XTS_BLOCK_SIZE) == 0))
crypto/xts.c:	if (err || likely((req->cryptlen % XTS_BLOCK_SIZE) == 0))
crypto/shash.c:	return crypto_shash_final(ahash_request_ctx(req), req->result);
crypto/shash.c:		return crypto_shash_final(desc, req->result);
crypto/shash.c:					    req->result) :
crypto/shash.c:	unsigned int nbytes = req->nbytes;
crypto/shash.c:	    (sg = req->src, offset = sg->offset,
crypto/shash.c:					  req->result);
crypto/scompress.c:	if (!req->src || !req->slen || req->slen > SCOMP_SCRATCH_SIZE)
crypto/scompress.c:	if (req->dst && !req->dlen)
crypto/scompress.c:	if (!req->dlen || req->dlen > SCOMP_SCRATCH_SIZE)
crypto/scompress.c:		req->dlen = SCOMP_SCRATCH_SIZE;
crypto/scompress.c:	scatterwalk_map_and_copy(scratch->src, req->src, 0, req->slen, 0);
crypto/scompress.c:		ret = crypto_scomp_compress(scomp, scratch->src, req->slen,
crypto/scompress.c:					    scratch->dst, &req->dlen, *ctx);
crypto/scompress.c:		ret = crypto_scomp_decompress(scomp, scratch->src, req->slen,
crypto/scompress.c:					      scratch->dst, &req->dlen, *ctx);
crypto/scompress.c:		if (!req->dst) {
crypto/scompress.c:			req->dst = sgl_alloc(req->dlen, GFP_ATOMIC, NULL);
crypto/scompress.c:			if (!req->dst) {
crypto/scompress.c:		scatterwalk_map_and_copy(scratch->dst, req->dst, 0, req->dlen,
crypto/scompress.c:	*req->__ctx = ctx;
crypto/scompress.c:	void *ctx = *req->__ctx;
crypto/echainiv.c:	if (req->cryptlen < ivsize)
crypto/echainiv.c:	info = req->iv;
crypto/echainiv.c:	if (req->src != req->dst) {
crypto/echainiv.c:		skcipher_request_set_callback(nreq, req->base.flags,
crypto/echainiv.c:		skcipher_request_set_crypt(nreq, req->src, req->dst,
crypto/echainiv.c:					   req->assoclen + req->cryptlen,
crypto/echainiv.c:	aead_request_set_callback(subreq, req->base.flags,
crypto/echainiv.c:				  req->base.complete, req->base.data);
crypto/echainiv.c:	aead_request_set_crypt(subreq, req->dst, req->dst,
crypto/echainiv.c:			       req->cryptlen, info);
crypto/echainiv.c:	aead_request_set_ad(subreq, req->assoclen);
crypto/echainiv.c:	scatterwalk_map_and_copy(info, req->dst, req->assoclen, ivsize, 1);
crypto/echainiv.c:	if (req->cryptlen < ivsize)
crypto/echainiv.c:	compl = req->base.complete;
crypto/echainiv.c:	data = req->base.data;
crypto/echainiv.c:	aead_request_set_callback(subreq, req->base.flags, compl, data);
crypto/echainiv.c:	aead_request_set_crypt(subreq, req->src, req->dst,
crypto/echainiv.c:			       req->cryptlen - ivsize, req->iv);
crypto/echainiv.c:	aead_request_set_ad(subreq, req->assoclen + ivsize);
crypto/echainiv.c:	scatterwalk_map_and_copy(req->iv, req->src, req->assoclen, ivsize, 0);
crypto/dh.c:	if (req->src) {
crypto/dh.c:		base = mpi_read_raw_from_sgl(req->src, req->src_len);
crypto/dh.c:		if (req->src) {
crypto/dh.c:	ret = mpi_write_to_sgl(val, req->dst, req->dst_len, &sign);
crypto/dh.c:	if (req->src)
crypto/acompress.c:	if (req->flags & CRYPTO_ACOMP_ALLOC_OUTPUT) {
crypto/acompress.c:		acomp->dst_free(req->dst);
crypto/acompress.c:		req->dst = NULL;
crypto/algif_skcipher.c:	areq->tsgl_entries = af_alg_count_tsgl(sk, len, 0);
crypto/algif_skcipher.c:	if (!areq->tsgl_entries)
crypto/algif_skcipher.c:		areq->tsgl_entries = 1;
crypto/algif_skcipher.c:	areq->tsgl = sock_kmalloc(sk, array_size(sizeof(*areq->tsgl),
crypto/algif_skcipher.c:						 areq->tsgl_entries),
crypto/algif_skcipher.c:	if (!areq->tsgl) {
crypto/algif_skcipher.c:	sg_init_table(areq->tsgl, areq->tsgl_entries);
crypto/algif_skcipher.c:	af_alg_pull_tsgl(sk, len, areq->tsgl, 0);
crypto/algif_skcipher.c:	skcipher_request_set_tfm(&areq->cra_u.skcipher_req, tfm);
crypto/algif_skcipher.c:	skcipher_request_set_crypt(&areq->cra_u.skcipher_req, areq->tsgl,
crypto/algif_skcipher.c:				   areq->first_rsgl.sgl.sg, len, ctx->iv);
crypto/algif_skcipher.c:		areq->iocb = msg->msg_iocb;
crypto/algif_skcipher.c:		areq->outlen = len;
crypto/algif_skcipher.c:		skcipher_request_set_callback(&areq->cra_u.skcipher_req,
crypto/algif_skcipher.c:			crypto_skcipher_encrypt(&areq->cra_u.skcipher_req) :
crypto/algif_skcipher.c:			crypto_skcipher_decrypt(&areq->cra_u.skcipher_req);
crypto/algif_skcipher.c:		skcipher_request_set_callback(&areq->cra_u.skcipher_req,
crypto/algif_skcipher.c:			crypto_skcipher_encrypt(&areq->cra_u.skcipher_req) :
crypto/algif_skcipher.c:			crypto_skcipher_decrypt(&areq->cra_u.skcipher_req),
crypto/af_alg.c:	struct sock *sk = areq->sk;
crypto/af_alg.c:	list_for_each_entry_safe(rsgl, tmp, &areq->rsgl_list, list) {
crypto/af_alg.c:		if (rsgl != &areq->first_rsgl)
crypto/af_alg.c:	tsgl = areq->tsgl;
crypto/af_alg.c:		for_each_sg(tsgl, sg, areq->tsgl_entries, i) {
crypto/af_alg.c:		sock_kfree_s(sk, tsgl, areq->tsgl_entries * sizeof(*tsgl));
crypto/af_alg.c:	struct sock *sk = areq->sk;
crypto/af_alg.c:	sock_kfree_s(sk, areq, areq->areqlen);
crypto/af_alg.c: * in areq->outlen before the AIO callback handler is invoked.
crypto/af_alg.c:	struct af_alg_async_req *areq = _req->data;
crypto/af_alg.c:	struct sock *sk = areq->sk;
crypto/af_alg.c:	struct kiocb *iocb = areq->iocb;
crypto/af_alg.c:	resultlen = areq->outlen;
crypto/af_alg.c:	areq->areqlen = areqlen;
crypto/af_alg.c:	areq->sk = sk;
crypto/af_alg.c:	areq->last_rsgl = NULL;
crypto/af_alg.c:	INIT_LIST_HEAD(&areq->rsgl_list);
crypto/af_alg.c:	areq->tsgl = NULL;
crypto/af_alg.c:	areq->tsgl_entries = 0;
crypto/af_alg.c:		if (list_empty(&areq->rsgl_list)) {
crypto/af_alg.c:			rsgl = &areq->first_rsgl;
crypto/af_alg.c:		list_add_tail(&rsgl->list, &areq->rsgl_list);
crypto/af_alg.c:		if (areq->last_rsgl)
crypto/af_alg.c:			af_alg_link_sg(&areq->last_rsgl->sgl, &rsgl->sgl);
crypto/af_alg.c:		areq->last_rsgl = rsgl;
crypto/api.c:	struct crypto_wait *wait = req->data;
crypto/pcrypt.c:	aead_request_complete(req->base.data, padata->info);
crypto/pcrypt.c:	struct aead_request *req = areq->data;
crypto/pcrypt.c:	aead_request_set_crypt(creq, req->src, req->dst,
crypto/pcrypt.c:			       req->cryptlen, req->iv);
crypto/pcrypt.c:	aead_request_set_ad(creq, req->assoclen);
crypto/pcrypt.c:	aead_request_set_crypt(creq, req->src, req->dst,
crypto/pcrypt.c:			       req->cryptlen, req->iv);
crypto/pcrypt.c:	aead_request_set_ad(creq, req->assoclen);
crypto/gcm.c:	memcpy(pctx->iv, req->iv, GCM_AES_IV_SIZE);
crypto/gcm.c:	sg = scatterwalk_ffwd(pctx->src + 1, req->src, req->assoclen);
crypto/gcm.c:	if (req->src != req->dst) {
crypto/gcm.c:		sg = scatterwalk_ffwd(pctx->dst + 1, req->dst, req->assoclen);
crypto/gcm.c:	dst = req->src == req->dst ? pctx->src : pctx->dst;
crypto/gcm.c:	lengths.a = cpu_to_be64(req->assoclen * 8);
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	remain = gcm_remain(req->assoclen);
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	if (req->assoclen)
crypto/gcm.c:				       req->src, req->assoclen, flags) ?:
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	scatterwalk_map_and_copy(auth_tag, req->dst,
crypto/gcm.c:				 req->assoclen + req->cryptlen,
crypto/gcm.c:	gctx->src = sg_next(req->src == req->dst ? pctx->src : pctx->dst);
crypto/gcm.c:	gctx->cryptlen = req->cryptlen;
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	crypto_gcm_init_crypt(req, req->cryptlen);
crypto/gcm.c:	unsigned int cryptlen = req->cryptlen - authsize;
crypto/gcm.c:	scatterwalk_map_and_copy(iauth_tag, req->src,
crypto/gcm.c:				 req->assoclen + cryptlen, authsize, 0);
crypto/gcm.c:	struct aead_request *req = areq->data;
crypto/gcm.c:	unsigned int cryptlen = req->cryptlen;
crypto/gcm.c:	scatterwalk_map_and_copy(iv + GCM_AES_IV_SIZE, req->src, 0, req->assoclen - 8, 0);
crypto/gcm.c:	memcpy(iv + 4, req->iv, 8);
crypto/gcm.c:	sg_set_buf(rctx->src, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
crypto/gcm.c:	sg = scatterwalk_ffwd(rctx->src + 1, req->src, req->assoclen);
crypto/gcm.c:	if (req->src != req->dst) {
crypto/gcm.c:		sg_set_buf(rctx->dst, iv + GCM_AES_IV_SIZE, req->assoclen - 8);
crypto/gcm.c:		sg = scatterwalk_ffwd(rctx->dst + 1, req->dst, req->assoclen);
crypto/gcm.c:	aead_request_set_callback(subreq, req->base.flags, req->base.complete,
crypto/gcm.c:				  req->base.data);
crypto/gcm.c:			       req->src == req->dst ? rctx->src : rctx->dst,
crypto/gcm.c:			       req->cryptlen, iv);
crypto/gcm.c:	aead_request_set_ad(subreq, req->assoclen - 8);
crypto/gcm.c:	err = crypto_ipsec_check_assoclen(req->assoclen);
crypto/gcm.c:	err = crypto_ipsec_check_assoclen(req->assoclen);
crypto/gcm.c:	if (req->src != req->dst) {
crypto/gcm.c:	memcpy(iv + 4, req->iv, 8);
crypto/gcm.c:	aead_request_set_callback(subreq, req->base.flags,
crypto/gcm.c:				  req->base.complete, req->base.data);
crypto/gcm.c:	aead_request_set_crypt(subreq, req->src, req->dst,
crypto/gcm.c:	aead_request_set_ad(subreq, req->assoclen + req->cryptlen -
crypto/gcm.c:				    subreq->cryptlen);
crypto/gcm.c:	unsigned int nbytes = req->assoclen + req->cryptlen -
crypto/gcm.c:	skcipher_request_set_callback(nreq, req->base.flags, NULL, NULL);
crypto/gcm.c:	skcipher_request_set_crypt(nreq, req->src, req->dst, nbytes, NULL);
crypto/gcm.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
crypto/gcm.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
crypto/adiantum.c:	const unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;
crypto/adiantum.c:	poly1305_core_blocks(&state, &tctx->header_hash_key, req->iv,
crypto/adiantum.c:	const unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;
crypto/adiantum.c:	const unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;
crypto/adiantum.c:	err = adiantum_hash_message(req, req->dst, &digest);
crypto/adiantum.c:	scatterwalk_map_and_copy(&rctx->rbuf.bignum, req->dst,
crypto/adiantum.c:	struct skcipher_request *req = areq->data;
crypto/adiantum.c:	const unsigned int bulk_len = req->cryptlen - BLOCKCIPHER_BLOCK_SIZE;
crypto/adiantum.c:	if (req->cryptlen < BLOCKCIPHER_BLOCK_SIZE)
crypto/adiantum.c:	err = adiantum_hash_message(req, req->src, &digest);
crypto/adiantum.c:	scatterwalk_map_and_copy(&rctx->rbuf.bignum, req->src,
crypto/adiantum.c:	if (round_up(stream_len, CHACHA_BLOCK_SIZE) <= req->cryptlen)
crypto/adiantum.c:	skcipher_request_set_crypt(&rctx->u.streamcipher_req, req->src,
crypto/adiantum.c:				   req->dst, stream_len, &rctx->rbuf);
crypto/adiantum.c:				      req->base.flags,
crypto/ctr.c:	memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
crypto/ctr.c:	skcipher_request_set_callback(subreq, req->base.flags,
crypto/ctr.c:				      req->base.complete, req->base.data);
crypto/ctr.c:	skcipher_request_set_crypt(subreq, req->src, req->dst,
crypto/ctr.c:				   req->cryptlen, iv);
crypto/chacha_generic.c:	return chacha_stream_xor(req, ctx, req->iv);
crypto/chacha_generic.c:	chacha_init_generic(state, ctx->key, req->iv);
crypto/chacha_generic.c:	memcpy(&real_iv[0], req->iv + 24, 8); /* stream position */
crypto/chacha_generic.c:	memcpy(&real_iv[8], req->iv + 16, 8); /* remaining 64 nonce bits */
crypto/chacha20poly1305.c:	memcpy(iv + sizeof(leicb) + ctx->saltlen, req->iv,
crypto/chacha20poly1305.c:	scatterwalk_map_and_copy(tag, req->src,
crypto/chacha20poly1305.c:				 req->assoclen + rctx->cryptlen,
crypto/chacha20poly1305.c:	scatterwalk_map_and_copy(rctx->tag, req->dst,
crypto/chacha20poly1305.c:				 req->assoclen + rctx->cryptlen,
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_verify_tag);
crypto/chacha20poly1305.c:	chacha_iv(creq->iv, req, 1);
crypto/chacha20poly1305.c:	src = scatterwalk_ffwd(rctx->src, req->src, req->assoclen);
crypto/chacha20poly1305.c:	if (req->src != req->dst)
crypto/chacha20poly1305.c:		dst = scatterwalk_ffwd(rctx->dst, req->dst, req->assoclen);
crypto/chacha20poly1305.c:	skcipher_request_set_callback(&creq->req, rctx->flags,
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:	skcipher_request_set_crypt(&creq->req, src, dst,
crypto/chacha20poly1305.c:				   rctx->cryptlen, creq->iv);
crypto/chacha20poly1305.c:	err = crypto_skcipher_decrypt(&creq->req);
crypto/chacha20poly1305.c:	if (rctx->cryptlen == req->cryptlen) /* encrypting */
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_tail_continue);
crypto/chacha20poly1305.c:	preq->tail.assoclen = cpu_to_le64(rctx->assoclen);
crypto/chacha20poly1305.c:	preq->tail.cryptlen = cpu_to_le64(rctx->cryptlen);
crypto/chacha20poly1305.c:	sg_init_one(preq->src, &preq->tail, sizeof(preq->tail));
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, preq->src,
crypto/chacha20poly1305.c:				rctx->tag, sizeof(preq->tail));
crypto/chacha20poly1305.c:	err = crypto_ahash_finup(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_tail);
crypto/chacha20poly1305.c:	memset(preq->pad, 0, sizeof(preq->pad));
crypto/chacha20poly1305.c:	sg_init_one(preq->src, preq->pad, padlen);
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, preq->src, NULL, padlen);
crypto/chacha20poly1305.c:	err = crypto_ahash_update(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_cipherpad);
crypto/chacha20poly1305.c:	struct scatterlist *crypt = req->src;
crypto/chacha20poly1305.c:	if (rctx->cryptlen == req->cryptlen) /* encrypting */
crypto/chacha20poly1305.c:		crypt = req->dst;
crypto/chacha20poly1305.c:	crypt = scatterwalk_ffwd(rctx->src, crypt, req->assoclen);
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, crypt, NULL, rctx->cryptlen);
crypto/chacha20poly1305.c:	err = crypto_ahash_update(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_cipher);
crypto/chacha20poly1305.c:	memset(preq->pad, 0, sizeof(preq->pad));
crypto/chacha20poly1305.c:	sg_init_one(preq->src, preq->pad, padlen);
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, preq->src, NULL, padlen);
crypto/chacha20poly1305.c:	err = crypto_ahash_update(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_adpad);
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, req->src, NULL, rctx->assoclen);
crypto/chacha20poly1305.c:	err = crypto_ahash_update(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_ad);
crypto/chacha20poly1305.c:	sg_init_one(preq->src, rctx->key, sizeof(rctx->key));
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	ahash_request_set_crypt(&preq->req, preq->src, NULL, sizeof(rctx->key));
crypto/chacha20poly1305.c:	err = crypto_ahash_update(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_setkey);
crypto/chacha20poly1305.c:	ahash_request_set_callback(&preq->req, rctx->flags,
crypto/chacha20poly1305.c:	ahash_request_set_tfm(&preq->req, ctx->poly);
crypto/chacha20poly1305.c:	err = crypto_ahash_init(&preq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_init);
crypto/chacha20poly1305.c:	rctx->assoclen = req->assoclen;
crypto/chacha20poly1305.c:	sg_init_one(creq->src, rctx->key, sizeof(rctx->key));
crypto/chacha20poly1305.c:	chacha_iv(creq->iv, req, 0);
crypto/chacha20poly1305.c:	skcipher_request_set_callback(&creq->req, rctx->flags,
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:	skcipher_request_set_crypt(&creq->req, creq->src, creq->src,
crypto/chacha20poly1305.c:				   POLY1305_KEY_SIZE, creq->iv);
crypto/chacha20poly1305.c:	err = crypto_skcipher_decrypt(&creq->req);
crypto/chacha20poly1305.c:	async_done_continue(areq->data, err, poly_genkey);
crypto/chacha20poly1305.c:	if (req->cryptlen == 0)
crypto/chacha20poly1305.c:	chacha_iv(creq->iv, req, 1);
crypto/chacha20poly1305.c:	src = scatterwalk_ffwd(rctx->src, req->src, req->assoclen);
crypto/chacha20poly1305.c:	if (req->src != req->dst)
crypto/chacha20poly1305.c:		dst = scatterwalk_ffwd(rctx->dst, req->dst, req->assoclen);
crypto/chacha20poly1305.c:	skcipher_request_set_callback(&creq->req, rctx->flags,
crypto/chacha20poly1305.c:	skcipher_request_set_tfm(&creq->req, ctx->chacha);
crypto/chacha20poly1305.c:	skcipher_request_set_crypt(&creq->req, src, dst,
crypto/chacha20poly1305.c:				   req->cryptlen, creq->iv);
crypto/chacha20poly1305.c:	err = crypto_skcipher_encrypt(&creq->req);
crypto/chacha20poly1305.c:	rctx->cryptlen = req->cryptlen;
crypto/chacha20poly1305.c:	rctx->cryptlen = req->cryptlen - POLY1305_DIGEST_SIZE;
crypto/cts.c:	struct skcipher_request *req = areq->data;
crypto/cts.c:	lastn = req->cryptlen - offset;
crypto/cts.c:	sg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);
crypto/cts.c:	scatterwalk_map_and_copy(d, req->src, offset, lastn, 0);
crypto/cts.c:	skcipher_request_set_callback(subreq, req->base.flags &
crypto/cts.c:	skcipher_request_set_crypt(subreq, sg, sg, bsize, req->iv);
crypto/cts.c:	struct skcipher_request *req = areq->data;
crypto/cts.c:	unsigned int nbytes = req->cryptlen;
crypto/cts.c:		skcipher_request_set_callback(subreq, req->base.flags,
crypto/cts.c:					      req->base.complete,
crypto/cts.c:					      req->base.data);
crypto/cts.c:		skcipher_request_set_crypt(subreq, req->src, req->dst, nbytes,
crypto/cts.c:					   req->iv);
crypto/cts.c:	skcipher_request_set_callback(subreq, req->base.flags,
crypto/cts.c:	skcipher_request_set_crypt(subreq, req->src, req->dst,
crypto/cts.c:				   offset, req->iv);
crypto/cts.c:	lastn = req->cryptlen - offset;
crypto/cts.c:	sg = scatterwalk_ffwd(rctx->sg, req->dst, offset - bsize);
crypto/cts.c:	scatterwalk_map_and_copy(d, req->src, offset, lastn, 0);
crypto/cts.c:	skcipher_request_set_callback(subreq, req->base.flags &
crypto/cts.c:	struct skcipher_request *req = areq->data;
crypto/cts.c:	unsigned int nbytes = req->cryptlen;
crypto/cts.c:		skcipher_request_set_callback(subreq, req->base.flags,
crypto/cts.c:					      req->base.complete,
crypto/cts.c:					      req->base.data);
crypto/cts.c:		skcipher_request_set_crypt(subreq, req->src, req->dst, nbytes,
crypto/cts.c:					   req->iv);
crypto/cts.c:	skcipher_request_set_callback(subreq, req->base.flags,
crypto/cts.c:		memcpy(space, req->iv, bsize);
crypto/cts.c:		scatterwalk_map_and_copy(space, req->src, offset - 2 * bsize,
crypto/cts.c:	skcipher_request_set_crypt(subreq, req->src, req->dst,
crypto/cts.c:				   offset, req->iv);
crypto/rsa-pkcs1pad.c:	sg_copy_to_buffer(req->dst, sg_nents_for_len(req->dst, len),
crypto/rsa-pkcs1pad.c:	sg_copy_from_buffer(req->dst,
crypto/rsa-pkcs1pad.c:			    sg_nents_for_len(req->dst, ctx->key_size),
crypto/rsa-pkcs1pad.c:	req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	struct akcipher_request *req = child_async_req->data;
crypto/rsa-pkcs1pad.c:	async_req.data = req->base.data;
crypto/rsa-pkcs1pad.c:	async_req.flags = child_async_req->flags;
crypto/rsa-pkcs1pad.c:	req->base.complete(&async_req,
crypto/rsa-pkcs1pad.c:	if (req->src_len > ctx->key_size - 11)
crypto/rsa-pkcs1pad.c:	if (req->dst_len < ctx->key_size) {
crypto/rsa-pkcs1pad.c:		req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
crypto/rsa-pkcs1pad.c:	ps_end = ctx->key_size - req->src_len - 2;
crypto/rsa-pkcs1pad.c:			ctx->key_size - 1 - req->src_len, req->src);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:				   req->dst, ctx->key_size - 1, req->dst_len);
crypto/rsa-pkcs1pad.c:	if (req->dst_len < dst_len - pos)
crypto/rsa-pkcs1pad.c:	req->dst_len = dst_len - pos;
crypto/rsa-pkcs1pad.c:		sg_copy_from_buffer(req->dst,
crypto/rsa-pkcs1pad.c:				sg_nents_for_len(req->dst, req->dst_len),
crypto/rsa-pkcs1pad.c:				out_buf + pos, req->dst_len);
crypto/rsa-pkcs1pad.c:	struct akcipher_request *req = child_async_req->data;
crypto/rsa-pkcs1pad.c:	async_req.data = req->base.data;
crypto/rsa-pkcs1pad.c:	async_req.flags = child_async_req->flags;
crypto/rsa-pkcs1pad.c:	req->base.complete(&async_req, pkcs1pad_decrypt_complete(req, err));
crypto/rsa-pkcs1pad.c:	if (!ctx->key_size || req->src_len != ctx->key_size)
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req->src,
crypto/rsa-pkcs1pad.c:				   req_ctx->out_sg, req->src_len,
crypto/rsa-pkcs1pad.c:	if (req->src_len + digest_size > ctx->key_size - 11)
crypto/rsa-pkcs1pad.c:	if (req->dst_len < ctx->key_size) {
crypto/rsa-pkcs1pad.c:		req->dst_len = ctx->key_size;
crypto/rsa-pkcs1pad.c:	req_ctx->in_buf = kmalloc(ctx->key_size - 1 - req->src_len,
crypto/rsa-pkcs1pad.c:	ps_end = ctx->key_size - digest_size - req->src_len - 2;
crypto/rsa-pkcs1pad.c:			ctx->key_size - 1 - req->src_len, req->src);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:				   req->dst, ctx->key_size - 1, req->dst_len);
crypto/rsa-pkcs1pad.c:	if (req->dst_len != dst_len - pos) {
crypto/rsa-pkcs1pad.c:		req->dst_len = dst_len - pos;
crypto/rsa-pkcs1pad.c:	sg_pcopy_to_buffer(req->src,
crypto/rsa-pkcs1pad.c:			   sg_nents_for_len(req->src,
crypto/rsa-pkcs1pad.c:					    req->src_len + req->dst_len),
crypto/rsa-pkcs1pad.c:			   req->dst_len, ctx->key_size);
crypto/rsa-pkcs1pad.c:		   req->dst_len) != 0)
crypto/rsa-pkcs1pad.c:	struct akcipher_request *req = child_async_req->data;
crypto/rsa-pkcs1pad.c:	async_req.data = req->base.data;
crypto/rsa-pkcs1pad.c:	async_req.flags = child_async_req->flags;
crypto/rsa-pkcs1pad.c:	req->base.complete(&async_req, pkcs1pad_verify_complete(req, err));
crypto/rsa-pkcs1pad.c:	if (WARN_ON(req->dst) ||
crypto/rsa-pkcs1pad.c:	    WARN_ON(!req->dst_len) ||
crypto/rsa-pkcs1pad.c:	    !ctx->key_size || req->src_len < ctx->key_size)
crypto/rsa-pkcs1pad.c:	req_ctx->out_buf = kmalloc(ctx->key_size + req->dst_len, GFP_KERNEL);
crypto/rsa-pkcs1pad.c:	akcipher_request_set_callback(&req_ctx->child_req, req->base.flags,
crypto/rsa-pkcs1pad.c:	akcipher_request_set_crypt(&req_ctx->child_req, req->src,
crypto/rsa-pkcs1pad.c:				   req_ctx->out_sg, req->src_len,
crypto/algif_aead.c:	rsgl_src = areq->first_rsgl.sgl.sg;
crypto/algif_aead.c:					   areq->first_rsgl.sgl.sg, processed);
crypto/algif_aead.c:					   areq->first_rsgl.sgl.sg, outlen);
crypto/algif_aead.c:		areq->tsgl_entries = af_alg_count_tsgl(sk, processed,
crypto/algif_aead.c:		if (!areq->tsgl_entries)
crypto/algif_aead.c:			areq->tsgl_entries = 1;
crypto/algif_aead.c:		areq->tsgl = sock_kmalloc(sk, array_size(sizeof(*areq->tsgl),
crypto/algif_aead.c:							 areq->tsgl_entries),
crypto/algif_aead.c:		if (!areq->tsgl) {
crypto/algif_aead.c:		sg_init_table(areq->tsgl, areq->tsgl_entries);
crypto/algif_aead.c:		af_alg_pull_tsgl(sk, processed, areq->tsgl, processed - as);
crypto/algif_aead.c:			struct af_alg_sgl *sgl_prev = &areq->last_rsgl->sgl;
crypto/algif_aead.c:				 areq->tsgl);
crypto/algif_aead.c:			rsgl_src = areq->tsgl;
crypto/algif_aead.c:	aead_request_set_crypt(&areq->cra_u.aead_req, rsgl_src,
crypto/algif_aead.c:			       areq->first_rsgl.sgl.sg, used, ctx->iv);
crypto/algif_aead.c:	aead_request_set_ad(&areq->cra_u.aead_req, ctx->aead_assoclen);
crypto/algif_aead.c:	aead_request_set_tfm(&areq->cra_u.aead_req, tfm);
crypto/algif_aead.c:		areq->iocb = msg->msg_iocb;
crypto/algif_aead.c:		areq->outlen = outlen;
crypto/algif_aead.c:		aead_request_set_callback(&areq->cra_u.aead_req,
crypto/algif_aead.c:		err = ctx->enc ? crypto_aead_encrypt(&areq->cra_u.aead_req) :
crypto/algif_aead.c:				 crypto_aead_decrypt(&areq->cra_u.aead_req);
crypto/algif_aead.c:		aead_request_set_callback(&areq->cra_u.aead_req,
crypto/algif_aead.c:				crypto_aead_encrypt(&areq->cra_u.aead_req) :
crypto/algif_aead.c:				crypto_aead_decrypt(&areq->cra_u.aead_req),
crypto/essiv.c:	struct skcipher_request *req = areq->data;
crypto/essiv.c:	crypto_cipher_encrypt_one(tctx->essiv_cipher, req->iv, req->iv);
crypto/essiv.c:	skcipher_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
crypto/essiv.c:				   req->iv);
crypto/essiv.c:	struct aead_request *req = areq->data;
crypto/essiv.c:	struct scatterlist *src = req->src;
crypto/essiv.c:	crypto_cipher_encrypt_one(tctx->essiv_cipher, req->iv, req->iv);
crypto/essiv.c:	if (req->src == req->dst || !enc) {
crypto/essiv.c:		scatterwalk_map_and_copy(req->iv, req->dst,
crypto/essiv.c:					 req->assoclen - crypto_aead_ivsize(tfm),
crypto/essiv.c:		int ssize = req->assoclen - ivsize;
crypto/essiv.c:		nents = sg_nents_for_len(req->src, ssize);
crypto/essiv.c:		memcpy(iv, req->iv, ivsize);
crypto/essiv.c:			scatterwalk_map_and_copy(rctx->assoc, req->src, 0,
crypto/essiv.c:			sg_set_page(rctx->sg, sg_page(req->src), ssize,
crypto/essiv.c:				    req->src->offset);
crypto/essiv.c:		sg = scatterwalk_ffwd(rctx->sg + 2, req->src, req->assoclen);
crypto/essiv.c:	aead_request_set_ad(subreq, req->assoclen);
crypto/essiv.c:	aead_request_set_crypt(subreq, src, req->dst, req->cryptlen, req->iv);
Documentation/cpu-freq/cpufreq-stats.rst:   3. Configuring cpufreq-stats
Documentation/cpu-freq/cpufreq-stats.rst:cpufreq-stats is a driver that provides CPU frequency statistics for each CPU.
Documentation/cpu-freq/cpufreq-stats.rst:3. Configuring cpufreq-stats
Documentation/cpu-freq/cpufreq-stats.rst:To configure cpufreq-stats in your kernel::
Documentation/cpu-freq/cpufreq-stats.rst:cpufreq-stats.
Documentation/cpu-freq/index.rst:   cpufreq-stats
Documentation/devicetree/bindings/memory-controllers/exynos5422-dmc.txt:- devfreq-events : phandles for PPMU devices connected to this DMC.
Documentation/devicetree/bindings/memory-controllers/exynos5422-dmc.txt:- devfreq-events : phandles of the PPMU events used by the controller.
Documentation/devicetree/bindings/memory-controllers/exynos5422-dmc.txt:		devfreq-events = <&ppmu_event3_dmc0_0>,	<&ppmu_event3_dmc0_1>,
Documentation/devicetree/bindings/input/dlg,da7280.txt:- dlg,resonant-freq-hz: use in case of LRA.
Documentation/devicetree/bindings/input/dlg,da7280.txt:- dlg,freq-track-enable: Enable for resonant frequency tracking.
Documentation/devicetree/bindings/input/dlg,da7280.txt:		dlg,resonant-freq-hz = <180>;
Documentation/devicetree/bindings/input/dlg,da7280.txt:		dlg,freq-track-enable;
Documentation/devicetree/bindings/ufs/ufs-mediatek.txt:- freq-table-hz      : Array of <min max> operating frequencies stored in the same
Documentation/devicetree/bindings/ufs/ufs-mediatek.txt:		freq-table-hz = <0 0>;
Documentation/devicetree/bindings/ufs/cdns,ufshc.txt:- freq-table-hz	: Clock frequency table.
Documentation/devicetree/bindings/ufs/cdns,ufshc.txt:		freq-table-hz = <0 0>, <0 0>;
Documentation/devicetree/bindings/ufs/ufs-hisi.txt:- freq-table-hz     : Array of <min max> operating frequencies stored in the same
Documentation/devicetree/bindings/ufs/ufs-hisi.txt:		freq-table-hz = <0 0>, <0 0>;
Documentation/devicetree/bindings/ufs/ufshcd-pltfrm.txt:- freq-table-hz		: Array of <min max> operating frequencies stored in the same
Documentation/devicetree/bindings/ufs/ufshcd-pltfrm.txt:		freq-table-hz = <100000000 200000000>, <0 0>, <0 0>, <0 0>;
Documentation/devicetree/bindings/ufs/ti,j721e-ufs.yaml:                freq-table-hz = <19200000 19200000>;
Documentation/devicetree/bindings/opp/opp.txt:  of frequency and voltage like <freq-kHz vol-uV>.
Documentation/devicetree/bindings/opp/qcom-nvmem-cpufreq.txt:The qcom-cpufreq-nvmem driver reads the msm-id and efuse value from the SoC
Documentation/devicetree/bindings/opp/allwinner,sun50i-h6-operating-points.yaml:  sun50i-cpufreq-nvmem driver reads the efuse value from the SoC to
Documentation/devicetree/bindings/rtc/rtc-cmos.txt:  - freq-reg : Contains the initial value of the frequency register also
Documentation/devicetree/bindings/rtc/rtc-cmos.txt:	         freq-reg = <0x26>;
Documentation/devicetree/bindings/iio/dac/ad5755.txt: - adi,dc-dc-freq-hz:
Documentation/devicetree/bindings/iio/dac/ad5755.txt:	adi,dc-dc-freq-hz = <410000>;
Documentation/devicetree/bindings/thermal/db8500-thermal.txt:	trip0-cdev-name0 = "thermal-cpufreq-0";
Documentation/devicetree/bindings/thermal/db8500-thermal.txt:	trip1-cdev-name0 = "thermal-cpufreq-0";
Documentation/devicetree/bindings/thermal/thermal-cooling-devices.yaml:                    qcom,freq-domain = <&cpufreq_hw 0>;
Documentation/devicetree/bindings/arm/tegra/nvidia,tegra20-pmc.yaml:  nvidia,core-power-req-active-high:
Documentation/devicetree/bindings/arm/tegra/nvidia,tegra20-pmc.yaml:  nvidia,sys-clock-req-active-high:
Documentation/devicetree/bindings/arm/tegra/nvidia,tegra20-pmc.yaml:              nvidia,core-power-req-active-high;
Documentation/devicetree/bindings/arm/tegra/nvidia,tegra20-pmc.yaml:              nvidia,sys-clock-req-active-high;
Documentation/devicetree/bindings/net/wireless/ieee80211.txt: - ieee80211-freq-limit : list of supported frequency ranges in KHz. This can be
Documentation/devicetree/bindings/net/wireless/ieee80211.txt:		ieee80211-freq-limit = <2402000 2482000>,
Documentation/devicetree/bindings/net/wireless/mediatek,mt76.txt:- ieee80211-freq-limit: See ieee80211.txt
Documentation/devicetree/bindings/net/wireless/mediatek,mt76.txt:			ieee80211-freq-limit = <5000000 6000000>;
Documentation/devicetree/bindings/pinctrl/nuvoton,npcm7xx-pinctrl.txt:	clkreq_pins: clkreq-pins {
Documentation/devicetree/bindings/devfreq/event/exynos-ppmu.txt:The Exynos PPMU driver uses the devfreq-event class to provide event data
Documentation/devicetree/bindings/devfreq/rk3399_dmc.txt:- devfreq-events:	 Node to get DDR loading, Refer to
Documentation/devicetree/bindings/devfreq/rk3399_dmc.txt:		devfreq-events = <&dfi>;
Documentation/devicetree/bindings/devfreq/exynos-bus.txt:- devfreq-events: the devfreq-event device to monitor the current utilization
Documentation/devicetree/bindings/devfreq/exynos-bus.txt:		devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
Documentation/devicetree/bindings/devfreq/exynos-bus.txt:		devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:	Definition:	must be "qcom,cpufreq-hw" or "qcom,cpufreq-epss".
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			"freq-domain0", "freq-domain1".
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:- #freq-domain-cells:
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:* Property qcom,freq-domain
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:Devices supporting freq-domain must set their "qcom,freq-domain" property with
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 0>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 0>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 0>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 0>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 1>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 1>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 1>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:			qcom,freq-domain = <&cpufreq_hw 1>;
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:		compatible = "qcom,cpufreq-hw";
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:		reg-names = "freq-domain0", "freq-domain1";
Documentation/devicetree/bindings/cpufreq/cpufreq-qcom-hw.txt:		#freq-domain-cells = <1>;
Documentation/devicetree/bindings/cpufreq/imx-cpufreq-dt.txt:i.MX CPUFreq-DT OPP bindings
Documentation/devicetree/bindings/sound/cs42l52.txt:  - cirrus,chgfreq-divisor : Values used to set the Charge Pump Frequency.
Documentation/devicetree/bindings/sound/cs42l52.txt:	cirrus,chgfreq-divisor = <0x05>;
Documentation/devicetree/bindings/sound/cs42l56.txt:  - cirrus,chgfreq-divisor : Values used to set the Charge Pump Frequency.
Documentation/devicetree/bindings/sound/cs42l56.txt:	cirrus,chgfreq-divisor = <0x05>;
Documentation/power/energy-model.rst:        |  cpufreq-dt   |  |   arm_scmi    |  |    Other     |
Documentation/filesystems/fuse.rst: |          [sleep on req->waitq]     |
Documentation/filesystems/fuse.rst: |          [woken up]                |      [wake up req->waitq]
Documentation/filesystems/fuse.rst: |      [sleep on req->waitq]         |
Documentation/filesystems/fuse.rst: |         [sleep on req->waitq]      |
Documentation/filesystems/fuse.rst:get_user_pages().  The 'req->locked' flag indicates when the copy is
Documentation/driver-api/thermal/cpu-cooling-api.rst:    "thermal-cpufreq-%x". This api can support multiple instances of cpufreq
Documentation/driver-api/thermal/cpu-cooling-api.rst:    the name "thermal-cpufreq-%x" linking it with a device tree node, in
Documentation/driver-api/thermal/cpu-cooling-api.rst:    This interface function unregisters the "thermal-cpufreq-%x" cooling device.
Documentation/driver-api/devfreq.rst:.. kernel-doc:: include/linux/devfreq-event.h
Documentation/driver-api/devfreq.rst:.. kernel-doc:: drivers/devfreq/devfreq-event.c
Documentation/driver-api/mmc/mmc-async-req.rst:  if (is_first_req && req->size > threshold)
Documentation/driver-api/mmc/mmc-async-req.rst:      dma_issue_pending(req->dma_desc);
Documentation/driver-api/mmc/mmc-async-req.rst:      dma_issue_pending(req->dma_desc);
Documentation/driver-api/usb/dwc3.rst:receive a Mass Storage *CBW* [#cbw]_, req->length must either be set
Documentation/ABI/testing/sysfs-class-devfreq:		devfreq-provided central polling
Documentation/ABI/testing/sysfs-class-devfreq-event:What:		/sys/class/devfreq-event/event(x)/
Documentation/ABI/testing/sysfs-class-devfreq-event:		Provide a place in sysfs for the devfreq-event objects.
Documentation/ABI/testing/sysfs-class-devfreq-event:		This allows accessing various devfreq-event specific variables.
Documentation/ABI/testing/sysfs-class-devfreq-event:		The name of devfreq-event object denoted as 'event(x)' which
Documentation/ABI/testing/sysfs-class-devfreq-event:		includes the unique number of 'x' for each devfreq-event object.
Documentation/ABI/testing/sysfs-class-devfreq-event:What:		/sys/class/devfreq-event/event(x)/name
Documentation/ABI/testing/sysfs-class-devfreq-event:		The /sys/class/devfreq-event/event(x)/name attribute contains
Documentation/ABI/testing/sysfs-class-devfreq-event:		the name of the devfreq-event object. This attribute is
Documentation/ABI/testing/sysfs-class-devfreq-event:What:		/sys/class/devfreq-event/event(x)/enable_count
Documentation/ABI/testing/sysfs-class-devfreq-event:		The /sys/class/devfreq-event/event(x)/enable_count attribute
Documentation/ABI/testing/sysfs-class-devfreq-event:		contains the reference count to enable the devfreq-event
Documentation/userspace-api/media/v4l/user-func.rst:    vidioc-enum-freq-bands
Documentation/userspace-api/media/v4l/user-func.rst:    vidioc-s-hw-freq-seek
Documentation/admin-guide/pm/cpufreq_drivers.rst:``cpufreq-nforce2``
Documentation/admin-guide/pm/cpufreq_drivers.rst: The cpufreq-nforce2 driver changes the FSB on nVidia nForce2 platforms.
Documentation/admin-guide/pm/intel-speed-select.rst:          speed-select-turbo-freq-clip-frequencies
kernel/power/qos.c:	list_del(&req->node);
kernel/power/qos.c:		val |= req->flags;
kernel/power/qos.c:		req->flags = val;
kernel/power/qos.c:		INIT_LIST_HEAD(&req->node);
kernel/power/qos.c:		list_add_tail(&req->node, &pqf->list);
kernel/power/qos.c:	return req->qos == &cpu_latency_constraints;
kernel/power/qos.c:	int ret = pm_qos_update_target(req->qos, &req->node, action, value);
kernel/power/qos.c:	req->qos = &cpu_latency_constraints;
kernel/power/qos.c:	if (new_value == req->node.prio)
kernel/power/qos.c:	switch(req->type) {
kernel/power/qos.c:		ret = pm_qos_update_target(&req->qos->min_freq, &req->pnode,
kernel/power/qos.c:		ret = pm_qos_update_target(&req->qos->max_freq, &req->pnode,
kernel/power/qos.c:	req->qos = qos;
kernel/power/qos.c:	req->type = type;
kernel/power/qos.c:		req->qos = NULL;
kernel/power/qos.c:		req->type = 0;
kernel/power/qos.c:	if (req->pnode.prio == new_value)
kernel/power/qos.c:	req->qos = NULL;
kernel/power/qos.c:	req->type = 0;
kernel/sched/fair.c:		 * As is, the util number is not freq-invariant (we'd have to
kernel/events/core.c:		ctx->nr_freq--;
kernel/events/core.c:	 * Since hrtimers have a fixed rate, we can do a static freq->period
net/packet/af_packet.c:	dev = __dev_get_by_index(sock_net(sk), mreq->mr_ifindex);
net/packet/af_packet.c:	if (mreq->mr_alen > dev->addr_len)
net/packet/af_packet.c:		if (ml->ifindex == mreq->mr_ifindex &&
net/packet/af_packet.c:		    ml->type == mreq->mr_type &&
net/packet/af_packet.c:		    ml->alen == mreq->mr_alen &&
net/packet/af_packet.c:		    memcmp(ml->addr, mreq->mr_address, ml->alen) == 0) {
net/packet/af_packet.c:	i->type = mreq->mr_type;
net/packet/af_packet.c:	i->ifindex = mreq->mr_ifindex;
net/packet/af_packet.c:	i->alen = mreq->mr_alen;
net/packet/af_packet.c:	memcpy(i->addr, mreq->mr_address, i->alen);
net/packet/af_packet.c:		if (ml->ifindex == mreq->mr_ifindex &&
net/packet/af_packet.c:		    ml->type == mreq->mr_type &&
net/packet/af_packet.c:		    ml->alen == mreq->mr_alen &&
net/packet/af_packet.c:		    memcmp(ml->addr, mreq->mr_address, ml->alen) == 0) {
net/packet/af_packet.c:	unsigned int block_nr = req->tp_block_nr;
net/packet/af_packet.c:	if (req->tp_block_nr) {
net/packet/af_packet.c:		if (unlikely((int)req->tp_block_size <= 0))
net/packet/af_packet.c:		if (unlikely(!PAGE_ALIGNED(req->tp_block_size)))
net/packet/af_packet.c:		    req->tp_block_size <
net/packet/af_packet.c:		if (unlikely(req->tp_frame_size < min_frame_size))
net/packet/af_packet.c:		if (unlikely(req->tp_frame_size & (TPACKET_ALIGNMENT - 1)))
net/packet/af_packet.c:		rb->frames_per_block = req->tp_block_size / req->tp_frame_size;
net/packet/af_packet.c:		if (unlikely(rb->frames_per_block > UINT_MAX / req->tp_block_nr))
net/packet/af_packet.c:		if (unlikely((rb->frames_per_block * req->tp_block_nr) !=
net/packet/af_packet.c:					req->tp_frame_nr))
net/packet/af_packet.c:		order = get_order(req->tp_block_size);
net/packet/af_packet.c:				rx_owner_map = bitmap_alloc(req->tp_frame_nr,
net/packet/af_packet.c:		if (unlikely(req->tp_frame_nr))
net/packet/af_packet.c:		rb->frame_max = (req->tp_frame_nr - 1);
net/packet/af_packet.c:		rb->frame_size = req->tp_frame_size;
net/packet/af_packet.c:		swap(rb->pg_vec_len, req->tp_block_nr);
net/packet/af_packet.c:		rb->pg_vec_pages = req->tp_block_size/PAGE_SIZE;
net/packet/af_packet.c:		free_pg_vec(pg_vec, order, req->tp_block_nr);
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_INFO) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_INFO) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_MCLIST) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_RING_CFG) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_FANOUT) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_MEMINFO) &&
net/packet/diag.c:	if ((req->pdiag_show & PACKET_SHOW_FILTER) &&
net/packet/diag.c:	if (req->sdiag_protocol)
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_NAME) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_VFS) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_PEER) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_ICONS) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_RQLEN) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_MEMINFO) &&
net/unix/diag.c:	if ((req->udiag_show & UDIAG_SHOW_UID) &&
net/unix/diag.c:			if (!(req->udiag_states & (1 << sk->sk_state)))
net/unix/diag.c:	if (req->udiag_ino == 0)
net/unix/diag.c:	sk = unix_lookup_by_ino(req->udiag_ino);
net/unix/diag.c:	err = sock_diag_check_cookie(sk, req->udiag_cookie);
net/unix/diag.c:			   nlh->nlmsg_seq, 0, req->udiag_ino);
net/wireless/of.c:	prop = of_find_property(np, "ieee80211-freq-limit", &len);
net/wireless/of.c:		dev_err(dev, "ieee80211-freq-limit wrong format");
net/wireless/mlme.c:	    (!req->prev_bssid || !ether_addr_equal(wdev->current_bss->pub.bssid,
net/wireless/mlme.c:						   req->prev_bssid)))
net/wireless/mlme.c:	cfg80211_oper_and_ht_capa(&req->ht_capa_mask,
net/wireless/mlme.c:	cfg80211_oper_and_vht_capa(&req->vht_capa_mask,
net/wireless/mlme.c:	req->bss = cfg80211_get_bss(&rdev->wiphy, chan, bssid, ssid, ssid_len,
net/wireless/mlme.c:	if (!req->bss)
net/wireless/mlme.c:		cfg80211_hold_bss(bss_from_pub(req->bss));
net/wireless/mlme.c:		cfg80211_put_bss(&rdev->wiphy, req->bss);
net/wireless/wext-sme.c:		freq->m = chan->center_freq;
net/wireless/wext-sme.c:		freq->e = 6;
net/wireless/nl80211.c:		flags = &req->flags;
net/wireless/nl80211.c:		mac_addr = req->mac_addr;
net/wireless/nl80211.c:		mac_addr_mask = req->mac_addr_mask;
net/wireless/nl80211.c:		flags = &req->flags;
net/wireless/nl80211.c:		mac_addr = req->mac_addr;
net/wireless/nl80211.c:		mac_addr_mask = req->mac_addr_mask;
net/wireless/nl80211.c:		sched_scan_req->reqid = cfg80211_assign_cookie(rdev);
net/wireless/nl80211.c:	sched_scan_req->dev = dev;
net/wireless/nl80211.c:	sched_scan_req->wiphy = &rdev->wiphy;
net/wireless/nl80211.c:		sched_scan_req->owner_nlportid = info->snd_portid;
net/wireless/nl80211.c:	if (!req || req->reqid ||
net/wireless/nl80211.c:	    (req->owner_nlportid &&
net/wireless/nl80211.c:	     req->owner_nlportid != info->snd_portid))
net/wireless/nl80211.c:	if (req->n_scan_plans == 1 &&
net/wireless/nl80211.c:			req->scan_plans[0].interval * 1000))
net/wireless/nl80211.c:	if (nla_put_u32(msg, NL80211_ATTR_SCHED_SCAN_DELAY, req->delay))
net/wireless/nl80211.c:	if (req->relative_rssi_set) {
net/wireless/nl80211.c:			       req->relative_rssi))
net/wireless/nl80211.c:		rssi_adjust.band = req->rssi_adjust.band;
net/wireless/nl80211.c:		rssi_adjust.delta = req->rssi_adjust.delta;
net/wireless/nl80211.c:	for (i = 0; i < req->n_channels; i++) {
net/wireless/nl80211.c:		if (nla_put_u32(msg, i, req->channels[i]->center_freq))
net/wireless/nl80211.c:	if (req->n_match_sets) {
net/wireless/nl80211.c:		for (i = 0; i < req->n_match_sets; i++) {
net/wireless/nl80211.c:				    req->match_sets[i].ssid.ssid_len,
net/wireless/nl80211.c:				    req->match_sets[i].ssid.ssid))
net/wireless/nl80211.c:	for (i = 0; i < req->n_scan_plans; i++) {
net/wireless/nl80211.c:				req->scan_plans[i].interval) ||
net/wireless/nl80211.c:		    (req->scan_plans[i].iterations &&
net/wireless/nl80211.c:				 req->scan_plans[i].iterations)))
net/wireless/nl80211.c:	for (i = 0; i < req->n_ssids; i++) {
net/wireless/nl80211.c:		if (nla_put(msg, i, req->ssids[i].ssid_len, req->ssids[i].ssid))
net/wireless/nl80211.c:	if (req->flags & NL80211_SCAN_FLAG_FREQ_KHZ) {
net/wireless/nl80211.c:		for (i = 0; i < req->n_channels; i++) {
net/wireless/nl80211.c:				   ieee80211_channel_to_khz(req->channels[i])))
net/wireless/nl80211.c:		for (i = 0; i < req->n_channels; i++) {
net/wireless/nl80211.c:			if (nla_put_u32(msg, i, req->channels[i]->center_freq))
net/wireless/nl80211.c:	if (req->ie &&
net/wireless/nl80211.c:	    nla_put(msg, NL80211_ATTR_IE, req->ie_len, req->ie))
net/wireless/nl80211.c:	if (req->flags &&
net/wireless/nl80211.c:	    nla_put_u32(msg, NL80211_ATTR_SCAN_FLAGS, req->flags))
net/wireless/nl80211.c:	info = rdev->int_scan_req ? &rdev->int_scan_req->info :
net/wireless/nl80211.c:		&rdev->scan_req->info;
net/wireless/nl80211.c:			wiphy_to_rdev(req->wiphy)->wiphy_idx) ||
net/wireless/nl80211.c:	    nla_put_u32(msg, NL80211_ATTR_IFINDEX, req->dev->ifindex) ||
net/wireless/nl80211.c:	    nla_put_u64_64bit(msg, NL80211_ATTR_COOKIE, req->reqid,
net/wireless/nl80211.c:	genlmsg_multicast_netns(&nl80211_fam, wiphy_net(req->wiphy), msg, 0,
net/wireless/nl80211.c:			if (sched_scan_req->owner_nlportid == notify->portid) {
net/wireless/nl80211.c:				sched_scan_req->nl_owner_dead = true;
net/wireless/pmsr.c:		req->timeout = nla_get_u32(info->attrs[NL80211_ATTR_TIMEOUT]);
net/wireless/pmsr.c:		err = nl80211_parse_random_mac(info->attrs, req->mac_addr,
net/wireless/pmsr.c:					       req->mac_addr_mask);
net/wireless/pmsr.c:		memcpy(req->mac_addr, wdev_address(wdev), ETH_ALEN);
net/wireless/pmsr.c:		eth_broadcast_addr(req->mac_addr_mask);
net/wireless/pmsr.c:		err = pmsr_parse_peer(rdev, peer, &req->peers[idx], info);
net/wireless/pmsr.c:	req->n_peers = count;
net/wireless/pmsr.c:	req->cookie = cfg80211_assign_cookie(rdev);
net/wireless/pmsr.c:	req->nl_portid = info->snd_portid;
net/wireless/pmsr.c:	list_add_tail(&req->list, &wdev->pmsr_list);
net/wireless/pmsr.c:	nl_set_extack_cookie_u64(info->extack, req->cookie);
net/wireless/pmsr.c:	trace_cfg80211_pmsr_complete(wdev->wiphy, wdev, req->cookie);
net/wireless/pmsr.c:	if (nla_put_u64_64bit(msg, NL80211_ATTR_COOKIE, req->cookie,
net/wireless/pmsr.c:	genlmsg_unicast(wiphy_net(wdev->wiphy), msg, req->nl_portid);
net/wireless/pmsr.c:	list_del(&req->list);
net/wireless/pmsr.c:	trace_cfg80211_pmsr_report(wdev->wiphy, wdev, req->cookie,
net/wireless/pmsr.c:	if (nla_put_u64_64bit(msg, NL80211_ATTR_COOKIE, req->cookie,
net/wireless/pmsr.c:	genlmsg_unicast(wiphy_net(wdev->wiphy), msg, req->nl_portid);
net/wireless/pmsr.c:		if (req->nl_portid)
net/wireless/pmsr.c:		list_move_tail(&req->list, &free_list);
net/wireless/pmsr.c:		req->nl_portid = 0;
net/wireless/pmsr.c:		if (req->nl_portid == portid) {
net/wireless/pmsr.c:			req->nl_portid = 0;
net/wireless/reg.c:			list_del(&ureq->list);
net/wireless/ibss.c:		freq->m = chan->center_freq;
net/wireless/ibss.c:		freq->e = 6;
net/wireless/trace.h:		if (req->bss)
net/wireless/trace.h:			MAC_ASSIGN(bssid, req->bss->bssid);
net/wireless/trace.h:		__entry->auth_type = req->auth_type;
net/wireless/trace.h:		if (req->bss)
net/wireless/trace.h:			MAC_ASSIGN(bssid, req->bss->bssid);
net/wireless/trace.h:		MAC_ASSIGN(prev_bssid, req->prev_bssid);
net/wireless/trace.h:		__entry->use_mfp = req->use_mfp;
net/wireless/trace.h:		__entry->flags = req->flags;
net/wireless/trace.h:		MAC_ASSIGN(bssid, req->bssid);
net/wireless/trace.h:		__entry->reason_code = req->reason_code;
net/wireless/trace.h:		if (req->bss)
net/wireless/trace.h:			MAC_ASSIGN(bssid, req->bss->bssid);
net/wireless/trace.h:		__entry->reason_code = req->reason_code;
net/wireless/trace.h:		__entry->local_state_change = req->local_state_change;
net/wireless/core.c:	if (rdev->scan_req && rdev->scan_req->wdev == wdev) {
net/wireless/core.c:		if (WARN_ON(!rdev->scan_req->notified &&
net/wireless/core.c:			     !rdev->int_scan_req->notified)))
net/wireless/core.c:			rdev->scan_req->info.aborted = true;
net/wireless/core.c:		if (req->nl_owner_dead)
net/wireless/core.c:		if (rdev->scan_req && rdev->scan_req->wdev == wdev) {
net/wireless/core.c:			if (WARN_ON(!rdev->scan_req->notified &&
net/wireless/core.c:				     !rdev->int_scan_req->notified)))
net/wireless/core.c:				rdev->scan_req->info.aborted = true;
net/wireless/wext-compat.c:	if (freq->e == 0) {
net/wireless/wext-compat.c:		if (freq->m < 0)
net/wireless/wext-compat.c:		if (freq->m > 14)
net/wireless/wext-compat.c:		return ieee80211_channel_to_frequency(freq->m, band);
net/wireless/wext-compat.c:		for (i = 0; i < freq->e; i++)
net/wireless/wext-compat.c:		return freq->m / div;
net/wireless/wext-compat.c:		freq->m = chandef.chan->center_freq;
net/wireless/wext-compat.c:		freq->e = 6;
net/wireless/scan.c:	rdev_req->scan_6ghz = true;
net/wireless/scan.c:					       rdev_req->wdev->iftype);
net/wireless/scan.c:	if (rdev_req->flags & NL80211_SCAN_FLAG_COLOCATED_6GHZ) {
net/wireless/scan.c:	for (i = 0; i < rdev_req->n_channels; i++) {
net/wireless/scan.c:		if (rdev_req->channels[i]->band == NL80211_BAND_6GHZ &&
net/wireless/scan.c:		      cfg80211_channel_is_psc(rdev_req->channels[i])) ||
net/wireless/scan.c:		     !(rdev_req->flags & NL80211_SCAN_FLAG_COLOCATED_6GHZ))) {
net/wireless/scan.c:						   rdev_req->channels[i],
net/wireless/scan.c:	if (!(rdev_req->flags & NL80211_SCAN_FLAG_COLOCATED_6GHZ))
net/wireless/scan.c:		for (i = 0; i < rdev_req->n_channels; i++) {
net/wireless/scan.c:			if (rdev_req->channels[i] == chan)
net/wireless/scan.c:			rdev->int_scan_req->info = old->info;
net/wireless/scan.c:	for (i = 0; i < rdev_req->n_channels; i++) {
net/wireless/scan.c:		if (rdev_req->channels[i]->band != NL80211_BAND_6GHZ)
net/wireless/scan.c:	for (i = idx = 0; i < rdev_req->n_channels; i++) {
net/wireless/scan.c:		if (rdev_req->channels[i]->band != NL80211_BAND_6GHZ)
net/wireless/scan.c:			request->channels[idx++] = rdev_req->channels[i];
net/wireless/scan.c:	rdev_req->scan_6ghz = false;
net/wireless/scan.c:	wdev = rdev_req->wdev;
net/wireless/scan.c:	    !rdev_req->scan_6ghz && !request->info.aborted &&
net/wireless/scan.c:	list_add_rcu(&req->list, &rdev->sched_scan_req_list);
net/wireless/scan.c:	list_del_rcu(&req->list);
net/wireless/scan.c:		if (req->report_results) {
net/wireless/scan.c:			req->report_results = false;
net/wireless/scan.c:			if (req->flags & NL80211_SCAN_FLAG_FLUSH) {
net/wireless/scan.c:				__cfg80211_bss_expire(rdev, req->scan_start);
net/wireless/scan.c:				req->scan_start = jiffies;
net/wireless/scan.c:		int err = rdev_sched_scan_stop(rdev, req->dev, req->reqid);
net/wireless/scan.c:	if (wreq && wreq->num_channels)
net/wireless/scan.c:		n_channels = wreq->num_channels;
net/wireless/scan.c:	creq->wiphy = wiphy;
net/wireless/scan.c:	creq->wdev = dev->ieee80211_ptr;
net/wireless/scan.c:	creq->ssids = (void *)&creq->channels[n_channels];
net/wireless/scan.c:	creq->n_channels = n_channels;
net/wireless/scan.c:	creq->n_ssids = 1;
net/wireless/scan.c:	creq->scan_start = jiffies;
net/wireless/scan.c:			if (wreq && wreq->num_channels) {
net/wireless/scan.c:				for (k = 0; k < wreq->num_channels; k++) {
net/wireless/scan.c:						&wreq->channel_list[k];
net/wireless/scan.c:			creq->channels[i] = &wiphy->bands[band]->channels[j];
net/wireless/scan.c:	/* Set real number of channels specified in creq->channels[] */
net/wireless/scan.c:	creq->n_channels = i;
net/wireless/scan.c:			if (wreq->essid_len > IEEE80211_MAX_SSID_LEN) {
net/wireless/scan.c:			memcpy(creq->ssids[0].ssid, wreq->essid, wreq->essid_len);
net/wireless/scan.c:			creq->ssids[0].ssid_len = wreq->essid_len;
net/wireless/scan.c:		if (wreq->scan_type == IW_SCAN_TYPE_PASSIVE)
net/wireless/scan.c:			creq->n_ssids = 0;
net/wireless/scan.c:			creq->rates[i] = (1 << wiphy->bands[i]->n_bitrates) - 1;
net/wireless/scan.c:	eth_broadcast_addr(creq->bssid);
net/9p/trans_rdma.c:	if (unlikely(req->rc.sdata)) {
net/9p/trans_rdma.c:	req->rc.size = c->rc.size;
net/9p/trans_rdma.c:	req->rc.sdata = c->rc.sdata;
net/9p/trans_rdma.c:			    c->busa, c->req->tc.size,
net/9p/trans_rdma.c:			p9_fcall_fini(&req->rc);
net/9p/trans_rdma.c:			req->rc.sdata = NULL;
net/9p/trans_rdma.c:	rpl_context->rc.sdata = req->rc.sdata;
net/9p/trans_rdma.c:	req->rc.sdata = NULL;
net/9p/trans_rdma.c:				    c->req->tc.sdata, c->req->tc.size,
net/9p/trans_rdma.c:	sge.length = c->req->tc.size;
net/9p/trans_rdma.c:	req->status = REQ_STATUS_SENT;
net/9p/trans_rdma.c:	req->status = REQ_STATUS_ERROR;
net/9p/trans_xen.c:	u32 size = p9_req->tc.size;
net/9p/trans_xen.c:	num = p9_req->tc.tag % priv->num_rings;
net/9p/trans_xen.c:	xen_9pfs_write_packet(ring->data.out, p9_req->tc.sdata, size,
net/9p/trans_xen.c:	p9_req->status = REQ_STATUS_SENT;
net/9p/trans_xen.c:		if (!req || req->status != REQ_STATUS_SENT) {
net/9p/trans_xen.c:		memcpy(&req->rc, &h, sizeof(h));
net/9p/trans_xen.c:		req->rc.offset = 0;
net/9p/trans_xen.c:		xen_9pfs_read_packet(req->rc.sdata, ring->data.in, h.size,
net/9p/trans_xen.c:		status = (req->status != REQ_STATUS_ERROR) ?
net/9p/trans_virtio.c:			req->rc.size = len;
net/9p/trans_virtio.c:	req->status = REQ_STATUS_SENT;
net/9p/trans_virtio.c:			   VIRTQUEUE_NUM, req->tc.sdata, req->tc.size);
net/9p/trans_virtio.c:			  VIRTQUEUE_NUM, req->rc.sdata, req->rc.capacity);
net/9p/trans_virtio.c:			memcpy(&req->tc.sdata[req->tc.size - 4], &v, 4);
net/9p/trans_virtio.c:		sz = cpu_to_le32(req->tc.size + outlen);
net/9p/trans_virtio.c:		memcpy(&req->tc.sdata[0], &sz, sizeof(sz));
net/9p/trans_virtio.c:			memcpy(&req->tc.sdata[req->tc.size - 4], &v, 4);
net/9p/trans_virtio.c:	req->status = REQ_STATUS_SENT;
net/9p/trans_virtio.c:			   VIRTQUEUE_NUM, req->tc.sdata, req->tc.size);
net/9p/trans_virtio.c:			  VIRTQUEUE_NUM, req->rc.sdata, in_hdr_len);
net/9p/trans_virtio.c:	err = wait_event_killable(req->wq, req->status >= REQ_STATUS_RCVD);
net/9p/trans_fd.c:		list_move(&req->req_list, &cancel_list);
net/9p/trans_fd.c:		list_move(&req->req_list, &cancel_list);
net/9p/trans_fd.c:		list_del(&req->req_list);
net/9p/trans_fd.c:		if (!req->t_err)
net/9p/trans_fd.c:			req->t_err = err;
net/9p/trans_fd.c:		if (!m->rreq || (m->rreq->status != REQ_STATUS_SENT)) {
net/9p/trans_fd.c:		if (!m->rreq->rc.sdata) {
net/9p/trans_fd.c:		m->rc.sdata = m->rreq->rc.sdata;
net/9p/trans_fd.c:		m->rreq->rc.size = m->rc.offset;
net/9p/trans_fd.c:		if (m->rreq->status == REQ_STATUS_SENT) {
net/9p/trans_fd.c:			list_del(&m->rreq->req_list);
net/9p/trans_fd.c:		} else if (m->rreq->status == REQ_STATUS_FLSHD) {
net/9p/trans_fd.c:		req->status = REQ_STATUS_SENT;
net/9p/trans_fd.c:		list_move_tail(&req->req_list, &m->req_list);
net/9p/trans_fd.c:		m->wbuf = req->tc.sdata;
net/9p/trans_fd.c:		m->wsize = req->tc.size;
net/9p/trans_fd.c:		 m, current, &req->tc, req->tc.id);
net/9p/trans_fd.c:	req->status = REQ_STATUS_UNSENT;
net/9p/trans_fd.c:	list_add_tail(&req->req_list, &m->unsent_req_list);
net/9p/trans_fd.c:	if (req->status == REQ_STATUS_UNSENT) {
net/9p/trans_fd.c:		list_del(&req->req_list);
net/9p/trans_fd.c:		req->status = REQ_STATUS_FLSHD;
net/9p/trans_fd.c:	if (req->status == REQ_STATUS_RCVD) {
net/9p/trans_fd.c:	list_del(&req->req_list);
net/9p/trans_fd.c:	req->status = REQ_STATUS_FLSHD;
net/9p/client.c:	if (p9_fcall_init(c, &req->tc, alloc_msize))
net/9p/client.c:	if (p9_fcall_init(c, &req->rc, alloc_msize))
net/9p/client.c:	p9pdu_reset(&req->tc);
net/9p/client.c:	p9pdu_reset(&req->rc);
net/9p/client.c:	req->t_err = 0;
net/9p/client.c:	req->status = REQ_STATUS_ALLOC;
net/9p/client.c:	init_waitqueue_head(&req->wq);
net/9p/client.c:	INIT_LIST_HEAD(&req->req_list);
net/9p/client.c:	req->tc.tag = tag;
net/9p/client.c:	refcount_set(&req->refcount.refcount, 2);
net/9p/client.c:	p9_fcall_fini(&req->tc);
net/9p/client.c:	p9_fcall_fini(&req->rc);
net/9p/client.c:		if (req->tc.tag != tag) {
net/9p/client.c:				req->tc.tag);
net/9p/client.c:	p9_debug(P9_DEBUG_MUX, " tag %d\n", req->tc.tag);
net/9p/client.c:	req->status = status;
net/9p/client.c:	wake_up(&req->wq);
net/9p/client.c:	p9_debug(P9_DEBUG_MUX, "wakeup: %d\n", req->tc.tag);
net/9p/client.c:	err = p9_parse_header(&req->rc, NULL, &type, NULL, 0);
net/9p/client.c:	if (req->rc.size >= c->msize) {
net/9p/client.c:			 req->rc.size);
net/9p/client.c:	trace_9p_protocol_dump(c, &req->rc);
net/9p/client.c:		err = p9pdu_readf(&req->rc, c->proto_version, "s?d",
net/9p/client.c:		err = p9pdu_readf(&req->rc, c->proto_version, "d", &ecode);
net/9p/client.c:	err = p9_parse_header(&req->rc, NULL, &type, NULL, 0);
net/9p/client.c:	trace_9p_protocol_dump(c, &req->rc);
net/9p/client.c:		len = req->rc.size - req->rc.offset;
net/9p/client.c:		ename = &req->rc.sdata[req->rc.offset];
net/9p/client.c:		err = p9pdu_readf(&req->rc, c->proto_version, "s?d",
net/9p/client.c:		err = p9pdu_readf(&req->rc, c->proto_version, "d", &ecode);
net/9p/client.c:	err = p9_parse_header(&oldreq->tc, NULL, NULL, &oldtag, 1);
net/9p/client.c:	if (oldreq->status == REQ_STATUS_SENT) {
net/9p/client.c:	p9pdu_prepare(&req->tc, req->tc.tag, type);
net/9p/client.c:	err = p9pdu_vwritef(&req->tc, c->proto_version, fmt, ap);
net/9p/client.c:	p9pdu_finalize(c, &req->tc);
net/9p/client.c:	trace_9p_client_req(c, type, req->tc.tag);
net/9p/client.c:	err = wait_event_killable(req->wq, req->status >= REQ_STATUS_RCVD);
net/9p/client.c:	if (req->status == REQ_STATUS_ERROR) {
net/9p/client.c:		p9_debug(P9_DEBUG_ERROR, "req_status error %d\n", req->t_err);
net/9p/client.c:		err = req->t_err;
net/9p/client.c:		if (req->status == REQ_STATUS_RCVD)
net/9p/client.c:	trace_9p_client_res(c, type, req->rc.tag, err);
net/9p/client.c:	if (req->status == REQ_STATUS_ERROR) {
net/9p/client.c:		p9_debug(P9_DEBUG_ERROR, "req_status error %d\n", req->t_err);
net/9p/client.c:		err = req->t_err;
net/9p/client.c:		if (req->status == REQ_STATUS_RCVD)
net/9p/client.c:	trace_9p_client_res(c, type, req->rc.tag, err);
net/9p/client.c:	err = p9pdu_readf(&req->rc, c->proto_version, "ds", &msize, &version);
net/9p/client.c:		trace_9p_protocol_dump(c, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Q", &qid);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "R", &nwqids, &wqids);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Qd", &qid, &iounit);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Qd", qid, &iounit);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Qd", &qid, &iounit);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Q", qid);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	*err = p9pdu_readf(&req->rc, clnt->proto_version,
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:		*err = p9pdu_readf(&req->rc, clnt->proto_version, "d", &count);
net/9p/client.c:			trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "wS", &ignored, ret);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "A", ret);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "ddqqqqqqd", &sb->type,
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "q", attr_size);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "D", &count, &dataptr);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Q", qid);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "Q", qid);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "b", status);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "bqqds", &glock->type,
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/9p/client.c:	err = p9pdu_readf(&req->rc, clnt->proto_version, "s", target);
net/9p/client.c:		trace_9p_protocol_dump(clnt, &req->rc);
net/mptcp/mptcp_diag.c:	msk = mptcp_token_get_sock(req->id.idiag_cookie[0]);
net/mptcp/token.c:		if (req->token == token)
net/mptcp/token.c:	mptcp_crypto_key_sha(subflow_req->local_key,
net/mptcp/token.c:			     &subflow_req->token,
net/mptcp/token.c:			     &subflow_req->idsn);
net/mptcp/token.c:		 req, subflow_req->local_key, subflow_req->token,
net/mptcp/token.c:		 subflow_req->idsn);
net/mptcp/token.c:	token = subflow_req->token;
net/mptcp/token.c:	hlist_nulls_add_head_rcu(&subflow_req->token_node, &bucket->req_chain);
net/mptcp/token.c:	bucket = token_bucket(req->token);
net/mptcp/token.c:	pos = __token_lookup_req(bucket, req->token);
net/mptcp/token.c:		hlist_nulls_del_init_rcu(&req->token_node);
net/mptcp/token.c:	if (hlist_nulls_unhashed(&subflow_req->token_node))
net/mptcp/token.c:	bucket = token_bucket(subflow_req->token);
net/mptcp/token.c:	pos = __token_lookup_req(bucket, subflow_req->token);
net/mptcp/subflow.c:	if (subflow_req->msk)
net/mptcp/subflow.c:		sock_put((struct sock *)subflow_req->msk);
net/mptcp/subflow.c:	struct mptcp_sock *msk = subflow_req->msk;
net/mptcp/subflow.c:	get_random_bytes(&subflow_req->local_nonce, sizeof(u32));
net/mptcp/subflow.c:			      subflow_req->local_nonce,
net/mptcp/subflow.c:			      subflow_req->remote_nonce, hmac);
net/mptcp/subflow.c:	subflow_req->thmac = get_unaligned_be64(hmac);
net/mptcp/subflow.c:	msk = mptcp_token_get_sock(subflow_req->token);
net/mptcp/subflow.c:	subflow_req->local_id = local_id;
net/mptcp/subflow.c:	subflow_req->mp_capable = 0;
net/mptcp/subflow.c:	subflow_req->mp_join = 0;
net/mptcp/subflow.c:	subflow_req->msk = NULL;
net/mptcp/subflow.c:		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq;
net/mptcp/subflow.c:			get_random_bytes(&subflow_req->local_key, sizeof(subflow_req->local_key));
net/mptcp/subflow.c:		} while (subflow_req->local_key == 0);
net/mptcp/subflow.c:		if (unlikely(req->syncookie)) {
net/mptcp/subflow.c:			mptcp_crypto_key_sha(subflow_req->local_key,
net/mptcp/subflow.c:					     &subflow_req->token,
net/mptcp/subflow.c:					     &subflow_req->idsn);
net/mptcp/subflow.c:			if (mptcp_token_exists(subflow_req->token)) {
net/mptcp/subflow.c:				subflow_req->mp_capable = 1;
net/mptcp/subflow.c:			subflow_req->mp_capable = 1;
net/mptcp/subflow.c:		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq;
net/mptcp/subflow.c:		subflow_req->mp_join = 1;
net/mptcp/subflow.c:		subflow_req->backup = mp_opt.backup;
net/mptcp/subflow.c:		subflow_req->remote_id = mp_opt.join_id;
net/mptcp/subflow.c:		subflow_req->token = mp_opt.token;
net/mptcp/subflow.c:		subflow_req->remote_nonce = mp_opt.nonce;
net/mptcp/subflow.c:		subflow_req->msk = subflow_token_join_request(req);
net/mptcp/subflow.c:		if (!subflow_req->msk)
net/mptcp/subflow.c:		if (subflow_use_different_sport(subflow_req->msk, sk_listener)) {
net/mptcp/subflow.c:				 ntohs(inet_sk((struct sock *)subflow_req->msk)->inet_sport));
net/mptcp/subflow.c:			if (!mptcp_pm_sport_in_anno_list(subflow_req->msk, sk_listener)) {
net/mptcp/subflow.c:				sock_put((struct sock *)subflow_req->msk);
net/mptcp/subflow.c:				subflow_req->msk = NULL;
net/mptcp/subflow.c:				subflow_req->mp_join = 0;
net/mptcp/subflow.c:		if (unlikely(req->syncookie)) {
net/mptcp/subflow.c:			if (mptcp_can_accept_new_subflow(subflow_req->msk))
net/mptcp/subflow.c:		pr_debug("token=%u, remote_nonce=%u msk=%p", subflow_req->token,
net/mptcp/subflow.c:			 subflow_req->remote_nonce, subflow_req->msk);
net/mptcp/subflow.c:		subflow_req->local_key = mp_opt.rcvr_key;
net/mptcp/subflow.c:		subflow_req->mp_capable = 1;
net/mptcp/subflow.c:		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq - 1;
net/mptcp/subflow.c:		if (mptcp_can_accept_new_subflow(subflow_req->msk))
net/mptcp/subflow.c:			subflow_req->mp_join = 1;
net/mptcp/subflow.c:		subflow_req->ssn_offset = TCP_SKB_CB(skb)->seq - 1;
net/mptcp/subflow.c:	if (!req->syncookie)
net/mptcp/subflow.c:	if (!req->syncookie)
net/mptcp/subflow.c:	msk = subflow_req->msk;
net/mptcp/subflow.c:			      subflow_req->remote_nonce,
net/mptcp/subflow.c:			      subflow_req->local_nonce, hmac);
net/mptcp/subflow.c:	 * from req->sk.  The tcp socket is released.
net/mptcp/subflow.c:	fallback_is_fatal = tcp_rsk(req)->is_mptcp && subflow_req->mp_join;
net/mptcp/subflow.c:	if (subflow_req->mp_capable) {
net/mptcp/subflow.c:		if (TCP_SKB_CB(skb)->seq != subflow_req->ssn_offset + 1) {
net/mptcp/subflow.c:	} else if (subflow_req->mp_join) {
net/mptcp/subflow.c:		    !mptcp_can_accept_new_subflow(subflow_req->msk)) {
net/mptcp/subflow.c:			owner = subflow_req->msk;
net/mptcp/subflow.c:			subflow_req->msk = NULL;
net/mptcp/subflow.c:	req->rsk_ops->send_reset(sk, skb);
net/mptcp/subflow.c:	    (!subflow_req->mp_capable && !subflow_req->mp_join)) {
net/mptcp/subflow.c:	if (subflow_req->mp_capable) {
net/mptcp/subflow.c:		new_ctx->local_key = subflow_req->local_key;
net/mptcp/subflow.c:		new_ctx->token = subflow_req->token;
net/mptcp/subflow.c:		new_ctx->ssn_offset = subflow_req->ssn_offset;
net/mptcp/subflow.c:		new_ctx->idsn = subflow_req->idsn;
net/mptcp/subflow.c:	} else if (subflow_req->mp_join) {
net/mptcp/subflow.c:		new_ctx->ssn_offset = subflow_req->ssn_offset;
net/mptcp/subflow.c:		new_ctx->backup = subflow_req->backup;
net/mptcp/subflow.c:		new_ctx->local_id = subflow_req->local_id;
net/mptcp/subflow.c:		new_ctx->remote_id = subflow_req->remote_id;
net/mptcp/subflow.c:		new_ctx->token = subflow_req->token;
net/mptcp/subflow.c:		new_ctx->thmac = subflow_req->thmac;
net/mptcp/token_test.c:	KUNIT_EXPECT_NE(test, 0, (int)req->token);
net/mptcp/token_test.c:	KUNIT_EXPECT_PTR_EQ(test, null_msk, mptcp_token_get_sock(req->token));
net/mptcp/token_test.c:	msk->token = req->token;
net/mptcp/token_test.c:	msk->token = req->token;
net/mptcp/syncookies.c:	entry->token = subflow_req->token;
net/mptcp/syncookies.c:	entry->remote_nonce = subflow_req->remote_nonce;
net/mptcp/syncookies.c:	entry->local_nonce = subflow_req->local_nonce;
net/mptcp/syncookies.c:	entry->backup = subflow_req->backup;
net/mptcp/syncookies.c:	entry->join_id = subflow_req->remote_id;
net/mptcp/syncookies.c:	entry->local_id = subflow_req->local_id;
net/mptcp/syncookies.c:	struct net *net = read_pnet(&subflow_req->sk.req.ireq_net);
net/mptcp/syncookies.c:	struct net *net = read_pnet(&subflow_req->sk.req.ireq_net);
net/mptcp/syncookies.c:	subflow_req->remote_nonce = e->remote_nonce;
net/mptcp/syncookies.c:	subflow_req->local_nonce = e->local_nonce;
net/mptcp/syncookies.c:	subflow_req->backup = e->backup;
net/mptcp/syncookies.c:	subflow_req->remote_id = e->join_id;
net/mptcp/syncookies.c:	subflow_req->token = e->token;
net/mptcp/syncookies.c:	subflow_req->msk = msk;
net/mptcp/options.c:	if (subflow_req->mp_capable) {
net/mptcp/options.c:		opts->sndr_key = subflow_req->local_key;
net/mptcp/options.c:			 subflow_req, subflow_req->local_key);
net/mptcp/options.c:	} else if (subflow_req->mp_join) {
net/mptcp/options.c:		opts->backup = subflow_req->backup;
net/mptcp/options.c:		opts->join_id = subflow_req->local_id;
net/mptcp/options.c:		opts->thmac = subflow_req->thmac;
net/mptcp/options.c:		opts->nonce = subflow_req->local_nonce;
net/mptcp/protocol.c:	msk->local_key = subflow_req->local_key;
net/mptcp/protocol.c:	msk->token = subflow_req->token;
net/mptcp/protocol.c:	msk->write_seq = subflow_req->idsn + 1;
net/mptcp/protocol.c:	msk->wnd_end = msk->snd_nxt + req->rsk_rcv_wnd;
net/tipc/socket.c:	if (mreq->type < TIPC_RESERVED_TYPES)
net/tipc/socket.c:	if (mreq->scope > TIPC_NODE_SCOPE)
net/tipc/socket.c:	msg_set_lookup_scope(hdr, mreq->scope);
net/tipc/socket.c:	msg_set_nametype(hdr, mreq->type);
net/tipc/socket.c:	seq.type = mreq->type;
net/tipc/socket.c:	seq.lower = mreq->instance;
net/tipc/socket.c:	tipc_nametbl_build_group(net, grp, mreq->type, mreq->scope);
net/tipc/socket.c:	rc = tipc_sk_publish(tsk, mreq->scope, &seq);
net/tipc/group.c:	bool global = mreq->scope != TIPC_NODE_SCOPE;
net/tipc/group.c:	u32 type = mreq->type;
net/tipc/group.c:	grp->instance = mreq->instance;
net/tipc/group.c:	grp->scope = mreq->scope;
net/tipc/group.c:	grp->loopback = mreq->flags & TIPC_GROUP_LOOPBACK;
net/tipc/group.c:	grp->events = mreq->flags & TIPC_GROUP_MEMBER_EVTS;
net/tipc/diag.c:	err = tipc_sk_fill_sock_diag(skb, cb, tsk, req->tidiag_states,
net/nfc/llcp_commands.c:	/* sdreq->tlv_len is u8, takes uri_len, + 3 for header, + 1 for NULL */
net/nfc/llcp_commands.c:	sdreq->tlv_len = uri_len + 3;
net/nfc/llcp_commands.c:		sdreq->tlv_len--;
net/nfc/llcp_commands.c:	sdreq->tlv = kzalloc(sdreq->tlv_len + 1, GFP_KERNEL);
net/nfc/llcp_commands.c:	if (sdreq->tlv == NULL) {
net/nfc/llcp_commands.c:	sdreq->tlv[0] = LLCP_TLV_SDREQ;
net/nfc/llcp_commands.c:	sdreq->tlv[1] = sdreq->tlv_len - 2;
net/nfc/llcp_commands.c:	sdreq->tlv[2] = tid;
net/nfc/llcp_commands.c:	sdreq->tid = tid;
net/nfc/llcp_commands.c:	sdreq->uri = sdreq->tlv + 3;
net/nfc/llcp_commands.c:	memcpy(sdreq->uri, uri, uri_len);
net/nfc/llcp_commands.c:	sdreq->time = jiffies;
net/nfc/llcp_commands.c:	INIT_HLIST_NODE(&sdreq->node);
net/nfc/llcp_commands.c:		pr_debug("tid %d for %s\n", sdreq->tid, sdreq->uri);
net/nfc/llcp_commands.c:		skb_put_data(skb, sdreq->tlv, sdreq->tlv_len);
net/nfc/llcp_commands.c:		hlist_del(&sdreq->node);
net/nfc/llcp_commands.c:		hlist_add_head(&sdreq->node, &local->pending_sdreqs);
net/nfc/digital_core.c:				     cmd->req->data, cmd->req->len, false);
net/nfc/digital_technology.c:	sel_req->sel_cmd = sel_cmd;
net/nfc/digital_technology.c:	sel_req->b2 = 0x70;
net/nfc/digital_technology.c:	memcpy(sel_req->nfcid1, sdd_res->nfcid1, 4);
net/nfc/digital_technology.c:	sel_req->bcc = sdd_res->bcc;
net/nfc/digital_technology.c:	attrib_req->cmd = DIGITAL_CMD_ATTRIB_REQ;
net/nfc/digital_technology.c:	memcpy(attrib_req->nfcid0, sensb_res->nfcid0,
net/nfc/digital_technology.c:	       sizeof(attrib_req->nfcid0));
net/nfc/digital_technology.c:	attrib_req->param1 = DIGITAL_ATTRIB_P1_TR0_DEFAULT |
net/nfc/digital_technology.c:	attrib_req->param2 = DIGITAL_ATTRIB_P2_LISTEN_POLL_1 |
net/nfc/digital_technology.c:	attrib_req->param3 = sensb_res->proto_info[1] & 0x07;
net/nfc/digital_technology.c:	attrib_req->param4 = DIGITAL_ATTRIB_P4_DID(0);
net/nfc/digital_technology.c:	sensb_req->cmd = DIGITAL_CMD_SENSB_REQ;
net/nfc/digital_technology.c:	sensb_req->afi = 0x00; /* All families and sub-families */
net/nfc/digital_technology.c:	sensb_req->param = DIGITAL_SENSB_N(0);
net/nfc/digital_technology.c:	sensf_req->cmd = DIGITAL_CMD_SENSF_REQ;
net/nfc/digital_technology.c:	sensf_req->sc1 = 0xFF;
net/nfc/digital_technology.c:	sensf_req->sc2 = 0xFF;
net/nfc/digital_technology.c:	sensf_req->rc = 0;
net/nfc/digital_technology.c:	sensf_req->tsn = 0;
net/nfc/digital_technology.c:	skb_put(skb, sizeof(*req) - sizeof(req->mask)); /* No mask */
net/nfc/digital_technology.c:	req->flags = DIGITAL_ISO15693_REQ_FLAG_DATA_RATE |
net/nfc/digital_technology.c:	req->cmd = DIGITAL_CMD_ISO15693_INVENTORY_REQ;
net/nfc/digital_technology.c:	req->mask_len = 0;
net/nfc/digital_technology.c:	if (sensf_req->rc == DIGITAL_SENSF_REQ_RC_NONE)
net/nfc/digital_technology.c:	switch (sensf_req->rc) {
net/nfc/digital_technology.c:		sensf_res->rd[0] = sensf_req->sc1;
net/nfc/digital_technology.c:		sensf_res->rd[1] = sensf_req->sc2;
net/nfc/digital_technology.c:	if (sensf_req->cmd != DIGITAL_CMD_SENSF_REQ) {
net/nfc/digital_dep.c:	psl_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	psl_req->cmd = DIGITAL_CMD_PSL_REQ;
net/nfc/digital_dep.c:	psl_req->did = 0;
net/nfc/digital_dep.c:	psl_req->brs = (0x2 << 3) | 0x2; /* 424F both directions */
net/nfc/digital_dep.c:	psl_req->fsl = DIGITAL_PAYLOAD_BITS_TO_FSL(payload_bits);
net/nfc/digital_dep.c:	atr_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	atr_req->cmd = DIGITAL_CMD_ATR_REQ;
net/nfc/digital_dep.c:		memcpy(atr_req->nfcid3, target->nfcid2, NFC_NFCID2_MAXSIZE);
net/nfc/digital_dep.c:		get_random_bytes(atr_req->nfcid3, NFC_NFCID3_MAXSIZE);
net/nfc/digital_dep.c:	atr_req->did = 0;
net/nfc/digital_dep.c:	atr_req->bs = 0;
net/nfc/digital_dep.c:	atr_req->br = 0;
net/nfc/digital_dep.c:	atr_req->pp = DIGITAL_PAYLOAD_BITS_TO_PP(payload_bits);
net/nfc/digital_dep.c:		atr_req->pp |= DIGITAL_GB_BIT;
net/nfc/digital_dep.c:	dep_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	dep_req->cmd = DIGITAL_CMD_DEP_REQ;
net/nfc/digital_dep.c:	dep_req->pfb = DIGITAL_NFC_DEP_PFB_ACK_NACK_PDU |
net/nfc/digital_dep.c:	dep_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	dep_req->cmd = DIGITAL_CMD_DEP_REQ;
net/nfc/digital_dep.c:	dep_req->pfb = DIGITAL_NFC_DEP_PFB_ACK_NACK_PDU |
net/nfc/digital_dep.c:	dep_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	dep_req->cmd = DIGITAL_CMD_DEP_REQ;
net/nfc/digital_dep.c:	dep_req->pfb = DIGITAL_NFC_DEP_PFB_SUPERVISOR_PDU;
net/nfc/digital_dep.c:	dep_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	dep_req->cmd = DIGITAL_CMD_DEP_REQ;
net/nfc/digital_dep.c:	dep_req->pfb = DIGITAL_NFC_DEP_PFB_SUPERVISOR_PDU |
net/nfc/digital_dep.c:	dep_req->dir = DIGITAL_NFC_DEP_FRAME_DIR_OUT;
net/nfc/digital_dep.c:	dep_req->cmd = DIGITAL_CMD_DEP_REQ;
net/nfc/digital_dep.c:	dep_req->pfb = ddev->curr_nfc_dep_pni;
net/nfc/digital_dep.c:	if (resp->len < size || dep_req->dir != DIGITAL_NFC_DEP_FRAME_DIR_OUT ||
net/nfc/digital_dep.c:	    dep_req->cmd != DIGITAL_CMD_DEP_REQ) {
net/nfc/digital_dep.c:	pfb = dep_req->pfb;
net/nfc/digital_dep.c:	    psl_req->dir != DIGITAL_NFC_DEP_FRAME_DIR_OUT ||
net/nfc/digital_dep.c:	    psl_req->cmd != DIGITAL_CMD_PSL_REQ) {
net/nfc/digital_dep.c:	dsi = (psl_req->brs >> 3) & 0x07;
net/nfc/digital_dep.c:	payload_bits = DIGITAL_PAYLOAD_FSL_TO_BITS(psl_req->fsl);
net/nfc/digital_dep.c:	rc = digital_tg_send_psl_res(ddev, psl_req->did, rf_tech);
net/nfc/digital_dep.c:	memcpy(atr_res->nfcid3, atr_req->nfcid3, sizeof(atr_req->nfcid3));
net/nfc/digital_dep.c:	if (atr_req->dir != DIGITAL_NFC_DEP_FRAME_DIR_OUT ||
net/nfc/digital_dep.c:	    atr_req->cmd != DIGITAL_CMD_ATR_REQ ||
net/nfc/digital_dep.c:	    atr_req->did > DIGITAL_DID_MAX) {
net/nfc/digital_dep.c:	payload_bits = DIGITAL_PAYLOAD_PP_TO_BITS(atr_req->pp);
net/nfc/digital_dep.c:	ddev->did = atr_req->did;
net/nfc/digital_dep.c:			      NFC_COMM_PASSIVE, atr_req->gb, gb_len);
net/nfc/netlink.c:		tlvs_len += sdreq->tlv_len;
net/nfc/netlink.c:		hlist_add_head(&sdreq->node, &sdreq_list);
net/vmw_vsock/diag.c:				if (!(req->vdiag_states & (1 << sk->sk_state)))
net/vmw_vsock/diag.c:			if (!(req->vdiag_states & (1 << sk->sk_state)))
net/mac80211/iface.c:		local->fif_probe_req--;
net/mac80211/iface.c:		local->fif_probe_req--;
net/mac80211/main.c:		local->int_scan_req->rates[band] = (u32) -1;
net/mac80211/mlme.c:	switch (req->auth_type) {
net/mac80211/mlme.c:	auth_data = kzalloc(sizeof(*auth_data) + req->auth_data_len +
net/mac80211/mlme.c:			    req->ie_len, GFP_KERNEL);
net/mac80211/mlme.c:	auth_data->bss = req->bss;
net/mac80211/mlme.c:	if (req->auth_data_len >= 4) {
net/mac80211/mlme.c:		if (req->auth_type == NL80211_AUTHTYPE_SAE) {
net/mac80211/mlme.c:			__le16 *pos = (__le16 *) req->auth_data;
net/mac80211/mlme.c:		memcpy(auth_data->data, req->auth_data + 4,
net/mac80211/mlme.c:		       req->auth_data_len - 4);
net/mac80211/mlme.c:		auth_data->data_len += req->auth_data_len - 4;
net/mac80211/mlme.c:	cont_auth = ifmgd->auth_data && req->bss == ifmgd->auth_data->bss;
net/mac80211/mlme.c:	if (req->ie && req->ie_len) {
net/mac80211/mlme.c:		       req->ie, req->ie_len);
net/mac80211/mlme.c:		auth_data->data_len += req->ie_len;
net/mac80211/mlme.c:	if (req->key && req->key_len) {
net/mac80211/mlme.c:		auth_data->key_len = req->key_len;
net/mac80211/mlme.c:		auth_data->key_idx = req->key_idx;
net/mac80211/mlme.c:		memcpy(auth_data->key, req->key, req->key_len);
net/mac80211/mlme.c:		if (cont_auth && req->auth_type == NL80211_AUTHTYPE_SAE) {
net/mac80211/mlme.c:	if (cont_auth && req->auth_type == NL80211_AUTHTYPE_SAE &&
net/mac80211/mlme.c:		ieee80211_mark_sta_auth(sdata, req->bss->bssid);
net/mac80211/mlme.c:			   ifmgd->associated->bssid, req->bss->bssid);
net/mac80211/mlme.c:	sdata_info(sdata, "authenticate with %pM\n", req->bss->bssid);
net/mac80211/mlme.c:	err = ieee80211_prep_connection(sdata, req->bss, cont_auth, false);
net/mac80211/mlme.c:		sta_info_destroy_addr(sdata, req->bss->bssid);
net/mac80211/mlme.c:	bool is_6ghz = req->bss->channel->band == NL80211_BAND_6GHZ;
net/mac80211/mlme.c:	bool is_5ghz = req->bss->channel->band == NL80211_BAND_5GHZ;
net/mac80211/mlme.c:	struct ieee80211_bss *bss = (void *)req->bss->priv;
net/mac80211/mlme.c:	assoc_data = kzalloc(sizeof(*assoc_data) + req->ie_len, GFP_KERNEL);
net/mac80211/mlme.c:	ssidie = ieee80211_bss_get_ie(req->bss, WLAN_EID_SSID);
net/mac80211/mlme.c:			   ifmgd->associated->bssid, req->bss->bssid);
net/mac80211/mlme.c:		match = ether_addr_equal(ifmgd->bssid, req->bss->bssid);
net/mac80211/mlme.c:	for (i = 0; i < req->crypto.n_ciphers_pairwise; i++) {
net/mac80211/mlme.c:		if (req->crypto.ciphers_pairwise[i] == WLAN_CIPHER_SUITE_WEP40 ||
net/mac80211/mlme.c:		    req->crypto.ciphers_pairwise[i] == WLAN_CIPHER_SUITE_TKIP ||
net/mac80211/mlme.c:		    req->crypto.ciphers_pairwise[i] == WLAN_CIPHER_SUITE_WEP104) {
net/mac80211/mlme.c:	sband = local->hw.wiphy->bands[req->bss->channel->band];
net/mac80211/mlme.c:	memcpy(&ifmgd->ht_capa, &req->ht_capa, sizeof(ifmgd->ht_capa));
net/mac80211/mlme.c:	memcpy(&ifmgd->ht_capa_mask, &req->ht_capa_mask,
net/mac80211/mlme.c:	memcpy(&ifmgd->vht_capa, &req->vht_capa, sizeof(ifmgd->vht_capa));
net/mac80211/mlme.c:	memcpy(&ifmgd->vht_capa_mask, &req->vht_capa_mask,
net/mac80211/mlme.c:	memcpy(&ifmgd->s1g_capa, &req->s1g_capa, sizeof(ifmgd->s1g_capa));
net/mac80211/mlme.c:	memcpy(&ifmgd->s1g_capa_mask, &req->s1g_capa_mask,
net/mac80211/mlme.c:	if (req->ie && req->ie_len) {
net/mac80211/mlme.c:		memcpy(assoc_data->ie, req->ie, req->ie_len);
net/mac80211/mlme.c:		assoc_data->ie_len = req->ie_len;
net/mac80211/mlme.c:	if (req->fils_kek) {
net/mac80211/mlme.c:		if (WARN_ON(req->fils_kek_len > FILS_MAX_KEK_LEN)) {
net/mac80211/mlme.c:		memcpy(assoc_data->fils_kek, req->fils_kek,
net/mac80211/mlme.c:		       req->fils_kek_len);
net/mac80211/mlme.c:		assoc_data->fils_kek_len = req->fils_kek_len;
net/mac80211/mlme.c:	if (req->fils_nonces)
net/mac80211/mlme.c:		memcpy(assoc_data->fils_nonces, req->fils_nonces,
net/mac80211/mlme.c:	assoc_data->bss = req->bss;
net/mac80211/mlme.c:	assoc_data->capability = req->bss->capability;
net/mac80211/mlme.c:	ht_ie = ieee80211_bss_get_ie(req->bss, WLAN_EID_HT_OPERATION);
net/mac80211/mlme.c:	vht_ie = ieee80211_bss_get_ie(req->bss, WLAN_EID_VHT_CAPABILITY);
net/mac80211/mlme.c:	if (req->prev_bssid)
net/mac80211/mlme.c:		memcpy(assoc_data->prev_bssid, req->prev_bssid, ETH_ALEN);
net/mac80211/mlme.c:	if (req->use_mfp) {
net/mac80211/mlme.c:	if (req->flags & ASSOC_REQ_USE_RRM)
net/mac80211/mlme.c:	if (req->crypto.control_port)
net/mac80211/mlme.c:	sdata->control_port_protocol = req->crypto.control_port_ethertype;
net/mac80211/mlme.c:	sdata->control_port_no_encrypt = req->crypto.control_port_no_encrypt;
net/mac80211/mlme.c:					req->crypto.control_port_over_nl80211;
net/mac80211/mlme.c:	sdata->control_port_no_preauth = req->crypto.control_port_no_preauth;
net/mac80211/mlme.c:	sdata->encrypt_headroom = ieee80211_cs_headroom(local, &req->crypto,
net/mac80211/mlme.c:		if (req->flags & ASSOC_REQ_DISABLE_HT)
net/mac80211/mlme.c:		    req->flags & ASSOC_REQ_DISABLE_VHT)
net/mac80211/mlme.c:	if (req->flags & ASSOC_REQ_DISABLE_HT) {
net/mac80211/mlme.c:	if (req->flags & ASSOC_REQ_DISABLE_VHT)
net/mac80211/mlme.c:	if (req->flags & ASSOC_REQ_DISABLE_HE)
net/mac80211/mlme.c:	err = ieee80211_prep_connection(sdata, req->bss, true, override);
net/mac80211/mlme.c:	beacon_ies = rcu_dereference(req->bss->beacon_ies);
net/mac80211/mlme.c:		assoc_data->timeout = TU_TO_EXP_TIME(req->bss->beacon_interval);
net/mac80211/mlme.c:	bool tx = !req->local_state_change;
net/mac80211/mlme.c:	    ether_addr_equal(ifmgd->auth_data->bss->bssid, req->bssid)) {
net/mac80211/mlme.c:			   req->bssid, req->reason_code,
net/mac80211/mlme.c:			   ieee80211_get_reason_code_string(req->reason_code));
net/mac80211/mlme.c:		ieee80211_send_deauth_disassoc(sdata, req->bssid, req->bssid,
net/mac80211/mlme.c:					       req->reason_code, tx,
net/mac80211/mlme.c:					    req->reason_code, false);
net/mac80211/mlme.c:	    ether_addr_equal(ifmgd->assoc_data->bss->bssid, req->bssid)) {
net/mac80211/mlme.c:			   req->bssid, req->reason_code,
net/mac80211/mlme.c:			   ieee80211_get_reason_code_string(req->reason_code));
net/mac80211/mlme.c:		ieee80211_send_deauth_disassoc(sdata, req->bssid, req->bssid,
net/mac80211/mlme.c:					       req->reason_code, tx,
net/mac80211/mlme.c:					    req->reason_code, false);
net/mac80211/mlme.c:	    ether_addr_equal(ifmgd->associated->bssid, req->bssid)) {
net/mac80211/mlme.c:			   req->bssid, req->reason_code,
net/mac80211/mlme.c:			   ieee80211_get_reason_code_string(req->reason_code));
net/mac80211/mlme.c:				       req->reason_code, tx, frame_buf);
net/mac80211/mlme.c:					    req->reason_code, false);
net/mac80211/mlme.c:	if (ifmgd->associated != req->bss)
net/mac80211/mlme.c:		   req->bss->bssid, req->reason_code, ieee80211_get_reason_code_string(req->reason_code));
net/mac80211/mlme.c:	memcpy(bssid, req->bss->bssid, ETH_ALEN);
net/mac80211/mlme.c:			       req->reason_code, !req->local_state_change,
net/mac80211/mlme.c:				    req->reason_code, false);
net/mac80211/cfg.c:	sdata = IEEE80211_WDEV_TO_SUB_IF(req->wdev);
net/mac80211/cfg.c:		     !(req->flags & NL80211_SCAN_FLAG_AP)))
net/mac80211/ibss.c:	struct ieee80211_mgmt *mgmt = (void *)req->data;
net/mac80211/ibss.c:	int tx_last_beacon, len = req->len;
net/mac80211/agg-rx.c:	resp->data = req->data & IEEE80211_ADDBA_EXT_NO_FRAG;
net/mac80211/agg-rx.c:	frag_level = u32_get_bits(req->data,
net/mac80211/util.c:		if (sched_scan_req->n_scan_plans > 1 ||
net/mac80211/scan.c:			scan_req_flags = scan_req->flags;
net/mac80211/scan.c:			sched_scan_req_flags = sched_scan_req->flags;
net/mac80211/scan.c:		for (i = 0; i < req->n_channels; i++) {
net/mac80211/scan.c:			local->hw_scan_req->req.channels[i] = req->channels[i];
net/mac80211/scan.c:			bands_used |= BIT(req->channels[i]->band);
net/mac80211/scan.c:		n_chans = req->n_channels;
net/mac80211/scan.c:			for (i = 0; i < req->n_channels; i++) {
net/mac80211/scan.c:				if (req->channels[i]->band !=
net/mac80211/scan.c:				local->hw_scan_req->req.channels[n_chans] =
net/mac80211/scan.c:							req->channels[i];
net/mac80211/scan.c:				bands_used |= BIT(req->channels[i]->band);
net/mac80211/scan.c:	local->hw_scan_req->req.n_channels = n_chans;
net/mac80211/scan.c:	ieee80211_prepare_scan_chandef(&chandef, req->scan_width);
net/mac80211/scan.c:	if (req->flags & NL80211_SCAN_FLAG_MIN_PREQ_CONTENT)
net/mac80211/scan.c:					 (u8 *)local->hw_scan_req->req.ie,
net/mac80211/scan.c:					 &local->hw_scan_req->ies,
net/mac80211/scan.c:					 req->ie, req->ie_len,
net/mac80211/scan.c:					 bands_used, req->rates, &chandef,
net/mac80211/scan.c:	local->hw_scan_req->req.ie_len = ielen;
net/mac80211/scan.c:	local->hw_scan_req->req.no_cck = req->no_cck;
net/mac80211/scan.c:	ether_addr_copy(local->hw_scan_req->req.mac_addr, req->mac_addr);
net/mac80211/scan.c:	ether_addr_copy(local->hw_scan_req->req.mac_addr_mask,
net/mac80211/scan.c:			req->mac_addr_mask);
net/mac80211/scan.c:	ether_addr_copy(local->hw_scan_req->req.bssid, req->bssid);
net/mac80211/scan.c:	if (scan_req->no_cck)
net/mac80211/scan.c:	if (scan_req->flags & NL80211_SCAN_FLAG_MIN_PREQ_CONTENT)
net/mac80211/scan.c:	if (scan_req->flags & NL80211_SCAN_FLAG_RANDOM_SN)
net/mac80211/scan.c:	for (i = 0; i < scan_req->n_ssids; i++)
net/mac80211/scan.c:			sdata, local->scan_addr, scan_req->bssid,
net/mac80211/scan.c:			scan_req->ssids[i].ssid, scan_req->ssids[i].ssid_len,
net/mac80211/scan.c:			scan_req->ie, scan_req->ie_len,
net/mac80211/scan.c:			scan_req->rates[band], flags,
net/mac80211/scan.c:		local->hw_scan_ies_bufsize = local->scan_ies_len + req->ie_len;
net/mac80211/scan.c:			for (i = 0; i < req->n_channels; i++) {
net/mac80211/scan.c:				if (bands_counted & BIT(req->channels[i]->band))
net/mac80211/scan.c:				bands_counted |= BIT(req->channels[i]->band);
net/mac80211/scan.c:				req->n_channels * sizeof(req->channels[0]) +
net/mac80211/scan.c:		local->hw_scan_req->req.ssids = req->ssids;
net/mac80211/scan.c:		local->hw_scan_req->req.n_ssids = req->n_ssids;
net/mac80211/scan.c:			req->n_channels * sizeof(req->channels[0]);
net/mac80211/scan.c:		local->hw_scan_req->req.ie = ies;
net/mac80211/scan.c:		local->hw_scan_req->req.flags = req->flags;
net/mac80211/scan.c:		eth_broadcast_addr(local->hw_scan_req->req.bssid);
net/mac80211/scan.c:		local->hw_scan_req->req.duration = req->duration;
net/mac80211/scan.c:		local->hw_scan_req->req.duration_mandatory =
net/mac80211/scan.c:			req->duration_mandatory;
net/mac80211/scan.c:		local->hw_scan_req->req.n_6ghz_params = req->n_6ghz_params;
net/mac80211/scan.c:		local->hw_scan_req->req.scan_6ghz_params =
net/mac80211/scan.c:			req->scan_6ghz_params;
net/mac80211/scan.c:		local->hw_scan_req->req.scan_6ghz = req->scan_6ghz;
net/mac80211/scan.c:	if (req->flags & NL80211_SCAN_FLAG_RANDOM_ADDR)
net/mac80211/scan.c:				     req->mac_addr,
net/mac80211/scan.c:				     req->mac_addr_mask);
net/mac80211/scan.c:	} else if ((req->n_channels == 1) &&
net/mac80211/scan.c:		   (req->channels[0] == local->_oper_chandef.chan)) {
net/mac80211/scan.c:		if ((req->channels[0]->flags & (IEEE80211_CHAN_NO_IR |
net/mac80211/scan.c:		    !req->n_ssids) {
net/mac80211/scan.c:	next_chan = scan_req->channels[local->scan_channel_idx];
net/mac80211/scan.c:		if (scan_req->flags & NL80211_SCAN_FLAG_LOW_PRIORITY)
net/mac80211/scan.c:	chan = scan_req->channels[local->scan_channel_idx];
net/mac80211/scan.c:	switch (scan_req->scan_width) {
net/mac80211/scan.c:		    oper_scan_width == scan_req->scan_width)
net/mac80211/scan.c:	    !scan_req->n_ssids) {
net/mac80211/scan.c:			if (local->scan_channel_idx >= scan_req->n_channels) {
net/mac80211/scan.c:				local->int_scan_req->channels[n_ch] = tmp_ch;
net/mac80211/scan.c:		local->int_scan_req->n_channels = n_ch;
net/mac80211/scan.c:			local->int_scan_req->channels[n_ch] = channels[i];
net/mac80211/scan.c:		local->int_scan_req->n_channels = n_ch;
net/mac80211/scan.c:	local->int_scan_req->ssids = &local->scan_ssid;
net/mac80211/scan.c:	local->int_scan_req->n_ssids = 1;
net/mac80211/scan.c:	local->int_scan_req->scan_width = scan_width;
net/mac80211/scan.c:	memcpy(local->int_scan_req->ssids[0].ssid, ssid, IEEE80211_MAX_SSID_LEN);
net/mac80211/scan.c:	local->int_scan_req->ssids[0].ssid_len = ssid_len;
net/mac80211/scan.c:	iebufsz = local->scan_ies_len + req->ie_len;
net/mac80211/scan.c:	if (req->flags & NL80211_SCAN_FLAG_MIN_PREQ_CONTENT)
net/mac80211/scan.c:	ieee80211_prepare_scan_chandef(&chandef, req->scan_width);
net/mac80211/scan.c:				 &sched_scan_ies, req->ie,
net/mac80211/scan.c:				 req->ie_len, bands_used, rate_masks, &chandef,
net/smc/smc_diag.c:	if ((req->diag_ext & (1 << (SMC_DIAG_CONNINFO - 1))) &&
net/smc/smc_diag.c:	    (req->diag_ext & (1 << (SMC_DIAG_LGRINFO - 1))) &&
net/smc/smc_diag.c:	    (req->diag_ext & (1 << (SMC_DIAG_DMBINFO - 1))) &&
net/decnet/dn_table.c:	u32 portid = req ? req->portid : 0;
net/sctp/stream.c:		if ((!resp_seq || req->request_seq == resp_seq) &&
net/sctp/stream.c:		    (!type || type == req->param_hdr.type))
net/sctp/stream.c:	request_seq = ntohl(outreq->request_seq);
net/sctp/stream.c:	if (ntohl(outreq->send_reset_at_tsn) >
net/sctp/stream.c:	str_p = outreq->list_of_streams;
net/sctp/stream.c:				asoc, outreq->response_seq,
net/sctp/stream.c:	request_seq = ntohl(inreq->request_seq);
net/sctp/stream.c:	str_p = inreq->list_of_streams;
net/sctp/stream.c:	request_seq = ntohl(tsnreq->request_seq);
net/sctp/stream.c:	if (req->type == SCTP_PARAM_RESET_OUT_REQUEST) {
net/sctp/stream.c:		str_p = outreq->list_of_streams;
net/sctp/stream.c:		nums = (ntohs(outreq->param_hdr.length) - sizeof(*outreq)) /
net/sctp/stream.c:	} else if (req->type == SCTP_PARAM_RESET_IN_REQUEST) {
net/sctp/stream.c:		str_p = inreq->list_of_streams;
net/sctp/stream.c:		nums = (ntohs(inreq->param_hdr.length) - sizeof(*inreq)) /
net/sctp/stream.c:	} else if (req->type == SCTP_PARAM_RESET_TSN_REQUEST) {
net/sctp/stream.c:	} else if (req->type == SCTP_PARAM_RESET_ADD_OUT_STREAMS) {
net/sctp/stream.c:	} else if (req->type == SCTP_PARAM_RESET_ADD_IN_STREAMS) {
net/sctp/diag.c:	int ext = req->idiag_ext;
net/sctp/diag.c:	err = sock_diag_check_cookie(sk, req->id.idiag_cookie);
net/sctp/diag.c:	if (req->sdiag_family == AF_INET) {
net/sctp/diag.c:		laddr.v4.sin_port = req->id.idiag_sport;
net/sctp/diag.c:		laddr.v4.sin_addr.s_addr = req->id.idiag_src[0];
net/sctp/diag.c:		paddr.v4.sin_port = req->id.idiag_dport;
net/sctp/diag.c:		paddr.v4.sin_addr.s_addr = req->id.idiag_dst[0];
net/sctp/diag.c:		laddr.v6.sin6_port = req->id.idiag_sport;
net/sctp/diag.c:		memcpy(&laddr.v6.sin6_addr, req->id.idiag_src,
net/sctp/diag.c:		paddr.v6.sin6_port = req->id.idiag_dport;
net/sctp/diag.c:		memcpy(&paddr.v6.sin6_addr, req->id.idiag_dst,
net/tls/tls_sw.c:	struct scatterlist *sgout = aead_req->dst;
net/tls/tls_sw.c:	struct scatterlist *sgin = aead_req->src;
net/tls/tls_sw.c:	skb = (struct sk_buff *)req->data;
net/tls/tls_sw.c:	struct sock *sk = req->data;
net/caif/chnl_net.c:		conn_req->sockaddr.u.dgm.connection_id =
net/caif/chnl_net.c:		conn_req->sockaddr.u.dgm.connection_id =
net/caif/chnl_net.c:			conn_req->protocol = CAIFPROTO_DATAGRAM_LOOP;
net/caif/chnl_net.c:			conn_req->protocol = CAIFPROTO_DATAGRAM;
net/caif/cfctrl.c:	req->sequence_no = atomic_read(&ctrl->req_seq_no);
net/caif/cfctrl.c:	list_add_tail(&req->list, &ctrl->list);
net/caif/cfctrl.c:	req->client_layer = user_layer;
net/caif/cfctrl.c:	req->cmd = CFCTRL_CMD_LINK_SETUP;
net/caif/cfctrl.c:	req->param = *param;
net/caif/cfctrl.c:						       req ? req->client_layer
net/caif/cfctrl.c:							  req ? req->
net/batman-adv/translation-table.c:		tt_vlan_req->vid = tt_vlan->vid;
net/batman-adv/translation-table.c:		tt_vlan_req->crc = tt_vlan->crc;
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_INFO) && xsk_diag_put_info(xs, nlskb))
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_INFO) &&
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_RING_CFG) &&
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_UMEM) &&
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_MEMINFO) &&
net/xdp/xsk_diag.c:	if ((req->xdiag_show & XDP_SHOW_STATS) &&
net/ceph/mon_client.c:	dout("%s greq %p request %p reply %p\n", __func__, req, req->request,
net/ceph/mon_client.c:	     req->reply);
net/ceph/mon_client.c:	WARN_ON(!RB_EMPTY_NODE(&req->node));
net/ceph/mon_client.c:	if (req->reply)
net/ceph/mon_client.c:		ceph_msg_put(req->reply);
net/ceph/mon_client.c:	if (req->request)
net/ceph/mon_client.c:		ceph_msg_put(req->request);
net/ceph/mon_client.c:		kref_put(&req->kref, release_generic_request);
net/ceph/mon_client.c:	kref_get(&req->kref);
net/ceph/mon_client.c:	req->monc = monc;
net/ceph/mon_client.c:	kref_init(&req->kref);
net/ceph/mon_client.c:	RB_CLEAR_NODE(&req->node);
net/ceph/mon_client.c:	init_completion(&req->completion);
net/ceph/mon_client.c:	struct ceph_mon_client *monc = req->monc;
net/ceph/mon_client.c:	WARN_ON(req->tid);
net/ceph/mon_client.c:	req->tid = ++monc->last_tid;
net/ceph/mon_client.c:	WARN_ON(!req->tid);
net/ceph/mon_client.c:	dout("%s greq %p tid %llu\n", __func__, req, req->tid);
net/ceph/mon_client.c:	req->request->hdr.tid = cpu_to_le64(req->tid);
net/ceph/mon_client.c:	ceph_con_send(&monc->con, ceph_msg_get(req->request));
net/ceph/mon_client.c:	struct ceph_mon_client *monc = req->monc;
net/ceph/mon_client.c:	dout("%s greq %p tid %llu\n", __func__, req, req->tid);
net/ceph/mon_client.c:	ceph_msg_revoke(req->request);
net/ceph/mon_client.c:	ceph_msg_revoke_incoming(req->reply);
net/ceph/mon_client.c:	if (req->complete_cb)
net/ceph/mon_client.c:		req->complete_cb(req);
net/ceph/mon_client.c:		complete_all(&req->completion);
net/ceph/mon_client.c:	struct ceph_mon_client *monc = req->monc;
net/ceph/mon_client.c:	dout("%s greq %p tid %llu\n", __func__, req, req->tid);
net/ceph/mon_client.c:					    req->tid);
net/ceph/mon_client.c:	dout("%s greq %p tid %llu\n", __func__, req, req->tid);
net/ceph/mon_client.c:	ret = wait_for_completion_interruptible(&req->completion);
net/ceph/mon_client.c:		ret = req->result; /* completed */
net/ceph/mon_client.c:		dout("get_generic_reply %lld got %p\n", tid, req->reply);
net/ceph/mon_client.c:		m = ceph_msg_get(req->reply);
net/ceph/mon_client.c:	req->result = 0;
net/ceph/mon_client.c:	*req->u.st = reply->st; /* struct */
net/ceph/mon_client.c:	req->request = ceph_msg_new(CEPH_MSG_STATFS, sizeof(*h), GFP_NOFS,
net/ceph/mon_client.c:	if (!req->request)
net/ceph/mon_client.c:	req->reply = ceph_msg_new(CEPH_MSG_STATFS_REPLY, 64, GFP_NOFS, true);
net/ceph/mon_client.c:	if (!req->reply)
net/ceph/mon_client.c:	req->u.st = buf;
net/ceph/mon_client.c:	req->request->hdr.version = cpu_to_le16(2);
net/ceph/mon_client.c:	h = req->request->front.iov_base;
net/ceph/mon_client.c:	req->result = 0;
net/ceph/mon_client.c:	req->u.newest = ceph_decode_64(&p);
net/ceph/mon_client.c:	req->request = ceph_msg_new(CEPH_MSG_MON_GET_VERSION,
net/ceph/mon_client.c:	if (!req->request)
net/ceph/mon_client.c:	req->reply = ceph_msg_new(CEPH_MSG_MON_GET_VERSION_REPLY, 32, GFP_NOIO,
net/ceph/mon_client.c:	if (!req->reply)
net/ceph/mon_client.c:	req->complete_cb = cb;
net/ceph/mon_client.c:	req->private_data = private_data;
net/ceph/mon_client.c:		void *p = req->request->front.iov_base;
net/ceph/mon_client.c:		void *const end = p + req->request->front_alloc_len;
net/ceph/mon_client.c:		ceph_encode_64(&p, req->tid); /* handle */
net/ceph/mon_client.c:		*newest = req->u.newest;
net/ceph/mon_client.c:	req->result = ceph_decode_32(&p);
net/ceph/mon_client.c:	req->request = ceph_msg_new(CEPH_MSG_MON_COMMAND, 256, GFP_NOIO, true);
net/ceph/mon_client.c:	if (!req->request)
net/ceph/mon_client.c:	req->reply = ceph_msg_new(CEPH_MSG_MON_COMMAND_ACK, 512, GFP_NOIO,
net/ceph/mon_client.c:	if (!req->reply)
net/ceph/mon_client.c:	h = req->request->front.iov_base;
net/ceph/mon_client.c:		ceph_msg_revoke(req->request);
net/ceph/mon_client.c:		ceph_msg_revoke_incoming(req->reply);
net/ceph/mon_client.c:		ceph_con_send(&monc->con, ceph_msg_get(req->request));
net/ceph/debugfs.c:		op = le16_to_cpu(req->request->hdr.type);
net/ceph/debugfs.c:			seq_printf(s, "%llu statfs\n", req->tid);
net/ceph/debugfs.c:			seq_printf(s, "%llu mon_get_version", req->tid);
net/ceph/debugfs.c:			seq_printf(s, "%llu unknown\n", req->tid);
net/ceph/debugfs.c:	seq_printf(s, "%llu\t", req->r_tid);
net/ceph/debugfs.c:	dump_target(s, &req->r_t);
net/ceph/debugfs.c:	seq_printf(s, "\t%d", req->r_attempts);
net/ceph/debugfs.c:	for (i = 0; i < req->r_num_ops; i++) {
net/ceph/debugfs.c:		struct ceph_osd_req_op *op = &req->r_ops[i];
net/ceph/debugfs.c:	seq_printf(s, "%llu\t", lreq->linger_id);
net/ceph/debugfs.c:	dump_target(s, &lreq->t);
net/ceph/debugfs.c:	seq_printf(s, "\t%u\t%s%s/%d\n", lreq->register_gen,
net/ceph/debugfs.c:		   lreq->is_watch ? "W" : "N", lreq->committed ? "C" : "",
net/ceph/debugfs.c:		   lreq->last_error);
net/ceph/osd_client.c:	WARN_ON(!mutex_is_locked(&lreq->lock));
net/ceph/osd_client.c:	BUG_ON(which >= osd_req->r_num_ops);
net/ceph/osd_client.c:	return &osd_req->r_ops[which].raw_data_in;
net/ceph/osd_client.c:	osd_req->r_ops[which].cls.indata_len += pagelist->length;
net/ceph/osd_client.c:	osd_req->r_ops[which].indata_len += pagelist->length;
net/ceph/osd_client.c:	osd_req->r_ops[which].cls.indata_len += length;
net/ceph/osd_client.c:	osd_req->r_ops[which].indata_len += length;
net/ceph/osd_client.c:	osd_req->r_ops[which].cls.indata_len += bytes;
net/ceph/osd_client.c:	osd_req->r_ops[which].indata_len += bytes;
net/ceph/osd_client.c:	BUG_ON(which >= osd_req->r_num_ops);
net/ceph/osd_client.c:	op = &osd_req->r_ops[which];
net/ceph/osd_client.c:	WARN_ON(!RB_EMPTY_NODE(&req->r_node));
net/ceph/osd_client.c:	WARN_ON(!RB_EMPTY_NODE(&req->r_mc_node));
net/ceph/osd_client.c:	WARN_ON(!list_empty(&req->r_private_item));
net/ceph/osd_client.c:	WARN_ON(req->r_osd);
net/ceph/osd_client.c:	     req->r_request, req->r_reply);
net/ceph/osd_client.c:	if (req->r_request)
net/ceph/osd_client.c:		ceph_msg_put(req->r_request);
net/ceph/osd_client.c:	if (req->r_reply)
net/ceph/osd_client.c:		ceph_msg_put(req->r_reply);
net/ceph/osd_client.c:	for (which = 0; which < req->r_num_ops; which++)
net/ceph/osd_client.c:	target_destroy(&req->r_t);
net/ceph/osd_client.c:	ceph_put_snap_context(req->r_snapc);
net/ceph/osd_client.c:	if (req->r_mempool)
net/ceph/osd_client.c:		mempool_free(req, req->r_osdc->req_mempool);
net/ceph/osd_client.c:	else if (req->r_num_ops <= CEPH_OSD_SLAB_OPS)
net/ceph/osd_client.c:	     kref_read(&req->r_kref));
net/ceph/osd_client.c:	kref_get(&req->r_kref);
net/ceph/osd_client.c:		     kref_read(&req->r_kref));
net/ceph/osd_client.c:		kref_put(&req->r_kref, ceph_osdc_release_request);
net/ceph/osd_client.c:	kref_init(&req->r_kref);
net/ceph/osd_client.c:	init_completion(&req->r_completion);
net/ceph/osd_client.c:	RB_CLEAR_NODE(&req->r_node);
net/ceph/osd_client.c:	RB_CLEAR_NODE(&req->r_mc_node);
net/ceph/osd_client.c:	INIT_LIST_HEAD(&req->r_private_item);
net/ceph/osd_client.c:	target_init(&req->r_t);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	bool mempool = req->r_mempool;
net/ceph/osd_client.c:	unsigned int num_ops = req->r_num_ops;
net/ceph/osd_client.c:	u64 snapid = req->r_snapid;
net/ceph/osd_client.c:	struct ceph_snap_context *snapc = req->r_snapc;
net/ceph/osd_client.c:	bool linger = req->r_linger;
net/ceph/osd_client.c:	struct ceph_msg *request_msg = req->r_request;
net/ceph/osd_client.c:	struct ceph_msg *reply_msg = req->r_reply;
net/ceph/osd_client.c:	WARN_ON(kref_read(&req->r_kref) != 1);
net/ceph/osd_client.c:	target_destroy(&req->r_t);
net/ceph/osd_client.c:	req->r_osdc = osdc;
net/ceph/osd_client.c:	req->r_mempool = mempool;
net/ceph/osd_client.c:	req->r_num_ops = num_ops;
net/ceph/osd_client.c:	req->r_snapid = snapid;
net/ceph/osd_client.c:	req->r_snapc = snapc;
net/ceph/osd_client.c:	req->r_linger = linger;
net/ceph/osd_client.c:	req->r_request = request_msg;
net/ceph/osd_client.c:	req->r_reply = reply_msg;
net/ceph/osd_client.c:	req->r_osdc = osdc;
net/ceph/osd_client.c:	req->r_mempool = use_mempool;
net/ceph/osd_client.c:	req->r_num_ops = num_ops;
net/ceph/osd_client.c:	req->r_snapid = CEPH_NOSNAP;
net/ceph/osd_client.c:	req->r_snapc = ceph_get_snap_context(snapc);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	WARN_ON(req->r_request || req->r_reply);
net/ceph/osd_client.c:	WARN_ON(ceph_oid_empty(&req->r_base_oid));
net/ceph/osd_client.c:	WARN_ON(ceph_oloc_empty(&req->r_base_oloc));
net/ceph/osd_client.c:			ceph_oloc_encoding_size(&req->r_base_oloc); /* oloc */
net/ceph/osd_client.c:	msg_size += 4 + req->r_base_oid.name_len; /* oid */
net/ceph/osd_client.c:	msg_size += 2 + req->r_num_ops * sizeof(struct ceph_osd_op);
net/ceph/osd_client.c:	msg_size += 4 + 8 * (req->r_snapc ? req->r_snapc->num_snaps : 0);
net/ceph/osd_client.c:	if (req->r_mempool)
net/ceph/osd_client.c:	req->r_request = msg;
net/ceph/osd_client.c:	msg_size += req->r_base_oid.name_len;
net/ceph/osd_client.c:	msg_size += req->r_num_ops * sizeof(struct ceph_osd_op);
net/ceph/osd_client.c:	if (req->r_mempool)
net/ceph/osd_client.c:	req->r_reply = msg;
net/ceph/osd_client.c:	for (op = req->r_ops; op != &req->r_ops[req->r_num_ops]; op++) {
net/ceph/osd_client.c:	BUG_ON(which >= osd_req->r_num_ops);
net/ceph/osd_client.c:	op = &osd_req->r_ops[which];
net/ceph/osd_client.c:	BUG_ON(which >= osd_req->r_num_ops);
net/ceph/osd_client.c:	op = &osd_req->r_ops[which];
net/ceph/osd_client.c:	BUG_ON(which + 1 >= osd_req->r_num_ops);
net/ceph/osd_client.c:	prev_op = &osd_req->r_ops[which];
net/ceph/osd_client.c:	req->r_base_oloc.pool = layout->pool_id;
net/ceph/osd_client.c:	req->r_base_oloc.pool_ns = ceph_try_get_string(layout->pool_ns);
net/ceph/osd_client.c:	ceph_oid_printf(&req->r_base_oid, "%llx.%08llx", vino.ino, objnum);
net/ceph/osd_client.c:	req->r_flags = flags | osdc->client->options->read_from_replica;
net/ceph/osd_client.c:	req->r_snapid = vino.snap;
net/ceph/osd_client.c:		req->r_data_offset = off;
net/ceph/osd_client.c:		dout(" reassigning req %p tid %llu\n", req, req->r_tid);
net/ceph/osd_client.c:		     lreq->linger_id);
net/ceph/osd_client.c:			req->r_stamp = jiffies;
net/ceph/osd_client.c:	WARN_ON(!req->r_tid || req->r_osd);
net/ceph/osd_client.c:	     req, req->r_tid);
net/ceph/osd_client.c:	req->r_osd = osd;
net/ceph/osd_client.c:	WARN_ON(req->r_osd != osd);
net/ceph/osd_client.c:	     req, req->r_tid);
net/ceph/osd_client.c:	req->r_osd = NULL;
net/ceph/osd_client.c:	struct ceph_osd *osd = req->r_osd;
net/ceph/osd_client.c:	spg = lookup_spg_mapping(&osd->o_backoff_mappings, &req->r_t.spgid);
net/ceph/osd_client.c:	hoid_fill_from_target(&hoid, &req->r_t);
net/ceph/osd_client.c:	     __func__, req, req->r_tid, osd->o_osd, backoff->spgid.pgid.pool,
net/ceph/osd_client.c:	struct ceph_msg *request_msg = req->r_request;
net/ceph/osd_client.c:	struct ceph_msg *reply_msg = req->r_reply;
net/ceph/osd_client.c:	if (req->r_request->num_data_items || req->r_reply->num_data_items)
net/ceph/osd_client.c:	for (op = req->r_ops; op != &req->r_ops[req->r_num_ops]; op++) {
net/ceph/osd_client.c:	if (req->r_flags & CEPH_OSD_FLAG_WRITE) {
net/ceph/osd_client.c:		WARN_ON(req->r_snapid != CEPH_NOSNAP);
net/ceph/osd_client.c:		WARN_ON(req->r_mtime.tv_sec || req->r_mtime.tv_nsec ||
net/ceph/osd_client.c:			req->r_data_offset || req->r_snapc);
net/ceph/osd_client.c:	encode_spgid(&p, &req->r_t.spgid); /* actual spg */
net/ceph/osd_client.c:	ceph_encode_32(&p, req->r_t.pgid.seed); /* raw hash */
net/ceph/osd_client.c:	ceph_encode_32(&p, req->r_osdc->osdmap->epoch);
net/ceph/osd_client.c:	ceph_encode_32(&p, req->r_flags);
net/ceph/osd_client.c:	ceph_encode_timespec64(p, &req->r_mtime);
net/ceph/osd_client.c:	encode_oloc(&p, end, &req->r_t.target_oloc);
net/ceph/osd_client.c:	ceph_encode_string(&p, end, req->r_t.target_oid.name,
net/ceph/osd_client.c:			   req->r_t.target_oid.name_len);
net/ceph/osd_client.c:	ceph_encode_16(&p, req->r_num_ops);
net/ceph/osd_client.c:	for (i = 0; i < req->r_num_ops; i++) {
net/ceph/osd_client.c:		data_len += osd_req_encode_op(p, &req->r_ops[i]);
net/ceph/osd_client.c:	ceph_encode_64(&p, req->r_snapid); /* snapid */
net/ceph/osd_client.c:	if (req->r_snapc) {
net/ceph/osd_client.c:		ceph_encode_64(&p, req->r_snapc->seq);
net/ceph/osd_client.c:		ceph_encode_32(&p, req->r_snapc->num_snaps);
net/ceph/osd_client.c:		for (i = 0; i < req->r_snapc->num_snaps; i++)
net/ceph/osd_client.c:			ceph_encode_64(&p, req->r_snapc->snaps[i]);
net/ceph/osd_client.c:	ceph_encode_32(&p, req->r_attempts); /* retry_attempt */
net/ceph/osd_client.c:	msg->hdr.data_off = cpu_to_le16(req->r_data_offset);
net/ceph/osd_client.c:	     req->r_t.target_oid.name, req->r_t.target_oid.name_len);
net/ceph/osd_client.c:	struct ceph_osd *osd = req->r_osd;
net/ceph/osd_client.c:	WARN_ON(osd->o_osd != req->r_t.osd);
net/ceph/osd_client.c:	if (req->r_sent)
net/ceph/osd_client.c:		ceph_msg_revoke(req->r_request);
net/ceph/osd_client.c:	req->r_flags |= CEPH_OSD_FLAG_KNOWN_REDIR;
net/ceph/osd_client.c:	if (req->r_attempts)
net/ceph/osd_client.c:		req->r_flags |= CEPH_OSD_FLAG_RETRY;
net/ceph/osd_client.c:		WARN_ON(req->r_flags & CEPH_OSD_FLAG_RETRY);
net/ceph/osd_client.c:	encode_request_partial(req, req->r_request);
net/ceph/osd_client.c:	     __func__, req, req->r_tid, req->r_t.pgid.pool, req->r_t.pgid.seed,
net/ceph/osd_client.c:	     req->r_t.spgid.pgid.pool, req->r_t.spgid.pgid.seed,
net/ceph/osd_client.c:	     req->r_t.spgid.shard, osd->o_osd, req->r_t.epoch, req->r_flags,
net/ceph/osd_client.c:	     req->r_attempts);
net/ceph/osd_client.c:	req->r_t.paused = false;
net/ceph/osd_client.c:	req->r_stamp = jiffies;
net/ceph/osd_client.c:	req->r_attempts++;
net/ceph/osd_client.c:	req->r_sent = osd->o_incarnation;
net/ceph/osd_client.c:	req->r_request->hdr.tid = cpu_to_le64(req->r_tid);
net/ceph/osd_client.c:	ceph_con_send(&osd->o_con, ceph_msg_get(req->r_request));
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	WARN_ON(req->r_tid);
net/ceph/osd_client.c:	ct_res = calc_target(osdc, &req->r_t, false);
net/ceph/osd_client.c:	osd = lookup_create_osd(osdc, req->r_t.osd, wrlocked);
net/ceph/osd_client.c:		req->r_t.paused = true;
net/ceph/osd_client.c:	} else if ((req->r_flags & CEPH_OSD_FLAG_WRITE) &&
net/ceph/osd_client.c:		req->r_t.paused = true;
net/ceph/osd_client.c:	} else if ((req->r_flags & CEPH_OSD_FLAG_READ) &&
net/ceph/osd_client.c:		req->r_t.paused = true;
net/ceph/osd_client.c:	} else if ((req->r_flags & CEPH_OSD_FLAG_WRITE) &&
net/ceph/osd_client.c:		   !(req->r_flags & (CEPH_OSD_FLAG_FULL_TRY |
net/ceph/osd_client.c:		    pool_full(osdc, req->r_t.base_oloc.pool))) {
net/ceph/osd_client.c:			req->r_t.paused = true;
net/ceph/osd_client.c:	req->r_tid = atomic64_inc_return(&osdc->last_tid);
net/ceph/osd_client.c:	WARN_ON(req->r_flags & (CEPH_OSD_FLAG_ACK | CEPH_OSD_FLAG_ONDISK));
net/ceph/osd_client.c:	WARN_ON(!(req->r_flags & (CEPH_OSD_FLAG_READ | CEPH_OSD_FLAG_WRITE)));
net/ceph/osd_client.c:	req->r_flags |= CEPH_OSD_FLAG_ONDISK;
net/ceph/osd_client.c:	atomic_inc(&req->r_osdc->num_requests);
net/ceph/osd_client.c:	req->r_start_stamp = jiffies;
net/ceph/osd_client.c:	req->r_start_latency = ktime_get();
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	WARN_ON(lookup_request_mc(&osdc->map_checks, req->r_tid));
net/ceph/osd_client.c:	dout("%s req %p tid %llu\n", __func__, req, req->r_tid);
net/ceph/osd_client.c:	req->r_end_latency = ktime_get();
net/ceph/osd_client.c:	if (req->r_osd)
net/ceph/osd_client.c:		unlink_request(req->r_osd, req);
net/ceph/osd_client.c:	ceph_msg_revoke(req->r_request);
net/ceph/osd_client.c:	ceph_msg_revoke_incoming(req->r_reply);
net/ceph/osd_client.c:	     req->r_tid, req->r_callback, req->r_result);
net/ceph/osd_client.c:	if (req->r_callback)
net/ceph/osd_client.c:		req->r_callback(req);
net/ceph/osd_client.c:	complete_all(&req->r_completion);
net/ceph/osd_client.c:	dout("%s req %p tid %llu err %d\n", __func__, req, req->r_tid, err);
net/ceph/osd_client.c:	req->r_result = err;
net/ceph/osd_client.c:	INIT_WORK(&req->r_complete_work, complete_request_workfn);
net/ceph/osd_client.c:	queue_work(req->r_osdc->completion_wq, &req->r_complete_work);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	lookup_req = lookup_request_mc(&osdc->map_checks, req->r_tid);
net/ceph/osd_client.c:	dout("%s req %p tid %llu\n", __func__, req, req->r_tid);
net/ceph/osd_client.c:	complete_all(&req->r_completion);
net/ceph/osd_client.c:	dout("%s req %p tid %llu err %d\n", __func__, req, req->r_tid, err);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	if ((req->r_flags & CEPH_OSD_FLAG_WRITE) &&
net/ceph/osd_client.c:	     pool_full(osdc, req->r_t.base_oloc.pool))) {
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	if (req->r_attempts) {
net/ceph/osd_client.c:		req->r_map_dne_bound = map->epoch;
net/ceph/osd_client.c:		     req->r_tid);
net/ceph/osd_client.c:		     req, req->r_tid, req->r_map_dne_bound, map->epoch);
net/ceph/osd_client.c:	if (req->r_map_dne_bound) {
net/ceph/osd_client.c:		if (map->epoch >= req->r_map_dne_bound) {
net/ceph/osd_client.c:					    req->r_tid);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = &greq->monc->client->osdc;
net/ceph/osd_client.c:	u64 tid = greq->private_data;
net/ceph/osd_client.c:	WARN_ON(greq->result || !greq->u.newest);
net/ceph/osd_client.c:	     req, req->r_tid, req->r_map_dne_bound, greq->u.newest);
net/ceph/osd_client.c:	if (!req->r_map_dne_bound)
net/ceph/osd_client.c:		req->r_map_dne_bound = greq->u.newest;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	lookup_req = lookup_request_mc(&osdc->map_checks, req->r_tid);
net/ceph/osd_client.c:					  map_check_cb, req->r_tid);
net/ceph/osd_client.c:	     lreq->reg_req, lreq->ping_req);
net/ceph/osd_client.c:	WARN_ON(!RB_EMPTY_NODE(&lreq->node));
net/ceph/osd_client.c:	WARN_ON(!RB_EMPTY_NODE(&lreq->osdc_node));
net/ceph/osd_client.c:	WARN_ON(!RB_EMPTY_NODE(&lreq->mc_node));
net/ceph/osd_client.c:	WARN_ON(!list_empty(&lreq->scan_item));
net/ceph/osd_client.c:	WARN_ON(!list_empty(&lreq->pending_lworks));
net/ceph/osd_client.c:	WARN_ON(lreq->osd);
net/ceph/osd_client.c:	if (lreq->reg_req)
net/ceph/osd_client.c:		ceph_osdc_put_request(lreq->reg_req);
net/ceph/osd_client.c:	if (lreq->ping_req)
net/ceph/osd_client.c:		ceph_osdc_put_request(lreq->ping_req);
net/ceph/osd_client.c:	target_destroy(&lreq->t);
net/ceph/osd_client.c:		kref_put(&lreq->kref, linger_release);
net/ceph/osd_client.c:	kref_get(&lreq->kref);
net/ceph/osd_client.c:	kref_init(&lreq->kref);
net/ceph/osd_client.c:	mutex_init(&lreq->lock);
net/ceph/osd_client.c:	RB_CLEAR_NODE(&lreq->node);
net/ceph/osd_client.c:	RB_CLEAR_NODE(&lreq->osdc_node);
net/ceph/osd_client.c:	RB_CLEAR_NODE(&lreq->mc_node);
net/ceph/osd_client.c:	INIT_LIST_HEAD(&lreq->scan_item);
net/ceph/osd_client.c:	INIT_LIST_HEAD(&lreq->pending_lworks);
net/ceph/osd_client.c:	init_completion(&lreq->reg_commit_wait);
net/ceph/osd_client.c:	init_completion(&lreq->notify_finish_wait);
net/ceph/osd_client.c:	lreq->osdc = osdc;
net/ceph/osd_client.c:	target_init(&lreq->t);
net/ceph/osd_client.c:	WARN_ON(!lreq->linger_id || lreq->osd);
net/ceph/osd_client.c:	     osd->o_osd, lreq, lreq->linger_id);
net/ceph/osd_client.c:	lreq->osd = osd;
net/ceph/osd_client.c:	WARN_ON(lreq->osd != osd);
net/ceph/osd_client.c:	     osd->o_osd, lreq, lreq->linger_id);
net/ceph/osd_client.c:	lreq->osd = NULL;
net/ceph/osd_client.c:	verify_osdc_locked(lreq->osdc);
net/ceph/osd_client.c:	return !RB_EMPTY_NODE(&lreq->osdc_node);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	WARN_ON(lreq->linger_id);
net/ceph/osd_client.c:	lreq->linger_id = ++osdc->last_linger_id;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	struct ceph_osd_linger_request *lreq = req->r_priv;
net/ceph/osd_client.c:	WARN_ON(!req->r_linger);
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	list_add_tail(&lwork->pending_item, &lreq->pending_lworks);
net/ceph/osd_client.c:	WARN_ON(!lreq->is_watch);
net/ceph/osd_client.c:	lreq->wcb(lreq->data, lwork->notify.notify_id, lreq->linger_id,
net/ceph/osd_client.c:	lreq->errcb(lreq->data, lreq->linger_id, lwork->error.err);
net/ceph/osd_client.c:	lwork->error.err = lreq->last_error;
net/ceph/osd_client.c:	if (!completion_done(&lreq->reg_commit_wait)) {
net/ceph/osd_client.c:		lreq->reg_commit_error = (result <= 0 ? result : 0);
net/ceph/osd_client.c:		complete_all(&lreq->reg_commit_wait);
net/ceph/osd_client.c:	struct ceph_osd_linger_request *lreq = req->r_priv;
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	     lreq->linger_id, req->r_result);
net/ceph/osd_client.c:	linger_reg_commit_complete(lreq, req->r_result);
net/ceph/osd_client.c:	lreq->committed = true;
net/ceph/osd_client.c:	if (!lreq->is_watch) {
net/ceph/osd_client.c:		WARN_ON(req->r_ops[0].op != CEPH_OSD_OP_NOTIFY ||
net/ceph/osd_client.c:		if (req->r_ops[0].outdata_len >= sizeof(u64)) {
net/ceph/osd_client.c:			lreq->notify_id = ceph_decode_64(&p);
net/ceph/osd_client.c:			     lreq->notify_id);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	struct ceph_osd_linger_request *lreq = req->r_priv;
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	     lreq, lreq->linger_id, req->r_result, lreq->last_error);
net/ceph/osd_client.c:	if (req->r_result < 0) {
net/ceph/osd_client.c:		if (!lreq->last_error) {
net/ceph/osd_client.c:			lreq->last_error = normalize_watch_error(req->r_result);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	struct ceph_osd_request *req = lreq->reg_req;
net/ceph/osd_client.c:	struct ceph_osd_req_op *op = &req->r_ops[0];
net/ceph/osd_client.c:	verify_osdc_wrlocked(req->r_osdc);
net/ceph/osd_client.c:	dout("%s lreq %p linger_id %llu\n", __func__, lreq, lreq->linger_id);
net/ceph/osd_client.c:	if (req->r_osd)
net/ceph/osd_client.c:	target_copy(&req->r_t, &lreq->t);
net/ceph/osd_client.c:	req->r_mtime = lreq->mtime;
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	if (lreq->is_watch && lreq->committed) {
net/ceph/osd_client.c:			op->watch.cookie != lreq->linger_id);
net/ceph/osd_client.c:		op->watch.gen = ++lreq->register_gen;
net/ceph/osd_client.c:		req->r_callback = linger_reconnect_cb;
net/ceph/osd_client.c:		if (!lreq->is_watch)
net/ceph/osd_client.c:			lreq->notify_id = 0;
net/ceph/osd_client.c:		req->r_callback = linger_commit_cb;
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	req->r_priv = linger_get(lreq);
net/ceph/osd_client.c:	req->r_linger = true;
net/ceph/osd_client.c:	struct ceph_osd_linger_request *lreq = req->r_priv;
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	     __func__, lreq, lreq->linger_id, req->r_result, lreq->ping_sent,
net/ceph/osd_client.c:	     lreq->last_error);
net/ceph/osd_client.c:	if (lreq->register_gen == req->r_ops[0].watch.gen) {
net/ceph/osd_client.c:		if (!req->r_result) {
net/ceph/osd_client.c:			lreq->watch_valid_thru = lreq->ping_sent;
net/ceph/osd_client.c:		} else if (!lreq->last_error) {
net/ceph/osd_client.c:			lreq->last_error = normalize_watch_error(req->r_result);
net/ceph/osd_client.c:		     lreq->register_gen, req->r_ops[0].watch.gen);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	struct ceph_osd_request *req = lreq->ping_req;
net/ceph/osd_client.c:	struct ceph_osd_req_op *op = &req->r_ops[0];
net/ceph/osd_client.c:	lreq->ping_sent = jiffies;
net/ceph/osd_client.c:	     __func__, lreq, lreq->linger_id, lreq->ping_sent,
net/ceph/osd_client.c:	     lreq->register_gen);
net/ceph/osd_client.c:	if (req->r_osd)
net/ceph/osd_client.c:	target_copy(&req->r_t, &lreq->t);
net/ceph/osd_client.c:		op->watch.cookie != lreq->linger_id ||
net/ceph/osd_client.c:	op->watch.gen = lreq->register_gen;
net/ceph/osd_client.c:	req->r_callback = linger_ping_cb;
net/ceph/osd_client.c:	req->r_priv = linger_get(lreq);
net/ceph/osd_client.c:	req->r_linger = true;
net/ceph/osd_client.c:	req->r_tid = atomic64_inc_return(&osdc->last_tid);
net/ceph/osd_client.c:	link_request(lreq->osd, req);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	if (lreq->is_watch) {
net/ceph/osd_client.c:		lreq->reg_req->r_ops[0].watch.cookie = lreq->linger_id;
net/ceph/osd_client.c:		lreq->ping_req->r_ops[0].watch.cookie = lreq->linger_id;
net/ceph/osd_client.c:		lreq->reg_req->r_ops[0].notify.cookie = lreq->linger_id;
net/ceph/osd_client.c:	calc_target(osdc, &lreq->t, false);
net/ceph/osd_client.c:	osd = lookup_create_osd(osdc, lreq->t.osd, true);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:				       lreq->linger_id);
net/ceph/osd_client.c:	if (lreq->is_watch && lreq->ping_req->r_osd)
net/ceph/osd_client.c:		cancel_linger_request(lreq->ping_req);
net/ceph/osd_client.c:	if (lreq->reg_req->r_osd)
net/ceph/osd_client.c:		cancel_linger_request(lreq->reg_req);
net/ceph/osd_client.c:	unlink_linger(lreq->osd, lreq);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	if (lreq->register_gen) {
net/ceph/osd_client.c:		lreq->map_dne_bound = map->epoch;
net/ceph/osd_client.c:		     lreq, lreq->linger_id);
net/ceph/osd_client.c:		     __func__, lreq, lreq->linger_id, lreq->map_dne_bound,
net/ceph/osd_client.c:	if (lreq->map_dne_bound) {
net/ceph/osd_client.c:		if (map->epoch >= lreq->map_dne_bound) {
net/ceph/osd_client.c:				lreq->linger_id);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = &greq->monc->client->osdc;
net/ceph/osd_client.c:	u64 linger_id = greq->private_data;
net/ceph/osd_client.c:	WARN_ON(greq->result || !greq->u.newest);
net/ceph/osd_client.c:	     __func__, lreq, lreq->linger_id, lreq->map_dne_bound,
net/ceph/osd_client.c:	     greq->u.newest);
net/ceph/osd_client.c:	if (!lreq->map_dne_bound)
net/ceph/osd_client.c:		lreq->map_dne_bound = greq->u.newest;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:				       lreq->linger_id);
net/ceph/osd_client.c:					  linger_map_check_cb, lreq->linger_id);
net/ceph/osd_client.c:	dout("%s lreq %p linger_id %llu\n", __func__, lreq, lreq->linger_id);
net/ceph/osd_client.c:	ret = wait_for_completion_interruptible(&lreq->reg_commit_wait);
net/ceph/osd_client.c:	return ret ?: lreq->reg_commit_error;
net/ceph/osd_client.c:	dout("%s lreq %p linger_id %llu\n", __func__, lreq, lreq->linger_id);
net/ceph/osd_client.c:	ret = wait_for_completion_interruptible(&lreq->notify_finish_wait);
net/ceph/osd_client.c:	return ret ?: lreq->notify_finish_error;
net/ceph/osd_client.c:			if (time_before(req->r_stamp, cutoff)) {
net/ceph/osd_client.c:				     req, req->r_tid, osd->o_osd);
net/ceph/osd_client.c:			    time_before(req->r_start_stamp, expiry_cutoff)) {
net/ceph/osd_client.c:				       req->r_tid, osd->o_osd);
net/ceph/osd_client.c:			     lreq, lreq->linger_id, osd->o_osd);
net/ceph/osd_client.c:			mutex_lock(&lreq->lock);
net/ceph/osd_client.c:			if (lreq->is_watch && lreq->committed && !lreq->last_error)
net/ceph/osd_client.c:			mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:			if (time_before(req->r_start_stamp, expiry_cutoff)) {
net/ceph/osd_client.c:				       req->r_tid, osdc->homeless_osd.o_osd);
net/ceph/osd_client.c:	m.redirect.oloc.pool_ns = req->r_t.target_oloc.pool_ns;
net/ceph/osd_client.c:		       req->r_tid, ret);
net/ceph/osd_client.c:	     __func__, req, req->r_tid, m.flags, m.pgid.pool, m.pgid.seed,
net/ceph/osd_client.c:		if (m.retry_attempt != req->r_attempts - 1) {
net/ceph/osd_client.c:			     req, req->r_tid, m.retry_attempt,
net/ceph/osd_client.c:			     req->r_attempts - 1);
net/ceph/osd_client.c:		dout("req %p tid %llu redirect pool %lld\n", req, req->r_tid,
net/ceph/osd_client.c:		req->r_t.target_oloc.pool = m.redirect.oloc.pool;
net/ceph/osd_client.c:		req->r_flags |= CEPH_OSD_FLAG_REDIRECTED |
net/ceph/osd_client.c:		req->r_tid = 0;
net/ceph/osd_client.c:		dout("req %p tid %llu EAGAIN\n", req, req->r_tid);
net/ceph/osd_client.c:		req->r_t.pgid.pool = 0;
net/ceph/osd_client.c:		req->r_t.pgid.seed = 0;
net/ceph/osd_client.c:		WARN_ON(!req->r_t.used_replica);
net/ceph/osd_client.c:		req->r_flags &= ~(CEPH_OSD_FLAG_BALANCE_READS |
net/ceph/osd_client.c:		req->r_tid = 0;
net/ceph/osd_client.c:	if (m.num_ops != req->r_num_ops) {
net/ceph/osd_client.c:		       req->r_num_ops, req->r_tid);
net/ceph/osd_client.c:	for (i = 0; i < req->r_num_ops; i++) {
net/ceph/osd_client.c:		     req->r_tid, i, m.rval[i], m.outdata_len[i]);
net/ceph/osd_client.c:		req->r_ops[i].rval = m.rval[i];
net/ceph/osd_client.c:		req->r_ops[i].outdata_len = m.outdata_len[i];
net/ceph/osd_client.c:		       le32_to_cpu(msg->hdr.data_len), req->r_tid);
net/ceph/osd_client.c:	     req, req->r_tid, m.result, data_len);
net/ceph/osd_client.c:	req->r_result = m.result ?: data_len;
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = lreq->osdc;
net/ceph/osd_client.c:	ct_res = calc_target(osdc, &lreq->t, true);
net/ceph/osd_client.c:		osd = lookup_create_osd(osdc, lreq->t.osd, true);
net/ceph/osd_client.c:		if (osd != lreq->osd) {
net/ceph/osd_client.c:			unlink_linger(lreq->osd, lreq);
net/ceph/osd_client.c:		     lreq->linger_id);
net/ceph/osd_client.c:			     pool_cleared_full(osdc, lreq->t.base_oloc.pool));
net/ceph/osd_client.c:			if (list_empty(&lreq->scan_item))
net/ceph/osd_client.c:				list_add_tail(&lreq->scan_item, need_resend_linger);
net/ceph/osd_client.c:			list_del_init(&lreq->scan_item);
net/ceph/osd_client.c:		dout("%s req %p tid %llu\n", __func__, req, req->r_tid);
net/ceph/osd_client.c:		ct_res = calc_target(osdc, &req->r_t, false);
net/ceph/osd_client.c:			     pool_cleared_full(osdc, req->r_t.base_oloc.pool));
net/ceph/osd_client.c:			    (!(req->r_flags & CEPH_OSD_FLAG_WRITE) ||
net/ceph/osd_client.c:		if (req->r_t.epoch < osdc->osdmap->epoch) {
net/ceph/osd_client.c:			ct_res = calc_target(osdc, &req->r_t, false);
net/ceph/osd_client.c:		osd = lookup_create_osd(osdc, req->r_t.osd, true);
net/ceph/osd_client.c:		if (!req->r_linger) {
net/ceph/osd_client.c:			if (!osd_homeless(osd) && !req->r_t.paused)
net/ceph/osd_client.c:		if (!osd_homeless(lreq->osd))
net/ceph/osd_client.c:		list_del_init(&lreq->scan_item);
net/ceph/osd_client.c:		if (!req->r_linger) {
net/ceph/osd_client.c:			if (!req->r_t.paused)
net/ceph/osd_client.c:		if (!ceph_spg_compare(&req->r_t.spgid, &m->spgid)) {
net/ceph/osd_client.c:			if (target_contained_by(&req->r_t, m->begin, m->end)) {
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	     opcode, cookie, lreq, lreq->is_watch);
net/ceph/osd_client.c:		if (!lreq->last_error) {
net/ceph/osd_client.c:			lreq->last_error = -ENOTCONN;
net/ceph/osd_client.c:	} else if (!lreq->is_watch) {
net/ceph/osd_client.c:		if (lreq->notify_id && lreq->notify_id != notify_id) {
net/ceph/osd_client.c:			     lreq->notify_id, notify_id);
net/ceph/osd_client.c:		} else if (!completion_done(&lreq->notify_finish_wait)) {
net/ceph/osd_client.c:				if (lreq->preply_pages) {
net/ceph/osd_client.c:					*lreq->preply_pages = data->pages;
net/ceph/osd_client.c:					*lreq->preply_len = data->length;
net/ceph/osd_client.c:			lreq->notify_finish_error = return_code;
net/ceph/osd_client.c:			complete_all(&lreq->notify_finish_wait);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	struct ceph_osd_client *osdc = req->r_osdc;
net/ceph/osd_client.c:	if (req->r_osd)
net/ceph/osd_client.c:	dout("%s req %p tid %llu\n", __func__, req, req->r_tid);
net/ceph/osd_client.c:	left = wait_for_completion_killable_timeout(&req->r_completion,
net/ceph/osd_client.c:		left = req->r_result; /* completed */
net/ceph/osd_client.c:			if (req->r_tid > last_tid)
net/ceph/osd_client.c:			if (!(req->r_flags & CEPH_OSD_FLAG_WRITE))
net/ceph/osd_client.c:			     __func__, req, req->r_tid, last_tid);
net/ceph/osd_client.c:			wait_for_completion(&req->r_completion);
net/ceph/osd_client.c:	req = ceph_osdc_alloc_request(lreq->osdc, NULL, 1, false, GFP_NOIO);
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_base_oid, &lreq->t.base_oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_base_oloc, &lreq->t.base_oloc);
net/ceph/osd_client.c:	lreq->is_watch = true;
net/ceph/osd_client.c:	lreq->wcb = wcb;
net/ceph/osd_client.c:	lreq->errcb = errcb;
net/ceph/osd_client.c:	lreq->data = data;
net/ceph/osd_client.c:	lreq->watch_valid_thru = jiffies;
net/ceph/osd_client.c:	ceph_oid_copy(&lreq->t.base_oid, oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&lreq->t.base_oloc, oloc);
net/ceph/osd_client.c:	lreq->t.flags = CEPH_OSD_FLAG_WRITE;
net/ceph/osd_client.c:	ktime_get_real_ts64(&lreq->mtime);
net/ceph/osd_client.c:	lreq->reg_req = alloc_watch_request(lreq, CEPH_OSD_WATCH_OP_WATCH);
net/ceph/osd_client.c:	if (!lreq->reg_req) {
net/ceph/osd_client.c:	lreq->ping_req = alloc_watch_request(lreq, CEPH_OSD_WATCH_OP_PING);
net/ceph/osd_client.c:	if (!lreq->ping_req) {
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_base_oid, &lreq->t.base_oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_base_oloc, &lreq->t.base_oloc);
net/ceph/osd_client.c:	req->r_flags = CEPH_OSD_FLAG_WRITE;
net/ceph/osd_client.c:	ktime_get_real_ts64(&req->r_mtime);
net/ceph/osd_client.c:	osd_req_op_watch_init(req, 0, lreq->linger_id,
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_base_oid, oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_base_oloc, oloc);
net/ceph/osd_client.c:	req->r_flags = CEPH_OSD_FLAG_READ;
net/ceph/osd_client.c:	lreq->preply_pages = preply_pages;
net/ceph/osd_client.c:	lreq->preply_len = preply_len;
net/ceph/osd_client.c:	ceph_oid_copy(&lreq->t.base_oid, oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&lreq->t.base_oloc, oloc);
net/ceph/osd_client.c:	lreq->t.flags = CEPH_OSD_FLAG_READ;
net/ceph/osd_client.c:	lreq->reg_req = alloc_linger_request(lreq);
net/ceph/osd_client.c:	if (!lreq->reg_req) {
net/ceph/osd_client.c:	ret = osd_req_op_notify_init(lreq->reg_req, 0, 0, 1, timeout,
net/ceph/osd_client.c:	ceph_osd_data_pages_init(osd_req_op_data(lreq->reg_req, 0, notify,
net/ceph/osd_client.c:	ret = ceph_osdc_alloc_messages(lreq->reg_req, GFP_NOIO);
net/ceph/osd_client.c:	mutex_lock(&lreq->lock);
net/ceph/osd_client.c:	stamp = lreq->watch_valid_thru;
net/ceph/osd_client.c:	if (!list_empty(&lreq->pending_lworks)) {
net/ceph/osd_client.c:		    list_first_entry(&lreq->pending_lworks,
net/ceph/osd_client.c:	     lreq, lreq->linger_id, age, lreq->last_error);
net/ceph/osd_client.c:	ret = lreq->last_error ?: 1 + jiffies_to_msecs(age);
net/ceph/osd_client.c:	mutex_unlock(&lreq->lock);
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_base_oid, oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_base_oloc, oloc);
net/ceph/osd_client.c:	req->r_flags = CEPH_OSD_FLAG_READ;
net/ceph/osd_client.c:		void *const end = p + req->r_ops[0].outdata_len;
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_base_oid, oid);
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_base_oloc, oloc);
net/ceph/osd_client.c:	req->r_flags = flags;
net/ceph/osd_client.c:		ret = req->r_ops[0].rval;
net/ceph/osd_client.c:			*resp_len = req->r_ops[0].outdata_len;
net/ceph/osd_client.c:	req->r_flags = CEPH_OSD_FLAG_WRITE;
net/ceph/osd_client.c:	ceph_oloc_copy(&req->r_t.base_oloc, dst_oloc);
net/ceph/osd_client.c:	ceph_oid_copy(&req->r_t.base_oid, dst_oid);
net/ceph/osd_client.c:	ceph_msg_revoke_incoming(req->r_reply);
net/ceph/osd_client.c:	if (front_len > req->r_reply->front_alloc_len) {
net/ceph/osd_client.c:			__func__, osd->o_osd, req->r_tid, front_len,
net/ceph/osd_client.c:			req->r_reply->front_alloc_len);
net/ceph/osd_client.c:		ceph_msg_put(req->r_reply);
net/ceph/osd_client.c:		req->r_reply = m;
net/ceph/osd_client.c:	if (data_len > req->r_reply->data_length) {
net/ceph/osd_client.c:			__func__, osd->o_osd, req->r_tid, data_len,
net/ceph/osd_client.c:			req->r_reply->data_length);
net/ceph/osd_client.c:	m = ceph_msg_get(req->r_reply);
net/netfilter/nf_conntrack_sane.c:		if (req->RPC_code != htonl(SANE_NET_START)) {
net/netfilter/nf_tables_api.c:		if (!strcmp(req->module, module_name)) {
net/netfilter/nf_tables_api.c:			if (req->done)
net/netfilter/nf_tables_api.c:	req->done = false;
net/netfilter/nf_tables_api.c:	strlcpy(req->module, module_name, MODULE_NAME_LEN);
net/netfilter/nf_tables_api.c:	list_add_tail(&req->list, &net->nft.module_list);
net/netfilter/nf_tables_api.c:		WARN_ON_ONCE(!req->done);
net/netfilter/nf_tables_api.c:		list_del(&req->list);
net/netfilter/nf_tables_api.c:		request_module("%s", req->module);
net/netfilter/nf_tables_api.c:		req->done = true;
net/netlink/diag.c:	if ((req->ndiag_show & NDIAG_SHOW_GROUPS) &&
net/netlink/diag.c:	if ((req->ndiag_show & NDIAG_SHOW_MEMINFO) &&
net/netlink/diag.c:	if ((req->ndiag_show & NDIAG_SHOW_FLAGS) &&
net/netlink/diag.c:	if (req->sdiag_protocol == NDIAG_PROTO_ALL) {
net/netlink/diag.c:		if (req->sdiag_protocol >= MAX_LINKS)
net/netlink/diag.c:		err = __netlink_diag_dump(skb, cb, req->sdiag_protocol, s_num);
net/dccp/ipv4.c:		inet_csk_reqsk_queue_drop(req->rsk_listener, req);
net/dccp/ipv4.c:	sk_daddr_set(newsk, ireq->ir_rmt_addr);
net/dccp/ipv4.c:	sk_rcv_saddr_set(newsk, ireq->ir_loc_addr);
net/dccp/ipv4.c:	newinet->inet_saddr	= ireq->ir_loc_addr;
net/dccp/ipv4.c:	RCU_INIT_POINTER(newinet->inet_opt, rcu_dereference(ireq->ireq_opt));
net/dccp/ipv4.c:		ireq->ireq_opt = NULL;
net/dccp/ipv4.c:		dh->dccph_checksum = dccp_v4_csum_finish(skb, ireq->ir_loc_addr,
net/dccp/ipv4.c:							      ireq->ir_rmt_addr);
net/dccp/ipv4.c:		err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
net/dccp/ipv4.c:					    ireq->ir_rmt_addr,
net/dccp/ipv4.c:					    rcu_dereference(ireq->ireq_opt),
net/dccp/ipv4.c:	ireq->ir_mark = inet_request_mark(sk, skb);
net/dccp/ipv4.c:	ireq->ireq_family = AF_INET;
net/dccp/ipv4.c:	ireq->ir_iif = sk->sk_bound_dev_if;
net/dccp/ipv4.c:	dreq->dreq_isr	   = dcb->dccpd_seq;
net/dccp/ipv4.c:	dreq->dreq_gsr	   = dreq->dreq_isr;
net/dccp/ipv4.c:	dreq->dreq_iss	   = dccp_v4_init_sequence(skb);
net/dccp/ipv4.c:	dreq->dreq_gss     = dreq->dreq_iss;
net/dccp/ipv4.c:	dreq->dreq_service = service;
net/dccp/ipv4.c:		sk = req->rsk_listener;
net/dccp/minisocks.c:		newdp->dccps_service	    = dreq->dreq_service;
net/dccp/minisocks.c:		newdp->dccps_timestamp_echo = dreq->dreq_timestamp_echo;
net/dccp/minisocks.c:		newdp->dccps_timestamp_time = dreq->dreq_timestamp_time;
net/dccp/minisocks.c:		newdp->dccps_iss = dreq->dreq_iss;
net/dccp/minisocks.c:		newdp->dccps_gss = dreq->dreq_gss;
net/dccp/minisocks.c:		newdp->dccps_isr = dreq->dreq_isr;
net/dccp/minisocks.c:		newdp->dccps_gsr = dreq->dreq_gsr;
net/dccp/minisocks.c:		if (dccp_feat_activate_values(newsk, &dreq->dreq_featneg)) {
net/dccp/minisocks.c:	spin_lock_bh(&dreq->dreq_lock);
net/dccp/minisocks.c:		if (after48(DCCP_SKB_CB(skb)->dccpd_seq, dreq->dreq_gsr)) {
net/dccp/minisocks.c:			dreq->dreq_gsr = DCCP_SKB_CB(skb)->dccpd_seq;
net/dccp/minisocks.c:				dreq->dreq_iss, dreq->dreq_gss)) {
net/dccp/minisocks.c:			      (unsigned long long) dreq->dreq_iss,
net/dccp/minisocks.c:			      (unsigned long long) dreq->dreq_gss);
net/dccp/minisocks.c:		req->rsk_ops->send_reset(sk, skb);
net/dccp/minisocks.c:	spin_unlock_bh(&dreq->dreq_lock);
net/dccp/minisocks.c:	spin_lock_init(&dreq->dreq_lock);
net/dccp/minisocks.c:	dreq->dreq_timestamp_echo  = 0;
net/dccp/minisocks.c:	return dccp_feat_clone_list(&dp->dccps_featneg, &dreq->dreq_featneg);
net/dccp/feat.c:	struct list_head *fn = dreq ? &dreq->dreq_featneg : &dp->dccps_featneg;
net/dccp/feat.c:	struct list_head *fn = &dreq->dreq_featneg;
net/dccp/feat.c:	struct list_head *fn = dreq ? &dreq->dreq_featneg : &dp->dccps_featneg;
net/dccp/options.c:				dreq->dreq_timestamp_echo = ntohl(opt_val);
net/dccp/options.c:				dreq->dreq_timestamp_time = dccp_timestamp();
net/dccp/options.c:		elapsed_time = dccp_timestamp() - dreq->dreq_timestamp_time;
net/dccp/options.c:		tstamp_echo  = htonl(dreq->dreq_timestamp_echo);
net/dccp/options.c:		dreq->dreq_timestamp_echo = 0;
net/dccp/options.c:	if (dreq->dreq_timestamp_echo != 0 &&
net/dccp/output.c:		dccp_inc_seqno(&dreq->dreq_gss);
net/dccp/output.c:	DCCP_SKB_CB(skb)->dccpd_seq  = dreq->dreq_gss;
net/dccp/output.c:	dccp_hdr_set_seq(dh, dreq->dreq_gss);
net/dccp/output.c:	dccp_hdr_set_ack(dccp_hdr_ack_bits(skb), dreq->dreq_gsr);
net/dccp/output.c:	dccp_hdr_response(skb)->dccph_resp_service = dreq->dreq_service;
net/dccp/ipv6.c:	fl6.daddr = ireq->ir_v6_rmt_addr;
net/dccp/ipv6.c:	fl6.saddr = ireq->ir_v6_loc_addr;
net/dccp/ipv6.c:	fl6.flowi6_oif = ireq->ir_iif;
net/dccp/ipv6.c:	fl6.fl6_dport = ireq->ir_rmt_port;
net/dccp/ipv6.c:	fl6.fl6_sport = htons(ireq->ir_num);
net/dccp/ipv6.c:							 &ireq->ir_v6_loc_addr,
net/dccp/ipv6.c:							 &ireq->ir_v6_rmt_addr);
net/dccp/ipv6.c:		fl6.daddr = ireq->ir_v6_rmt_addr;
net/dccp/ipv6.c:		opt = ireq->ipv6_opt;
net/dccp/ipv6.c:	ireq->ir_v6_rmt_addr = ipv6_hdr(skb)->saddr;
net/dccp/ipv6.c:	ireq->ir_v6_loc_addr = ipv6_hdr(skb)->daddr;
net/dccp/ipv6.c:	ireq->ireq_family = AF_INET6;
net/dccp/ipv6.c:	ireq->ir_mark = inet_request_mark(sk, skb);
net/dccp/ipv6.c:		ireq->pktopts = skb;
net/dccp/ipv6.c:	ireq->ir_iif = sk->sk_bound_dev_if;
net/dccp/ipv6.c:	    ipv6_addr_type(&ireq->ir_v6_rmt_addr) & IPV6_ADDR_LINKLOCAL)
net/dccp/ipv6.c:		ireq->ir_iif = inet6_iif(skb);
net/dccp/ipv6.c:	dreq->dreq_isr	   = dcb->dccpd_seq;
net/dccp/ipv6.c:	dreq->dreq_gsr     = dreq->dreq_isr;
net/dccp/ipv6.c:	dreq->dreq_iss	   = dccp_v6_init_sequence(skb);
net/dccp/ipv6.c:	dreq->dreq_gss     = dreq->dreq_iss;
net/dccp/ipv6.c:	dreq->dreq_service = service;
net/dccp/ipv6.c:	newsk->sk_v6_daddr	= ireq->ir_v6_rmt_addr;
net/dccp/ipv6.c:	newnp->saddr		= ireq->ir_v6_loc_addr;
net/dccp/ipv6.c:	newsk->sk_v6_rcv_saddr	= ireq->ir_v6_loc_addr;
net/dccp/ipv6.c:	newsk->sk_bound_dev_if	= ireq->ir_iif;
net/dccp/ipv6.c:	opt = ireq->ipv6_opt;
net/dccp/ipv6.c:	if (*own_req && ireq->pktopts) {
net/dccp/ipv6.c:		newnp->pktoptions = skb_clone(ireq->pktopts, GFP_ATOMIC);
net/dccp/ipv6.c:		consume_skb(ireq->pktopts);
net/dccp/ipv6.c:		ireq->pktopts = NULL;
net/dccp/ipv6.c:		sk = req->rsk_listener;
net/netlabel/netlabel_kapi.c:	switch (req->rsk_ops->family) {
net/netlabel/netlabel_kapi.c:						   ireq->ir_rmt_addr);
net/netlabel/netlabel_kapi.c:						   &ireq->ir_v6_rmt_addr);
net/netlabel/netlabel_kapi.c:	switch (req->rsk_ops->family) {
net/ipv4/tcp.c:	tp->fastopen_req->data = msg;
net/ipv4/tcp.c:	tp->fastopen_req->size = size;
net/ipv4/tcp.c:	tp->fastopen_req->uarg = uarg;
net/ipv4/tcp.c:		*copied = tp->fastopen_req->copied;
net/ipv4/tcp.c:			inet_csk_reqsk_queue_drop(req->rsk_listener, req);
net/ipv4/esp4.c:	if (req->src != req->dst)
net/ipv4/esp4.c:		for (sg = sg_next(req->src); sg; sg = sg_next(sg))
net/ipv4/af_inet.c:				tcp_sk(sk)->fastopen_req->data ? 1 : 0;
net/ipv4/tcp_input.c:	if (req && !req->num_retrans && tcp_rsk(req)->snt_synack)
net/ipv4/tcp_input.c:				    &ireq->ir_rmt_addr, port);
net/ipv4/tcp_input.c:				    &ireq->ir_v6_rmt_addr, port);
net/ipv4/tcp_input.c:	req->rsk_rcv_wnd = 0;		/* So that tcp_send_synack() knows! */
net/ipv4/tcp_input.c:	req->mss = rx_opt->mss_clamp;
net/ipv4/tcp_input.c:	req->ts_recent = rx_opt->saw_tstamp ? rx_opt->rcv_tsval : 0;
net/ipv4/tcp_input.c:	ireq->tstamp_ok = rx_opt->tstamp_ok;
net/ipv4/tcp_input.c:	ireq->sack_ok = rx_opt->sack_ok;
net/ipv4/tcp_input.c:	ireq->snd_wscale = rx_opt->snd_wscale;
net/ipv4/tcp_input.c:	ireq->wscale_ok = rx_opt->wscale_ok;
net/ipv4/tcp_input.c:	ireq->acked = 0;
net/ipv4/tcp_input.c:	ireq->ecn_ok = 0;
net/ipv4/tcp_input.c:	ireq->ir_rmt_port = tcp_hdr(skb)->source;
net/ipv4/tcp_input.c:	ireq->ir_num = ntohs(tcp_hdr(skb)->dest);
net/ipv4/tcp_input.c:	ireq->ir_mark = inet_request_mark(sk, skb);
net/ipv4/tcp_input.c:	ireq->smc_ok = rx_opt->smc_ok;
net/ipv4/tcp_input.c:		ireq->ireq_opt = NULL;
net/ipv4/tcp_input.c:		ireq->pktopts = NULL;
net/ipv4/tcp_input.c:		atomic64_set(&ireq->ir_cookie, 0);
net/ipv4/tcp_input.c:		ireq->ireq_state = TCP_NEW_SYN_RECV;
net/ipv4/tcp_input.c:		write_pnet(&ireq->ireq_net, sock_net(sk_listener));
net/ipv4/tcp_input.c:		ireq->ireq_family = sk_listener->sk_family;
net/ipv4/tcp_input.c:			req->saved_syn = saved_syn;
net/ipv4/tcp_input.c:	req->syncookie = want_cookie;
net/ipv4/tcp_input.c:		isn = cookie_init_sequence(af_ops, sk, skb, &req->mss);
net/ipv4/tcp_minisocks.c:	req->rsk_window_clamp = window_clamp ? : dst_metric(dst, RTAX_WINDOW);
net/ipv4/tcp_minisocks.c:	    (req->rsk_window_clamp > full_space || req->rsk_window_clamp == 0))
net/ipv4/tcp_minisocks.c:		req->rsk_window_clamp = full_space;
net/ipv4/tcp_minisocks.c:		mss - (ireq->tstamp_ok ? TCPOLEN_TSTAMP_ALIGNED : 0),
net/ipv4/tcp_minisocks.c:		&req->rsk_rcv_wnd,
net/ipv4/tcp_minisocks.c:		&req->rsk_window_clamp,
net/ipv4/tcp_minisocks.c:		ireq->wscale_ok,
net/ipv4/tcp_minisocks.c:	ireq->rcv_wscale = rcv_wscale;
net/ipv4/tcp_minisocks.c:		if (oldtp->syn_smc && !ireq->smc_ok)
net/ipv4/tcp_minisocks.c:	seq = treq->rcv_isn + 1;
net/ipv4/tcp_minisocks.c:	seq = treq->snt_isn + 1;
net/ipv4/tcp_minisocks.c:	tcp_init_wl(newtp, treq->rcv_isn);
net/ipv4/tcp_minisocks.c:	newsk->sk_txhash = treq->txhash;
net/ipv4/tcp_minisocks.c:	newtp->total_retrans = req->num_retrans;
net/ipv4/tcp_minisocks.c:	WRITE_ONCE(newtp->write_seq, newtp->pushed_seq = treq->snt_isn + 1);
net/ipv4/tcp_minisocks.c:	newtp->rx_opt.tstamp_ok = ireq->tstamp_ok;
net/ipv4/tcp_minisocks.c:	newtp->rx_opt.sack_ok = ireq->sack_ok;
net/ipv4/tcp_minisocks.c:	newtp->window_clamp = req->rsk_window_clamp;
net/ipv4/tcp_minisocks.c:	newtp->rcv_ssthresh = req->rsk_rcv_wnd;
net/ipv4/tcp_minisocks.c:	newtp->rcv_wnd = req->rsk_rcv_wnd;
net/ipv4/tcp_minisocks.c:	newtp->rx_opt.wscale_ok = ireq->wscale_ok;
net/ipv4/tcp_minisocks.c:		newtp->rx_opt.snd_wscale = ireq->snd_wscale;
net/ipv4/tcp_minisocks.c:		newtp->rx_opt.rcv_wscale = ireq->rcv_wscale;
net/ipv4/tcp_minisocks.c:		newtp->rx_opt.ts_recent = req->ts_recent;
net/ipv4/tcp_minisocks.c:	if (req->num_timeout) {
net/ipv4/tcp_minisocks.c:		newtp->undo_marker = treq->snt_isn;
net/ipv4/tcp_minisocks.c:		newtp->retrans_stamp = div_u64(treq->snt_synack,
net/ipv4/tcp_minisocks.c:	newtp->tsoffset = treq->ts_off;
net/ipv4/tcp_minisocks.c:	newtp->rx_opt.mss_clamp = req->mss;
net/ipv4/tcp_minisocks.c:			tmp_opt.ts_recent = req->ts_recent;
net/ipv4/tcp_minisocks.c:			tmp_opt.ts_recent_stamp = ktime_get_seconds() - ((TCP_TIMEOUT_INIT/HZ)<<req->num_timeout);
net/ipv4/tcp_minisocks.c:			expires += min(TCP_TIMEOUT_INIT << req->num_timeout,
net/ipv4/tcp_minisocks.c:				mod_timer_pending(&req->rsk_timer, expires);
net/ipv4/tcp_minisocks.c:				req->rsk_timer.expires = expires;
net/ipv4/tcp_minisocks.c:					  tcp_rsk(req)->rcv_nxt, tcp_rsk(req)->rcv_nxt + req->rsk_rcv_wnd)) {
net/ipv4/tcp_minisocks.c:			req->rsk_ops->send_ack(sk, skb, req);
net/ipv4/tcp_minisocks.c:		req->ts_recent = tmp_opt.rcv_tsval;
net/ipv4/tcp_minisocks.c:	if (req->num_timeout < inet_csk(sk)->icsk_accept_queue.rskq_defer_accept &&
net/ipv4/tcp_minisocks.c:		req->rsk_ops->send_reset(sk, skb);
net/ipv4/syncookies.c:	options = ireq->wscale_ok ? ireq->snd_wscale : TS_OPT_WSCALE_MASK;
net/ipv4/syncookies.c:	if (ireq->sack_ok)
net/ipv4/syncookies.c:	if (ireq->ecn_ok)
net/ipv4/syncookies.c:		refcount_set(&req->rsk_refcnt, 1);
net/ipv4/syncookies.c:	treq->syn_tos = TCP_SKB_CB(skb)->ip_dsfield;
net/ipv4/syncookies.c:	treq->is_mptcp = sk_is_mptcp(sk);
net/ipv4/syncookies.c:	if (treq->is_mptcp) {
net/ipv4/syncookies.c:	treq->rcv_isn		= ntohl(th->seq) - 1;
net/ipv4/syncookies.c:	treq->snt_isn		= cookie;
net/ipv4/syncookies.c:	treq->ts_off		= 0;
net/ipv4/syncookies.c:	treq->txhash		= net_tx_rndhash();
net/ipv4/syncookies.c:	req->mss		= mss;
net/ipv4/syncookies.c:	ireq->ir_num		= ntohs(th->dest);
net/ipv4/syncookies.c:	ireq->ir_rmt_port	= th->source;
net/ipv4/syncookies.c:	ireq->ir_mark		= inet_request_mark(sk, skb);
net/ipv4/syncookies.c:	ireq->snd_wscale	= tcp_opt.snd_wscale;
net/ipv4/syncookies.c:	ireq->sack_ok		= tcp_opt.sack_ok;
net/ipv4/syncookies.c:	ireq->wscale_ok		= tcp_opt.wscale_ok;
net/ipv4/syncookies.c:	ireq->tstamp_ok		= tcp_opt.saw_tstamp;
net/ipv4/syncookies.c:	req->ts_recent		= tcp_opt.saw_tstamp ? tcp_opt.rcv_tsval : 0;
net/ipv4/syncookies.c:	treq->snt_synack	= 0;
net/ipv4/syncookies.c:	treq->tfo_listener	= false;
net/ipv4/syncookies.c:		ireq->smc_ok = 0;
net/ipv4/syncookies.c:	ireq->ir_iif = inet_request_bound_dev_if(sk, skb);
net/ipv4/syncookies.c:	RCU_INIT_POINTER(ireq->ireq_opt, tcp_v4_save_options(sock_net(sk), skb));
net/ipv4/syncookies.c:	req->num_retrans = 0;
net/ipv4/syncookies.c:	flowi4_init_output(&fl4, ireq->ir_iif, ireq->ir_mark,
net/ipv4/syncookies.c:			   opt->srr ? opt->faddr : ireq->ir_rmt_addr,
net/ipv4/syncookies.c:			   ireq->ir_loc_addr, th->source, th->dest, sk->sk_uid);
net/ipv4/syncookies.c:	req->rsk_window_clamp = tp->window_clamp ? :dst_metric(&rt->dst, RTAX_WINDOW);
net/ipv4/syncookies.c:	    (req->rsk_window_clamp > full_space || req->rsk_window_clamp == 0))
net/ipv4/syncookies.c:		req->rsk_window_clamp = full_space;
net/ipv4/syncookies.c:	tcp_select_initial_window(sk, full_space, req->mss,
net/ipv4/syncookies.c:				  &req->rsk_rcv_wnd, &req->rsk_window_clamp,
net/ipv4/syncookies.c:				  ireq->wscale_ok, &rcv_wscale,
net/ipv4/syncookies.c:	ireq->rcv_wscale  = rcv_wscale;
net/ipv4/syncookies.c:	ireq->ecn_ok = cookie_ecn_ok(&tcp_opt, sock_net(sk), &rt->dst);
net/ipv4/inet_diag.c:	handler = inet_diag_table[req->sdiag_protocol];
net/ipv4/inet_diag.c:	return req->sdiag_protocol;
net/ipv4/inet_diag.c:	int ext = req->idiag_ext;
net/ipv4/inet_diag.c:	if (req->sdiag_family == AF_INET)
net/ipv4/inet_diag.c:		sk = inet_lookup(net, hashinfo, NULL, 0, req->id.idiag_dst[0],
net/ipv4/inet_diag.c:				 req->id.idiag_dport, req->id.idiag_src[0],
net/ipv4/inet_diag.c:				 req->id.idiag_sport, req->id.idiag_if);
net/ipv4/inet_diag.c:	else if (req->sdiag_family == AF_INET6) {
net/ipv4/inet_diag.c:		if (ipv6_addr_v4mapped((struct in6_addr *)req->id.idiag_dst) &&
net/ipv4/inet_diag.c:		    ipv6_addr_v4mapped((struct in6_addr *)req->id.idiag_src))
net/ipv4/inet_diag.c:			sk = inet_lookup(net, hashinfo, NULL, 0, req->id.idiag_dst[3],
net/ipv4/inet_diag.c:					 req->id.idiag_dport, req->id.idiag_src[3],
net/ipv4/inet_diag.c:					 req->id.idiag_sport, req->id.idiag_if);
net/ipv4/inet_diag.c:					  (struct in6_addr *)req->id.idiag_dst,
net/ipv4/inet_diag.c:					  req->id.idiag_dport,
net/ipv4/inet_diag.c:					  (struct in6_addr *)req->id.idiag_src,
net/ipv4/inet_diag.c:					  req->id.idiag_sport,
net/ipv4/inet_diag.c:					  req->id.idiag_if);
net/ipv4/inet_diag.c:	if (sock_diag_check_cookie(sk, req->id.idiag_cookie)) {
net/ipv4/inet_connection_sock.c:	newsk = req->sk;
net/ipv4/inet_connection_sock.c:			 * so can't free req now. Instead, we set req->sk to
net/ipv4/inet_connection_sock.c:			req->sk = NULL;
net/ipv4/inet_connection_sock.c:	struct net *net = read_pnet(&ireq->ireq_net);
net/ipv4/inet_connection_sock.c:	opt = rcu_dereference(ireq->ireq_opt);
net/ipv4/inet_connection_sock.c:	flowi4_init_output(fl4, ireq->ir_iif, ireq->ir_mark,
net/ipv4/inet_connection_sock.c:			   (opt && opt->opt.srr) ? opt->opt.faddr : ireq->ir_rmt_addr,
net/ipv4/inet_connection_sock.c:			   ireq->ir_loc_addr, ireq->ir_rmt_port,
net/ipv4/inet_connection_sock.c:			   htons(ireq->ir_num), sk->sk_uid);
net/ipv4/inet_connection_sock.c:	struct net *net = read_pnet(&ireq->ireq_net);
net/ipv4/inet_connection_sock.c:	opt = rcu_dereference(ireq->ireq_opt);
net/ipv4/inet_connection_sock.c:	flowi4_init_output(fl4, ireq->ir_iif, ireq->ir_mark,
net/ipv4/inet_connection_sock.c:			   (opt && opt->opt.srr) ? opt->opt.faddr : ireq->ir_rmt_addr,
net/ipv4/inet_connection_sock.c:			   ireq->ir_loc_addr, ireq->ir_rmt_port,
net/ipv4/inet_connection_sock.c:			   htons(ireq->ir_num), sk->sk_uid);
net/ipv4/inet_connection_sock.c:		*expire = req->num_timeout >= max_syn_ack_retries;
net/ipv4/inet_connection_sock.c:	*expire = req->num_timeout >= max_syn_ack_retries &&
net/ipv4/inet_connection_sock.c:		  (!inet_rsk(req)->acked || req->num_timeout >= rskq_defer_accept);
net/ipv4/inet_connection_sock.c:		  req->num_timeout >= rskq_defer_accept - 1;
net/ipv4/inet_connection_sock.c:	int err = req->rsk_ops->rtx_syn_ack(parent, req);
net/ipv4/inet_connection_sock.c:		req->num_retrans++;
net/ipv4/inet_connection_sock.c:		spinlock_t *lock = inet_ehash_lockp(hashinfo, req->rsk_hash);
net/ipv4/inet_connection_sock.c:	if (timer_pending(&req->rsk_timer) && del_timer_sync(&req->rsk_timer))
net/ipv4/inet_connection_sock.c:	struct sock *sk_listener = req->rsk_listener;
net/ipv4/inet_connection_sock.c:	req->rsk_ops->syn_ack_timeout(req);
net/ipv4/inet_connection_sock.c:		if (req->num_timeout++ == 0)
net/ipv4/inet_connection_sock.c:		timeo = min(TCP_TIMEOUT_INIT << req->num_timeout, TCP_RTO_MAX);
net/ipv4/inet_connection_sock.c:		mod_timer(&req->rsk_timer, jiffies + timeo);
net/ipv4/inet_connection_sock.c:	timer_setup(&req->rsk_timer, reqsk_timer_handler, TIMER_PINNED);
net/ipv4/inet_connection_sock.c:	mod_timer(&req->rsk_timer, jiffies + timeout);
net/ipv4/inet_connection_sock.c:	refcount_set(&req->rsk_refcnt, 2 + 1);
net/ipv4/inet_connection_sock.c:		BUG_ON(sk != req->rsk_listener);
net/ipv4/inet_connection_sock.c:		req->sk = child;
net/ipv4/inet_connection_sock.c:		req->dl_next = NULL;
net/ipv4/inet_connection_sock.c:		struct sock *child = req->sk;
net/ipv4/inet_connection_sock.c:			next = req->dl_next;
net/ipv4/tcp_timer.c:	req->rsk_ops->syn_ack_timeout(req);
net/ipv4/tcp_timer.c:	if (req->num_timeout >= max_retries) {
net/ipv4/tcp_timer.c:	req->num_timeout++;
net/ipv4/tcp_timer.c:			  TCP_TIMEOUT_INIT << req->num_timeout, TCP_RTO_MAX);
net/ipv4/tcp_fastopen.c:	if (req->rsk_ops->family == AF_INET) {
net/ipv4/tcp_fastopen.c:	if (req->rsk_ops->family == AF_INET6) {
net/ipv4/tcp_fastopen.c:	refcount_set(&req->rsk_refcnt, 2);
net/ipv4/tcp_fastopen.c:			tp->fastopen_req->cookie = cookie;
net/ipv4/tcp_output.c:		if (tp->syn_smc && ireq->smc_ok) {
net/ipv4/tcp_output.c:			ireq->tstamp_ok &= !ireq->sack_ok;
net/ipv4/tcp_output.c:	if (likely(ireq->wscale_ok)) {
net/ipv4/tcp_output.c:		opts->ws = ireq->rcv_wscale;
net/ipv4/tcp_output.c:	if (likely(ireq->tstamp_ok)) {
net/ipv4/tcp_output.c:		opts->tsecr = req->ts_recent;
net/ipv4/tcp_output.c:	if (likely(ireq->sack_ok)) {
net/ipv4/tcp_output.c:		if (unlikely(!ireq->tstamp_ok))
net/ipv4/tcp_output.c:	if (unlikely(synack_type == TCP_SYNACK_COOKIE && ireq->tstamp_ok))
net/ipv4/tcp_output.c:	th->source = htons(ireq->ir_num);
net/ipv4/tcp_output.c:	th->dest = ireq->ir_rmt_port;
net/ipv4/tcp_output.c:	skb->mark = ireq->ir_mark;
net/ipv4/tcp_output.c:	th->window = htons(min(req->rsk_rcv_wnd, 65535U));
net/ipv4/tcp_metrics.c:	saddr.family = req->rsk_ops->family;
net/ipv4/tcp_metrics.c:	daddr.family = req->rsk_ops->family;
net/ipv4/tcp_ipv4.c:		inet_csk_reqsk_queue_drop(req->rsk_listener, req);
net/ipv4/tcp_ipv4.c:		tcp_listendrop(req->rsk_listener);
net/ipv4/tcp_ipv4.c:			req->rsk_rcv_wnd >> inet_rsk(req)->rcv_wscale,
net/ipv4/tcp_ipv4.c:			req->ts_recent,
net/ipv4/tcp_ipv4.c:		__tcp_v4_send_check(skb, ireq->ir_loc_addr, ireq->ir_rmt_addr);
net/ipv4/tcp_ipv4.c:		err = ip_build_and_send_pkt(skb, sk, ireq->ir_loc_addr,
net/ipv4/tcp_ipv4.c:					    ireq->ir_rmt_addr,
net/ipv4/tcp_ipv4.c:					    rcu_dereference(ireq->ireq_opt),
net/ipv4/tcp_ipv4.c:	RCU_INIT_POINTER(ireq->ireq_opt, tcp_v4_save_options(net, skb));
net/ipv4/tcp_ipv4.c:	sk_daddr_set(newsk, ireq->ir_rmt_addr);
net/ipv4/tcp_ipv4.c:	sk_rcv_saddr_set(newsk, ireq->ir_loc_addr);
net/ipv4/tcp_ipv4.c:	newsk->sk_bound_dev_if = ireq->ir_iif;
net/ipv4/tcp_ipv4.c:	newinet->inet_saddr   = ireq->ir_loc_addr;
net/ipv4/tcp_ipv4.c:	inet_opt	      = rcu_dereference(ireq->ireq_opt);
net/ipv4/tcp_ipv4.c:	l3index = l3mdev_master_ifindex_by_index(sock_net(sk), ireq->ir_iif);
net/ipv4/tcp_ipv4.c:		ireq->ireq_opt = NULL;
net/ipv4/tcp_ipv4.c:		sk = req->rsk_listener;
net/ipv4/tcp_ipv4.c:	long delta = req->rsk_timer.expires - jiffies;
net/ipv4/tcp_ipv4.c:		ireq->ir_loc_addr,
net/ipv4/tcp_ipv4.c:		ireq->ir_num,
net/ipv4/tcp_ipv4.c:		ireq->ir_rmt_addr,
net/ipv4/tcp_ipv4.c:		ntohs(ireq->ir_rmt_port),
net/ipv4/tcp_ipv4.c:		req->num_timeout,
net/ipv4/tcp_ipv4.c:				 sock_i_uid(req->rsk_listener)),
net/ipv4/tcp_ipv4.c:				       sock_i_uid(req->rsk_listener));
net/ipv4/udp_diag.c:	if (req->sdiag_family == AF_INET)
net/ipv4/udp_diag.c:				req->id.idiag_src[0], req->id.idiag_sport,
net/ipv4/udp_diag.c:				req->id.idiag_dst[0], req->id.idiag_dport,
net/ipv4/udp_diag.c:				req->id.idiag_if, 0, tbl, NULL);
net/ipv4/udp_diag.c:	else if (req->sdiag_family == AF_INET6)
net/ipv4/udp_diag.c:				(struct in6_addr *)req->id.idiag_src,
net/ipv4/udp_diag.c:				req->id.idiag_sport,
net/ipv4/udp_diag.c:				(struct in6_addr *)req->id.idiag_dst,
net/ipv4/udp_diag.c:				req->id.idiag_dport,
net/ipv4/udp_diag.c:				req->id.idiag_if, 0, tbl, NULL);
net/ipv4/udp_diag.c:	err = sock_diag_check_cookie(sk, req->id.idiag_cookie);
net/ipv4/udp_diag.c:	if (req->sdiag_family == AF_INET)
net/ipv4/udp_diag.c:				req->id.idiag_dst[0], req->id.idiag_dport,
net/ipv4/udp_diag.c:				req->id.idiag_src[0], req->id.idiag_sport,
net/ipv4/udp_diag.c:				req->id.idiag_if, 0, tbl, NULL);
net/ipv4/udp_diag.c:	else if (req->sdiag_family == AF_INET6) {
net/ipv4/udp_diag.c:		if (ipv6_addr_v4mapped((struct in6_addr *)req->id.idiag_dst) &&
net/ipv4/udp_diag.c:		    ipv6_addr_v4mapped((struct in6_addr *)req->id.idiag_src))
net/ipv4/udp_diag.c:					req->id.idiag_dst[3], req->id.idiag_dport,
net/ipv4/udp_diag.c:					req->id.idiag_src[3], req->id.idiag_sport,
net/ipv4/udp_diag.c:					req->id.idiag_if, 0, tbl, NULL);
net/ipv4/udp_diag.c:					(struct in6_addr *)req->id.idiag_dst,
net/ipv4/udp_diag.c:					req->id.idiag_dport,
net/ipv4/udp_diag.c:					(struct in6_addr *)req->id.idiag_src,
net/ipv4/udp_diag.c:					req->id.idiag_sport,
net/ipv4/udp_diag.c:					req->id.idiag_if, 0, tbl, NULL);
net/ipv4/udp_diag.c:	if (sock_diag_check_cookie(sk, req->id.idiag_cookie)) {
net/core/devlink.c:	return nla_put_string(req->msg, DEVLINK_ATTR_INFO_DRIVER_NAME, name);
net/core/devlink.c:	return nla_put_string(req->msg, DEVLINK_ATTR_INFO_SERIAL_NUMBER, sn);
net/core/devlink.c:	return nla_put_string(req->msg, DEVLINK_ATTR_INFO_BOARD_SERIAL_NUMBER,
net/core/devlink.c:	nest = nla_nest_start_noflag(req->msg, attr);
net/core/devlink.c:	err = nla_put_string(req->msg, DEVLINK_ATTR_INFO_VERSION_NAME,
net/core/devlink.c:	err = nla_put_string(req->msg, DEVLINK_ATTR_INFO_VERSION_VALUE,
net/core/devlink.c:	nla_nest_end(req->msg, nest);
net/core/devlink.c:	nla_nest_cancel(req->msg, nest);
net/core/request_sock.c: * When a child socket is accepted, its corresponding req->sk is set to
net/core/request_sock.c: * NULL since it's no longer needed. More importantly, "req->sk == NULL"
net/core/request_sock.c: * This function also sets "treq->tfo_listener" to false.
net/core/request_sock.c: * treq->tfo_listener is used by the listener so it is protected by the
net/core/request_sock.c:	struct sock *lsk = req->rsk_listener;
net/core/request_sock.c:	if (req->sk)	/* the child socket hasn't been accepted yet */
net/core/request_sock.c:	req->rsk_timer.expires = jiffies + 60*HZ;
net/core/request_sock.c:	req->dl_next = NULL;
net/core/sock_diag.c:	if (req->sdiag_family >= AF_MAX)
net/core/sock_diag.c:	req->sdiag_family = array_index_nospec(req->sdiag_family, AF_MAX);
net/core/sock_diag.c:	if (sock_diag_handlers[req->sdiag_family] == NULL)
net/core/sock_diag.c:		sock_load_diag_module(req->sdiag_family, 0);
net/core/sock_diag.c:	hndl = sock_diag_handlers[req->sdiag_family];
net/sunrpc/svcsock.c:	memcpy(&req->rq_private_buf, &req->rq_rcv_buf, sizeof(struct xdr_buf));
net/sunrpc/svcsock.c:	dst = &req->rq_private_buf.head[0];
net/sunrpc/svcsock.c:	xprt_complete_rqst(req->rq_task, rqstp->rq_arg.len);
net/sunrpc/clnt.c:	hdrsize += RPC_REPHDRSIZE + req->rq_cred->cr_auth->au_ralign;
net/sunrpc/clnt.c:	xdr_inline_pages(&req->rq_rcv_buf, hdrsize << 2, pages, base, len);
net/sunrpc/clnt.c:	trace_rpc_xdr_reply_pages(req->rq_task, &req->rq_rcv_buf);
net/sunrpc/clnt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/clnt.c:	if (req->rq_buffer)
net/sunrpc/clnt.c:	req->rq_callsize = RPC_CALLHDRSIZE + (auth->au_cslack << 1) +
net/sunrpc/clnt.c:	req->rq_callsize <<= 2;
net/sunrpc/clnt.c:	req->rq_rcvsize = RPC_REPHDRSIZE + auth->au_rslack + \
net/sunrpc/clnt.c:	req->rq_rcvsize <<= 2;
net/sunrpc/clnt.c:	xdr_buf_init(&req->rq_snd_buf,
net/sunrpc/clnt.c:		     req->rq_buffer,
net/sunrpc/clnt.c:		     req->rq_callsize);
net/sunrpc/clnt.c:	xdr_buf_init(&req->rq_rcv_buf,
net/sunrpc/clnt.c:		     req->rq_rbuffer,
net/sunrpc/clnt.c:		     req->rq_rcvsize);
net/sunrpc/clnt.c:	req->rq_reply_bytes_recvd = 0;
net/sunrpc/clnt.c:	req->rq_snd_buf.head[0].iov_len = 0;
net/sunrpc/clnt.c:	xdr_init_encode(&xdr, &req->rq_snd_buf,
net/sunrpc/clnt.c:			req->rq_snd_buf.head[0].iov_base, req);
net/sunrpc/clnt.c:	xdr_free_bvec(&req->rq_snd_buf);
net/sunrpc/clnt.c:		xprt_conditional_disconnect(req->rq_xprt,
net/sunrpc/clnt.c:			req->rq_connect_cookie);
net/sunrpc/clnt.c:	if (!req || !req->rq_xprt)
net/sunrpc/clnt.c:	return xprt_connected(req->rq_xprt);
net/sunrpc/clnt.c:	 * before it changed req->rq_reply_bytes_recvd.
net/sunrpc/clnt.c:	if (!req->rq_reply_bytes_recvd)
net/sunrpc/clnt.c:	req->rq_rcv_buf.len = req->rq_private_buf.len;
net/sunrpc/clnt.c:	trace_rpc_xdr_recvfrom(task, &req->rq_rcv_buf);
net/sunrpc/clnt.c:	WARN_ON(memcmp(&req->rq_rcv_buf, &req->rq_private_buf,
net/sunrpc/clnt.c:				sizeof(req->rq_rcv_buf)) != 0);
net/sunrpc/clnt.c:	xdr_init_decode(&xdr, &req->rq_rcv_buf,
net/sunrpc/clnt.c:			req->rq_rcv_buf.head[0].iov_base, req);
net/sunrpc/clnt.c:			xprt_conditional_disconnect(req->rq_xprt,
net/sunrpc/clnt.c:						    req->rq_connect_cookie);
net/sunrpc/clnt.c:	*p++ = req->rq_xid;
net/sunrpc/auth_gss/auth_gss.c:	struct rpc_cred *cred = req->rq_cred;
net/sunrpc/auth_gss/auth_gss.c:	req->rq_seqno = (ctx->gc_seq < MAXSEQ) ? ctx->gc_seq++ : MAXSEQ;
net/sunrpc/auth_gss/auth_gss.c:	if (req->rq_seqno == MAXSEQ)
net/sunrpc/auth_gss/auth_gss.c:	*p++ = cpu_to_be32(req->rq_seqno);
net/sunrpc/auth_gss/auth_gss.c:	iov.iov_base = req->rq_snd_buf.head[0].iov_base;
net/sunrpc/auth_gss/auth_gss.c:	struct rpc_cred *cred = req->rq_cred;
net/sunrpc/auth_gss/auth_gss.c:	if (gss_seq_is_newer(req->rq_seqno, READ_ONCE(ctx->gc_seq)))
net/sunrpc/auth_gss/auth_gss.c:	while (gss_seq_is_newer(req->rq_seqno, seq_xmit)) {
net/sunrpc/auth_gss/auth_gss.c:		seq_xmit = cmpxchg(&ctx->gc_seq_xmit, tmp, req->rq_seqno);
net/sunrpc/auth_gss/auth_gss.c:		ret = !gss_seq_is_newer(req->rq_seqno, seq_xmit - win);
net/sunrpc/auth_gss/gss_rpc_xdr.c:	xdr_inline_pages(&req->rq_rcv_buf,
net/sunrpc/backchannel_rqst.c:	WARN_ON_ONCE(test_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state));
net/sunrpc/backchannel_rqst.c:	xbufp = &req->rq_rcv_buf;
net/sunrpc/backchannel_rqst.c:	xbufp = &req->rq_snd_buf;
net/sunrpc/backchannel_rqst.c:	req->rq_xprt = xprt;
net/sunrpc/backchannel_rqst.c:	INIT_LIST_HEAD(&req->rq_bc_list);
net/sunrpc/backchannel_rqst.c:	if (xprt_alloc_xdr_buf(&req->rq_rcv_buf, gfp_flags) < 0) {
net/sunrpc/backchannel_rqst.c:	req->rq_rcv_buf.len = PAGE_SIZE;
net/sunrpc/backchannel_rqst.c:	if (xprt_alloc_xdr_buf(&req->rq_snd_buf, gfp_flags) < 0) {
net/sunrpc/backchannel_rqst.c:		list_add(&req->rq_bc_pa_list, &tmp_list);
net/sunrpc/backchannel_rqst.c:		list_del(&req->rq_bc_pa_list);
net/sunrpc/backchannel_rqst.c:		list_del(&req->rq_bc_pa_list);
net/sunrpc/backchannel_rqst.c:	req->rq_reply_bytes_recvd = 0;
net/sunrpc/backchannel_rqst.c:	memcpy(&req->rq_private_buf, &req->rq_rcv_buf,
net/sunrpc/backchannel_rqst.c:			sizeof(req->rq_private_buf));
net/sunrpc/backchannel_rqst.c:	req->rq_xid = xid;
net/sunrpc/backchannel_rqst.c:	req->rq_connect_cookie = xprt->connect_cookie;
net/sunrpc/backchannel_rqst.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/backchannel_rqst.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/backchannel_rqst.c:	req->rq_connect_cookie = xprt->connect_cookie - 1;
net/sunrpc/backchannel_rqst.c:	clear_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state);
net/sunrpc/backchannel_rqst.c:		list_add_tail(&req->rq_bc_pa_list, &xprt->bc_pa_list);
net/sunrpc/backchannel_rqst.c:			if (req->rq_connect_cookie != xprt->connect_cookie)
net/sunrpc/backchannel_rqst.c:			if (req->rq_xid == xid)
net/sunrpc/backchannel_rqst.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/backchannel_rqst.c:	list_del(&req->rq_bc_pa_list);
net/sunrpc/backchannel_rqst.c:	req->rq_private_buf.len = copied;
net/sunrpc/backchannel_rqst.c:	set_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state);
net/sunrpc/backchannel_rqst.c:	list_add(&req->rq_bc_list, &bc_serv->sv_cb_list);
net/sunrpc/svc.c:	rqstp->rq_xid = req->rq_xid;
net/sunrpc/svc.c:	rqstp->rq_prot = req->rq_xprt->prot;
net/sunrpc/svc.c:	rqstp->rq_bc_net = req->rq_xprt->xprt_net;
net/sunrpc/svc.c:	rqstp->rq_addrlen = sizeof(req->rq_xprt->addr);
net/sunrpc/svc.c:	memcpy(&rqstp->rq_addr, &req->rq_xprt->addr, rqstp->rq_addrlen);
net/sunrpc/svc.c:	memcpy(&rqstp->rq_arg, &req->rq_rcv_buf, sizeof(rqstp->rq_arg));
net/sunrpc/svc.c:	memcpy(&rqstp->rq_res, &req->rq_snd_buf, sizeof(rqstp->rq_res));
net/sunrpc/svc.c:	rqstp->rq_arg.len = req->rq_private_buf.len;
net/sunrpc/svc.c:	atomic_dec(&req->rq_xprt->bc_slot_count);
net/sunrpc/svc.c:	memcpy(&req->rq_snd_buf, &rqstp->rq_res, sizeof(req->rq_snd_buf));
net/sunrpc/auth.c:	put_rpccred(req->rq_cred);
net/sunrpc/auth.c:	req->rq_cred = new;
net/sunrpc/stats.c:	op_metrics->om_ntrans += max(req->rq_ntrans, 1);
net/sunrpc/stats.c:	op_metrics->om_bytes_sent += req->rq_xmit_bytes_sent;
net/sunrpc/stats.c:	op_metrics->om_bytes_recv += req->rq_reply_bytes_recvd;
net/sunrpc/stats.c:	if (ktime_to_ns(req->rq_xtime)) {
net/sunrpc/stats.c:		backlog = ktime_sub(req->rq_xtime, task->tk_start);
net/sunrpc/stats.c:	op_metrics->om_rtt = ktime_add(op_metrics->om_rtt, req->rq_rtt);
net/sunrpc/stats.c:	trace_rpc_stats_latency(req->rq_task, backlog, req->rq_rtt, execute);
net/sunrpc/xprtrdma/backchannel.c:	rpcrdma_set_xdrlen(&req->rl_hdrbuf, 0);
net/sunrpc/xprtrdma/backchannel.c:	xdr_init_encode(&req->rl_stream, &req->rl_hdrbuf,
net/sunrpc/xprtrdma/backchannel.c:			rdmab_data(req->rl_rdmabuf), rqst);
net/sunrpc/xprtrdma/backchannel.c:	p = xdr_reserve_space(&req->rl_stream, 28);
net/sunrpc/xprtrdma/backchannel.c:	rpcrdma_recv_buffer_put(req->rl_reply);
net/sunrpc/xprtrdma/backchannel.c:	req->rl_reply = NULL;
net/sunrpc/xprtrdma/backchannel.c:	rqst = &req->rl_slot;
net/sunrpc/xprtrdma/backchannel.c:	xdr_buf_init(&rqst->rq_snd_buf, rdmab_data(req->rl_sendbuf), size);
net/sunrpc/xprtrdma/backchannel.c:	req->rl_reply = rep;
net/sunrpc/xprtrdma/transport.c:	task->tk_rqstp = &req->rl_slot;
net/sunrpc/xprtrdma/transport.c:	if (!rpcrdma_check_regbuf(r_xprt, req->rl_sendbuf, rqst->rq_callsize,
net/sunrpc/xprtrdma/transport.c:	if (!rpcrdma_check_regbuf(r_xprt, req->rl_recvbuf, rqst->rq_rcvsize,
net/sunrpc/xprtrdma/transport.c:	rqst->rq_buffer = rdmab_data(req->rl_sendbuf);
net/sunrpc/xprtrdma/transport.c:	rqst->rq_rbuffer = rdmab_data(req->rl_recvbuf);
net/sunrpc/xprtrdma/transport.c:	if (unlikely(!list_empty(&req->rl_registered))) {
net/sunrpc/xprtrdma/svc_rdma_backchannel.c:	dst = &req->rq_private_buf.head[0];
net/sunrpc/xprtrdma/svc_rdma_backchannel.c:	memcpy(&req->rq_private_buf, &req->rq_rcv_buf, sizeof(struct xdr_buf));
net/sunrpc/xprtrdma/svc_rdma_backchannel.c:	xprt_complete_rqst(req->rq_task, rcvbuf->len);
net/sunrpc/xprtrdma/frwr_ops.c:	rpcrdma_mr_push(mr, &mr->mr_req->rl_free_mrs);
net/sunrpc/xprtrdma/frwr_ops.c:	while ((mr = rpcrdma_mr_pop(&req->rl_registered)))
net/sunrpc/xprtrdma/frwr_ops.c:	post_wr = &req->rl_wr;
net/sunrpc/xprtrdma/frwr_ops.c:	list_for_each_entry(mr, &req->rl_registered, mr_list) {
net/sunrpc/xprtrdma/frwr_ops.c:	while ((mr = rpcrdma_mr_pop(&req->rl_registered))) {
net/sunrpc/xprtrdma/frwr_ops.c:	struct rpcrdma_rep *rep = mr->mr_req->rl_reply;
net/sunrpc/xprtrdma/frwr_ops.c:	while ((mr = rpcrdma_mr_pop(&req->rl_registered))) {
net/sunrpc/xprtrdma/frwr_ops.c:	rpcrdma_complete_rqst(req->rl_reply);
net/sunrpc/xprtrdma/verbs.c:	req->rl_sendbuf = rpcrdma_regbuf_alloc(size, DMA_TO_DEVICE, flags);
net/sunrpc/xprtrdma/verbs.c:	if (!req->rl_sendbuf)
net/sunrpc/xprtrdma/verbs.c:	req->rl_recvbuf = rpcrdma_regbuf_alloc(size, DMA_NONE, flags);
net/sunrpc/xprtrdma/verbs.c:	if (!req->rl_recvbuf)
net/sunrpc/xprtrdma/verbs.c:	INIT_LIST_HEAD(&req->rl_free_mrs);
net/sunrpc/xprtrdma/verbs.c:	INIT_LIST_HEAD(&req->rl_registered);
net/sunrpc/xprtrdma/verbs.c:	list_add(&req->rl_all, &buffer->rb_allreqs);
net/sunrpc/xprtrdma/verbs.c:	kfree(req->rl_sendbuf);
net/sunrpc/xprtrdma/verbs.c:	req->rl_rdmabuf = rb;
net/sunrpc/xprtrdma/verbs.c:	xdr_buf_init(&req->rl_hdrbuf, rdmab_data(rb), rdmab_length(rb));
net/sunrpc/xprtrdma/verbs.c:	req->rl_slot.rq_cong = 0;
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_free(req->rl_rdmabuf);
net/sunrpc/xprtrdma/verbs.c:	req->rl_rdmabuf = NULL;
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_dma_unmap(req->rl_sendbuf);
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_dma_unmap(req->rl_recvbuf);
net/sunrpc/xprtrdma/verbs.c:		list_add(&req->rl_list, &buf->rb_send_bufs);
net/sunrpc/xprtrdma/verbs.c: * removing req->rl_all from buf->rb_all_reqs safely.
net/sunrpc/xprtrdma/verbs.c:	list_del(&req->rl_all);
net/sunrpc/xprtrdma/verbs.c:	while ((mr = rpcrdma_mr_pop(&req->rl_free_mrs))) {
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_free(req->rl_recvbuf);
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_free(req->rl_sendbuf);
net/sunrpc/xprtrdma/verbs.c:	rpcrdma_regbuf_free(req->rl_rdmabuf);
net/sunrpc/xprtrdma/verbs.c: * removing mr->mr_list from req->rl_free_mrs safely.
net/sunrpc/xprtrdma/verbs.c:		list_del(&req->rl_list);
net/sunrpc/xprtrdma/verbs.c:		list_del_init(&req->rl_list);
net/sunrpc/xprtrdma/verbs.c:	if (req->rl_reply)
net/sunrpc/xprtrdma/verbs.c:		rpcrdma_rep_put(buffers, req->rl_reply);
net/sunrpc/xprtrdma/verbs.c:	req->rl_reply = NULL;
net/sunrpc/xprtrdma/verbs.c:	list_add(&req->rl_list, &buffers->rb_send_bufs);
net/sunrpc/xprtrdma/verbs.c:	struct ib_send_wr *send_wr = &req->rl_wr;
net/sunrpc/xprtrdma/verbs.c:	if (!ep->re_send_count || kref_read(&req->rl_kref) > 1) {
net/sunrpc/xprtrdma/rpc_rdma.c:	*mr = rpcrdma_mr_pop(&req->rl_free_mrs);
net/sunrpc/xprtrdma/rpc_rdma.c:	rpcrdma_mr_push(*mr, &req->rl_registered);
net/sunrpc/xprtrdma/rpc_rdma.c:	return frwr_map(r_xprt, seg, nsegs, writing, req->rl_slot.rq_xid, *mr);
net/sunrpc/xprtrdma/rpc_rdma.c:	struct xdr_stream *xdr = &req->rl_stream;
net/sunrpc/xprtrdma/rpc_rdma.c:	seg = req->rl_segments;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct xdr_stream *xdr = &req->rl_stream;
net/sunrpc/xprtrdma/rpc_rdma.c:	seg = req->rl_segments;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct xdr_stream *xdr = &req->rl_stream;
net/sunrpc/xprtrdma/rpc_rdma.c:	seg = req->rl_segments;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_rep *rep = req->rl_reply;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_regbuf *rb = sc->sc_req->rl_sendbuf;
net/sunrpc/xprtrdma/rpc_rdma.c:	kref_put(&sc->sc_req->rl_kref, rpcrdma_sendctx_done);
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_sendctx *sc = req->rl_sendctx;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_regbuf *rb = req->rl_rdmabuf;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct ib_sge *sge = &sc->sc_sges[req->rl_wr.num_sge++];
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_sendctx *sc = req->rl_sendctx;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct ib_sge *sge = &sc->sc_sges[req->rl_wr.num_sge++];
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_regbuf *rb = req->rl_sendbuf;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_sendctx *sc = req->rl_sendctx;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_regbuf *rb = req->rl_sendbuf;
net/sunrpc/xprtrdma/rpc_rdma.c:		sge = &sc->sc_sges[req->rl_wr.num_sge++];
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_sendctx *sc = req->rl_sendctx;
net/sunrpc/xprtrdma/rpc_rdma.c:	struct ib_sge *sge = &sc->sc_sges[req->rl_wr.num_sge++];
net/sunrpc/xprtrdma/rpc_rdma.c:	struct rpcrdma_regbuf *rb = req->rl_sendbuf;
net/sunrpc/xprtrdma/rpc_rdma.c:	if (req->rl_sendctx->sc_unmap_count)
net/sunrpc/xprtrdma/rpc_rdma.c:		kref_get(&req->rl_kref);
net/sunrpc/xprtrdma/rpc_rdma.c:		kref_get(&req->rl_kref);
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_sendctx = rpcrdma_sendctx_get_locked(r_xprt);
net/sunrpc/xprtrdma/rpc_rdma.c:	if (!req->rl_sendctx)
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_sendctx->sc_unmap_count = 0;
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_sendctx->sc_req = req;
net/sunrpc/xprtrdma/rpc_rdma.c:	kref_init(&req->rl_kref);
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_wr.wr_cqe = &req->rl_sendctx->sc_cqe;
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_wr.sg_list = req->rl_sendctx->sc_sges;
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_wr.num_sge = 0;
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_wr.opcode = IB_WR_SEND;
net/sunrpc/xprtrdma/rpc_rdma.c:	rpcrdma_sendctx_unmap(req->rl_sendctx);
net/sunrpc/xprtrdma/rpc_rdma.c:	trace_xprtrdma_prepsend_failed(&req->rl_slot, ret);
net/sunrpc/xprtrdma/rpc_rdma.c:	struct xdr_stream *xdr = &req->rl_stream;
net/sunrpc/xprtrdma/rpc_rdma.c:	rpcrdma_set_xdrlen(&req->rl_hdrbuf, 0);
net/sunrpc/xprtrdma/rpc_rdma.c:	xdr_init_encode(xdr, &req->rl_hdrbuf, rdmab_data(req->rl_rdmabuf),
net/sunrpc/xprtrdma/rpc_rdma.c:		rtype = buf->len < rdmab_length(req->rl_sendbuf) ?
net/sunrpc/xprtrdma/rpc_rdma.c:	ret = rpcrdma_prepare_send_sges(r_xprt, req, req->rl_hdrbuf.len,
net/sunrpc/xprtrdma/rpc_rdma.c:	rpcrdma_complete_rqst(req->rl_reply);
net/sunrpc/xprtrdma/rpc_rdma.c:	if (unlikely(req->rl_reply))
net/sunrpc/xprtrdma/rpc_rdma.c:		rpcrdma_recv_buffer_put(req->rl_reply);
net/sunrpc/xprtrdma/rpc_rdma.c:	req->rl_reply = rep;
net/sunrpc/xprtrdma/rpc_rdma.c:		frwr_reminv(rep, &req->rl_registered);
net/sunrpc/xprtrdma/rpc_rdma.c:	if (!list_empty(&req->rl_registered))
net/sunrpc/xprtrdma/rpc_rdma.c:		kref_put(&req->rl_kref, rpcrdma_reply_done);
net/sunrpc/rpcb_clnt.c:	if (rpc_uaddr2sockaddr(req->rq_xprt->xprt_net, (char *)p, len,
net/sunrpc/cache.c:	hlist_del_init(&dreq->hash);
net/sunrpc/cache.c:	if (!list_empty(&dreq->recent)) {
net/sunrpc/cache.c:		list_del_init(&dreq->recent);
net/sunrpc/cache.c:	INIT_LIST_HEAD(&dreq->recent);
net/sunrpc/cache.c:	hlist_add_head(&dreq->hash, &cache_defer_hash[hash]);
net/sunrpc/cache.c:	dreq->item = item;
net/sunrpc/cache.c:		list_add(&dreq->recent, &cache_defer_list);
net/sunrpc/cache.c:	dreq->revisit = cache_restart_thread;
net/sunrpc/cache.c:		    &sleeper.completion, req->thread_wait) <= 0) {
net/sunrpc/cache.c:	if (req->thread_wait) {
net/sunrpc/cache.c:	dreq = req->defer(req);
net/sunrpc/cache.c:		if (dreq->item == item) {
net/sunrpc/cache.c:			list_add(&dreq->recent, &pending);
net/sunrpc/cache.c:		list_del_init(&dreq->recent);
net/sunrpc/cache.c:		dreq->revisit(dreq, 0);
net/sunrpc/cache.c:		if (dreq->owner == owner) {
net/sunrpc/cache.c:			list_add(&dreq->recent, &pending);
net/sunrpc/cache.c:		list_del_init(&dreq->recent);
net/sunrpc/cache.c:		dreq->revisit(dreq, 1);
net/sunrpc/xprtsock.c:	struct xdr_buf *buf = &req->rq_private_buf;
net/sunrpc/xprtsock.c:	if (transport->recv.copied && !req->rq_private_buf.len)
net/sunrpc/xprtsock.c:		req->rq_private_buf.len = transport->recv.copied;
net/sunrpc/xprtsock.c:	if (!req || (transport->recv.copied && !req->rq_private_buf.len)) {
net/sunrpc/xprtsock.c:		xprt_complete_rqst(req->rq_task, transport->recv.copied);
net/sunrpc/xprtsock.c:		req->rq_private_buf.len = transport->recv.copied;
net/sunrpc/xprtsock.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprtsock.c:	xdr_free_bvec(&req->rq_rcv_buf);
net/sunrpc/xprtsock.c:	req->rq_task->tk_status = xdr_alloc_bvec(&req->rq_rcv_buf, GFP_KERNEL);
net/sunrpc/xprtsock.c:	return transport->xmit.offset != 0 && req->rq_bytes_sent == 0;
net/sunrpc/xprtsock.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprtsock.c:	struct xdr_buf *xdr = &req->rq_snd_buf;
net/sunrpc/xprtsock.c:	unsigned int msglen = rm ? req->rq_slen + sizeof(rm) : req->rq_slen;
net/sunrpc/xprtsock.c:			req->rq_svec->iov_base, req->rq_svec->iov_len);
net/sunrpc/xprtsock.c:	req->rq_xtime = ktime_get();
net/sunrpc/xprtsock.c:		req->rq_bytes_sent = transport->xmit.offset;
net/sunrpc/xprtsock.c:		if (likely(req->rq_bytes_sent >= msglen)) {
net/sunrpc/xprtsock.c:			req->rq_xmit_bytes_sent += transport->xmit.offset;
net/sunrpc/xprtsock.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprtsock.c:	struct xdr_buf *xdr = &req->rq_snd_buf;
net/sunrpc/xprtsock.c:				req->rq_svec->iov_base,
net/sunrpc/xprtsock.c:				req->rq_svec->iov_len);
net/sunrpc/xprtsock.c:	req->rq_xtime = ktime_get();
net/sunrpc/xprtsock.c:		req->rq_xmit_bytes_sent += sent;
net/sunrpc/xprtsock.c:		if (sent >= req->rq_slen)
net/sunrpc/xprtsock.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprtsock.c:	struct xdr_buf *xdr = &req->rq_snd_buf;
net/sunrpc/xprtsock.c:	unsigned int msglen = rm ? req->rq_slen + sizeof(rm) : req->rq_slen;
net/sunrpc/xprtsock.c:				req->rq_svec->iov_base,
net/sunrpc/xprtsock.c:				req->rq_svec->iov_len);
net/sunrpc/xprtsock.c:	req->rq_xtime = ktime_get();
net/sunrpc/xprtsock.c:		req->rq_bytes_sent = transport->xmit.offset;
net/sunrpc/xprtsock.c:		if (likely(req->rq_bytes_sent >= msglen)) {
net/sunrpc/xprtsock.c:			req->rq_xmit_bytes_sent += transport->xmit.offset;
net/sunrpc/xprtsock.c:	struct xdr_buf *xdr = &req->rq_snd_buf;
net/sunrpc/xprtsock.c:			container_of(req->rq_xprt, struct sock_xprt, xprt);
net/sunrpc/xprtsock.c:	req->rq_xtime = ktime_get();
net/sunrpc/xprtsock.c:	xprt = req->rq_xprt->bc_xprt;
net/sunrpc/xprt.c:	unsigned long timeout = jiffies + req->rq_timeout;
net/sunrpc/xprt.c:	if (time_before(timeout, req->rq_majortimeo))
net/sunrpc/xprt.c:	return req->rq_majortimeo;
net/sunrpc/xprt.c:	if (req->rq_cong)
net/sunrpc/xprt.c:	trace_xprt_get_cong(xprt, req->rq_task);
net/sunrpc/xprt.c:	req->rq_cong = 1;
net/sunrpc/xprt.c:	if (!req->rq_cong)
net/sunrpc/xprt.c:	req->rq_cong = 0;
net/sunrpc/xprt.c:	trace_xprt_put_cong(xprt, req->rq_task);
net/sunrpc/xprt.c:	if (req->rq_cong)
net/sunrpc/xprt.c:	__xprt_put_cong(req->rq_xprt, req);
net/sunrpc/xprt.c:	const struct rpc_timeout *to = req->rq_task->tk_client->cl_timeout;
net/sunrpc/xprt.c:	unsigned long majortimeo = req->rq_timeout;
net/sunrpc/xprt.c:	req->rq_majortimeo += xprt_calc_majortimeo(req);
net/sunrpc/xprt.c:	req->rq_minortimeo += req->rq_timeout;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	req->rq_timeout = task->tk_client->cl_timeout->to_initval;
net/sunrpc/xprt.c:	req->rq_majortimeo = time_init + xprt_calc_majortimeo(req);
net/sunrpc/xprt.c:	req->rq_minortimeo = time_init + req->rq_timeout;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	const struct rpc_timeout *to = req->rq_task->tk_client->cl_timeout;
net/sunrpc/xprt.c:	if (time_before(jiffies, req->rq_minortimeo))
net/sunrpc/xprt.c:	if (time_before(jiffies, req->rq_majortimeo)) {
net/sunrpc/xprt.c:			req->rq_timeout <<= 1;
net/sunrpc/xprt.c:			req->rq_timeout += to->to_increment;
net/sunrpc/xprt.c:		if (to->to_maxval && req->rq_timeout >= to->to_maxval)
net/sunrpc/xprt.c:			req->rq_timeout = to->to_maxval;
net/sunrpc/xprt.c:		req->rq_retries++;
net/sunrpc/xprt.c:		req->rq_timeout = to->to_initval;
net/sunrpc/xprt.c:		req->rq_retries = 0;
net/sunrpc/xprt.c:		rpc_init_rtt(req->rq_task->tk_client->cl_rtt, to->to_initval);
net/sunrpc/xprt.c:	if (req->rq_timeout == 0) {
net/sunrpc/xprt.c:		req->rq_timeout = 5 * HZ;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	return req->rq_connect_cookie != xprt_connect_cookie(xprt) ||
net/sunrpc/xprt.c:		switch (xprt_xid_cmp(xid, req->rq_xid)) {
net/sunrpc/xprt.c:		switch(xprt_xid_cmp(new->rq_xid, req->rq_xid)) {
net/sunrpc/xprt.c:	rb_erase(&req->rq_recv, &xprt->recv_queue);
net/sunrpc/xprt.c:	return atomic_read(&req->rq_pin) != 0;
net/sunrpc/xprt.c:	atomic_inc(&req->rq_pin);
net/sunrpc/xprt.c:	if (!test_bit(RPC_TASK_MSG_PIN_WAIT, &req->rq_task->tk_runstate)) {
net/sunrpc/xprt.c:		atomic_dec(&req->rq_pin);
net/sunrpc/xprt.c:	if (atomic_dec_and_test(&req->rq_pin))
net/sunrpc/xprt.c:		wake_up_var(&req->rq_pin);
net/sunrpc/xprt.c:	wait_var_event(&req->rq_pin, !xprt_is_pinned_rqst(req));
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	memcpy(&req->rq_private_buf, &req->rq_rcv_buf,
net/sunrpc/xprt.c:			sizeof(req->rq_private_buf));
net/sunrpc/xprt.c:		xprt_request_rb_remove(req->rq_xprt, req);
net/sunrpc/xprt.c:	long m = usecs_to_jiffies(ktime_to_us(req->rq_rtt));
net/sunrpc/xprt.c:		if (req->rq_ntrans == 1)
net/sunrpc/xprt.c:		rpc_set_timeo(rtt, timer, req->rq_ntrans - 1);
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	req->rq_private_buf.len = copied;
net/sunrpc/xprt.c:	/* req->rq_reply_bytes_recvd */
net/sunrpc/xprt.c:	req->rq_reply_bytes_recvd = copied;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	trace_xprt_timer(xprt, req->rq_xid, task->tk_status);
net/sunrpc/xprt.c:	if (!req->rq_reply_bytes_recvd) {
net/sunrpc/xprt.c:	rpc_sleep_on_timeout(&req->rq_xprt->pending, task, xprt_timer,
net/sunrpc/xprt.c:	timeout <<= rpc_ntimeo(rtt, timer) + req->rq_retries;
net/sunrpc/xprt.c:	rpc_sleep_on_timeout(&req->rq_xprt->pending, task, xprt_timer,
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	 * req->rq_reply_bytes_recvd, and the call to rpc_sleep_on().
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:		req->rq_bytes_sent = 0;
net/sunrpc/xprt.c:		if (req->rq_cong) {
net/sunrpc/xprt.c:				list_add_tail(&req->rq_xmit, &pos->rq_xmit);
net/sunrpc/xprt.c:				INIT_LIST_HEAD(&req->rq_xmit2);
net/sunrpc/xprt.c:				list_add_tail(&req->rq_xmit, &pos->rq_xmit);
net/sunrpc/xprt.c:				INIT_LIST_HEAD(&req->rq_xmit2);
net/sunrpc/xprt.c:		} else if (!req->rq_seqno) {
net/sunrpc/xprt.c:				list_add_tail(&req->rq_xmit2, &pos->rq_xmit2);
net/sunrpc/xprt.c:				INIT_LIST_HEAD(&req->rq_xmit);
net/sunrpc/xprt.c:		list_add_tail(&req->rq_xmit, &xprt->xmit_queue);
net/sunrpc/xprt.c:		INIT_LIST_HEAD(&req->rq_xmit2);
net/sunrpc/xprt.c:	if (!list_empty(&req->rq_xmit)) {
net/sunrpc/xprt.c:		list_del(&req->rq_xmit);
net/sunrpc/xprt.c:		if (!list_empty(&req->rq_xmit2)) {
net/sunrpc/xprt.c:			struct rpc_rqst *next = list_first_entry(&req->rq_xmit2,
net/sunrpc/xprt.c:			list_del(&req->rq_xmit2);
net/sunrpc/xprt.c:		list_del(&req->rq_xmit2);
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	struct rpc_xprt	*xprt = req->rq_xprt;
net/sunrpc/xprt.c:	struct rpc_xprt *xprt = req->rq_xprt;
net/sunrpc/xprt.c:	struct rpc_task *task = req->rq_task;
net/sunrpc/xprt.c:	if (!req->rq_bytes_sent) {
net/sunrpc/xprt.c:	 * Update req->rq_ntrans before transmitting to avoid races with
net/sunrpc/xprt.c:	req->rq_ntrans++;
net/sunrpc/xprt.c:	trace_rpc_xdr_sendto(task, &req->rq_snd_buf);
net/sunrpc/xprt.c:		req->rq_ntrans--;
net/sunrpc/xprt.c:	req->rq_connect_cookie = connect_cookie;
net/sunrpc/xprt.c:	struct rpc_xprt	*xprt = req->rq_xprt;
net/sunrpc/xprt.c:		list_del(&req->rq_list);
net/sunrpc/xprt.c:		list_add(&req->rq_list, &xprt->free);
net/sunrpc/xprt.c:		list_del(&req->rq_list);
net/sunrpc/xprt.c:		list_add(&req->rq_list, &xprt->free);
net/sunrpc/xprt.c:	req->rq_connect_cookie = xprt_connect_cookie(xprt) - 1;
net/sunrpc/xprt.c:	req->rq_task	= task;
net/sunrpc/xprt.c:	req->rq_xprt    = xprt;
net/sunrpc/xprt.c:	req->rq_buffer  = NULL;
net/sunrpc/xprt.c:	req->rq_xid	= xprt_alloc_xid(xprt);
net/sunrpc/xprt.c:	req->rq_snd_buf.len = 0;
net/sunrpc/xprt.c:	req->rq_snd_buf.buflen = 0;
net/sunrpc/xprt.c:	req->rq_rcv_buf.len = 0;
net/sunrpc/xprt.c:	req->rq_rcv_buf.buflen = 0;
net/sunrpc/xprt.c:	req->rq_snd_buf.bvec = NULL;
net/sunrpc/xprt.c:	req->rq_rcv_buf.bvec = NULL;
net/sunrpc/xprt.c:	req->rq_release_snd_buf = NULL;
net/sunrpc/xprt.c:	xprt = req->rq_xprt;
net/sunrpc/xprt.c:	if (req->rq_buffer)
net/sunrpc/xprt.c:	xdr_free_bvec(&req->rq_rcv_buf);
net/sunrpc/xprt.c:	xdr_free_bvec(&req->rq_snd_buf);
net/sunrpc/xprt.c:	if (req->rq_cred != NULL)
net/sunrpc/xprt.c:		put_rpccred(req->rq_cred);
net/sunrpc/xprt.c:	if (req->rq_release_snd_buf)
net/sunrpc/xprt.c:		req->rq_release_snd_buf(req);
net/sunrpc/xprt.c:	struct xdr_buf *xbufp = &req->rq_snd_buf;
net/sunrpc/xprt.c:	req->rq_task = task;
net/sunrpc/xprt.c:	xprt_init_connect_cookie(req, req->rq_xprt);
net/ipv6/ip6_flowlabel.c:	err = fl6_renew(fl, freq->flr_linger, freq->flr_expires);
net/ipv6/ip6_flowlabel.c:	fl->share = freq->flr_share;
net/ipv6/ip6_flowlabel.c:	addr_type = ipv6_addr_type(&freq->flr_dst);
net/ipv6/ip6_flowlabel.c:	fl->dst = freq->flr_dst;
net/ipv6/ip6_flowlabel.c:		freq->flr_label = np->rcv_flowinfo & IPV6_FLOWLABEL_MASK;
net/ipv6/ip6_flowlabel.c:		freq->flr_label = np->flow_label;
net/ipv6/ip6_flowlabel.c:			freq->flr_label = sfl->fl->label;
net/ipv6/ip6_flowlabel.c:			freq->flr_dst = sfl->fl->dst;
net/ipv6/ip6_flowlabel.c:			freq->flr_share = sfl->fl->share;
net/ipv6/ip6_flowlabel.c:			freq->flr_expires = (sfl->fl->expires - jiffies) / HZ;
net/ipv6/ip6_flowlabel.c:			freq->flr_linger = sfl->fl->linger / HZ;
net/ipv6/ip6_flowlabel.c:	if (freq->flr_flags & IPV6_FL_F_REFLECT) {
net/ipv6/ip6_flowlabel.c:		if (sfl->fl->label == freq->flr_label)
net/ipv6/ip6_flowlabel.c:	if (freq->flr_label == (np->flow_label & IPV6_FLOWLABEL_MASK))
net/ipv6/ip6_flowlabel.c:		if (sfl->fl->label == freq->flr_label) {
net/ipv6/ip6_flowlabel.c:			err = fl6_renew(sfl->fl, freq->flr_linger,
net/ipv6/ip6_flowlabel.c:					freq->flr_expires);
net/ipv6/ip6_flowlabel.c:	if (freq->flr_share == IPV6_FL_S_NONE &&
net/ipv6/ip6_flowlabel.c:		struct ip6_flowlabel *fl = fl_lookup(net, freq->flr_label);
net/ipv6/ip6_flowlabel.c:			err = fl6_renew(fl, freq->flr_linger,
net/ipv6/ip6_flowlabel.c:					freq->flr_expires);
net/ipv6/ip6_flowlabel.c:	if (freq->flr_flags & IPV6_FL_F_REFLECT) {
net/ipv6/ip6_flowlabel.c:	if (freq->flr_label & ~IPV6_FLOWLABEL_MASK)
net/ipv6/ip6_flowlabel.c:	    (freq->flr_label & IPV6_FLOWLABEL_STATELESS_FLAG))
net/ipv6/ip6_flowlabel.c:	if (freq->flr_label) {
net/ipv6/ip6_flowlabel.c:			if (sfl->fl->label == freq->flr_label) {
net/ipv6/ip6_flowlabel.c:				if (freq->flr_flags & IPV6_FL_F_EXCL) {
net/ipv6/ip6_flowlabel.c:			fl1 = fl_lookup(net, freq->flr_label);
net/ipv6/ip6_flowlabel.c:			if (freq->flr_flags&IPV6_FL_F_EXCL)
net/ipv6/ip6_flowlabel.c:	if (!(freq->flr_flags & IPV6_FL_F_CREATE))
net/ipv6/ip6_flowlabel.c:	fl1 = fl_intern(net, fl, freq->flr_label);
net/ipv6/ip6_flowlabel.c:	if (!freq->flr_label) {
net/ipv6/syncookies.c:	treq->tfo_listener = false;
net/ipv6/syncookies.c:	req->mss = mss;
net/ipv6/syncookies.c:	ireq->ir_rmt_port = th->source;
net/ipv6/syncookies.c:	ireq->ir_num = ntohs(th->dest);
net/ipv6/syncookies.c:	ireq->ir_v6_rmt_addr = ipv6_hdr(skb)->saddr;
net/ipv6/syncookies.c:	ireq->ir_v6_loc_addr = ipv6_hdr(skb)->daddr;
net/ipv6/syncookies.c:		ireq->pktopts = skb;
net/ipv6/syncookies.c:	ireq->ir_iif = inet_request_bound_dev_if(sk, skb);
net/ipv6/syncookies.c:	    ipv6_addr_type(&ireq->ir_v6_rmt_addr) & IPV6_ADDR_LINKLOCAL)
net/ipv6/syncookies.c:		ireq->ir_iif = tcp_v6_iif(skb);
net/ipv6/syncookies.c:	ireq->ir_mark = inet_request_mark(sk, skb);
net/ipv6/syncookies.c:	req->num_retrans = 0;
net/ipv6/syncookies.c:	ireq->snd_wscale	= tcp_opt.snd_wscale;
net/ipv6/syncookies.c:	ireq->sack_ok		= tcp_opt.sack_ok;
net/ipv6/syncookies.c:	ireq->wscale_ok		= tcp_opt.wscale_ok;
net/ipv6/syncookies.c:	ireq->tstamp_ok		= tcp_opt.saw_tstamp;
net/ipv6/syncookies.c:	req->ts_recent		= tcp_opt.saw_tstamp ? tcp_opt.rcv_tsval : 0;
net/ipv6/syncookies.c:	treq->snt_synack	= 0;
net/ipv6/syncookies.c:	treq->rcv_isn = ntohl(th->seq) - 1;
net/ipv6/syncookies.c:	treq->snt_isn = cookie;
net/ipv6/syncookies.c:	treq->ts_off = 0;
net/ipv6/syncookies.c:	treq->txhash = net_tx_rndhash();
net/ipv6/syncookies.c:		ireq->smc_ok = 0;
net/ipv6/syncookies.c:		fl6.daddr = ireq->ir_v6_rmt_addr;
net/ipv6/syncookies.c:		fl6.saddr = ireq->ir_v6_loc_addr;
net/ipv6/syncookies.c:		fl6.flowi6_oif = ireq->ir_iif;
net/ipv6/syncookies.c:		fl6.flowi6_mark = ireq->ir_mark;
net/ipv6/syncookies.c:		fl6.fl6_dport = ireq->ir_rmt_port;
net/ipv6/syncookies.c:	req->rsk_window_clamp = tp->window_clamp ? :dst_metric(dst, RTAX_WINDOW);
net/ipv6/syncookies.c:	    (req->rsk_window_clamp > full_space || req->rsk_window_clamp == 0))
net/ipv6/syncookies.c:		req->rsk_window_clamp = full_space;
net/ipv6/syncookies.c:	tcp_select_initial_window(sk, full_space, req->mss,
net/ipv6/syncookies.c:				  &req->rsk_rcv_wnd, &req->rsk_window_clamp,
net/ipv6/syncookies.c:				  ireq->wscale_ok, &rcv_wscale,
net/ipv6/syncookies.c:	ireq->rcv_wscale = rcv_wscale;
net/ipv6/syncookies.c:	ireq->ecn_ok = cookie_ecn_ok(&tcp_opt, sock_net(sk), dst);
net/ipv6/addrconf.c:	if (!(ipv6_addr_type(&ireq->ifr6_addr) & IPV6_ADDR_COMPATv4))
net/ipv6/addrconf.c:	p.iph.daddr = ireq->ifr6_addr.s6_addr32[3];
net/ipv6/esp6.c:	if (req->src != req->dst)
net/ipv6/esp6.c:		for (sg = sg_next(req->src); sg; sg = sg_next(sg))
net/ipv6/tcp_ipv6.c:		__tcp_v6_send_check(skb, &ireq->ir_v6_loc_addr,
net/ipv6/tcp_ipv6.c:				    &ireq->ir_v6_rmt_addr);
net/ipv6/tcp_ipv6.c:		fl6->daddr = ireq->ir_v6_rmt_addr;
net/ipv6/tcp_ipv6.c:		if (np->repflow && ireq->pktopts)
net/ipv6/tcp_ipv6.c:			fl6->flowlabel = ip6_flowlabel(ipv6_hdr(ireq->pktopts));
net/ipv6/tcp_ipv6.c:		opt = ireq->ipv6_opt;
net/ipv6/tcp_ipv6.c:	ireq->ir_v6_rmt_addr = ipv6_hdr(skb)->saddr;
net/ipv6/tcp_ipv6.c:	ireq->ir_v6_loc_addr = ipv6_hdr(skb)->daddr;
net/ipv6/tcp_ipv6.c:	    ipv6_addr_type(&ireq->ir_v6_rmt_addr) & IPV6_ADDR_LINKLOCAL)
net/ipv6/tcp_ipv6.c:		ireq->ir_iif = tcp_v6_iif(skb);
net/ipv6/tcp_ipv6.c:		ireq->pktopts = skb;
net/ipv6/tcp_ipv6.c:			req->rsk_rcv_wnd >> inet_rsk(req)->rcv_wscale,
net/ipv6/tcp_ipv6.c:			req->ts_recent, sk->sk_bound_dev_if,
net/ipv6/tcp_ipv6.c:	newsk->sk_v6_daddr = ireq->ir_v6_rmt_addr;
net/ipv6/tcp_ipv6.c:	newnp->saddr = ireq->ir_v6_loc_addr;
net/ipv6/tcp_ipv6.c:	newsk->sk_v6_rcv_saddr = ireq->ir_v6_loc_addr;
net/ipv6/tcp_ipv6.c:	newsk->sk_bound_dev_if = ireq->ir_iif;
net/ipv6/tcp_ipv6.c:	opt = ireq->ipv6_opt;
net/ipv6/tcp_ipv6.c:	l3index = l3mdev_master_ifindex_by_index(sock_net(sk), ireq->ir_iif);
net/ipv6/tcp_ipv6.c:		if (ireq->pktopts) {
net/ipv6/tcp_ipv6.c:			newnp->pktoptions = skb_clone(ireq->pktopts,
net/ipv6/tcp_ipv6.c:			consume_skb(ireq->pktopts);
net/ipv6/tcp_ipv6.c:			ireq->pktopts = NULL;
net/ipv6/tcp_ipv6.c:		sk = req->rsk_listener;
net/ipv6/tcp_ipv6.c:	long ttd = req->rsk_timer.expires - jiffies;
net/ipv6/tcp_ipv6.c:		   req->num_timeout,
net/ipv6/tcp_ipv6.c:				    sock_i_uid(req->rsk_listener)),
net/ipv6/inet6_connection_sock.c:	fl6->daddr = ireq->ir_v6_rmt_addr;
net/ipv6/inet6_connection_sock.c:	fl6->saddr = ireq->ir_v6_loc_addr;
net/ipv6/inet6_connection_sock.c:	fl6->flowi6_oif = ireq->ir_iif;
net/ipv6/inet6_connection_sock.c:	fl6->flowi6_mark = ireq->ir_mark;
net/ipv6/inet6_connection_sock.c:	fl6->fl6_dport = ireq->ir_rmt_port;
net/ipv6/inet6_connection_sock.c:	fl6->fl6_sport = htons(ireq->ir_num);
net/bluetooth/smp.c:		req->io_capability = conn->hcon->io_capability;
net/bluetooth/smp.c:		req->oob_flag = oob_flag;
net/bluetooth/smp.c:		req->max_key_size = hdev->le_max_key_size;
net/bluetooth/smp.c:		req->init_key_dist = local_dist;
net/bluetooth/smp.c:		req->resp_key_dist = remote_dist;
net/bluetooth/smp.c:		req->auth_req = (authreq & AUTH_REQ_MASK(hdev));
net/bluetooth/smp.c:	rsp->init_key_dist = req->init_key_dist & remote_dist;
net/bluetooth/smp.c:	rsp->resp_key_dist = req->resp_key_dist & local_dist;
net/bluetooth/smp.c:		persistent = !!((req->auth_req & rsp->auth_req) &
net/bluetooth/smp.c:		*keydist &= req->init_key_dist;
net/bluetooth/smp.c:		*keydist &= req->resp_key_dist;
net/bluetooth/smp.c:		req->auth_req        = SMP_AUTH_CT2;
net/bluetooth/smp.c:		req->init_key_dist   = local_dist;
net/bluetooth/smp.c:		req->resp_key_dist   = remote_dist;
net/bluetooth/smp.c:		req->max_key_size    = conn->hcon->enc_key_size;
net/bluetooth/smp.c:	rsp->init_key_dist   = req->init_key_dist & remote_dist;
net/bluetooth/smp.c:	rsp->resp_key_dist   = req->resp_key_dist & local_dist;
net/bluetooth/smp.c:	auth = req->auth_req & AUTH_REQ_MASK(hdev);
net/bluetooth/smp.c:	if (req->oob_flag == SMP_OOB_PRESENT && SMP_DEV(hdev)->local_oob)
net/bluetooth/smp.c:		if (req->auth_req & SMP_AUTH_CT2)
net/bluetooth/smp.c:		key_size = min(req->max_key_size, rsp.max_key_size);
net/bluetooth/smp.c:					 req->io_capability);
net/bluetooth/smp.c:	key_size = min(req->max_key_size, rsp.max_key_size);
net/bluetooth/smp.c:	ret = tk_request(conn, 0, auth, rsp.io_capability, req->io_capability);
net/bluetooth/smp.c:	key_size = min(req->max_key_size, rsp->max_key_size);
net/bluetooth/smp.c:	if ((req->auth_req & SMP_AUTH_CT2) && (auth & SMP_AUTH_CT2))
net/bluetooth/smp.c:	if ((req->auth_req & SMP_AUTH_SC) && (auth & SMP_AUTH_SC))
net/bluetooth/smp.c:		method = get_auth_method(smp, req->io_capability,
net/bluetooth/smp.c:	auth |= req->auth_req;
net/bluetooth/smp.c:	ret = tk_request(conn, 0, auth, req->io_capability, rsp->io_capability);
net/bluetooth/smp.c:	smp->remote_key_dist = (req->init_key_dist & rsp->resp_key_dist);
net/bluetooth/smp.c:	auth = req->auth_req & AUTH_REQ_MASK(hdev);
net/bluetooth/smp.c:	if (tk_request(conn, 0, auth, rsp->io_capability, req->io_capability)) {
net/bluetooth/ecdh_helper.c:	struct ecdh_completion *res = req->data;
net/bluetooth/cmtp/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/cmtp/core.c:	session->flags = req->flags;
net/bluetooth/cmtp/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/cmtp/core.c:	session = __cmtp_get_session(&req->bdaddr);
net/bluetooth/cmtp/core.c:		if (copy_to_user(req->ci, &ci, sizeof(ci))) {
net/bluetooth/cmtp/core.c:		if (++n >= req->cnum)
net/bluetooth/cmtp/core.c:		req->ci++;
net/bluetooth/cmtp/core.c:	req->cnum = n;
net/bluetooth/rfcomm/tty.c:	if (req->dev_id < 0) {
net/bluetooth/rfcomm/tty.c:		dev->id = req->dev_id;
net/bluetooth/rfcomm/tty.c:	bacpy(&dev->src, &req->src);
net/bluetooth/rfcomm/tty.c:	bacpy(&dev->dst, &req->dst);
net/bluetooth/rfcomm/tty.c:	dev->channel = req->channel;
net/bluetooth/rfcomm/tty.c:	dev->flags = req->flags &
net/bluetooth/rfcomm/tty.c:	if (req->flags & (1 << RFCOMM_REUSE_DLC)) {
net/bluetooth/rfcomm/tty.c:	BT_DBG("id %d channel %d", req->dev_id, req->channel);
net/bluetooth/a2mp.c:	ext_feat = le16_to_cpu(req->ext_feat);
net/bluetooth/a2mp.c:	BT_DBG("mtu %d efm 0x%4.4x", le16_to_cpu(req->mtu), ext_feat);
net/bluetooth/a2mp.c:	BT_DBG("id %d", req->id);
net/bluetooth/a2mp.c:	hdev = hci_dev_get(req->id);
net/bluetooth/a2mp.c:		rsp.id = req->id;
net/bluetooth/a2mp.c:	BT_DBG("id %d", req->id);
net/bluetooth/a2mp.c:	hdev = hci_dev_get(req->id);
net/bluetooth/a2mp.c:		rsp.id = req->id;
net/bluetooth/a2mp.c:	BT_DBG("local_id %d, remote_id %d", req->local_id, req->remote_id);
net/bluetooth/a2mp.c:	rsp.local_id = req->remote_id;
net/bluetooth/a2mp.c:	rsp.remote_id = req->local_id;
net/bluetooth/a2mp.c:	hdev = hci_dev_get(req->remote_id);
net/bluetooth/a2mp.c:		assoc = kmemdup(req->amp_assoc, assoc_len, GFP_KERNEL);
net/bluetooth/a2mp.c:	hcon = phylink_add(hdev, mgr, req->local_id, false);
net/bluetooth/a2mp.c:	BT_DBG("local_id %d remote_id %d", req->local_id, req->remote_id);
net/bluetooth/a2mp.c:	rsp.local_id = req->remote_id;
net/bluetooth/a2mp.c:	rsp.remote_id = req->local_id;
net/bluetooth/a2mp.c:	hdev = hci_dev_get(req->remote_id);
net/bluetooth/a2mp.c:	req->local_id = hdev->id;
net/bluetooth/a2mp.c:	req->remote_id = bredr_chan->remote_amp_id;
net/bluetooth/a2mp.c:	memcpy(req->amp_assoc, loc_assoc->data, loc_assoc->len);
net/bluetooth/hci_request.c:	skb_queue_head_init(&req->cmd_q);
net/bluetooth/hci_request.c:	req->hdev = hdev;
net/bluetooth/hci_request.c:	req->err = 0;
net/bluetooth/hci_request.c:	skb_queue_purge(&req->cmd_q);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	bt_dev_dbg(hdev, "length %u", skb_queue_len(&req->cmd_q));
net/bluetooth/hci_request.c:	if (req->err) {
net/bluetooth/hci_request.c:		skb_queue_purge(&req->cmd_q);
net/bluetooth/hci_request.c:		return req->err;
net/bluetooth/hci_request.c:	if (skb_queue_empty(&req->cmd_q))
net/bluetooth/hci_request.c:	skb = skb_peek_tail(&req->cmd_q);
net/bluetooth/hci_request.c:	skb_queue_splice_tail(&req->cmd_q, &hdev->cmd_q);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	if (req->err)
net/bluetooth/hci_request.c:		req->err = -ENOMEM;
net/bluetooth/hci_request.c:	if (skb_queue_empty(&req->cmd_q))
net/bluetooth/hci_request.c:	skb_queue_tail(&req->cmd_q, skb);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	bt_dev_dbg(req->hdev, "Remove %pMR (0x%x) from whitelist", &cp.bdaddr,
net/bluetooth/hci_request.c:	if (use_ll_privacy(req->hdev) &&
net/bluetooth/hci_request.c:	    hci_dev_test_flag(req->hdev, HCI_ENABLE_LL_PRIVACY)) {
net/bluetooth/hci_request.c:		irk = hci_find_irk_by_addr(req->hdev, bdaddr, bdaddr_type);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	bt_dev_dbg(req->hdev, "Pausing advertising instances");
net/bluetooth/hci_request.c:	if (!ext_adv_capable(req->hdev))
net/bluetooth/hci_request.c:		cancel_adv_timeout(req->hdev);
net/bluetooth/hci_request.c:	bt_dev_dbg(req->hdev, "Resuming advertising instances");
net/bluetooth/hci_request.c:	if (ext_adv_capable(req->hdev)) {
net/bluetooth/hci_request.c:		list_for_each_entry(adv, &req->hdev->adv_instances, list) {
net/bluetooth/hci_request.c:						req->hdev->cur_adv_instance,
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	if (ext_adv_capable(req->hdev)) {
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	hci_dev_lock(req->hdev);
net/bluetooth/hci_request.c:	hci_dev_unlock(req->hdev);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:			if (req->hdev->hci_ver < BLUETOOTH_VER_1_2)
net/bluetooth/hci_request.c:	hci_dev_lock(req->hdev);
net/bluetooth/hci_request.c:	hci_dev_unlock(req->hdev);
net/bluetooth/hci_request.c:	bt_dev_dbg(req->hdev, "");
net/bluetooth/hci_request.c:	hci_dev_lock(req->hdev);
net/bluetooth/hci_request.c:	hci_inquiry_cache_flush(req->hdev);
net/bluetooth/hci_request.c:	hci_dev_unlock(req->hdev);
net/bluetooth/hci_request.c:	if (req->hdev->discovery.limited)
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	bt_dev_dbg(req->hdev, "");
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_request.c:	hci_dev_lock(req->hdev);
net/bluetooth/hci_request.c:	hci_dev_unlock(req->hdev);
net/bluetooth/hci_request.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hidp/core.c:	input->id.vendor  = req->vendor;
net/bluetooth/hidp/core.c:	input->id.product = req->product;
net/bluetooth/hidp/core.c:	input->id.version = req->version;
net/bluetooth/hidp/core.c:	if (req->subclass & 0x40) {
net/bluetooth/hidp/core.c:	if (req->subclass & 0x80) {
net/bluetooth/hidp/core.c:	session->rd_data = memdup_user(req->rd_data, req->rd_size);
net/bluetooth/hidp/core.c:	session->rd_size = req->rd_size;
net/bluetooth/hidp/core.c:	hid->vendor  = req->vendor;
net/bluetooth/hidp/core.c:	hid->product = req->product;
net/bluetooth/hidp/core.c:	hid->version = req->version;
net/bluetooth/hidp/core.c:	hid->country = req->country;
net/bluetooth/hidp/core.c:	strscpy(hid->name, req->name, sizeof(hid->name));
net/bluetooth/hidp/core.c:	if (req->rd_size > 0) {
net/bluetooth/hidp/core.c:	session->flags = req->flags & BIT(HIDP_BLUETOOTH_VENDOR_ID);
net/bluetooth/hidp/core.c:	session->idle_to = req->idle_to;
net/bluetooth/hidp/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/hidp/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/hidp/core.c:	session = hidp_session_find(&req->bdaddr);
net/bluetooth/hidp/core.c:	if (req->flags & BIT(HIDP_VIRTUAL_CABLE_UNPLUG))
net/bluetooth/hidp/core.c:		if (copy_to_user(req->ci, &ci, sizeof(ci))) {
net/bluetooth/hidp/core.c:		if (++n >= req->cnum)
net/bluetooth/hidp/core.c:		req->ci++;
net/bluetooth/hidp/core.c:	req->cnum = n;
net/bluetooth/l2cap_core.c:	void *ptr = req->data;
net/bluetooth/l2cap_core.c:	req->dcid  = cpu_to_le16(chan->dcid);
net/bluetooth/l2cap_core.c:	req->flags = cpu_to_le16(0);
net/bluetooth/l2cap_core.c:	void *ptr = req->data;
net/bluetooth/l2cap_core.c:	req->dcid   = cpu_to_le16(chan->dcid);
net/bluetooth/l2cap_core.c:	req->flags  = cpu_to_le16(0);
net/bluetooth/l2cap_core.c:	u16 dcid = 0, scid = __le16_to_cpu(req->scid);
net/bluetooth/l2cap_core.c:	__le16 psm = req->psm;
net/bluetooth/l2cap_core.c:	dcid  = __le16_to_cpu(req->dcid);
net/bluetooth/l2cap_core.c:	flags = __le16_to_cpu(req->flags);
net/bluetooth/l2cap_core.c:	memcpy(chan->conf_req + chan->conf_len, req->data, len);
net/bluetooth/l2cap_core.c:	scid = __le16_to_cpu(req->scid);
net/bluetooth/l2cap_core.c:	dcid = __le16_to_cpu(req->dcid);
net/bluetooth/l2cap_core.c:	type = __le16_to_cpu(req->type);
net/bluetooth/l2cap_core.c:	psm = le16_to_cpu(req->psm);
net/bluetooth/l2cap_core.c:	scid = le16_to_cpu(req->scid);
net/bluetooth/l2cap_core.c:	BT_DBG("psm 0x%2.2x, scid 0x%4.4x, amp_id %d", psm, scid, req->amp_id);
net/bluetooth/l2cap_core.c:	if (req->amp_id == AMP_ID_BREDR) {
net/bluetooth/l2cap_core.c:			      req->amp_id);
net/bluetooth/l2cap_core.c:	hdev = hci_dev_get(req->amp_id);
net/bluetooth/l2cap_core.c:			     req->amp_id);
net/bluetooth/l2cap_core.c:	icid = le16_to_cpu(req->icid);
net/bluetooth/l2cap_core.c:	BT_DBG("icid 0x%4.4x, dest_amp_id %d", icid, req->dest_amp_id);
net/bluetooth/l2cap_core.c:	if (chan->local_amp_id == req->dest_amp_id) {
net/bluetooth/l2cap_core.c:	if (req->dest_amp_id != AMP_ID_BREDR) {
net/bluetooth/l2cap_core.c:		hdev = hci_dev_get(req->dest_amp_id);
net/bluetooth/l2cap_core.c:	chan->move_id = req->dest_amp_id;
net/bluetooth/l2cap_core.c:	if (req->dest_amp_id == AMP_ID_BREDR) {
net/bluetooth/l2cap_core.c:		/*amp_accept_physical(chan, req->dest_amp_id);*/
net/bluetooth/l2cap_core.c:	min		= __le16_to_cpu(req->min);
net/bluetooth/l2cap_core.c:	max		= __le16_to_cpu(req->max);
net/bluetooth/l2cap_core.c:	latency		= __le16_to_cpu(req->latency);
net/bluetooth/l2cap_core.c:	to_multiplier	= __le16_to_cpu(req->to_multiplier);
net/bluetooth/l2cap_core.c:	scid = __le16_to_cpu(req->scid);
net/bluetooth/l2cap_core.c:	mtu  = __le16_to_cpu(req->mtu);
net/bluetooth/l2cap_core.c:	mps  = __le16_to_cpu(req->mps);
net/bluetooth/l2cap_core.c:	psm  = req->psm;
net/bluetooth/l2cap_core.c:	l2cap_le_flowctl_init(chan, __le16_to_cpu(req->credits));
net/bluetooth/l2cap_core.c:	mtu  = __le16_to_cpu(req->mtu);
net/bluetooth/l2cap_core.c:	mps  = __le16_to_cpu(req->mps);
net/bluetooth/l2cap_core.c:	psm  = req->psm;
net/bluetooth/l2cap_core.c:		u16 scid = __le16_to_cpu(req->scid[i]);
net/bluetooth/l2cap_core.c:		l2cap_ecred_init(chan, __le16_to_cpu(req->credits));
net/bluetooth/l2cap_core.c:	mtu = __le16_to_cpu(req->mtu);
net/bluetooth/l2cap_core.c:	mps = __le16_to_cpu(req->mps);
net/bluetooth/l2cap_core.c:		scid = __le16_to_cpu(req->scid[i]);
net/bluetooth/mgmt.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/bnep/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/bnep/core.c:			   (*req->device) ? req->device : "bnep%d",
net/bluetooth/bnep/core.c:	s->role  = req->role;
net/bluetooth/bnep/core.c:	s->flags = req->flags;
net/bluetooth/bnep/core.c:	strcpy(req->device, dev->name);
net/bluetooth/bnep/core.c:	if (req->flags & ~valid_flags)
net/bluetooth/bnep/core.c:	s = __bnep_get_session(req->dst);
net/bluetooth/bnep/core.c:		if (copy_to_user(req->ci, &ci, sizeof(ci))) {
net/bluetooth/bnep/core.c:		if (++n >= req->cnum)
net/bluetooth/bnep/core.c:		req->ci++;
net/bluetooth/bnep/core.c:	req->cnum = n;
net/bluetooth/hci_conn.c:		if (bacmp(&req->hdev->random_addr, direct_rpa))
net/bluetooth/hci_conn.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/msft.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	BT_DBG("%s %ld", req->hdev->name, opt);
net/bluetooth/hci_core.c:	set_bit(HCI_RESET, &req->hdev->flags);
net/bluetooth/hci_core.c:	req->hdev->flow_ctl_mode = HCI_FLOW_CTL_MODE_PACKET_BASED;
net/bluetooth/hci_core.c:	req->hdev->flow_ctl_mode = HCI_FLOW_CTL_MODE_BLOCK_BASED;
net/bluetooth/hci_core.c:	if (req->hdev->commands[14] & 0x20)
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
net/bluetooth/hci_core.c:	BT_DBG("%s %x", req->hdev->name, scan);
net/bluetooth/hci_core.c:	BT_DBG("%s %x", req->hdev->name, auth);
net/bluetooth/hci_core.c:	BT_DBG("%s %x", req->hdev->name, encrypt);
net/bluetooth/hci_core.c:	BT_DBG("%s %x", req->hdev->name, policy);
net/bluetooth/hci_core.c:	struct hci_dev *hdev = req->hdev;
samples/seccomp/user-trap.c:	resp->id = req->id;
samples/seccomp/user-trap.c:	if (req->data.nr != __NR_mount) {
samples/seccomp/user-trap.c:		fprintf(stderr, "huh? trapped something besides mount? %d\n", req->data.nr);
samples/seccomp/user-trap.c:	if (!(req->data.args[3] & MS_BIND))
samples/seccomp/user-trap.c:	snprintf(path, sizeof(path), "/proc/%d/mem", req->pid);
samples/seccomp/user-trap.c:	if (ioctl(listener, SECCOMP_IOCTL_NOTIF_ID_VALID, &req->id) < 0) {
samples/seccomp/user-trap.c:	if (lseek(mem, req->data.args[0], SEEK_SET) < 0) {
samples/seccomp/user-trap.c:	if (lseek(mem, req->data.args[1], SEEK_SET) < 0) {
samples/seccomp/user-trap.c:		if (mount(source, target, NULL, req->data.args[3], NULL) < 0) {
samples/qmi/qmi_sample_client.c:	req->data_len = min_t(size_t, sizeof(req->data), count);
samples/qmi/qmi_sample_client.c:	if (copy_from_user(req->data, user_buf, req->data_len)) {
samples/qmi/qmi_sample_client.c:		   resp->data_len != req->data_len ||
samples/qmi/qmi_sample_client.c:		   memcmp(resp->data, req->data, req->data_len)) {
samples/connector/cn_test.c:	req->first = cn_test_id.idx;
samples/connector/cn_test.c:	req->range = 10;
samples/connector/cn_test.c:	req->first = cn_test_id.val;
samples/connector/cn_test.c:	req->range = 10;
samples/connector/cn_test.c:	req->first = cn_test_id.val + 20;
samples/connector/cn_test.c:	req->range = 10;
samples/acrn/vm-sample.c:			if ((__sync_add_and_fetch(&io_req->processed, 0) == ACRN_IOREQ_STATE_PROCESSING)
samples/acrn/vm-sample.c:					&& (!io_req->kernel_handled))
samples/acrn/vm-sample.c:				if (io_req->type == ACRN_IOREQ_TYPE_PORTIO) {
samples/acrn/vm-sample.c:					port = io_req->reqs.pio_request.address;
samples/acrn/vm-sample.c:					bytes = io_req->reqs.pio_request.size;
samples/acrn/vm-sample.c:					in = (io_req->reqs.pio_request.direction == ACRN_IOREQ_DIR_READ);
drivers/pci/controller/pci-hyperv.c:				q_res_req->probed_bar[i];
drivers/pci/controller/pci-hyperv.c:	res_req->message_type.type = PCI_QUERY_RESOURCE_REQUIREMENTS;
drivers/pci/controller/pci-hyperv.c:	res_req->wslot.slot = desc->win_slot.slot;
drivers/pci/controller/pci-hyperv.c:	version_req->message_type.type = PCI_QUERY_PROTOCOL_VERSION;
drivers/pci/controller/pci-hyperv.c:		version_req->protocol_version = version[i];
drivers/gpu/drm/nouveau/nouveau_gem.c:	ret = nouveau_gem_new(cli, req->info.size, req->align,
drivers/gpu/drm/nouveau/nouveau_gem.c:			      req->info.domain, req->info.tile_mode,
drivers/gpu/drm/nouveau/nouveau_gem.c:			      req->info.tile_flags, &nvbo);
drivers/gpu/drm/nouveau/nouveau_gem.c:				    &req->info.handle);
drivers/gpu/drm/nouveau/nouveau_gem.c:		ret = nouveau_gem_info(file_priv, &nvbo->bo.base, &req->info);
drivers/gpu/drm/nouveau/nouveau_gem.c:			drm_gem_handle_delete(file_priv, req->info.handle);
drivers/gpu/drm/nouveau/nouveau_gem.c:	for (i = 0; i < req->nr_relocs; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		if (unlikely(r->bo_index >= req->nr_buffers)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		if (unlikely(r->reloc_bo_index >= req->nr_buffers)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		if (temp->chan->chid == req->channel) {
drivers/gpu/drm/nouveau/nouveau_gem.c:	sync = req->vram_available & NOUVEAU_GEM_PUSHBUF_SYNC;
drivers/gpu/drm/nouveau/nouveau_gem.c:	req->vram_available = drm->gem.vram_available;
drivers/gpu/drm/nouveau/nouveau_gem.c:	req->gart_available = drm->gem.gart_available;
drivers/gpu/drm/nouveau/nouveau_gem.c:	if (unlikely(req->nr_push == 0))
drivers/gpu/drm/nouveau/nouveau_gem.c:	if (unlikely(req->nr_push > NOUVEAU_GEM_MAX_PUSH)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:			 req->nr_push, NOUVEAU_GEM_MAX_PUSH);
drivers/gpu/drm/nouveau/nouveau_gem.c:	if (unlikely(req->nr_buffers > NOUVEAU_GEM_MAX_BUFFERS)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:			 req->nr_buffers, NOUVEAU_GEM_MAX_BUFFERS);
drivers/gpu/drm/nouveau/nouveau_gem.c:	if (unlikely(req->nr_relocs > NOUVEAU_GEM_MAX_RELOCS)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:			 req->nr_relocs, NOUVEAU_GEM_MAX_RELOCS);
drivers/gpu/drm/nouveau/nouveau_gem.c:	push = u_memcpya(req->push, req->nr_push, sizeof(*push));
drivers/gpu/drm/nouveau/nouveau_gem.c:	bo = u_memcpya(req->buffers, req->nr_buffers, sizeof(*bo));
drivers/gpu/drm/nouveau/nouveau_gem.c:	for (i = 0; i < req->nr_push; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		if (push[i].bo_index >= req->nr_buffers) {
drivers/gpu/drm/nouveau/nouveau_gem.c:					   req->nr_buffers, &op, &do_reloc);
drivers/gpu/drm/nouveau/nouveau_gem.c:			reloc = u_memcpya(req->relocs, req->nr_relocs, sizeof(*reloc));
drivers/gpu/drm/nouveau/nouveau_gem.c:		ret = nouveau_dma_wait(chan, req->nr_push + 1, 16);
drivers/gpu/drm/nouveau/nouveau_gem.c:		for (i = 0; i < req->nr_push; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		ret = PUSH_WAIT(chan->chan.push, req->nr_push * 2);
drivers/gpu/drm/nouveau/nouveau_gem.c:		for (i = 0; i < req->nr_push; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		ret = PUSH_WAIT(chan->chan.push, req->nr_push * (2 + NOUVEAU_DMA_SKIPS));
drivers/gpu/drm/nouveau/nouveau_gem.c:		for (i = 0; i < req->nr_push; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:			if (unlikely(cmd != req->suffix0)) {
drivers/gpu/drm/nouveau/nouveau_gem.c:			u64_to_user_ptr(req->buffers);
drivers/gpu/drm/nouveau/nouveau_gem.c:		for (i = 0; i < req->nr_buffers; i++) {
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix0 = 0x00000000;
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix1 = 0x00000000;
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix0 = 0x00020000;
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix1 = 0x00000000;
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix0 = 0x20000000 |
drivers/gpu/drm/nouveau/nouveau_gem.c:		req->suffix1 = 0x00000000;
drivers/gpu/drm/nouveau/nouveau_gem.c:	bool no_wait = !!(req->flags & NOUVEAU_GEM_CPU_PREP_NOWAIT);
drivers/gpu/drm/nouveau/nouveau_gem.c:	bool write = !!(req->flags & NOUVEAU_GEM_CPU_PREP_WRITE);
drivers/gpu/drm/nouveau/nouveau_gem.c:	gem = drm_gem_object_lookup(file_priv, req->handle);
drivers/gpu/drm/nouveau/nouveau_gem.c:	gem = drm_gem_object_lookup(file_priv, req->handle);
drivers/gpu/drm/nouveau/nouveau_gem.c:	gem = drm_gem_object_lookup(file_priv, req->handle);
drivers/gpu/drm/nouveau/nouveau_usif.c:	if (!(ret = nvif_unpack(ret, &data, &size, req->v0, 0, 0, true))) {
drivers/gpu/drm/nouveau/nouveau_usif.c:		ntfy->reply = sizeof(struct nvif_notify_rep_v0) + req->v0.reply;
drivers/gpu/drm/nouveau/nouveau_usif.c:		ntfy->route = req->v0.route;
drivers/gpu/drm/nouveau/nouveau_usif.c:		ntfy->token = req->v0.token;
drivers/gpu/drm/nouveau/nouveau_usif.c:		req->v0.route = NVDRM_NOTIFY_USIF;
drivers/gpu/drm/nouveau/nouveau_usif.c:		req->v0.token = (unsigned long)(void *)ntfy;
drivers/gpu/drm/nouveau/nouveau_usif.c:		req->v0.token = ntfy->token;
drivers/gpu/drm/nouveau/nouveau_usif.c:		req->v0.route = ntfy->route;
drivers/gpu/drm/nouveau/nvkm/subdev/i2c/base.c:		notify->types = req->mask;
drivers/gpu/drm/nouveau/nvkm/subdev/i2c/base.c:		notify->index = req->port;
drivers/gpu/drm/nouveau/nvkm/subdev/gpio/base.c:		notify->types = req->mask;
drivers/gpu/drm/nouveau/nvkm/subdev/gpio/base.c:		notify->index = req->line;
drivers/gpu/drm/nouveau/nvkm/engine/sw/chan.c:	if (!(ret = nvif_unvers(ret, &data, &size, req->none))) {
drivers/gpu/drm/nouveau/nvkm/engine/fifo/base.c:	if (!(ret = nvif_unvers(ret, &data, &size, req->none))) {
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:	if (!(ret = nvif_unpack(ret, &data, &size, req->v0, 0, 0, false))) {
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:		if (ret = -ENXIO, req->v0.head <= disp->vblank.index_nr) {
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:			notify->index = req->v0.head;
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:	if (!(ret = nvif_unpack(ret, &data, &size, req->v0, 0, 0, false))) {
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:			if (ret = -ENXIO, outp->conn->index == req->v0.conn) {
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:					notify->types = req->v0.mask;
drivers/gpu/drm/nouveau/nvkm/engine/disp/base.c:					notify->index = req->v0.conn;
drivers/gpu/drm/nouveau/nvkm/core/client.c:	if (!(ret = nvif_unpack(ret, &data, &size, req->v0, 0, 0, true))) {
drivers/gpu/drm/nouveau/nvkm/core/client.c:				   "token %llx\n", req->v0.version,
drivers/gpu/drm/nouveau/nvkm/core/client.c:			   req->v0.reply, req->v0.route, req->v0.token);
drivers/gpu/drm/nouveau/nvkm/core/client.c:		notify->version = req->v0.version;
drivers/gpu/drm/nouveau/nvkm/core/client.c:		notify->rep.v0.version = req->v0.version;
drivers/gpu/drm/nouveau/nvkm/core/client.c:		notify->rep.v0.route = req->v0.route;
drivers/gpu/drm/nouveau/nvkm/core/client.c:		notify->rep.v0.token = req->v0.token;
drivers/gpu/drm/nouveau/nvkm/core/client.c:		reply = req->v0.reply;
drivers/gpu/drm/nouveau/nouveau_abi16.c:	chan = nouveau_abi16_chan(abi16, req->channel);
drivers/gpu/drm/vmwgfx/vmwgfx_bo.c:				req->size, false, &handle, &vbo,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->mip_levels[i] > DRM_VMW_MAX_MIP_LEVELS)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		num_sizes += req->mip_levels[i];
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	desc = svga3dsurface_get_desc(req->format);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:			       req->format);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata->flags = (SVGA3dSurfaceAllFlags)req->flags;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata->format = req->format;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata->scanout = req->scanout;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	memcpy(metadata->mip_levels, req->mip_levels,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:			    req->size_addr,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (dev_priv->has_mob && req->shareable) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				    req->shareable, VMW_RES_SURFACE,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	ret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:					   req->handle_type, &base);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		SVGA3D_FLAGS_64(req->svga3d_flags_upper_32_bits,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				req->base.svga3d_flags);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->base.array_size > 0 && !has_sm4_context(dev_priv)) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->svga3d_flags_upper_32_bits != 0)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->base.multisample_count != 0)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->multisample_pattern != SVGA3D_MS_PATTERN_NONE)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->quality_level != SVGA3D_MS_QUALITY_NONE)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->buffer_byte_stride > 0 && !has_sm5_context(dev_priv)) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	    req->base.multisample_count == 0) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->base.mip_levels > DRM_VMW_MAX_MIP_LEVELS) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.format = req->base.format;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.mip_levels[0] = req->base.mip_levels;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.multisample_count = req->base.multisample_count;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.multisample_pattern = req->multisample_pattern;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.quality_level = req->quality_level;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.array_size = req->base.array_size;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.buffer_byte_stride = req->buffer_byte_stride;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.base_size = req->base.base_size;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	metadata.scanout = req->base.drm_surface_flags &
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->base.buffer_handle != SVGA3D_INVALID_ID) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		ret = vmw_user_bo_lookup(tfile, req->base.buffer_handle,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				backup_handle = req->base.buffer_handle;
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	} else if (req->base.drm_surface_flags &
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:					req->base.drm_surface_flags &
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->base.drm_surface_flags & drm_vmw_surface_flag_coherent) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				    req->base.drm_surface_flags &
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	ret = vmw_surface_handle_reference(dev_priv, file_priv, req->sid,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:					   req->handle_type, &base);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->scanout) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (!svga3dsurface_is_screen_target_format(req->format)) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		if (req->base_size.width > dev_priv->texture_max_width ||
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		    req->base_size.height > dev_priv->texture_max_height) {
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				       req->base_size.width,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:				       req->base_size.height,
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:			svga3dsurface_get_desc(req->format);
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->autogen_filter != SVGA3D_TEX_FILTER_NONE)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->num_sizes != 1)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:	if (req->sizes != NULL)
drivers/gpu/drm/vmwgfx/vmwgfx_surface.c:		num_layers = req->array_size;
drivers/gpu/drm/lima/lima_devfreq.c:	last = devfreq->time_last_update;
drivers/gpu/drm/lima/lima_devfreq.c:	if (devfreq->busy_count > 0)
drivers/gpu/drm/lima/lima_devfreq.c:		devfreq->busy_time += ktime_sub(now, last);
drivers/gpu/drm/lima/lima_devfreq.c:		devfreq->idle_time += ktime_sub(now, last);
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->time_last_update = now;
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->busy_time = 0;
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->idle_time = 0;
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->time_last_update = ktime_get();
drivers/gpu/drm/lima/lima_devfreq.c:	spin_lock_irqsave(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	status->total_time = ktime_to_ns(ktime_add(devfreq->busy_time,
drivers/gpu/drm/lima/lima_devfreq.c:						   devfreq->idle_time));
drivers/gpu/drm/lima/lima_devfreq.c:	status->busy_time = ktime_to_ns(devfreq->busy_time);
drivers/gpu/drm/lima/lima_devfreq.c:	spin_unlock_irqrestore(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	if (devfreq->cooling) {
drivers/gpu/drm/lima/lima_devfreq.c:		devfreq_cooling_unregister(devfreq->cooling);
drivers/gpu/drm/lima/lima_devfreq.c:		devfreq->cooling = NULL;
drivers/gpu/drm/lima/lima_devfreq.c:	if (devfreq->devfreq) {
drivers/gpu/drm/lima/lima_devfreq.c:		devm_devfreq_remove_device(ldev->dev, devfreq->devfreq);
drivers/gpu/drm/lima/lima_devfreq.c:		devfreq->devfreq = NULL;
drivers/gpu/drm/lima/lima_devfreq.c:	dev_pm_opp_put_regulators(devfreq->regulators_opp_table);
drivers/gpu/drm/lima/lima_devfreq.c:	dev_pm_opp_put_clkname(devfreq->clkname_opp_table);
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->regulators_opp_table = NULL;
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->clkname_opp_table = NULL;
drivers/gpu/drm/lima/lima_devfreq.c:	spin_lock_init(&ldevfreq->lock);
drivers/gpu/drm/lima/lima_devfreq.c:	ldevfreq->clkname_opp_table = opp_table;
drivers/gpu/drm/lima/lima_devfreq.c:		ldevfreq->regulators_opp_table = opp_table;
drivers/gpu/drm/lima/lima_devfreq.c:	ldevfreq->devfreq = devfreq;
drivers/gpu/drm/lima/lima_devfreq.c:		ldevfreq->cooling = cooling;
drivers/gpu/drm/lima/lima_devfreq.c:	if (!devfreq->devfreq)
drivers/gpu/drm/lima/lima_devfreq.c:	spin_lock_irqsave(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	devfreq->busy_count++;
drivers/gpu/drm/lima/lima_devfreq.c:	spin_unlock_irqrestore(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	if (!devfreq->devfreq)
drivers/gpu/drm/lima/lima_devfreq.c:	spin_lock_irqsave(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	WARN_ON(--devfreq->busy_count < 0);
drivers/gpu/drm/lima/lima_devfreq.c:	spin_unlock_irqrestore(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	if (!devfreq->devfreq)
drivers/gpu/drm/lima/lima_devfreq.c:	spin_lock_irqsave(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	spin_unlock_irqrestore(&devfreq->lock, irqflags);
drivers/gpu/drm/lima/lima_devfreq.c:	return devfreq_resume_device(devfreq->devfreq);
drivers/gpu/drm/lima/lima_devfreq.c:	if (!devfreq->devfreq)
drivers/gpu/drm/lima/lima_devfreq.c:	return devfreq_suspend_device(devfreq->devfreq);
drivers/gpu/drm/radeon/radeon_acpi.c:	DRM_DEBUG_DRIVER("SBIOS pending requests: %#x\n", req->pending);
drivers/gpu/drm/radeon/radeon_acpi.c:	count = hweight32(req->pending);
drivers/gpu/drm/radeon/r100.c:		  The critical point should never be above max_stop_req-4.  Setting
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	if (req->cmd_nr > G2D_CMDLIST_DATA_NUM ||
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	    req->cmd_buf_nr > G2D_CMDLIST_DATA_NUM) {
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	if (req->event_type != G2D_EVENT_NOT) {
drivers/gpu/drm/exynos/exynos_drm_g2d.c:		e->event.user_data = req->user_data;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	size = cmdlist->last + req->cmd_nr * 2 + req->cmd_buf_nr * 2 + 2;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	cmd = (struct drm_exynos_g2d_cmd *)(unsigned long)req->cmd;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:				sizeof(*cmd) * req->cmd_nr)) {
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	cmdlist->last += req->cmd_nr * 2;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	ret = g2d_check_reg_offset(g2d, node, req->cmd_nr, false);
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	node->buf_info.map_nr = req->cmd_buf_nr;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	if (req->cmd_buf_nr) {
drivers/gpu/drm/exynos/exynos_drm_g2d.c:				(unsigned long)req->cmd_buf;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:					sizeof(*cmd_buf) * req->cmd_buf_nr)) {
drivers/gpu/drm/exynos/exynos_drm_g2d.c:		cmdlist->last += req->cmd_buf_nr * 2;
drivers/gpu/drm/exynos/exynos_drm_g2d.c:		ret = g2d_check_reg_offset(g2d, node, req->cmd_buf_nr, true);
drivers/gpu/drm/exynos/exynos_drm_g2d.c:	runqueue_node->async = req->async;
drivers/gpu/drm/vc4/vc4_perfmon.c:	if (req->ncounters > DRM_VC4_MAX_PERF_COUNTERS ||
drivers/gpu/drm/vc4/vc4_perfmon.c:	    !req->ncounters)
drivers/gpu/drm/vc4/vc4_perfmon.c:	for (i = 0; i < req->ncounters; i++) {
drivers/gpu/drm/vc4/vc4_perfmon.c:		if (req->events[i] >= VC4_PERFCNT_NUM_EVENTS)
drivers/gpu/drm/vc4/vc4_perfmon.c:	perfmon = kzalloc(struct_size(perfmon, counters, req->ncounters),
drivers/gpu/drm/vc4/vc4_perfmon.c:	for (i = 0; i < req->ncounters; i++)
drivers/gpu/drm/vc4/vc4_perfmon.c:		perfmon->events[i] = req->events[i];
drivers/gpu/drm/vc4/vc4_perfmon.c:	perfmon->ncounters = req->ncounters;
drivers/gpu/drm/vc4/vc4_perfmon.c:	req->id = ret;
drivers/gpu/drm/vc4/vc4_perfmon.c:	perfmon = idr_remove(&vc4file->perfmon.idr, req->id);
drivers/gpu/drm/vc4/vc4_perfmon.c:	perfmon = idr_find(&vc4file->perfmon.idr, req->id);
drivers/gpu/drm/vc4/vc4_perfmon.c:	if (copy_to_user(u64_to_user_ptr(req->values_ptr), perfmon->counters,
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	if (req->counterset > (panfrost_model_is_bifrost(pfdev) ? 1 : 0))
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	if (req->enable)
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:						     req->counterset);
drivers/gpu/drm/panfrost/panfrost_perfcnt.c:	void __user *user_ptr = (void __user *)(uintptr_t)req->buf_ptr;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	last = pfdevfreq->time_last_update;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (pfdevfreq->busy_count > 0)
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->busy_time += ktime_sub(now, last);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->idle_time += ktime_sub(now, last);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->time_last_update = now;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->busy_time = 0;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->idle_time = 0;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->time_last_update = ktime_get();
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_lock_irqsave(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	status->total_time = ktime_to_ns(ktime_add(pfdevfreq->busy_time,
drivers/gpu/drm/panfrost/panfrost_devfreq.c:						   pfdevfreq->idle_time));
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	status->busy_time = ktime_to_ns(pfdevfreq->busy_time);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_unlock_irqrestore(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->regulators_opp_table = opp_table;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->opp_of_table_added = true;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_lock_init(&pfdevfreq->lock);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->devfreq = devfreq;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->cooling = cooling;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (pfdevfreq->cooling) {
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		devfreq_cooling_unregister(pfdevfreq->cooling);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->cooling = NULL;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (pfdevfreq->opp_of_table_added) {
drivers/gpu/drm/panfrost/panfrost_devfreq.c:		pfdevfreq->opp_of_table_added = false;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	dev_pm_opp_put_regulators(pfdevfreq->regulators_opp_table);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->regulators_opp_table = NULL;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (!pfdevfreq->devfreq)
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	devfreq_resume_device(pfdevfreq->devfreq);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (!pfdevfreq->devfreq)
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	devfreq_suspend_device(pfdevfreq->devfreq);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (!pfdevfreq->devfreq)
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_lock_irqsave(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	pfdevfreq->busy_count++;
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_unlock_irqrestore(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	if (!pfdevfreq->devfreq)
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_lock_irqsave(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	WARN_ON(--pfdevfreq->busy_count < 0);
drivers/gpu/drm/panfrost/panfrost_devfreq.c:	spin_unlock_irqrestore(&pfdevfreq->lock, irqflags);
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:#define done INTEL_GUC_MSG_IS_RESPONSE(READ_ONCE(req->status))
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:		DRM_ERROR("CT: fence %u err %d\n", req->fence, err);
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:	*status = req->status;
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:		if (unlikely(fence != req->fence)) {
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:				 req->fence);
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:		if (unlikely(datalen > req->response_len)) {
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:				 req->fence, msgsize, msg);
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:			memcpy(req->response_buf, msg + 3, 4 * datalen);
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:		req->response_len = datalen;
drivers/gpu/drm/i915/gt/uc/intel_guc_ct.c:		WRITE_ONCE(req->status, status);
drivers/gpu/drm/i915/gt/intel_llc.c:	     gpu_freq--) {
drivers/gpu/drm/i915/gt/intel_rps.c:		new_freq--;
drivers/gpu/drm/i915/gvt/scheduler.c:	struct intel_context *ctx = workload->req->context;
drivers/gpu/drm/i915/gvt/scheduler.c:	struct intel_context *ctx = workload->req->context;
drivers/gpu/drm/i915/gvt/scheduler.c:	if (IS_GEN(req->engine->i915, 9) && is_inhibit_context(req->context))
drivers/gpu/drm/i915/gvt/scheduler.c:	if (req->engine->emit_init_breadcrumb) {
drivers/gpu/drm/i915/gvt/scheduler.c:		err = req->engine->emit_init_breadcrumb(req);
drivers/gpu/drm/i915/gvt/scheduler.c:	struct intel_context *ctx = workload->req->context;
drivers/gpu/drm/i915/gvt/scheduler.c:		/* If this request caused GPU hang, req->fence.error will
drivers/gpu/drm/i915/gvt/scheduler.c:			if (workload->req->fence.error == -EIO)
drivers/gpu/drm/i915/gvt/mmio_context.c:	int ring_id = req->engine->id;
drivers/gpu/drm/i915/gvt/mmio_context.c:	ret = req->engine->emit_flush(req, EMIT_BARRIER);
drivers/gpu/drm/i915/gvt/mmio_context.c:	ret = req->engine->emit_flush(req, EMIT_BARRIER);
drivers/gpu/drm/i915/gvt/mmio_context.c:			      *(cs-2), *(cs-1), vgpu->id, req->engine->id);
drivers/gpu/drm/i915/gvt/mmio_context.c:			      *(cs-2), *(cs-1), vgpu->id, req->engine->id);
drivers/gpu/drm/i915/gvt/mmio_context.c:	if (req->engine->id != RCS0)
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long bit_rate = clk_req->bitclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long esc_rate = clk_req->escclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long bit_rate = clk_req->bitclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long esc_rate = clk_req->escclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long bit_rate = clk_req->bitclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long esc_rate = clk_req->escclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long bit_rate = clk_req->bitclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy.c:	const unsigned long esc_rate = clk_req->escclk_rate;
drivers/gpu/drm/msm/dsi/phy/dsi_phy_7nm.c:	less_than_1500_mhz = (clk_req->bitclk_rate <= 1500000000);
drivers/gpu/drm/msm/dsi/dsi_host.c:	clk_req->bitclk_rate = msm_host->byte_clk_rate * 8;
drivers/gpu/drm/msm/dsi/dsi_host.c:	clk_req->escclk_rate = msm_host->esc_clk_rate;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_1 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_2 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_3 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_4 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_5 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_6 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_7 = ret;
drivers/gpu/drm/msm/dp/dp_link.c:	req->test_audio_period_ch_8 = ret;
drivers/gpu/drm/xen/xen_drm_front.c:	req->operation = operation;
drivers/gpu/drm/xen/xen_drm_front.c:	req->id = evtchnl->evt_next_id++;
drivers/gpu/drm/xen/xen_drm_front.c:	evtchnl->evt_id = req->id;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.x = x;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.y = y;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.width = width;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.height = height;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.bpp = bpp;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.set_config.fb_cookie = fb_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.gref_directory =
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.buffer_sz = size;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.data_ofs = offset;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.dbuf_cookie = dbuf_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.width = width;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.height = height;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_create.bpp = bpp;
drivers/gpu/drm/xen/xen_drm_front.c:		req->op.dbuf_create.flags |= XENDISPL_DBUF_FLG_REQ_ALLOC;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.dbuf_destroy.dbuf_cookie = dbuf_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_attach.dbuf_cookie = dbuf_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_attach.fb_cookie = fb_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_attach.width = width;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_attach.height = height;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_attach.pixel_format = pixel_format;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.fb_detach.fb_cookie = fb_cookie;
drivers/gpu/drm/xen/xen_drm_front.c:	req->op.pg_flip.fb_cookie = fb_cookie;
drivers/gpu/drm/drm_ioctl.c:	req->value = 0;
drivers/gpu/drm/drm_ioctl.c:	switch (req->capability) {
drivers/gpu/drm/drm_ioctl.c:		req->value = 1;
drivers/gpu/drm/drm_ioctl.c:		req->value |= dev->driver->prime_fd_to_handle ? DRM_PRIME_CAP_IMPORT : 0;
drivers/gpu/drm/drm_ioctl.c:		req->value |= dev->driver->prime_handle_to_fd ? DRM_PRIME_CAP_EXPORT : 0;
drivers/gpu/drm/drm_ioctl.c:		req->value = drm_core_check_feature(dev, DRIVER_SYNCOBJ);
drivers/gpu/drm/drm_ioctl.c:		req->value = drm_core_check_feature(dev, DRIVER_SYNCOBJ_TIMELINE);
drivers/gpu/drm/drm_ioctl.c:	switch (req->capability) {
drivers/gpu/drm/drm_ioctl.c:			req->value = 1;
drivers/gpu/drm/drm_ioctl.c:		req->value = 1;
drivers/gpu/drm/drm_ioctl.c:		req->value = dev->mode_config.preferred_depth;
drivers/gpu/drm/drm_ioctl.c:		req->value = dev->mode_config.prefer_shadow;
drivers/gpu/drm/drm_ioctl.c:		req->value = dev->mode_config.async_page_flip;
drivers/gpu/drm/drm_ioctl.c:		req->value = 1;
drivers/gpu/drm/drm_ioctl.c:				req->value = 0;
drivers/gpu/drm/drm_ioctl.c:			req->value = dev->mode_config.cursor_width;
drivers/gpu/drm/drm_ioctl.c:			req->value = 64;
drivers/gpu/drm/drm_ioctl.c:			req->value = dev->mode_config.cursor_height;
drivers/gpu/drm/drm_ioctl.c:			req->value = 64;
drivers/gpu/drm/drm_ioctl.c:		req->value = dev->mode_config.allow_fb_modifiers;
drivers/gpu/drm/drm_ioctl.c:		req->value = 1;
drivers/gpu/drm/drm_ioctl.c:	switch (req->capability) {
drivers/gpu/drm/drm_ioctl.c:		if (req->value > 1)
drivers/gpu/drm/drm_ioctl.c:		file_priv->stereo_allowed = req->value;
drivers/gpu/drm/drm_ioctl.c:		if (req->value > 1)
drivers/gpu/drm/drm_ioctl.c:		file_priv->universal_planes = req->value;
drivers/gpu/drm/drm_ioctl.c:		if (current->comm[0] == 'X' && req->value == 1) {
drivers/gpu/drm/drm_ioctl.c:		if (req->value > 2)
drivers/gpu/drm/drm_ioctl.c:		file_priv->atomic = req->value;
drivers/gpu/drm/drm_ioctl.c:		file_priv->universal_planes = req->value;
drivers/gpu/drm/drm_ioctl.c:		file_priv->aspect_ratio_allowed = req->value;
drivers/gpu/drm/drm_ioctl.c:		if (req->value > 1)
drivers/gpu/drm/drm_ioctl.c:		file_priv->aspect_ratio_allowed = req->value;
drivers/gpu/drm/drm_ioctl.c:		if (req->value > 1)
drivers/gpu/drm/drm_ioctl.c:		file_priv->writeback_connectors = req->value;
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->x & 0xffff0000 || crtc_req->y & 0xffff0000)
drivers/gpu/drm/drm_crtc.c:	crtc = drm_crtc_find(dev, file_priv, crtc_req->crtc_id);
drivers/gpu/drm/drm_crtc.c:		DRM_DEBUG_KMS("Unknown CRTC ID %d\n", crtc_req->crtc_id);
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->mode_valid && !drm_lease_held(file_priv, plane->base.id))
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->mode_valid) {
drivers/gpu/drm/drm_crtc.c:		if (crtc_req->fb_id == -1) {
drivers/gpu/drm/drm_crtc.c:			fb = drm_framebuffer_lookup(dev, file_priv, crtc_req->fb_id);
drivers/gpu/drm/drm_crtc.c:						crtc_req->fb_id);
drivers/gpu/drm/drm_crtc.c:		    (crtc_req->mode.flags & DRM_MODE_FLAG_PIC_AR_MASK) != DRM_MODE_FLAG_PIC_AR_NONE) {
drivers/gpu/drm/drm_crtc.c:		ret = drm_mode_convert_umode(dev, mode, &crtc_req->mode);
drivers/gpu/drm/drm_crtc.c:		ret = drm_crtc_check_viewport(crtc, crtc_req->x, crtc_req->y,
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->count_connectors == 0 && mode) {
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->count_connectors > 0 && (!mode || !fb)) {
drivers/gpu/drm/drm_crtc.c:			  crtc_req->count_connectors);
drivers/gpu/drm/drm_crtc.c:	if (crtc_req->count_connectors > 0) {
drivers/gpu/drm/drm_crtc.c:		if (crtc_req->count_connectors > config->num_connector) {
drivers/gpu/drm/drm_crtc.c:		connector_set = kmalloc_array(crtc_req->count_connectors,
drivers/gpu/drm/drm_crtc.c:		for (i = 0; i < crtc_req->count_connectors; i++) {
drivers/gpu/drm/drm_crtc.c:			set_connectors_ptr = (uint32_t __user *)(unsigned long)crtc_req->set_connectors_ptr;
drivers/gpu/drm/drm_crtc.c:	set.x = crtc_req->x;
drivers/gpu/drm/drm_crtc.c:	set.y = crtc_req->y;
drivers/gpu/drm/drm_crtc.c:	set.num_connectors = crtc_req->count_connectors;
drivers/gpu/drm/drm_crtc.c:		for (i = 0; i < crtc_req->count_connectors; i++) {
drivers/gpu/drm/drm_dp_mst_topology.c:	buf[idx++] = req->req_type & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:	switch (req->req_type) {
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.port_num.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.allocate_payload.port_number & 0xf) << 4 |
drivers/gpu/drm/drm_dp_mst_topology.c:			(req->u.allocate_payload.number_sdp_streams & 0xf);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.allocate_payload.vcpi & 0x7f);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.allocate_payload.pbn >> 8);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.allocate_payload.pbn & 0xff);
drivers/gpu/drm/drm_dp_mst_topology.c:		for (i = 0; i < req->u.allocate_payload.number_sdp_streams / 2; i++) {
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] = ((req->u.allocate_payload.sdp_stream_sink[i * 2] & 0xf) << 4) |
drivers/gpu/drm/drm_dp_mst_topology.c:				(req->u.allocate_payload.sdp_stream_sink[i * 2 + 1] & 0xf);
drivers/gpu/drm/drm_dp_mst_topology.c:		if (req->u.allocate_payload.number_sdp_streams & 1) {
drivers/gpu/drm/drm_dp_mst_topology.c:			i = req->u.allocate_payload.number_sdp_streams - 1;
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] = (req->u.allocate_payload.sdp_stream_sink[i] & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.query_payload.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.query_payload.vcpi & 0x7f);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_read.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] |= ((req->u.dpcd_read.dpcd_address & 0xf0000) >> 16) & 0xf;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_read.dpcd_address & 0xff00) >> 8;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_read.dpcd_address & 0xff);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_read.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_write.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] |= ((req->u.dpcd_write.dpcd_address & 0xf0000) >> 16) & 0xf;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_write.dpcd_address & 0xff00) >> 8;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_write.dpcd_address & 0xff);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.dpcd_write.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		memcpy(&buf[idx], req->u.dpcd_write.bytes, req->u.dpcd_write.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		idx += req->u.dpcd_write.num_bytes;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_read.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] |= (req->u.i2c_read.num_transactions & 0x3);
drivers/gpu/drm/drm_dp_mst_topology.c:		for (i = 0; i < (req->u.i2c_read.num_transactions & 0x3); i++) {
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] = req->u.i2c_read.transactions[i].i2c_dev_id & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] = req->u.i2c_read.transactions[i].num_bytes;
drivers/gpu/drm/drm_dp_mst_topology.c:			memcpy(&buf[idx], req->u.i2c_read.transactions[i].bytes, req->u.i2c_read.transactions[i].num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:			idx += req->u.i2c_read.transactions[i].num_bytes;
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] = (req->u.i2c_read.transactions[i].no_stop_bit & 0x1) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:			buf[idx] |= (req->u.i2c_read.transactions[i].i2c_transaction_delay & 0xf);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_read.read_i2c_device_id) & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_read.num_bytes_read);
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_write.port_number & 0xf) << 4;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_write.write_i2c_device_id) & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:		buf[idx] = (req->u.i2c_write.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		memcpy(&buf[idx], req->u.i2c_write.bytes, req->u.i2c_write.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		idx += req->u.i2c_write.num_bytes;
drivers/gpu/drm/drm_dp_mst_topology.c:		msg = &req->u.enc_status;
drivers/gpu/drm/drm_dp_mst_topology.c:	req->req_type = buf[idx++] & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:	switch (req->req_type) {
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.port_num.port_number = (buf[idx] >> 4) & 0xf;
drivers/gpu/drm/drm_dp_mst_topology.c:				&req->u.allocate_payload;
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.query_payload.port_number = (buf[idx] >> 4) & 0xf;
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.query_payload.vcpi = buf[idx] & 0x7f;
drivers/gpu/drm/drm_dp_mst_topology.c:			struct drm_dp_remote_dpcd_read *r = &req->u.dpcd_read;
drivers/gpu/drm/drm_dp_mst_topology.c:				&req->u.dpcd_write;
drivers/gpu/drm/drm_dp_mst_topology.c:			struct drm_dp_remote_i2c_read *r = &req->u.i2c_read;
drivers/gpu/drm/drm_dp_mst_topology.c:			struct drm_dp_remote_i2c_write *w = &req->u.i2c_write;
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.enc_status.stream_id = buf[idx++];
drivers/gpu/drm/drm_dp_mst_topology.c:		for (i = 0; i < sizeof(req->u.enc_status.client_id); i++)
drivers/gpu/drm/drm_dp_mst_topology.c:			req->u.enc_status.client_id[i] = buf[idx++];
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.enc_status.stream_event = FIELD_GET(GENMASK(1, 0),
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.enc_status.valid_stream_event = FIELD_GET(BIT(2),
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.enc_status.stream_behavior = FIELD_GET(GENMASK(4, 3),
drivers/gpu/drm/drm_dp_mst_topology.c:		req->u.enc_status.valid_stream_behavior = FIELD_GET(BIT(5),
drivers/gpu/drm/drm_dp_mst_topology.c:	if (req->req_type == DP_LINK_ADDRESS) {
drivers/gpu/drm/drm_dp_mst_topology.c:		P("type=%s\n", drm_dp_mst_req_type_str(req->req_type));
drivers/gpu/drm/drm_dp_mst_topology.c:	P("type=%s contents:\n", drm_dp_mst_req_type_str(req->req_type));
drivers/gpu/drm/drm_dp_mst_topology.c:	switch (req->req_type) {
drivers/gpu/drm/drm_dp_mst_topology.c:		P("port=%d\n", req->u.port_num.port_number);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.allocate_payload.port_number,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.allocate_payload.vcpi, req->u.allocate_payload.pbn,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.allocate_payload.number_sdp_streams,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.allocate_payload.number_sdp_streams,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.allocate_payload.sdp_stream_sink);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.query_payload.port_number,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.query_payload.vcpi);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_read.port_number, req->u.dpcd_read.dpcd_address,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_read.num_bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_write.port_number,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_write.dpcd_address,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_write.num_bytes, req->u.dpcd_write.num_bytes,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.dpcd_write.bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_read.port_number,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_read.num_transactions,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_read.read_i2c_device_id,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_read.num_bytes_read);
drivers/gpu/drm/drm_dp_mst_topology.c:		for (i = 0; i < req->u.i2c_read.num_transactions; i++) {
drivers/gpu/drm/drm_dp_mst_topology.c:				&req->u.i2c_read.transactions[i];
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_write.port_number,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_write.write_i2c_device_id,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_write.num_bytes, req->u.i2c_write.num_bytes,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.i2c_write.bytes);
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.enc_status.stream_id,
drivers/gpu/drm/drm_dp_mst_topology.c:		  (int)ARRAY_SIZE(req->u.enc_status.client_id),
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.enc_status.client_id, req->u.enc_status.stream_event,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.enc_status.valid_stream_event,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.enc_status.stream_behavior,
drivers/gpu/drm/drm_dp_mst_topology.c:		  req->u.enc_status.valid_stream_behavior);
drivers/gpu/drm/drm_dp_mst_topology.c:	struct drm_dp_sideband_msg_req_body *msg = &up_req->msg;
drivers/gpu/drm/drm_dp_mst_topology.c:	struct drm_dp_sideband_msg_hdr *hdr = &up_req->hdr;
drivers/gpu/drm/drm_dp_mst_topology.c:			list_del(&up_req->next);
drivers/gpu/drm/drm_dp_mst_topology.c:	INIT_LIST_HEAD(&up_req->next);
drivers/gpu/drm/drm_dp_mst_topology.c:	drm_dp_sideband_parse_req(&mgr->up_req_recv, &up_req->msg);
drivers/gpu/drm/drm_dp_mst_topology.c:	if (up_req->msg.req_type != DP_CONNECTION_STATUS_NOTIFY &&
drivers/gpu/drm/drm_dp_mst_topology.c:	    up_req->msg.req_type != DP_RESOURCE_STATUS_NOTIFY) {
drivers/gpu/drm/drm_dp_mst_topology.c:			      up_req->msg.req_type);
drivers/gpu/drm/drm_dp_mst_topology.c:	drm_dp_send_up_ack_reply(mgr, mgr->mst_primary, up_req->msg.req_type,
drivers/gpu/drm/drm_dp_mst_topology.c:	if (up_req->msg.req_type == DP_CONNECTION_STATUS_NOTIFY) {
drivers/gpu/drm/drm_dp_mst_topology.c:			&up_req->msg.u.conn_stat;
drivers/gpu/drm/drm_dp_mst_topology.c:	} else if (up_req->msg.req_type == DP_RESOURCE_STATUS_NOTIFY) {
drivers/gpu/drm/drm_dp_mst_topology.c:			&up_req->msg.u.resource_stat;
drivers/gpu/drm/drm_dp_mst_topology.c:	up_req->hdr = mgr->up_req_recv.initial_hdr;
drivers/gpu/drm/drm_dp_mst_topology.c:	list_add_tail(&up_req->next, &mgr->up_req_list);
drivers/gpu/drm/amd/pm/swsmu/smu11/smu_v11_0.c:	enum amd_pp_clock_type clk_type = clock_req->clock_type;
drivers/gpu/drm/amd/pm/swsmu/smu11/smu_v11_0.c:	uint32_t clk_freq = clock_req->clock_freq_in_khz / 1000;
drivers/gpu/drm/amd/pm/swsmu/smu11/sienna_cichlid_ppt.c:	req->I2CcontrollerPort = 1;
drivers/gpu/drm/amd/pm/swsmu/smu11/sienna_cichlid_ppt.c:	req->I2CSpeed = 2;
drivers/gpu/drm/amd/pm/swsmu/smu11/sienna_cichlid_ppt.c:	req->SlaveAddress = address;
drivers/gpu/drm/amd/pm/swsmu/smu11/sienna_cichlid_ppt.c:	req->NumCmds = numbytes;
drivers/gpu/drm/amd/pm/swsmu/smu11/sienna_cichlid_ppt.c:		SwI2cCmd_t *cmd =  &req->SwI2cCmds[i];
drivers/gpu/drm/amd/pm/swsmu/smu11/arcturus_ppt.c:	req->I2CcontrollerPort = 0;
drivers/gpu/drm/amd/pm/swsmu/smu11/arcturus_ppt.c:	req->I2CSpeed = 2;
drivers/gpu/drm/amd/pm/swsmu/smu11/arcturus_ppt.c:	req->SlaveAddress = address;
drivers/gpu/drm/amd/pm/swsmu/smu11/arcturus_ppt.c:	req->NumCmds = numbytes;
drivers/gpu/drm/amd/pm/swsmu/smu11/arcturus_ppt.c:		SwI2cCmd_t *cmd =  &req->SwI2cCmds[i];
drivers/gpu/drm/amd/pm/powerplay/hwmgr/smu10_hwmgr.c:	enum amd_pp_clock_type clk_type = clock_req->clock_type;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/smu10_hwmgr.c:	uint32_t clk_freq = clock_req->clock_freq_in_khz / 1000;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega10_hwmgr.c:	enum amd_pp_clock_type clk_type = clock_req->clock_type;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega10_hwmgr.c:	uint32_t clk_freq = clock_req->clock_freq_in_khz / 1000;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega20_hwmgr.c:	enum amd_pp_clock_type clk_type = clock_req->clock_type;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega20_hwmgr.c:	uint32_t clk_freq = clock_req->clock_freq_in_khz / 1000;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega12_hwmgr.c:	enum amd_pp_clock_type clk_type = clock_req->clock_type;
drivers/gpu/drm/amd/pm/powerplay/hwmgr/vega12_hwmgr.c:	uint32_t clk_freq = clock_req->clock_freq_in_khz / 1000;
drivers/gpu/drm/amd/amdgpu/amdgpu_acpi.c:	DRM_DEBUG_DRIVER("SBIOS pending requests: %#x\n", req->pending);
drivers/gpu/drm/amd/amdgpu/amdgpu_acpi.c:	count = hweight32(req->pending);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_pp_smu.c:	pp_clock_request.clock_type = dc_to_pp_clock_type(clock_for_voltage_req->clk_type);
drivers/gpu/drm/amd/display/amdgpu_dm/amdgpu_dm_pp_smu.c:	pp_clock_request.clock_freq_in_khz = clock_for_voltage_req->clocks_in_khz;
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:		switch (req->action) {
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:				req->address, req->length, req->data);
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:				req->address, req->length, req->data);
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:		(req->action == DCE_I2C_TRANSACTION_ACTION_I2C_WRITE) ||
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:		(req->action == DCE_I2C_TRANSACTION_ACTION_I2C_READ))
drivers/gpu/drm/amd/display/dc/dce/dce_i2c_sw.c:	req->status = result ?
drivers/gpu/drm/sun4i/sun8i_hdmi_phy_clk.c:	unsigned long rate = req->rate;
drivers/gpu/drm/sun4i/sun8i_hdmi_phy_clk.c:	req->rate = best_rate / best_div;
drivers/gpu/drm/sun4i/sun8i_hdmi_phy_clk.c:	req->best_parent_rate = best_rate;
drivers/gpu/drm/sun4i/sun8i_hdmi_phy_clk.c:	req->best_parent_hw = best_parent;
drivers/gpu/drm/sun4i/sun4i_hdmi_tmds_clk.c:	unsigned long rate = req->rate;
drivers/gpu/drm/sun4i/sun4i_hdmi_tmds_clk.c:	req->rate = best_parent / best_half / best_div;
drivers/gpu/drm/sun4i/sun4i_hdmi_tmds_clk.c:	req->best_parent_rate = best_parent;
drivers/gpu/drm/sun4i/sun4i_hdmi_tmds_clk.c:	req->best_parent_hw = parent;
drivers/gpu/drm/drm_plane.c:	plane = drm_plane_find(dev, file_priv, plane_req->plane_id);
drivers/gpu/drm/drm_plane.c:			      plane_req->plane_id);
drivers/gpu/drm/drm_plane.c:	if (plane_req->fb_id) {
drivers/gpu/drm/drm_plane.c:		fb = drm_framebuffer_lookup(dev, file_priv, plane_req->fb_id);
drivers/gpu/drm/drm_plane.c:				      plane_req->fb_id);
drivers/gpu/drm/drm_plane.c:		crtc = drm_crtc_find(dev, file_priv, plane_req->crtc_id);
drivers/gpu/drm/drm_plane.c:				      plane_req->crtc_id);
drivers/gpu/drm/drm_plane.c:				plane_req->crtc_x, plane_req->crtc_y,
drivers/gpu/drm/drm_plane.c:				plane_req->crtc_w, plane_req->crtc_h,
drivers/gpu/drm/drm_plane.c:				plane_req->src_x, plane_req->src_y,
drivers/gpu/drm/drm_plane.c:				plane_req->src_w, plane_req->src_h);
drivers/gpu/drm/drm_plane.c:		.width = req->width,
drivers/gpu/drm/drm_plane.c:		.height = req->height,
drivers/gpu/drm/drm_plane.c:		.pitches = { req->width * 4 },
drivers/gpu/drm/drm_plane.c:		.handles = { req->handle },
drivers/gpu/drm/drm_plane.c:	if (req->flags & DRM_MODE_CURSOR_BO) {
drivers/gpu/drm/drm_plane.c:		if (req->handle) {
drivers/gpu/drm/drm_plane.c:			fb->hot_x = req->hot_x;
drivers/gpu/drm/drm_plane.c:			fb->hot_y = req->hot_y;
drivers/gpu/drm/drm_plane.c:	if (req->flags & DRM_MODE_CURSOR_MOVE) {
drivers/gpu/drm/drm_plane.c:		crtc_x = req->x;
drivers/gpu/drm/drm_plane.c:		crtc_y = req->y;
drivers/gpu/drm/drm_plane.c:	if (ret == 0 && req->flags & DRM_MODE_CURSOR_MOVE) {
drivers/gpu/drm/drm_plane.c:		crtc->cursor_x = req->x;
drivers/gpu/drm/drm_plane.c:		crtc->cursor_y = req->y;
drivers/gpu/drm/drm_plane.c:	if (!req->flags || (~DRM_MODE_CURSOR_FLAGS & req->flags))
drivers/gpu/drm/drm_plane.c:	crtc = drm_crtc_find(dev, file_priv, req->crtc_id);
drivers/gpu/drm/drm_plane.c:		DRM_DEBUG_KMS("Unknown CRTC ID %d\n", req->crtc_id);
drivers/gpu/drm/drm_plane.c:	if (req->flags & DRM_MODE_CURSOR_BO) {
drivers/gpu/drm/drm_plane.c:			ret = crtc->funcs->cursor_set2(crtc, file_priv, req->handle,
drivers/gpu/drm/drm_plane.c:						      req->width, req->height, req->hot_x, req->hot_y);
drivers/gpu/drm/drm_plane.c:			ret = crtc->funcs->cursor_set(crtc, file_priv, req->handle,
drivers/gpu/drm/drm_plane.c:						      req->width, req->height);
drivers/gpu/drm/drm_plane.c:	if (req->flags & DRM_MODE_CURSOR_MOVE) {
drivers/gpu/drm/drm_plane.c:			ret = crtc->funcs->cursor_move(crtc, req->x, req->y);
drivers/hid/uhid.c:	if (req->err) {
drivers/hid/uhid.c:		ret = min3(count, (size_t)req->size, (size_t)UHID_DATA_MAX);
drivers/hid/uhid.c:		memcpy(buf, req->data, ret);
drivers/ide/ide-probe.c:	req->special = NULL;
drivers/ide/ide-probe.c:	scsi_req_init(&req->sreq);
drivers/ide/ide-probe.c:	req->sreq.sense = req->sense;
drivers/ide/ide-cd.c:		req->cmd[0] = GPCMD_READ_10;
drivers/ide/ide-cd.c:		req->cmd[0] = GPCMD_WRITE_10;
drivers/ide/ide-cd.c:	req->cmd[2] = (block >> 24) & 0xff;
drivers/ide/ide-cd.c:	req->cmd[3] = (block >> 16) & 0xff;
drivers/ide/ide-cd.c:	req->cmd[4] = (block >>  8) & 0xff;
drivers/ide/ide-cd.c:	req->cmd[5] = block & 0xff;
drivers/ide/ide-cd.c:	req->cmd[7] = (blocks >> 8) & 0xff;
drivers/ide/ide-cd.c:	req->cmd[8] = blocks & 0xff;
drivers/ide/ide-cd.c:	req->cmd_len = 10;
drivers/ide/ide-tape.c:		      req->cmd[0], (unsigned long long)blk_rq_pos(rq),
drivers/ide/ide-tape.c:	    (req->cmd[13] & REQ_IDETAPE_PC2) == 0)
drivers/ide/ide-tape.c:			if (req->cmd[13] & REQ_IDETAPE_PC2) {
drivers/ide/ide-tape.c:	if (req->cmd[13] & REQ_IDETAPE_READ) {
drivers/ide/ide-tape.c:	if (req->cmd[13] & REQ_IDETAPE_WRITE) {
drivers/ide/ide-tape.c:	if (req->cmd[13] & REQ_IDETAPE_PC1) {
drivers/ide/ide-tape.c:		req->cmd[13] &= ~(REQ_IDETAPE_PC1);
drivers/ide/ide-tape.c:		req->cmd[13] |= REQ_IDETAPE_PC2;
drivers/ide/ide-tape.c:	if (req->cmd[13] & REQ_IDETAPE_PC2) {
drivers/ide/ide-disk.c:	addr_req--;
drivers/ide/ide-atapi.c:	req->cmd[0] = GPCMD_REQUEST_SENSE;
drivers/ide/ide-atapi.c:	req->cmd[4] = cmd_len;
drivers/ide/ide-atapi.c:		req->cmd[13] = REQ_IDETAPE_PC1;
drivers/firewire/core-cdev.c:		req->type	= FW_CDEV_EVENT_REQUEST;
drivers/firewire/core-cdev.c:		req->tcode	= tcode;
drivers/firewire/core-cdev.c:		req->offset	= offset;
drivers/firewire/core-cdev.c:		req->length	= length;
drivers/firewire/core-cdev.c:		req->handle	= r->resource.handle;
drivers/firewire/core-cdev.c:		req->closure	= handler->closure;
drivers/firewire/core-cdev.c:		req->type	= FW_CDEV_EVENT_REQUEST2;
drivers/firewire/core-cdev.c:		req->tcode	= tcode;
drivers/firewire/core-cdev.c:		req->offset	= offset;
drivers/firewire/core-cdev.c:		req->source_node_id = source;
drivers/firewire/core-cdev.c:		req->destination_node_id = destination;
drivers/firewire/core-cdev.c:		req->card	= card->index;
drivers/firewire/core-cdev.c:		req->generation	= generation;
drivers/firewire/core-cdev.c:		req->length	= length;
drivers/firewire/core-cdev.c:		req->handle	= r->resource.handle;
drivers/firewire/core-cdev.c:		req->closure	= handler->closure;
drivers/staging/ks7010/ks_wlan_net.c:		len = min_t(int, req->essid_len, IW_ESSID_MAX_SIZE);
drivers/staging/ks7010/ks_wlan_net.c:		memcpy(priv->scan_ssid, req->essid, len);
drivers/staging/ks7010/ks_hostif.c:	for (i = 0; i < le16_to_cpu(assoc_req->req_ies_size); i++)
drivers/staging/ks7010/ks_hostif.c:	wrqu.data.length += (le16_to_cpu(assoc_req->req_ies_size)) * 2;
drivers/staging/ks7010/ks_hostif.c:	pb += le16_to_cpu(assoc_req->req_ies_size);
drivers/staging/ks7010/ks_hostif.c:	req->phy_type = cpu_to_le16(priv->reg.phy_type);
drivers/staging/ks7010/ks_hostif.c:	req->cts_mode = cpu_to_le16(priv->reg.cts_mode);
drivers/staging/ks7010/ks_hostif.c:	req->scan_type = cpu_to_le16(priv->reg.scan_type);
drivers/staging/ks7010/ks_hostif.c:	req->rate_set.size = priv->reg.rate_set.size;
drivers/staging/ks7010/ks_hostif.c:	req->capability = ks_wlan_cap(priv);
drivers/staging/ks7010/ks_hostif.c:	memcpy(&req->rate_set.body[0], &priv->reg.rate_set.body[0],
drivers/staging/rtl8192u/r8192U_wx.c:		if (req->essid_len) {
drivers/staging/rtl8192u/r8192U_wx.c:			int len = min_t(int, req->essid_len, IW_ESSID_MAX_SIZE);
drivers/staging/rtl8192u/r8192U_wx.c:			memcpy(ieee->current_network.ssid, req->essid, len);
drivers/staging/rtl8192u/ieee80211/rtl819x_BAProc.c:	dst = &req->addr2[0];
drivers/staging/rtl8192u/ieee80211/ieee80211_softmac.c:	req->header.frame_ctl = cpu_to_le16(IEEE80211_STYPE_PROBE_REQ);
drivers/staging/rtl8192u/ieee80211/ieee80211_softmac.c:	req->header.duration_id = 0; /* FIXME: is this OK? */
drivers/staging/rtl8192u/ieee80211/ieee80211_softmac.c:	eth_broadcast_addr(req->header.addr1);
drivers/staging/rtl8192u/ieee80211/ieee80211_softmac.c:	memcpy(req->header.addr2, ieee->dev->dev_addr, ETH_ALEN);
drivers/staging/rtl8192u/ieee80211/ieee80211_softmac.c:	eth_broadcast_addr(req->header.addr3);
drivers/staging/media/rkvdec/rkvdec.c:	list_for_each_entry(obj, &req->objects, list) {
drivers/staging/media/atomisp/pci/atomisp_ioctl.c:	if (req->count == 0) {
drivers/staging/media/atomisp/pci/atomisp_ioctl.c:	if (req->memory == V4L2_MEMORY_USERPTR)
drivers/staging/media/atomisp/pci/atomisp_ioctl.c:	for (i = 0; i < req->count; i++) {
drivers/staging/media/atomisp/pci/atomisp_ioctl.c:	if (req->count == 0) {
drivers/staging/media/sunxi/cedrus/cedrus.c:	list_for_each_entry(obj, &req->objects, list) {
drivers/staging/rtl8192e/rtl819x_BAProc.c:	dst = (u8 *)(&req->addr2[0]);
drivers/staging/rtl8192e/rtl8192e/rtl_wx.c:		if (req->essid_len) {
drivers/staging/rtl8192e/rtl8192e/rtl_wx.c:			int len = min_t(int, req->essid_len, IW_ESSID_MAX_SIZE);
drivers/staging/rtl8192e/rtl8192e/rtl_wx.c:			memcpy(ieee->current_network.ssid, req->essid, len);
drivers/staging/rtl8192e/rtllib_softmac.c:	req->header.frame_ctl = cpu_to_le16(RTLLIB_STYPE_PROBE_REQ);
drivers/staging/rtl8192e/rtllib_softmac.c:	req->header.duration_id = 0;
drivers/staging/rtl8192e/rtllib_softmac.c:	eth_broadcast_addr(req->header.addr1);
drivers/staging/rtl8192e/rtllib_softmac.c:	ether_addr_copy(req->header.addr2, ieee->dev->dev_addr);
drivers/staging/rtl8192e/rtllib_softmac.c:	eth_broadcast_addr(req->header.addr3);
drivers/staging/rtl8723bs/core/rtw_wlan_util.c:		start_seq = le16_to_cpu(preq->BA_starting_seqctrl) >> 4;
drivers/staging/rtl8723bs/core/rtw_wlan_util.c:		param = le16_to_cpu(preq->BA_para_set);
drivers/staging/rtl8723bs/os_dep/ioctl_linux.c:			int len = min((int)req->essid_len, IW_ESSID_MAX_SIZE);
drivers/staging/rtl8723bs/os_dep/ioctl_linux.c:			memcpy(ssid[0].Ssid, req->essid, len);
drivers/staging/rtl8723bs/os_dep/ioctl_linux.c:			DBG_871X("IW_SCAN_THIS_ESSID, ssid =%s, len =%d\n", req->essid, req->essid_len);
drivers/staging/rtl8723bs/os_dep/ioctl_linux.c:		} else if (req->scan_type == IW_SCAN_TYPE_PASSIVE) {
drivers/staging/rtl8723bs/os_dep/ioctl_linux.c:			DBG_871X("rtw_wx_set_scan, req->scan_type == IW_SCAN_TYPE_PASSIVE\n");
drivers/staging/emxx_udc/emxx_udc.c:	udc = (struct nbu2ss_udc *)_req->context;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.dma == DMA_ADDR_INVALID) {
drivers/staging/emxx_udc/emxx_udc.c:		if (req->unaligned) {
drivers/staging/emxx_udc/emxx_udc.c:			req->req.dma = ep->phys_buf;
drivers/staging/emxx_udc/emxx_udc.c:			req->req.dma = dma_map_single(udc->gadget.dev.parent,
drivers/staging/emxx_udc/emxx_udc.c:						      req->req.buf,
drivers/staging/emxx_udc/emxx_udc.c:						      req->req.length,
drivers/staging/emxx_udc/emxx_udc.c:		req->mapped = 1;
drivers/staging/emxx_udc/emxx_udc.c:		if (!req->unaligned)
drivers/staging/emxx_udc/emxx_udc.c:						   req->req.dma,
drivers/staging/emxx_udc/emxx_udc.c:						   req->req.length,
drivers/staging/emxx_udc/emxx_udc.c:		req->mapped = 0;
drivers/staging/emxx_udc/emxx_udc.c:		count = req->req.actual % 4;
drivers/staging/emxx_udc/emxx_udc.c:			p = req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:			p += (req->req.actual - count);
drivers/staging/emxx_udc/emxx_udc.c:	if (req->mapped) {
drivers/staging/emxx_udc/emxx_udc.c:		if (req->unaligned) {
drivers/staging/emxx_udc/emxx_udc.c:				memcpy(req->req.buf, ep->virt_buf,
drivers/staging/emxx_udc/emxx_udc.c:				       req->req.actual & 0xfffffffc);
drivers/staging/emxx_udc/emxx_udc.c:					 req->req.dma, req->req.length,
drivers/staging/emxx_udc/emxx_udc.c:		req->req.dma = DMA_ADDR_INVALID;
drivers/staging/emxx_udc/emxx_udc.c:		req->mapped = 0;
drivers/staging/emxx_udc/emxx_udc.c:		if (!req->unaligned)
drivers/staging/emxx_udc/emxx_udc.c:						req->req.dma, req->req.length,
drivers/staging/emxx_udc/emxx_udc.c:		p = req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:		p += (req->req.actual - count);
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual == req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.actual % EP0_PACKETSIZE) == 0) {
drivers/staging/emxx_udc/emxx_udc.c:			if (req->zero) {
drivers/staging/emxx_udc/emxx_udc.c:				req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:	i_remain_size = req->req.length - req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer = (u8 *)req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer += req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = result;
drivers/staging/emxx_udc/emxx_udc.c:		req->div_len = result;
drivers/staging/emxx_udc/emxx_udc.c:		i_remain_size = req->req.length - req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:		p_buffer = (u8 *)req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:		p_buffer += req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:		req->req.actual += result;
drivers/staging/emxx_udc/emxx_udc.c:			req->req.actual += result;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual == req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.actual % EP0_PACKETSIZE) == 0) {
drivers/staging/emxx_udc/emxx_udc.c:			if (req->zero) {
drivers/staging/emxx_udc/emxx_udc.c:				req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:	if ((req->req.actual % EP0_PACKETSIZE) != 0)
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual > req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:	if (req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:	req->dma_flag = true;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer = req->req.dma;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer += req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = result;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer = (u8 *)req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:	p_buf_32 = (union usb_reg_access *)(p_buffer + req->req.actual);
drivers/staging/emxx_udc/emxx_udc.c:	req->req.actual += result;
drivers/staging/emxx_udc/emxx_udc.c:	if ((req->req.actual == req->req.length) ||
drivers/staging/emxx_udc/emxx_udc.c:	    ((req->req.actual % ep->ep.maxpacket) != 0)) {
drivers/staging/emxx_udc/emxx_udc.c:	i_buf_size = min((req->req.length - req->req.actual), data_size);
drivers/staging/emxx_udc/emxx_udc.c:	if ((ep->ep_type != USB_ENDPOINT_XFER_INT) && (req->req.dma != 0) &&
drivers/staging/emxx_udc/emxx_udc.c:				req->req.actual += result;
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.actual == req->req.length) ||
drivers/staging/emxx_udc/emxx_udc.c:		    ((req->req.actual % ep->ep.maxpacket) != 0)) {
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.actual % ep->ep.maxpacket) == 0) {
drivers/staging/emxx_udc/emxx_udc.c:			if (req->zero) {
drivers/staging/emxx_udc/emxx_udc.c:				req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual > req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:			req->req.actual, req->req.length);
drivers/staging/emxx_udc/emxx_udc.c:	if (req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual == 0)
drivers/staging/emxx_udc/emxx_udc.c:	req->dma_flag = true;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer = req->req.dma;
drivers/staging/emxx_udc/emxx_udc.c:	p_buffer += req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = result;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:		p_buffer = (u8 *)req->req.buf;
drivers/staging/emxx_udc/emxx_udc.c:		p_buf_32 = (union usb_reg_access *)(p_buffer + req->req.actual);
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = result;
drivers/staging/emxx_udc/emxx_udc.c:	if ((ep->ep_type != USB_ENDPOINT_XFER_INT) && (req->req.dma != 0) &&
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual == 0) {
drivers/staging/emxx_udc/emxx_udc.c:	i_buf_size = req->req.length - req->req.actual;
drivers/staging/emxx_udc/emxx_udc.c:	else if (req->req.length == 0)
drivers/staging/emxx_udc/emxx_udc.c:	req->dma_flag = false;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.length == 0) {
drivers/staging/emxx_udc/emxx_udc.c:		req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.length % ep->ep.maxpacket) == 0)
drivers/staging/emxx_udc/emxx_udc.c:			req->zero = req->req.zero;
drivers/staging/emxx_udc/emxx_udc.c:			req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:	req->req.actual += req->div_len;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:		req->req.status = nret;
drivers/staging/emxx_udc/emxx_udc.c:		if (req->req.complete)
drivers/staging/emxx_udc/emxx_udc.c:			req->req.complete(&ep->ep, &req->req);
drivers/staging/emxx_udc/emxx_udc.c:		if (req->req.complete)
drivers/staging/emxx_udc/emxx_udc.c:	list_del_init(&req->queue);
drivers/staging/emxx_udc/emxx_udc.c:	if (likely(req->req.status == -EINPROGRESS))
drivers/staging/emxx_udc/emxx_udc.c:		req->req.status = status;
drivers/staging/emxx_udc/emxx_udc.c:	    (req->req.dma != 0))
drivers/staging/emxx_udc/emxx_udc.c:	req->req.complete(&ep->ep, &req->req);
drivers/staging/emxx_udc/emxx_udc.c:	if (req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:	req->req.actual += req->div_len;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual != req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:		if (req->zero && ((req->req.actual % ep->ep.maxpacket) == 0)) {
drivers/staging/emxx_udc/emxx_udc.c:				req->zero = false;
drivers/staging/emxx_udc/emxx_udc.c:	preq = &req->req;
drivers/staging/emxx_udc/emxx_udc.c:	if (!req->dma_flag)
drivers/staging/emxx_udc/emxx_udc.c:	preq->actual += req->div_len;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:	req->dma_flag = false;
drivers/staging/emxx_udc/emxx_udc.c:	if (preq->actual != preq->length) {
drivers/staging/emxx_udc/emxx_udc.c:		size = preq->actual % mpkt;
drivers/staging/emxx_udc/emxx_udc.c:			if (((preq->actual & 0x03) == 0) && (size < mpkt))
drivers/staging/emxx_udc/emxx_udc.c:	if (req->req.actual == req->req.length) {
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->req.length % ep->ep.maxpacket) && !req->zero) {
drivers/staging/emxx_udc/emxx_udc.c:			req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:			req->dma_flag = false;
drivers/staging/emxx_udc/emxx_udc.c:		if ((req->div_len % mpkt) == 0)
drivers/staging/emxx_udc/emxx_udc.c:			req->div_len -= mpkt * dmacnt;
drivers/staging/emxx_udc/emxx_udc.c:	if ((req->req.actual % ep->ep.maxpacket) > 0) {
drivers/staging/emxx_udc/emxx_udc.c:		if (req->req.actual == req->div_len) {
drivers/staging/emxx_udc/emxx_udc.c:			req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:			req->dma_flag = false;
drivers/staging/emxx_udc/emxx_udc.c:	req->req.actual += req->div_len;
drivers/staging/emxx_udc/emxx_udc.c:	req->div_len = 0;
drivers/staging/emxx_udc/emxx_udc.c:	req->dma_flag = false;
drivers/staging/emxx_udc/emxx_udc.c:	req->req.dma = DMA_ADDR_INVALID;
drivers/staging/emxx_udc/emxx_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/staging/emxx_udc/emxx_udc.c:	return &req->req;
drivers/staging/emxx_udc/emxx_udc.c:	if (unlikely(!_req->complete ||
drivers/staging/emxx_udc/emxx_udc.c:		     !_req->buf ||
drivers/staging/emxx_udc/emxx_udc.c:		     !list_empty(&req->queue))) {
drivers/staging/emxx_udc/emxx_udc.c:		if (!_req->complete)
drivers/staging/emxx_udc/emxx_udc.c:			pr_err("udc: %s --- !_req->complete\n", __func__);
drivers/staging/emxx_udc/emxx_udc.c:		if (!_req->buf)
drivers/staging/emxx_udc/emxx_udc.c:			pr_err("udc:%s --- !_req->buf\n", __func__);
drivers/staging/emxx_udc/emxx_udc.c:		if (!list_empty(&req->queue))
drivers/staging/emxx_udc/emxx_udc.c:			pr_err("%s --- !list_empty(&req->queue)\n", __func__);
drivers/staging/emxx_udc/emxx_udc.c:	if ((uintptr_t)req->req.buf & 0x3)
drivers/staging/emxx_udc/emxx_udc.c:		req->unaligned = true;
drivers/staging/emxx_udc/emxx_udc.c:		req->unaligned = false;
drivers/staging/emxx_udc/emxx_udc.c:	if (req->unaligned) {
drivers/staging/emxx_udc/emxx_udc.c:				memcpy(ep->virt_buf, req->req.buf,
drivers/staging/emxx_udc/emxx_udc.c:				       req->req.length);
drivers/staging/emxx_udc/emxx_udc.c:	    (req->req.dma != 0))
drivers/staging/emxx_udc/emxx_udc.c:	_req->status = -EINPROGRESS;
drivers/staging/emxx_udc/emxx_udc.c:	_req->actual = 0;
drivers/staging/emxx_udc/emxx_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/staging/emxx_udc/emxx_udc.c:			list_del(&req->queue);
drivers/staging/emxx_udc/emxx_udc.c:			if (req->req.length < 4 &&
drivers/staging/emxx_udc/emxx_udc.c:			    req->req.length == req->req.actual)
drivers/staging/emxx_udc/emxx_udc.c:			if (req->req.length == req->req.actual)
drivers/staging/emxx_udc/emxx_udc.c:		if (&req->req == _req) {
drivers/staging/wfx/queue.c:		if (req->packet_id != packet_id)
drivers/staging/wfx/queue.c:				 req->packet_id,
drivers/staging/wfx/data_tx.c:	req->packet_id = atomic_add_return(1, &wvif->wdev->packet_id) & 0xFFFF;
drivers/staging/wfx/data_tx.c:	req->packet_id |= IEEE80211_SEQ_TO_SN(le16_to_cpu(hdr->seq_ctrl)) << 16;
drivers/staging/wfx/data_tx.c:	req->packet_id |= queue_id << 28;
drivers/staging/wfx/data_tx.c:	req->fc_offset = offset;
drivers/staging/wfx/data_tx.c:		req->after_dtim = 1;
drivers/staging/wfx/data_tx.c:	req->peer_sta_id = wfx_tx_get_link_id(wvif, sta, hdr);
drivers/staging/wfx/data_tx.c:	req->queue_id = 3 - queue_id;
drivers/staging/wfx/data_tx.c:	req->retry_policy_index = wfx_tx_get_rate_id(wvif, tx_info);
drivers/staging/wfx/data_tx.c:	req->frame_format = wfx_tx_get_frame_format(tx_info);
drivers/staging/wfx/data_tx.c:		req->short_gi = 1;
drivers/staging/wfx/data_tx.c:			      req->fc_offset;
drivers/staging/wfx/data_tx.c:	wfx_tx_policy_put(wvif, req->retry_policy_index);
drivers/staging/wfx/hif_tx.c:	WARN(req->n_ssids > HIF_API_MAX_NB_SSIDS, "invalid params");
drivers/staging/wfx/hif_tx.c:	for (i = 0; i < req->n_ssids; i++) {
drivers/staging/wfx/hif_tx.c:		memcpy(body->ssid_def[i].ssid, req->ssids[i].ssid,
drivers/staging/wfx/hif_tx.c:			cpu_to_le32(req->ssids[i].ssid_len);
drivers/staging/wfx/hif_tx.c:		cpu_to_le32(req->channels[chan_start_idx]->max_power);
drivers/staging/wfx/hif_tx.c:			req->channels[i + chan_start_idx]->hw_value;
drivers/staging/wfx/hif_tx.c:	if (req->no_cck)
drivers/staging/wfx/hif_tx.c:	if (req->channels[chan_start_idx]->flags & IEEE80211_CHAN_NO_IR) {
drivers/staging/wfx/scan.c:				     NULL, 0, req->ie_len);
drivers/staging/wfx/scan.c:	skb_put_data(skb, req->ie, req->ie_len);
drivers/staging/wfx/scan.c:	for (i = start_idx; i < req->n_channels; i++) {
drivers/staging/wfx/scan.c:		ch_start = req->channels[start_idx];
drivers/staging/wfx/scan.c:		ch_cur = req->channels[i];
drivers/staging/wfx/scan.c:	if (req->channels[start_idx]->max_power != wvif->vif->bss_conf.txpower)
drivers/staging/wfx/scan.c:	update_probe_tmpl(wvif, &hw_req->req);
drivers/staging/wfx/scan.c:		ret = send_scan_req(wvif, &hw_req->req, chan_cur);
drivers/staging/wfx/scan.c:	} while (ret > 0 && chan_cur < hw_req->req.n_channels);
drivers/staging/wfx/scan.c:	WARN_ON(hw_req->req.n_channels > HIF_API_MAX_NB_CHANNELS);
drivers/staging/greybus/fw-download.c:	dev_dbg(fw_req->fw_download->parent, "firmware %s released\n",
drivers/staging/greybus/fw-download.c:		fw_req->name);
drivers/staging/greybus/fw-download.c:	release_firmware(fw_req->fw);
drivers/staging/greybus/fw-download.c:	if (!fw_req->timedout)
drivers/staging/greybus/fw-download.c:		ida_simple_remove(&fw_req->fw_download->id_map,
drivers/staging/greybus/fw-download.c:				  fw_req->firmware_id);
drivers/staging/greybus/fw-download.c:	kref_put(&fw_req->kref, fw_req_release);
drivers/staging/greybus/fw-download.c:		if (fw_req->firmware_id == firmware_id) {
drivers/staging/greybus/fw-download.c:			kref_get(&fw_req->kref);
drivers/staging/greybus/fw-download.c:	if (fw_req->disabled)
drivers/staging/greybus/fw-download.c:	list_del(&fw_req->node);
drivers/staging/greybus/fw-download.c:	fw_req->disabled = true;
drivers/staging/greybus/fw-download.c:	struct fw_download *fw_download = fw_req->fw_download;
drivers/staging/greybus/fw-download.c:		fw_req->firmware_id);
drivers/staging/greybus/fw-download.c:	fw_req->timedout = true;
drivers/staging/greybus/fw-download.c:	struct fw_download *fw_download = fw_req->fw_download;
drivers/staging/greybus/fw-download.c:	if (time_before(jiffies, fw_req->release_timeout_j))
drivers/staging/greybus/fw-download.c:		fw_req->firmware_id);
drivers/staging/greybus/fw-download.c:	fw_req->timedout = true;
drivers/staging/greybus/fw-download.c:	fw_req->firmware_id = ret;
drivers/staging/greybus/fw-download.c:	snprintf(fw_req->name, sizeof(fw_req->name),
drivers/staging/greybus/fw-download.c:		 fw_req->name);
drivers/staging/greybus/fw-download.c:	ret = request_firmware(&fw_req->fw, fw_req->name, fw_download->parent);
drivers/staging/greybus/fw-download.c:			"firmware request failed for %s (%d)\n", fw_req->name,
drivers/staging/greybus/fw-download.c:	fw_req->fw_download = fw_download;
drivers/staging/greybus/fw-download.c:	kref_init(&fw_req->kref);
drivers/staging/greybus/fw-download.c:	list_add(&fw_req->node, &fw_download->fw_requests);
drivers/staging/greybus/fw-download.c:	req_count = DIV_ROUND_UP(fw_req->fw->size, MIN_FETCH_SIZE);
drivers/staging/greybus/fw-download.c:	fw_req->release_timeout_j = jiffies + req_count * NEXT_REQ_TIMEOUT_J;
drivers/staging/greybus/fw-download.c:	INIT_DELAYED_WORK(&fw_req->dwork, fw_request_timedout);
drivers/staging/greybus/fw-download.c:	schedule_delayed_work(&fw_req->dwork, NEXT_REQ_TIMEOUT_J);
drivers/staging/greybus/fw-download.c:	ida_simple_remove(&fw_download->id_map, fw_req->firmware_id);
drivers/staging/greybus/fw-download.c:	response->firmware_id = fw_req->firmware_id;
drivers/staging/greybus/fw-download.c:	response->size = cpu_to_le32(fw_req->fw->size);
drivers/staging/greybus/fw-download.c:		"firmware size is %zu bytes\n", fw_req->fw->size);
drivers/staging/greybus/fw-download.c:	cancel_delayed_work_sync(&fw_req->dwork);
drivers/staging/greybus/fw-download.c:	if (fw_req->disabled) {
drivers/staging/greybus/fw-download.c:	fw = fw_req->fw;
drivers/staging/greybus/fw-download.c:	schedule_delayed_work(&fw_req->dwork, NEXT_REQ_TIMEOUT_J);
drivers/staging/greybus/fw-download.c:	cancel_delayed_work_sync(&fw_req->dwork);
drivers/staging/greybus/fw-download.c:		kref_get(&fw_req->kref);
drivers/staging/greybus/fw-download.c:		cancel_delayed_work_sync(&fw_req->dwork);
drivers/staging/greybus/camera.c:	req_size = sizeof(*req) + nstreams * sizeof(req->config[0]);
drivers/staging/greybus/camera.c:	req->num_streams = nstreams;
drivers/staging/greybus/camera.c:	req->flags = *flags;
drivers/staging/greybus/camera.c:	req->padding = 0;
drivers/staging/greybus/camera.c:		struct gb_camera_stream_config_request *cfg = &req->config[i];
drivers/staging/greybus/camera.c:	    (req->flags & GB_CAMERA_CONFIGURE_STREAMS_TEST_ONLY))
drivers/staging/greybus/camera.c:	req->request_id = cpu_to_le32(request_id);
drivers/staging/greybus/camera.c:	req->streams = streams;
drivers/staging/greybus/camera.c:	req->padding = 0;
drivers/staging/greybus/camera.c:	req->num_frames = cpu_to_le16(num_frames);
drivers/staging/greybus/camera.c:	memcpy(req->settings, settings, settings_size);
drivers/staging/greybus/power_supply.c:	req->psy_id = gbpsy->id;
drivers/staging/greybus/audio_module.c:				    req->jack_attribute, req->event);
drivers/staging/greybus/audio_module.c:			     req->jack_attribute, req->event);
drivers/staging/greybus/audio_module.c:	if (req->event == GB_AUDIO_JACK_EVENT_REMOVAL) {
drivers/staging/greybus/audio_module.c:	report = req->jack_attribute & module->jack_mask;
drivers/staging/greybus/audio_module.c:				    req->jack_attribute, req->event);
drivers/staging/greybus/audio_module.c:				    req->button_id, req->event);
drivers/staging/greybus/audio_module.c:			     req->button_id, req->event);
drivers/staging/greybus/audio_module.c:	switch (req->button_id) {
drivers/staging/greybus/audio_module.c:	if (req->event == GB_AUDIO_BUTTON_EVENT_PRESS)
drivers/staging/greybus/audio_module.c:		 le16_to_cpu(req->data_cport), req->event);
drivers/staging/rtl8188eu/core/rtw_mlme_ext.c:						  &ADDBA_req->dialog_token,
drivers/staging/rtl8188eu/core/rtw_mlme_ext.c:			BA_para_set = le16_to_cpu(ADDBA_req->BA_para_set) &
drivers/staging/rtl8188eu/core/rtw_mlme_ext.c:						  &ADDBA_req->BA_timeout_value,
drivers/staging/rtl8188eu/core/rtw_wlan_util.c:		param = le16_to_cpu(preq->BA_para_set);
drivers/staging/rtl8188eu/os_dep/ioctl_linux.c:			int len = min_t(int, req->essid_len,
drivers/staging/rtl8188eu/os_dep/ioctl_linux.c:			memcpy(ssid[0].ssid, req->essid, len);
drivers/staging/rtl8188eu/os_dep/ioctl_linux.c:			DBG_88E("IW_SCAN_THIS_ESSID, ssid =%s, len =%d\n", req->essid, req->essid_len);
drivers/staging/rtl8188eu/os_dep/ioctl_linux.c:		} else if (req->scan_type == IW_SCAN_TYPE_PASSIVE) {
drivers/staging/rtl8188eu/os_dep/ioctl_linux.c:			DBG_88E("%s, req->scan_type == IW_SCAN_TYPE_PASSIVE\n", __func__);
drivers/staging/wlan-ng/p80211req.c:		if (req->decrypt.data == P80211ENUM_truth_true)
drivers/staging/wlan-ng/p80211req.c:		if (req->encrypt.data == P80211ENUM_truth_true)
drivers/staging/wlan-ng/p80211netdev.c:	netdev_dbg(dev, "rx'd ioctl, cmd=%d, len=%d\n", cmd, req->len);
drivers/staging/wlan-ng/p80211netdev.c:	if (req->magic != P80211_IOCTL_MAGIC) {
drivers/staging/wlan-ng/p80211netdev.c:	msgbuf = memdup_user(req->data, req->len);
drivers/staging/wlan-ng/p80211netdev.c:		    ((void __user *)req->data, msgbuf, req->len)) {
drivers/staging/wlan-ng/prism2mgmt.c:	req->resultcode.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:		req->resultcode.data = P80211ENUM_resultcode_invalid_parameters;
drivers/staging/wlan-ng/prism2mgmt.c:	if (req->bssindex.data >= count) {
drivers/staging/wlan-ng/prism2mgmt.c:			   req->bssindex.data, count);
drivers/staging/wlan-ng/prism2mgmt.c:		req->resultcode.data = P80211ENUM_resultcode_invalid_parameters;
drivers/staging/wlan-ng/prism2mgmt.c:	item = &hw->scanresults->info.hscanresult.result[req->bssindex.data];
drivers/staging/wlan-ng/prism2mgmt.c:	req->signal.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->noise.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->signal.data = le16_to_cpu(item->sl);
drivers/staging/wlan-ng/prism2mgmt.c:	req->noise.data = le16_to_cpu(item->anl);
drivers/staging/wlan-ng/prism2mgmt.c:	req->bssid.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->bssid.data.len = WLAN_BSSID_LEN;
drivers/staging/wlan-ng/prism2mgmt.c:	memcpy(req->bssid.data.data, item->bssid, WLAN_BSSID_LEN);
drivers/staging/wlan-ng/prism2mgmt.c:	req->ssid.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->ssid.data.len = le16_to_cpu(item->ssid.len);
drivers/staging/wlan-ng/prism2mgmt.c:	req->ssid.data.len = min_t(u16, req->ssid.data.len, WLAN_SSID_MAXLEN);
drivers/staging/wlan-ng/prism2mgmt.c:	memcpy(req->ssid.data.data, item->ssid.data, req->ssid.data.len);
drivers/staging/wlan-ng/prism2mgmt.c:			req->basicrate ## N .data = item->supprates[(N) - 1]; \
drivers/staging/wlan-ng/prism2mgmt.c:			req->basicrate ## N .status = \
drivers/staging/wlan-ng/prism2mgmt.c:			req->supprate ## N .data = item->supprates[(N) - 1]; \
drivers/staging/wlan-ng/prism2mgmt.c:			req->supprate ## N .status = \
drivers/staging/wlan-ng/prism2mgmt.c:	req->beaconperiod.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->beaconperiod.data = le16_to_cpu(item->bcnint);
drivers/staging/wlan-ng/prism2mgmt.c:	req->timestamp.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->timestamp.data = jiffies;
drivers/staging/wlan-ng/prism2mgmt.c:	req->localtime.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->localtime.data = jiffies;
drivers/staging/wlan-ng/prism2mgmt.c:	req->ibssatimwindow.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->ibssatimwindow.data = le16_to_cpu(item->atim);
drivers/staging/wlan-ng/prism2mgmt.c:	req->dschannel.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->dschannel.data = le16_to_cpu(item->chid);
drivers/staging/wlan-ng/prism2mgmt.c:	req->capinfo.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->capinfo.data = count;
drivers/staging/wlan-ng/prism2mgmt.c:	req->privacy.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->privacy.data = WLAN_GET_MGMT_CAP_INFO_PRIVACY(count);
drivers/staging/wlan-ng/prism2mgmt.c:	req->cfpollable.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->cfpollable.data = WLAN_GET_MGMT_CAP_INFO_CFPOLLABLE(count);
drivers/staging/wlan-ng/prism2mgmt.c:	req->cfpollreq.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->cfpollreq.data = WLAN_GET_MGMT_CAP_INFO_CFPOLLREQ(count);
drivers/staging/wlan-ng/prism2mgmt.c:	req->bsstype.status = P80211ENUM_msgitem_status_data_ok;
drivers/staging/wlan-ng/prism2mgmt.c:	req->bsstype.data = (WLAN_GET_MGMT_CAP_INFO_ESS(count)) ?
drivers/staging/wlan-ng/prism2mgmt.c:	req->resultcode.data = P80211ENUM_resultcode_success;
drivers/staging/rtl8712/rtl871x_io.c:		INIT_LIST_HEAD(&pio_req->list);
drivers/staging/rtl8712/rtl871x_io.c:		list_add_tail(&pio_req->list, &pio_queue->free_ioreqs);
drivers/staging/rtl8712/rtl871x_ioctl_linux.c:			u32 len = min_t(u8, req->essid_len, IW_ESSID_MAX_SIZE);
drivers/staging/rtl8712/rtl871x_ioctl_linux.c:			memcpy(ssid.Ssid, req->essid, len);
drivers/input/touchscreen/ads7846.c:	spi_message_init(&req->msg);
drivers/input/touchscreen/ads7846.c:		req->ref_on = REF_ON;
drivers/input/touchscreen/ads7846.c:		req->xfer[0].tx_buf = &req->ref_on;
drivers/input/touchscreen/ads7846.c:		req->xfer[0].len = 1;
drivers/input/touchscreen/ads7846.c:		spi_message_add_tail(&req->xfer[0], &req->msg);
drivers/input/touchscreen/ads7846.c:		req->xfer[1].rx_buf = &req->scratch;
drivers/input/touchscreen/ads7846.c:		req->xfer[1].len = 2;
drivers/input/touchscreen/ads7846.c:		req->xfer[1].delay.value = ts->vref_delay_usecs;
drivers/input/touchscreen/ads7846.c:		req->xfer[1].delay.unit = SPI_DELAY_UNIT_USECS;
drivers/input/touchscreen/ads7846.c:		spi_message_add_tail(&req->xfer[1], &req->msg);
drivers/input/touchscreen/ads7846.c:	req->command = (u8) command;
drivers/input/touchscreen/ads7846.c:	req->xfer[2].tx_buf = &req->command;
drivers/input/touchscreen/ads7846.c:	req->xfer[2].len = 1;
drivers/input/touchscreen/ads7846.c:	spi_message_add_tail(&req->xfer[2], &req->msg);
drivers/input/touchscreen/ads7846.c:	req->xfer[3].rx_buf = &req->sample;
drivers/input/touchscreen/ads7846.c:	req->xfer[3].len = 2;
drivers/input/touchscreen/ads7846.c:	spi_message_add_tail(&req->xfer[3], &req->msg);
drivers/input/touchscreen/ads7846.c:	req->ref_off = PWRDOWN;
drivers/input/touchscreen/ads7846.c:	req->xfer[4].tx_buf = &req->ref_off;
drivers/input/touchscreen/ads7846.c:	req->xfer[4].len = 1;
drivers/input/touchscreen/ads7846.c:	spi_message_add_tail(&req->xfer[4], &req->msg);
drivers/input/touchscreen/ads7846.c:	req->xfer[5].rx_buf = &req->scratch;
drivers/input/touchscreen/ads7846.c:	req->xfer[5].len = 2;
drivers/input/touchscreen/ads7846.c:	CS_CHANGE(req->xfer[5]);
drivers/input/touchscreen/ads7846.c:	spi_message_add_tail(&req->xfer[5], &req->msg);
drivers/input/touchscreen/ads7846.c:	status = spi_sync(spi, &req->msg);
drivers/input/touchscreen/ads7846.c:		status = be16_to_cpu(req->sample);
drivers/input/touchscreen/ads7846.c:	spi_message_init(&req->msg);
drivers/input/touchscreen/ads7846.c:	req->command[0] = (u8) command;
drivers/input/touchscreen/ads7846.c:	req->xfer[0].tx_buf = req->command;
drivers/input/touchscreen/ads7846.c:	req->xfer[0].rx_buf = req->sample;
drivers/input/touchscreen/ads7846.c:	req->xfer[0].len = 3;
drivers/input/touchscreen/ads7846.c:	spi_message_add_tail(&req->xfer[0], &req->msg);
drivers/input/touchscreen/ads7846.c:	status = spi_sync(spi, &req->msg);
drivers/input/touchscreen/ads7846.c:		status = get_unaligned_be16(&req->sample[1]);
drivers/input/touchscreen/ad7877.c:	spi_message_init(&req->msg);
drivers/input/touchscreen/ad7877.c:	req->command = (u16) (AD7877_WRITEADD(AD7877_REG_CTRL1) |
drivers/input/touchscreen/ad7877.c:	req->xfer[0].tx_buf = &req->command;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].rx_buf = &req->sample;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].len = 2;
drivers/input/touchscreen/ad7877.c:	spi_message_add_tail(&req->xfer[0], &req->msg);
drivers/input/touchscreen/ad7877.c:	spi_message_add_tail(&req->xfer[1], &req->msg);
drivers/input/touchscreen/ad7877.c:	status = spi_sync(spi, &req->msg);
drivers/input/touchscreen/ad7877.c:	ret = status ? : req->sample;
drivers/input/touchscreen/ad7877.c:	spi_message_init(&req->msg);
drivers/input/touchscreen/ad7877.c:	req->command = (u16) (AD7877_WRITEADD(reg) | (val & MAX_12BIT));
drivers/input/touchscreen/ad7877.c:	req->xfer[0].tx_buf = &req->command;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].len = 2;
drivers/input/touchscreen/ad7877.c:	spi_message_add_tail(&req->xfer[0], &req->msg);
drivers/input/touchscreen/ad7877.c:	status = spi_sync(spi, &req->msg);
drivers/input/touchscreen/ad7877.c:	spi_message_init(&req->msg);
drivers/input/touchscreen/ad7877.c:	req->ref_on = AD7877_WRITEADD(AD7877_REG_CTRL2) |
drivers/input/touchscreen/ad7877.c:	req->reset = AD7877_WRITEADD(AD7877_REG_CTRL1) | AD7877_MODE_NOC;
drivers/input/touchscreen/ad7877.c:	req->command = (u16) command;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].tx_buf = &req->reset;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[0].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].tx_buf = &req->ref_on;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].delay.value = ts->vref_delay_usecs;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].delay.unit = SPI_DELAY_UNIT_USECS;
drivers/input/touchscreen/ad7877.c:	req->xfer[1].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[2].tx_buf = &req->command;
drivers/input/touchscreen/ad7877.c:	req->xfer[2].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[2].delay.value = ts->vref_delay_usecs;
drivers/input/touchscreen/ad7877.c:	req->xfer[2].delay.unit = SPI_DELAY_UNIT_USECS;
drivers/input/touchscreen/ad7877.c:	req->xfer[2].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[3].rx_buf = &req->sample;
drivers/input/touchscreen/ad7877.c:	req->xfer[3].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[3].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[4].tx_buf = &ts->cmd_crtl2;	/*REF OFF*/
drivers/input/touchscreen/ad7877.c:	req->xfer[4].len = 2;
drivers/input/touchscreen/ad7877.c:	req->xfer[4].cs_change = 1;
drivers/input/touchscreen/ad7877.c:	req->xfer[5].tx_buf = &ts->cmd_crtl1;	/*DEFAULT*/
drivers/input/touchscreen/ad7877.c:	req->xfer[5].len = 2;
drivers/input/touchscreen/ad7877.c:		spi_message_add_tail(&req->xfer[i], &req->msg);
drivers/input/touchscreen/ad7877.c:	status = spi_sync(spi, &req->msg);
drivers/input/touchscreen/ad7877.c:	sample = req->sample;
drivers/input/misc/da7280.c:	error = device_property_read_u32(dev, "dlg,resonant-freq-hz", &val);
drivers/input/misc/da7280.c:		device_property_read_bool(dev, "dlg,freq-track-enable");
drivers/input/misc/cm109.c:				dev->ctl_req->bRequest,
drivers/input/misc/cm109.c:				dev->ctl_req->bRequestType,
drivers/input/misc/cm109.c:				le16_to_cpu(dev->ctl_req->wValue),
drivers/input/misc/cm109.c:				le16_to_cpu(dev->ctl_req->wIndex),
drivers/input/misc/cm109.c:	dev->ctl_req->bRequestType = USB_TYPE_CLASS | USB_RECIP_INTERFACE |
drivers/input/misc/cm109.c:	dev->ctl_req->bRequest = USB_REQ_SET_CONFIGURATION;
drivers/input/misc/cm109.c:	dev->ctl_req->wValue = cpu_to_le16(0x200);
drivers/input/misc/cm109.c:	dev->ctl_req->wIndex = cpu_to_le16(interface->desc.bInterfaceNumber);
drivers/input/misc/cm109.c:	dev->ctl_req->wLength = cpu_to_le16(USB_PKT_LEN);
drivers/input/misc/uinput.c:		if (!req || req->code != UI_FF_UPLOAD ||
drivers/input/misc/uinput.c:		    !req->u.upload.effect) {
drivers/input/misc/uinput.c:		ff_up.effect = *req->u.upload.effect;
drivers/input/misc/uinput.c:		if (req->u.upload.old)
drivers/input/misc/uinput.c:			ff_up.old = *req->u.upload.old;
drivers/input/misc/uinput.c:		if (!req || req->code != UI_FF_ERASE) {
drivers/input/misc/uinput.c:		ff_erase.effect_id = req->u.effect_id;
drivers/input/misc/uinput.c:		if (!req || req->code != UI_FF_UPLOAD ||
drivers/input/misc/uinput.c:		    !req->u.upload.effect) {
drivers/input/misc/uinput.c:		req->retval = ff_up.retval;
drivers/input/misc/uinput.c:		complete(&req->done);
drivers/input/misc/uinput.c:		if (!req || req->code != UI_FF_ERASE) {
drivers/input/misc/uinput.c:		req->retval = ff_erase.retval;
drivers/input/misc/uinput.c:		complete(&req->done);
drivers/input/misc/yealink.c:	yld->ctl_req->bRequestType = USB_TYPE_CLASS | USB_RECIP_INTERFACE |
drivers/input/misc/yealink.c:	yld->ctl_req->bRequest	= USB_REQ_SET_CONFIGURATION;
drivers/input/misc/yealink.c:	yld->ctl_req->wValue	= cpu_to_le16(0x200);
drivers/input/misc/yealink.c:	yld->ctl_req->wIndex	= cpu_to_le16(interface->desc.bInterfaceNumber);
drivers/input/misc/yealink.c:	yld->ctl_req->wLength	= cpu_to_le16(USB_PKT_LEN);
drivers/media/i2c/ov8865.c:	ctrls->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov2740.c:		ov2740->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ccs/ccs-core.c:		sensor->link_freq->qmenu_int[sensor->link_freq->val];
drivers/media/i2c/imx214.c:		imx214->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov9734.c:		ov9734->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/mt9v032.c:		freq = mt9v032->pdata->link_freqs[mt9v032->link_freq->val];
drivers/media/i2c/ov9650.c:	return ov965x_set_banding_filter(ov965x, ctrls->light_freq->val);
drivers/media/i2c/imx258.c:		imx258->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov13858.c:		ov13858->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov5670.c:		ov5670->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/imx219.c:		imx219->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov8856.c:		ov8856->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/imx319.c:		imx319->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/imx355.c:		imx355->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov7251.c:		ov7251->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/imx290.c:		imx290->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov5648.c:	ctrls->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/hi556.c:		hi556->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov5645.c:		ov5645->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/i2c/ov5675.c:		ov5675->link_freq->flags |= V4L2_CTRL_FLAG_READ_ONLY;
drivers/media/pci/meye/meye.c:	if (req->memory != V4L2_MEMORY_MMAP)
drivers/media/pci/meye/meye.c:	if (meye.grab_fbuffer && req->count == gbuffers) {
drivers/media/pci/meye/meye.c:	gbuffers = max(2, min((int)req->count, MEYE_MAX_BUFNBRS));
drivers/media/pci/meye/meye.c:	req->count = gbuffers;
drivers/media/rc/imon.c:		control_req->bRequestType = 0x21;
drivers/media/rc/imon.c:		control_req->bRequest = 0x09;
drivers/media/rc/imon.c:		control_req->wValue = cpu_to_le16(0x0200);
drivers/media/rc/imon.c:		control_req->wIndex = cpu_to_le16(0x0001);
drivers/media/rc/imon.c:		control_req->wLength = cpu_to_le16(0x0008);
drivers/media/rc/igorplugusb.c:		if (req->bRequest == GET_INFRACODE &&
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->type = buftype;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->region_size = 0;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->count_min = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->count_actual = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->hold_count = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->contiguous = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->alignment = 256;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->count_min = MIN_INPUT_BUFFERS;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size =
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->count_min = out_min_count;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size =
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = dec_ops->scratch(width, height, is_interlaced);
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = dec_ops->scratch1(width, height, out_min_count,
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = dec_ops->persist1();
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->type = buftype;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->region_size = 0;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->count_min = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->count_actual = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->hold_count = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->contiguous = 1;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:	bufreq->alignment = 256;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->count_min = MIN_INPUT_BUFFERS;
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size =
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->count_min =
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = calculate_enc_output_frame_size(width, height,
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = enc_ops->scratch(width, height, work_mode,
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = enc_ops->scratch1(width, height, num_ref,
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = enc_ops->scratch2(width, height, num_ref,
drivers/media/platform/qcom/venus/hfi_plat_bufs_v6.c:		bufreq->size = enc_ops->persist();
drivers/media/platform/atmel/atmel-isc-base.c:			diff = abs(req->rate - rate);
drivers/media/platform/atmel/atmel-isc-base.c:				req->best_parent_rate = parent_rate;
drivers/media/platform/atmel/atmel-isc-base.c:				req->best_parent_hw = parent;
drivers/media/platform/atmel/atmel-isc-base.c:			if (!best_diff || rate < req->rate)
drivers/media/platform/atmel/atmel-isc-base.c:		__clk_get_name((req->best_parent_hw)->clk),
drivers/media/platform/atmel/atmel-isc-base.c:		req->best_parent_rate);
drivers/media/platform/atmel/atmel-isc-base.c:	req->rate = best_rate;
drivers/media/platform/rcar-vin/rcar-csi2.c:	for (hsfreq = priv->info->hsfreqrange; hsfreq->mbps != 0; hsfreq++)
drivers/media/platform/rcar-vin/rcar-csi2.c:		if (hsfreq->mbps >= mbps)
drivers/media/platform/rcar-vin/rcar-csi2.c:	if (!hsfreq->mbps) {
drivers/media/platform/rcar-vin/rcar-csi2.c:	rcsi2_write(priv, PHYPLL_REG, PHYPLL_HSFREQRANGE(hsfreq->reg));
drivers/media/platform/omap3isp/ispccdc.c:	if (!req->enable)
drivers/media/platform/omap3isp/ispccdc.c:	if (ccdc_lsc_validate_config(ccdc, &req->config) < 0) {
drivers/media/platform/omap3isp/ispccdc.c:	ccdc_lsc_setup_regs(ccdc, &req->config);
drivers/media/platform/omap3isp/ispccdc.c:	ccdc_lsc_program_table(ccdc, req->table.dma);
drivers/media/platform/omap3isp/ispccdc.c:	if (req->table.addr) {
drivers/media/platform/omap3isp/ispccdc.c:		sg_free_table(&req->table.sgt);
drivers/media/platform/omap3isp/ispccdc.c:		dma_free_coherent(isp->dev, req->config.size, req->table.addr,
drivers/media/platform/omap3isp/ispccdc.c:				  req->table.dma);
drivers/media/platform/omap3isp/ispccdc.c:		list_del(&req->list);
drivers/media/platform/omap3isp/ispccdc.c:		if (copy_from_user(&req->config, config->lsc_cfg,
drivers/media/platform/omap3isp/ispccdc.c:				   sizeof(req->config))) {
drivers/media/platform/omap3isp/ispccdc.c:		req->enable = 1;
drivers/media/platform/omap3isp/ispccdc.c:		req->table.addr = dma_alloc_coherent(isp->dev, req->config.size,
drivers/media/platform/omap3isp/ispccdc.c:						     &req->table.dma,
drivers/media/platform/omap3isp/ispccdc.c:		if (req->table.addr == NULL) {
drivers/media/platform/omap3isp/ispccdc.c:		ret = dma_get_sgtable(isp->dev, &req->table.sgt,
drivers/media/platform/omap3isp/ispccdc.c:				      req->table.addr, req->table.dma,
drivers/media/platform/omap3isp/ispccdc.c:				      req->config.size);
drivers/media/platform/omap3isp/ispccdc.c:		dma_sync_sg_for_cpu(isp->dev, req->table.sgt.sgl,
drivers/media/platform/omap3isp/ispccdc.c:				    req->table.sgt.nents, DMA_TO_DEVICE);
drivers/media/platform/omap3isp/ispccdc.c:		if (copy_from_user(req->table.addr, config->lsc,
drivers/media/platform/omap3isp/ispccdc.c:				   req->config.size)) {
drivers/media/platform/omap3isp/ispccdc.c:		dma_sync_sg_for_device(isp->dev, req->table.sgt.sgl,
drivers/media/platform/omap3isp/ispccdc.c:				       req->table.sgt.nents, DMA_TO_DEVICE);
drivers/media/radio/wl128x/fmdrv_v4l2.c:	ret = fmc_get_freq(fmdev, &freq->frequency);
drivers/media/radio/wl128x/fmdrv_v4l2.c:	freq->frequency = (u32) freq->frequency * 16;
drivers/media/radio/wl128x/fmdrv_v4l2.c:	return fmc_set_freq(fmdev, freq->frequency / 16);
drivers/media/radio/radio-wl1273.c:	freq->type = V4L2_TUNER_RADIO;
drivers/media/radio/radio-wl1273.c:	freq->frequency = WL1273_FREQ(wl1273_fm_get_freq(radio));
drivers/media/radio/radio-wl1273.c:	dev_dbg(radio->dev, "%s: %d\n", __func__, freq->frequency);
drivers/media/radio/radio-wl1273.c:	if (freq->type != V4L2_TUNER_RADIO) {
drivers/media/radio/radio-wl1273.c:			"freq->type != V4L2_TUNER_RADIO: %d\n", freq->type);
drivers/media/radio/radio-wl1273.c:		dev_dbg(radio->dev, "freq: %d\n", freq->frequency);
drivers/media/radio/radio-wl1273.c:					  WL1273_INV_FREQ(freq->frequency));
drivers/media/radio/radio-wl1273.c:					  WL1273_INV_FREQ(freq->frequency));
drivers/media/radio/si470x/radio-si470x-common.c:	if (freq->tuner != 0)
drivers/media/radio/si470x/radio-si470x-common.c:	freq->type = V4L2_TUNER_RADIO;
drivers/media/radio/si470x/radio-si470x-common.c:	return si470x_get_freq(radio, &freq->frequency);
drivers/media/radio/si470x/radio-si470x-common.c:	if (freq->tuner != 0)
drivers/media/radio/si470x/radio-si470x-common.c:	if (freq->frequency < bands[radio->band].rangelow ||
drivers/media/radio/si470x/radio-si470x-common.c:	    freq->frequency > bands[radio->band].rangehigh) {
drivers/media/radio/si470x/radio-si470x-common.c:	return si470x_set_freq(radio, freq->frequency);
drivers/media/dvb-core/dvb_vb2.c:	if (req->size > DVB_V2_MAX_SIZE)
drivers/media/dvb-core/dvb_vb2.c:		req->size = DVB_V2_MAX_SIZE;
drivers/media/dvb-core/dvb_vb2.c:	/* FIXME: round req->size to a 188 or 204 multiple */
drivers/media/dvb-core/dvb_vb2.c:	ctx->buf_siz = req->size;
drivers/media/dvb-core/dvb_vb2.c:	ctx->buf_cnt = req->count;
drivers/media/dvb-core/dvb_vb2.c:	ret = vb2_core_reqbufs(&ctx->vb_q, VB2_MEMORY_MMAP, &req->count);
drivers/media/v4l2-core/v4l2-mem2mem.c:	list_for_each_entry_safe(obj, obj_safe, &req->objects, list) {
drivers/media/v4l2-core/v4l2-ctrls.c:		ptr_to_ptr(ref->ctrl, ref->req->p_req, ref->ctrl->p_new);
drivers/media/v4l2-core/v4l2-ctrls.c:			media_request_object_unbind(&req->req_obj);
drivers/media/v4l2-core/v4l2-ctrls.c:			media_request_object_put(&req->req_obj);
drivers/media/v4l2-core/v4l2-ctrls.c:	if (WARN_ON(req->state != MEDIA_REQUEST_STATE_VALIDATING &&
drivers/media/v4l2-core/v4l2-ctrls.c:		    req->state != MEDIA_REQUEST_STATE_QUEUED))
drivers/media/v4l2-core/v4l2-ctrls.c:	if (set && WARN_ON(req->state != MEDIA_REQUEST_STATE_UPDATING))
drivers/media/v4l2-core/v4l2-ctrls.c:		if (req->state != MEDIA_REQUEST_STATE_COMPLETE) {
drivers/media/v4l2-core/v4l2-ctrls.c:			ptr_to_ptr(ctrl, ref->req->p_req, ref->p_req);
drivers/media/v4l2-core/v4l2-ctrls.c:	if (WARN_ON(req->state != MEDIA_REQUEST_STATE_QUEUED))
drivers/media/v4l2-core/videobuf-core.c:	if (req->memory != V4L2_MEMORY_MMAP     &&
drivers/media/v4l2-core/videobuf-core.c:	    req->memory != V4L2_MEMORY_USERPTR  &&
drivers/media/v4l2-core/videobuf-core.c:	    req->memory != V4L2_MEMORY_OVERLAY) {
drivers/media/v4l2-core/videobuf-core.c:	if (req->type != q->type) {
drivers/media/v4l2-core/videobuf-core.c:	if (req->count == 0) {
drivers/media/v4l2-core/videobuf-core.c:		dprintk(1, "reqbufs: count invalid (%d)\n", req->count);
drivers/media/v4l2-core/videobuf-core.c:	count = req->count;
drivers/media/v4l2-core/videobuf-core.c:	retval = __videobuf_mmap_setup(q, count, size, req->memory);
drivers/media/v4l2-core/videobuf-core.c:	req->count = retval;
drivers/media/mc/mc-request.c:	WARN_ON(req->state != MEDIA_REQUEST_STATE_CLEANING);
drivers/media/mc/mc-request.c:	WARN_ON(req->updating_count);
drivers/media/mc/mc-request.c:	WARN_ON(req->access_count);
drivers/media/mc/mc-request.c:	list_for_each_entry_safe(obj, obj_safe, &req->objects, list) {
drivers/media/mc/mc-request.c:	req->updating_count = 0;
drivers/media/mc/mc-request.c:	req->access_count = 0;
drivers/media/mc/mc-request.c:	WARN_ON(req->num_incomplete_objects);
drivers/media/mc/mc-request.c:	req->num_incomplete_objects = 0;
drivers/media/mc/mc-request.c:	wake_up_interruptible_all(&req->poll_wait);
drivers/media/mc/mc-request.c:	struct media_device *mdev = req->mdev;
drivers/media/mc/mc-request.c:	dev_dbg(mdev->dev, "request: release %s\n", req->debug_str);
drivers/media/mc/mc-request.c:	req->state = MEDIA_REQUEST_STATE_CLEANING;
drivers/media/mc/mc-request.c:	kref_put(&req->kref, media_request_release);
drivers/media/mc/mc-request.c:	poll_wait(filp, &req->poll_wait, wait);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->state == MEDIA_REQUEST_STATE_COMPLETE) {
drivers/media/mc/mc-request.c:	if (req->state != MEDIA_REQUEST_STATE_QUEUED) {
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	struct media_device *mdev = req->mdev;
drivers/media/mc/mc-request.c:	dev_dbg(mdev->dev, "request: queue %s\n", req->debug_str);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->state == MEDIA_REQUEST_STATE_IDLE)
drivers/media/mc/mc-request.c:		req->state = MEDIA_REQUEST_STATE_VALIDATING;
drivers/media/mc/mc-request.c:	state = req->state;
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:			req->debug_str, media_request_state_str(state));
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	req->state = ret ? MEDIA_REQUEST_STATE_IDLE
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:			req->debug_str, ret);
drivers/media/mc/mc-request.c:	struct media_device *mdev = req->mdev;
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->state != MEDIA_REQUEST_STATE_IDLE &&
drivers/media/mc/mc-request.c:	    req->state != MEDIA_REQUEST_STATE_COMPLETE) {
drivers/media/mc/mc-request.c:			req->debug_str);
drivers/media/mc/mc-request.c:		spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->access_count) {
drivers/media/mc/mc-request.c:			req->debug_str);
drivers/media/mc/mc-request.c:		spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	req->state = MEDIA_REQUEST_STATE_CLEANING;
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	req->state = MEDIA_REQUEST_STATE_IDLE;
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->mdev != mdev)
drivers/media/mc/mc-request.c:	req->mdev = mdev;
drivers/media/mc/mc-request.c:	req->state = MEDIA_REQUEST_STATE_IDLE;
drivers/media/mc/mc-request.c:	req->num_incomplete_objects = 0;
drivers/media/mc/mc-request.c:	kref_init(&req->kref);
drivers/media/mc/mc-request.c:	INIT_LIST_HEAD(&req->objects);
drivers/media/mc/mc-request.c:	spin_lock_init(&req->lock);
drivers/media/mc/mc-request.c:	init_waitqueue_head(&req->poll_wait);
drivers/media/mc/mc-request.c:	req->updating_count = 0;
drivers/media/mc/mc-request.c:	req->access_count = 0;
drivers/media/mc/mc-request.c:	snprintf(req->debug_str, sizeof(req->debug_str), "%u:%d",
drivers/media/mc/mc-request.c:	dev_dbg(mdev->dev, "request: allocated %s\n", req->debug_str);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	list_for_each_entry(obj, &req->objects, list) {
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (WARN_ON(req->state != MEDIA_REQUEST_STATE_UPDATING))
drivers/media/mc/mc-request.c:		list_add_tail(&obj->list, &req->objects);
drivers/media/mc/mc-request.c:		list_add(&obj->list, &req->objects);
drivers/media/mc/mc-request.c:	req->num_incomplete_objects++;
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (req->state == MEDIA_REQUEST_STATE_COMPLETE)
drivers/media/mc/mc-request.c:	if (WARN_ON(req->state == MEDIA_REQUEST_STATE_VALIDATING))
drivers/media/mc/mc-request.c:	if (req->state == MEDIA_REQUEST_STATE_CLEANING) {
drivers/media/mc/mc-request.c:			req->num_incomplete_objects--;
drivers/media/mc/mc-request.c:	if (WARN_ON(!req->num_incomplete_objects))
drivers/media/mc/mc-request.c:	req->num_incomplete_objects--;
drivers/media/mc/mc-request.c:	if (req->state == MEDIA_REQUEST_STATE_QUEUED &&
drivers/media/mc/mc-request.c:	    !req->num_incomplete_objects) {
drivers/media/mc/mc-request.c:		req->state = MEDIA_REQUEST_STATE_COMPLETE;
drivers/media/mc/mc-request.c:		wake_up_interruptible_all(&req->poll_wait);
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/mc/mc-request.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/mc/mc-request.c:	if (WARN_ON(!req->num_incomplete_objects) ||
drivers/media/mc/mc-request.c:	    WARN_ON(req->state != MEDIA_REQUEST_STATE_QUEUED))
drivers/media/mc/mc-request.c:	if (!--req->num_incomplete_objects) {
drivers/media/mc/mc-request.c:		req->state = MEDIA_REQUEST_STATE_COMPLETE;
drivers/media/mc/mc-request.c:		wake_up_interruptible_all(&req->poll_wait);
drivers/media/mc/mc-request.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/usb/cpia2/cpia2_v4l.c:	if(req->type != V4L2_BUF_TYPE_VIDEO_CAPTURE ||
drivers/media/usb/cpia2/cpia2_v4l.c:	   req->memory != V4L2_MEMORY_MMAP)
drivers/media/usb/cpia2/cpia2_v4l.c:	DBG("REQBUFS requested:%d returning:%d\n", req->count, cam->num_frames);
drivers/media/usb/cpia2/cpia2_v4l.c:	req->count = cam->num_frames;
drivers/media/usb/cpia2/cpia2_v4l.c:	memset(&req->reserved, 0, sizeof(req->reserved));
drivers/media/usb/au0828/au0828-video.c:	if (freq->tuner != 0)
drivers/media/usb/au0828/au0828-video.c:	freq->frequency = dev->ctrl_freq;
drivers/media/usb/au0828/au0828-video.c:	if (freq->tuner != 0)
drivers/media/usb/cx231xx/cx231xx-core.c:	if ((ven_req->wLength > URB_MAX_CTRL_SIZE))
drivers/media/usb/cx231xx/cx231xx-core.c:	if (ven_req->direction)
drivers/media/usb/cx231xx/cx231xx-core.c:	if ((ven_req->wLength > 4) && ((ven_req->bRequest == 0x4) ||
drivers/media/usb/cx231xx/cx231xx-core.c:					(ven_req->bRequest == 0x5) ||
drivers/media/usb/cx231xx/cx231xx-core.c:					(ven_req->bRequest == 0x6) ||
drivers/media/usb/cx231xx/cx231xx-core.c:					(ven_req->bRequest == 0x2))) {
drivers/media/usb/cx231xx/cx231xx-core.c:		pdata = ven_req->pBuff;
drivers/media/usb/cx231xx/cx231xx-core.c:		unsend_size = ven_req->wLength;
drivers/media/usb/cx231xx/cx231xx-core.c:		ven_req->wValue = ven_req->wValue & 0xFFFB;
drivers/media/usb/cx231xx/cx231xx-core.c:		ven_req->wValue = (ven_req->wValue & 0xFFBD) | 0x2;
drivers/media/usb/cx231xx/cx231xx-core.c:		ret = __usb_control_msg(dev, pipe, ven_req->bRequest,
drivers/media/usb/cx231xx/cx231xx-core.c:			ven_req->direction | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
drivers/media/usb/cx231xx/cx231xx-core.c:			ven_req->wValue, ven_req->wIndex, pdata,
drivers/media/usb/cx231xx/cx231xx-core.c:		ven_req->wValue = (ven_req->wValue & 0xFFBD) | 0x42;
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->bRequest,
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->direction | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->wValue, ven_req->wIndex, pdata,
drivers/media/usb/cx231xx/cx231xx-core.c:		ven_req->wValue = (ven_req->wValue & 0xFFBD) | 0x40;
drivers/media/usb/cx231xx/cx231xx-core.c:		ret = __usb_control_msg(dev, pipe, ven_req->bRequest,
drivers/media/usb/cx231xx/cx231xx-core.c:			ven_req->direction | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
drivers/media/usb/cx231xx/cx231xx-core.c:			ven_req->wValue, ven_req->wIndex, pdata,
drivers/media/usb/cx231xx/cx231xx-core.c:		ret = __usb_control_msg(dev, pipe, ven_req->bRequest,
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->direction | USB_TYPE_VENDOR | USB_RECIP_DEVICE,
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->wValue, ven_req->wIndex,
drivers/media/usb/cx231xx/cx231xx-core.c:				ven_req->pBuff, ven_req->wLength, HZ);
drivers/media/usb/dvb-usb-v2/ce6230.c:	request = req->cmd;
drivers/media/usb/dvb-usb-v2/ce6230.c:	value = req->value;
drivers/media/usb/dvb-usb-v2/ce6230.c:	index = req->index;
drivers/media/usb/dvb-usb-v2/ce6230.c:	switch (req->cmd) {
drivers/media/usb/dvb-usb-v2/ce6230.c:				KBUILD_MODNAME, req->cmd);
drivers/media/usb/dvb-usb-v2/ce6230.c:	buf = kmalloc(req->data_len, GFP_KERNEL);
drivers/media/usb/dvb-usb-v2/ce6230.c:		memcpy(buf, req->data, req->data_len);
drivers/media/usb/dvb-usb-v2/ce6230.c:			buf, req->data_len, CE6230_USB_TIMEOUT);
drivers/media/usb/dvb-usb-v2/ce6230.c:			buf, req->data_len);
drivers/media/usb/dvb-usb-v2/ce6230.c:		memcpy(req->data, buf, req->data_len);
drivers/media/usb/dvb-usb-v2/af9035.c:	if (req->wlen > (BUF_LEN - REQ_HDR_LEN - CHECKSUM_LEN) ||
drivers/media/usb/dvb-usb-v2/af9035.c:			req->rlen > (BUF_LEN - ACK_HDR_LEN - CHECKSUM_LEN)) {
drivers/media/usb/dvb-usb-v2/af9035.c:			req->wlen, req->rlen);
drivers/media/usb/dvb-usb-v2/af9035.c:	state->buf[0] = REQ_HDR_LEN + req->wlen + CHECKSUM_LEN - 1;
drivers/media/usb/dvb-usb-v2/af9035.c:	state->buf[1] = req->mbox;
drivers/media/usb/dvb-usb-v2/af9035.c:	state->buf[2] = req->cmd;
drivers/media/usb/dvb-usb-v2/af9035.c:	memcpy(&state->buf[REQ_HDR_LEN], req->wbuf, req->wlen);
drivers/media/usb/dvb-usb-v2/af9035.c:	wlen = REQ_HDR_LEN + req->wlen + CHECKSUM_LEN;
drivers/media/usb/dvb-usb-v2/af9035.c:	rlen = ACK_HDR_LEN + req->rlen + CHECKSUM_LEN;
drivers/media/usb/dvb-usb-v2/af9035.c:	if (req->cmd == CMD_FW_DL)
drivers/media/usb/dvb-usb-v2/af9035.c:	if (req->cmd == CMD_FW_DL)
drivers/media/usb/dvb-usb-v2/af9035.c:			req->cmd, tmp_checksum, checksum);
drivers/media/usb/dvb-usb-v2/af9035.c:		if (req->cmd == CMD_IR_GET || state->buf[2] == 1) {
drivers/media/usb/dvb-usb-v2/af9035.c:			req->cmd, state->buf[2]);
drivers/media/usb/dvb-usb-v2/af9035.c:	if (req->rlen)
drivers/media/usb/dvb-usb-v2/af9035.c:		memcpy(req->rbuf, &state->buf[ACK_HDR_LEN], req->rlen);
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[0] = req->cmd;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[2] = req->i2c_addr << 1;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[3] = req->addr >> 8;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[4] = req->addr & 0xff;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[5] = req->mbox;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[6] = req->addr_len;
drivers/media/usb/dvb-usb-v2/af9015.c:	state->buf[7] = req->data_len;
drivers/media/usb/dvb-usb-v2/af9015.c:	switch (req->cmd) {
drivers/media/usb/dvb-usb-v2/af9015.c:		if (((req->addr & 0xff00) == 0xff00) ||
drivers/media/usb/dvb-usb-v2/af9015.c:		    ((req->addr & 0xff00) == 0xae00))
drivers/media/usb/dvb-usb-v2/af9015.c:		dev_err(&intf->dev, "unknown cmd %d\n", req->cmd);
drivers/media/usb/dvb-usb-v2/af9015.c:	if ((write && (req->data_len > BUF_LEN - REQ_HDR_LEN)) ||
drivers/media/usb/dvb-usb-v2/af9015.c:	    (!write && (req->data_len > BUF_LEN - ACK_HDR_LEN))) {
drivers/media/usb/dvb-usb-v2/af9015.c:			req->cmd, req->data_len);
drivers/media/usb/dvb-usb-v2/af9015.c:		wlen += req->data_len;
drivers/media/usb/dvb-usb-v2/af9015.c:		memcpy(&state->buf[REQ_HDR_LEN], req->data, req->data_len);
drivers/media/usb/dvb-usb-v2/af9015.c:		rlen += req->data_len;
drivers/media/usb/dvb-usb-v2/af9015.c:	if (req->cmd == DOWNLOAD_FIRMWARE || req->cmd == RECONNECT_USB)
drivers/media/usb/dvb-usb-v2/af9015.c:		memcpy(req->data, &state->buf[ACK_HDR_LEN], req->data_len);
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:	if (req->size > sizeof(dev->buf)) {
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:		dev_err(&d->intf->dev, "too large message %u\n", req->size);
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:	if (req->index & CMD_WR_FLAG) {
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:		memcpy(dev->buf, req->data, req->size);
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:	ret = usb_control_msg(d->udev, pipe, 0, requesttype, req->value,
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:			req->index, dev->buf, req->size, 1000);
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:	dvb_usb_dbg_usb_control_msg(d->udev, 0, requesttype, req->value,
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:			req->index, dev->buf, req->size);
drivers/media/usb/dvb-usb-v2/rtl28xxu.c:		memcpy(req->data, dev->buf, req->size);
drivers/media/usb/dvb-usb-v2/ec168.c:	switch (req->cmd) {
drivers/media/usb/dvb-usb-v2/ec168.c:		request = req->cmd;
drivers/media/usb/dvb-usb-v2/ec168.c:		request = req->cmd;
drivers/media/usb/dvb-usb-v2/ec168.c:				KBUILD_MODNAME, req->cmd);
drivers/media/usb/dvb-usb-v2/ec168.c:	buf = kmalloc(req->size, GFP_KERNEL);
drivers/media/usb/dvb-usb-v2/ec168.c:		memcpy(buf, req->data, req->size);
drivers/media/usb/dvb-usb-v2/ec168.c:	ret = usb_control_msg(d->udev, pipe, request, requesttype, req->value,
drivers/media/usb/dvb-usb-v2/ec168.c:		req->index, buf, req->size, EC168_USB_TIMEOUT);
drivers/media/usb/dvb-usb-v2/ec168.c:	dvb_usb_dbg_usb_control_msg(d->udev, request, requesttype, req->value,
drivers/media/usb/dvb-usb-v2/ec168.c:			req->index, buf, req->size);
drivers/media/usb/dvb-usb-v2/ec168.c:		memcpy(req->data, buf, req->size);
drivers/media/usb/as102/as10x_cmd.c:			sizeof(preq->body.set_tune.req));
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.proc_id = cpu_to_le16(CONTROL_PROC_SETTUNE);
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.freq = (__force __u32)cpu_to_le32(ptune->freq);
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.bandwidth = ptune->bandwidth;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.hier_select = ptune->hier_select;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.modulation = ptune->modulation;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.hierarchy = ptune->hierarchy;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.interleaving_mode  =
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.code_rate  = ptune->code_rate;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.guard_interval = ptune->guard_interval;
drivers/media/usb/as102/as10x_cmd.c:	preq->body.set_tune.req.args.transmission_mode  =
drivers/media/usb/as102/as10x_cmd.c:					    sizeof(preq->body.set_tune.req)
drivers/media/usb/as102/as10x_cmd.c:			sizeof(preq->body.get_tune_status.req));
drivers/media/usb/as102/as10x_cmd.c:	preq->body.get_tune_status.req.proc_id =
drivers/media/usb/as102/as10x_cmd.c:			sizeof(preq->body.get_tune_status.req) + HEADER_SIZE,
drivers/media/usb/dvb-usb/cxusb-analog.c:	if (freq->tuner != 0)
drivers/media/usb/dvb-usb/cxusb-analog.c:	if (freq->tuner != 0)
drivers/media/usb/gspca/sonixb.c:		switch (sd->plfreq->val) {
drivers/media/usb/gspca/dtcs033.c:		reg_rw(gspca_dev, preq->bRequestType, preq->bRequest,
drivers/media/usb/gspca/dtcs033.c:			preq->wValue, preq->wIndex, preq->wLength);
drivers/media/usb/gspca/dtcs033.c:		} else if (preq->bRequestType & USB_DIR_IN) {
drivers/media/usb/gspca/dtcs033.c:				  preq->wLength,
drivers/media/usb/gspca/dtcs033.c:				  preq->wLength > 3 ? "...\n" : "\n");
drivers/media/usb/gspca/se401.c:		setexposure(gspca_dev, ctrl->val, sd->freq->val);
drivers/media/usb/gspca/w996Xcf.c:		if (sd->freq->val == 1) {
drivers/media/usb/gspca/sonixj.c:		switch (sd->freq->val) {
drivers/media/usb/gspca/sonixj.c:		switch (sd->freq->val) {
drivers/media/test-drivers/vicodec/vicodec-core.c:	list_for_each_entry(obj, &req->objects, list) {
drivers/media/test-drivers/vivid/vivid-core.c:	struct vivid_dev *dev = container_of(req->mdev, struct vivid_dev, mdev);
drivers/media/common/cx2341x.c:		props = (hdl->audio_sampling_freq->val << 0) |
drivers/media/common/cx2341x.c:			return hdl->ops->s_audio_sampling_freq(hdl, hdl->audio_sampling_freq->val);
drivers/media/common/videobuf2/videobuf2-core.c:	spin_lock_irqsave(&req->lock, flags);
drivers/media/common/videobuf2/videobuf2-core.c:	list_for_each_entry(obj, &req->objects, list)
drivers/media/common/videobuf2/videobuf2-core.c:	spin_unlock_irqrestore(&req->lock, flags);
drivers/media/common/videobuf2/videobuf2-core.c:			spin_lock_irqsave(&req->lock, flags);
drivers/media/common/videobuf2/videobuf2-core.c:			state = req->state;
drivers/media/common/videobuf2/videobuf2-core.c:			spin_unlock_irqrestore(&req->lock, flags);
drivers/media/common/videobuf2/videobuf2-v4l2.c:	if (req->state != MEDIA_REQUEST_STATE_IDLE &&
drivers/media/common/videobuf2/videobuf2-v4l2.c:	    req->state != MEDIA_REQUEST_STATE_UPDATING) {
drivers/media/common/videobuf2/videobuf2-v4l2.c:	int ret = vb2_verify_memory_type(q, req->memory, req->type);
drivers/media/common/videobuf2/videobuf2-v4l2.c:	fill_buf_caps(q, &req->capabilities);
drivers/media/common/videobuf2/videobuf2-v4l2.c:	return ret ? ret : vb2_core_reqbufs(q, req->memory, &req->count);
drivers/media/common/videobuf2/videobuf2-v4l2.c:	list_for_each_entry(obj, &req->objects, list) {
drivers/media/common/videobuf2/videobuf2-v4l2.c:		list_for_each_entry_continue_reverse(obj, &req->objects, list)
drivers/media/common/videobuf2/videobuf2-v4l2.c:	list_for_each_entry_safe(obj, obj_safe, &req->objects, list)
drivers/media/tuners/mt20xx.c:	desired_lo2=lo1freq-rfin-if2;
drivers/media/tuners/mt20xx.c:	f_lo2=f_lo1-freq-if2;
drivers/regulator/qcom_rpm-regulator.c:	if (WARN_ON((value << req->shift) & ~req->mask))
drivers/regulator/qcom_rpm-regulator.c:	vreg->val[req->word] &= ~req->mask;
drivers/regulator/qcom_rpm-regulator.c:	vreg->val[req->word] |= value << req->shift;
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	int max_mA = req->mask >> req->shift;
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0)
drivers/regulator/qcom_rpm-regulator.c:	if (req->mask == 0 || (value << req->shift) & ~req->mask)
drivers/regulator/qcom_rpm-regulator.c:	vreg->val[req->word] &= ~req->mask;
drivers/regulator/qcom_rpm-regulator.c:	vreg->val[req->word] |= value << req->shift;
drivers/memstick/host/r592.c:	r592_write_reg(dev, R592_FIFO_DMA, sg_dma_address(&dev->req->sg));
drivers/memstick/host/r592.c:	if (!dev->dma_capable || !dev->req->long_data)
drivers/memstick/host/r592.c:	len = dev->req->sg.length;
drivers/memstick/host/r592.c:	is_write = dev->req->data_dir == WRITE;
drivers/memstick/host/r592.c:	sg_count = dma_map_sg(&dev->pci_dev->dev, &dev->req->sg, 1, is_write ?
drivers/memstick/host/r592.c:	if (sg_count != 1 || sg_dma_len(&dev->req->sg) < R592_LFIFO_SIZE) {
drivers/memstick/host/r592.c:	dma_unmap_sg(&dev->pci_dev->dev, &dev->req->sg, 1, is_write ?
drivers/memstick/host/r592.c:	bool is_write = dev->req->tpc >= MS_TPC_SET_RW_REG_ADRS;
drivers/memstick/host/r592.c:	if (!dev->req->long_data) {
drivers/memstick/host/r592.c:			r592_write_fifo_pio(dev, dev->req->data,
drivers/memstick/host/r592.c:							dev->req->data_len);
drivers/memstick/host/r592.c:			r592_read_fifo_pio(dev, dev->req->data,
drivers/memstick/host/r592.c:							dev->req->data_len);
drivers/memstick/host/r592.c:	sg_miter_start(&miter, &dev->req->sg, 1, SG_MITER_ATOMIC |
drivers/memstick/host/r592.c:	is_write = dev->req->tpc >= MS_TPC_SET_RW_REG_ADRS;
drivers/memstick/host/r592.c:	len = dev->req->long_data ?
drivers/memstick/host/r592.c:		dev->req->sg.length : dev->req->data_len;
drivers/memstick/host/r592.c:			memstick_debug_get_tpc_name(dev->req->tpc), len);
drivers/memstick/host/r592.c:		(dev->req->tpc << R592_TPC_EXEC_TPC_SHIFT) |
drivers/memstick/host/r592.c:	if (dev->req->need_card_int)
drivers/memstick/host/r592.c:	if (dev->parallel_mode && dev->req->need_card_int) {
drivers/memstick/host/r592.c:		dev->req->int_reg = 0;
drivers/memstick/host/r592.c:			dev->req->int_reg |= MEMSTICK_INT_CMDNAK;
drivers/memstick/host/r592.c:			dev->req->int_reg |= MEMSTICK_INT_BREQ;
drivers/memstick/host/r592.c:			dev->req->int_reg |= MEMSTICK_INT_ERR;
drivers/memstick/host/r592.c:			dev->req->int_reg |= MEMSTICK_INT_CED;
drivers/memstick/host/r592.c:	dev->req->error = error;
drivers/memstick/host/r592.c:		dev->req->error = -ETIME;
drivers/memstick/host/tifm_ms.c:	if (host->req->long_data) {
drivers/memstick/host/tifm_ms.c:		length = host->req->sg.length - host->block_pos;
drivers/memstick/host/tifm_ms.c:		off = host->req->sg.offset + host->block_pos;
drivers/memstick/host/tifm_ms.c:		length = host->req->data_len - host->block_pos;
drivers/memstick/host/tifm_ms.c:		if (host->req->long_data) {
drivers/memstick/host/tifm_ms.c:			pg = nth_page(sg_page(&host->req->sg),
drivers/memstick/host/tifm_ms.c:			buf = host->req->data + host->block_pos;
drivers/memstick/host/tifm_ms.c:			p_cnt = host->req->data_len - host->block_pos;
drivers/memstick/host/tifm_ms.c:		t_size = host->req->data_dir == WRITE
drivers/memstick/host/tifm_ms.c:		if (host->req->long_data) {
drivers/memstick/host/tifm_ms.c:	if (!length && (host->req->data_dir == WRITE)) {
drivers/memstick/host/tifm_ms.c:	if (host->req->long_data) {
drivers/memstick/host/tifm_ms.c:		data_len = host->req->sg.length;
drivers/memstick/host/tifm_ms.c:		data_len = host->req->data_len;
drivers/memstick/host/tifm_ms.c:		if (1 != tifm_map_sg(sock, &host->req->sg, 1,
drivers/memstick/host/tifm_ms.c:				     host->req->data_dir == READ
drivers/memstick/host/tifm_ms.c:			host->req->error = -ENOMEM;
drivers/memstick/host/tifm_ms.c:			return host->req->error;
drivers/memstick/host/tifm_ms.c:		data_len = sg_dma_len(&host->req->sg);
drivers/memstick/host/tifm_ms.c:		if (host->req->data_dir == WRITE)
drivers/memstick/host/tifm_ms.c:		writel(sg_dma_address(&host->req->sg),
drivers/memstick/host/tifm_ms.c:	host->req->error = 0;
drivers/memstick/host/tifm_ms.c:	cmd = (host->req->tpc & 0xf) << 12;
drivers/memstick/host/tifm_ms.c:	host->req->int_reg = readl(sock->addr + SOCK_MS_STATUS) & 0xff;
drivers/memstick/host/tifm_ms.c:	host->req->int_reg = (host->req->int_reg & 1)
drivers/memstick/host/tifm_ms.c:			     | ((host->req->int_reg << 4) & 0xe0);
drivers/memstick/host/tifm_ms.c:		tifm_unmap_sg(sock, &host->req->sg, 1,
drivers/memstick/host/tifm_ms.c:			      host->req->data_dir == READ
drivers/memstick/host/tifm_ms.c:	if (!host->req->error) {
drivers/memstick/host/tifm_ms.c:		if (host->req->need_card_int
drivers/memstick/host/tifm_ms.c:			host->req->error = -ETIME;
drivers/memstick/host/tifm_ms.c:			host->req->error = -EILSEQ;
drivers/memstick/host/tifm_ms.c:					host->req->error = -ETIME;
drivers/memstick/host/tifm_ms.c:	       dev_name(&host->dev->dev), host->req ? host->req->tpc : 0,
drivers/memstick/host/tifm_ms.c:			tifm_unmap_sg(sock, &host->req->sg, 1,
drivers/memstick/host/tifm_ms.c:				      host->req->data_dir == READ
drivers/memstick/host/tifm_ms.c:		host->req->error = -ETIME;
drivers/memstick/host/tifm_ms.c:				host->req->error = -ETIME;
drivers/memstick/host/jmb38x_ms.c:	if (host->req->long_data) {
drivers/memstick/host/jmb38x_ms.c:		length = host->req->sg.length - host->block_pos;
drivers/memstick/host/jmb38x_ms.c:		off = host->req->sg.offset + host->block_pos;
drivers/memstick/host/jmb38x_ms.c:		length = host->req->data_len - host->block_pos;
drivers/memstick/host/jmb38x_ms.c:		if (host->req->long_data) {
drivers/memstick/host/jmb38x_ms.c:			pg = nth_page(sg_page(&host->req->sg),
drivers/memstick/host/jmb38x_ms.c:			buf = host->req->data + host->block_pos;
drivers/memstick/host/jmb38x_ms.c:			p_cnt = host->req->data_len - host->block_pos;
drivers/memstick/host/jmb38x_ms.c:		if (host->req->data_dir == WRITE)
drivers/memstick/host/jmb38x_ms.c:		if (host->req->long_data) {
drivers/memstick/host/jmb38x_ms.c:	if (!length && host->req->data_dir == WRITE) {
drivers/memstick/host/jmb38x_ms.c:		host->req->error = -ETIME;
drivers/memstick/host/jmb38x_ms.c:		return host->req->error;
drivers/memstick/host/jmb38x_ms.c:	cmd = host->req->tpc << 16;
drivers/memstick/host/jmb38x_ms.c:	if (host->req->data_dir == READ)
drivers/memstick/host/jmb38x_ms.c:	if (host->req->need_card_int) {
drivers/memstick/host/jmb38x_ms.c:	if (host->req->long_data) {
drivers/memstick/host/jmb38x_ms.c:		data_len = host->req->sg.length;
drivers/memstick/host/jmb38x_ms.c:		data_len = host->req->data_len;
drivers/memstick/host/jmb38x_ms.c:		if (1 != dma_map_sg(&host->chip->pdev->dev, &host->req->sg, 1,
drivers/memstick/host/jmb38x_ms.c:				    host->req->data_dir == READ
drivers/memstick/host/jmb38x_ms.c:			host->req->error = -ENOMEM;
drivers/memstick/host/jmb38x_ms.c:			return host->req->error;
drivers/memstick/host/jmb38x_ms.c:		data_len = sg_dma_len(&host->req->sg);
drivers/memstick/host/jmb38x_ms.c:		writel(sg_dma_address(&host->req->sg),
drivers/memstick/host/jmb38x_ms.c:		t_val |= host->req->data_dir == READ
drivers/memstick/host/jmb38x_ms.c:		if (host->req->data_dir == WRITE) {
drivers/memstick/host/jmb38x_ms.c:	host->req->error = 0;
drivers/memstick/host/jmb38x_ms.c:	host->req->int_reg = readl(host->addr + STATUS) & 0xff;
drivers/memstick/host/jmb38x_ms.c:		dma_unmap_sg(&host->chip->pdev->dev, &host->req->sg, 1,
drivers/memstick/host/jmb38x_ms.c:			     host->req->data_dir == READ
drivers/memstick/host/jmb38x_ms.c:		if (host->req->data_dir == READ)
drivers/memstick/host/jmb38x_ms.c:				host->req->error = -ETIME;
drivers/memstick/host/jmb38x_ms.c:				host->req->error = -EILSEQ;
drivers/memstick/host/jmb38x_ms.c:				host->req->error = -ETIME;
drivers/memstick/host/jmb38x_ms.c:					if (host->req->data_dir == READ) {
drivers/memstick/host/jmb38x_ms.c:		|| host->req->error))
drivers/memstick/host/jmb38x_ms.c:		host->req->error = -ETIME;
drivers/memstick/host/jmb38x_ms.c:			host->req->error = -ETIME;
drivers/memstick/host/rtsx_usb_ms.c:	if (req->need_card_int) {
drivers/memstick/host/rtsx_usb_ms.c:	if (req->long_data) {
drivers/memstick/host/rtsx_usb_ms.c:		err = ms_transfer_data(host, req->data_dir,
drivers/memstick/host/rtsx_usb_ms.c:				req->tpc, cfg, &(req->sg));
drivers/memstick/host/rtsx_usb_ms.c:		if (req->data_dir == READ)
drivers/memstick/host/rtsx_usb_ms.c:			err = ms_read_bytes(host, req->tpc, cfg,
drivers/memstick/host/rtsx_usb_ms.c:					req->data_len, req->data, &int_reg);
drivers/memstick/host/rtsx_usb_ms.c:			err = ms_write_bytes(host, req->tpc, cfg,
drivers/memstick/host/rtsx_usb_ms.c:					req->data_len, req->data, &int_reg);
drivers/memstick/host/rtsx_usb_ms.c:	if (req->need_card_int) {
drivers/memstick/host/rtsx_usb_ms.c:					NO_WAIT_INT, 1, &req->int_reg, NULL);
drivers/memstick/host/rtsx_usb_ms.c:				req->int_reg |= MEMSTICK_INT_CMDNAK;
drivers/memstick/host/rtsx_usb_ms.c:				req->int_reg |= MEMSTICK_INT_BREQ;
drivers/memstick/host/rtsx_usb_ms.c:				req->int_reg |= MEMSTICK_INT_ERR;
drivers/memstick/host/rtsx_usb_ms.c:				req->int_reg |= MEMSTICK_INT_CED;
drivers/memstick/host/rtsx_usb_ms.c:		dev_dbg(ms_dev(host), "int_reg: 0x%02x\n", req->int_reg);
drivers/memstick/host/rtsx_usb_ms.c:					host->req->error = -EIO;
drivers/memstick/host/rtsx_usb_ms.c:					host->req->error =
drivers/memstick/host/rtsx_usb_ms.c:						host->req->error);
drivers/memstick/host/rtsx_usb_ms.c:		host->req->error = -ENOMEDIUM;
drivers/memstick/host/rtsx_usb_ms.c:				host->req->error = -ENOMEDIUM;
drivers/memstick/host/rtsx_pci_ms.c:	if (req->need_card_int) {
drivers/memstick/host/rtsx_pci_ms.c:	if (req->long_data) {
drivers/memstick/host/rtsx_pci_ms.c:		err = ms_transfer_data(host, req->data_dir,
drivers/memstick/host/rtsx_pci_ms.c:				req->tpc, cfg, &(req->sg));
drivers/memstick/host/rtsx_pci_ms.c:		if (req->data_dir == READ) {
drivers/memstick/host/rtsx_pci_ms.c:			err = ms_read_bytes(host, req->tpc, cfg,
drivers/memstick/host/rtsx_pci_ms.c:					req->data_len, req->data, &int_reg);
drivers/memstick/host/rtsx_pci_ms.c:			err = ms_write_bytes(host, req->tpc, cfg,
drivers/memstick/host/rtsx_pci_ms.c:					req->data_len, req->data, &int_reg);
drivers/memstick/host/rtsx_pci_ms.c:	if (req->need_card_int && (host->ifmode == MEMSTICK_SERIAL)) {
drivers/memstick/host/rtsx_pci_ms.c:	if (req->need_card_int) {
drivers/memstick/host/rtsx_pci_ms.c:			req->int_reg |= MEMSTICK_INT_CMDNAK;
drivers/memstick/host/rtsx_pci_ms.c:			req->int_reg |= MEMSTICK_INT_BREQ;
drivers/memstick/host/rtsx_pci_ms.c:			req->int_reg |= MEMSTICK_INT_ERR;
drivers/memstick/host/rtsx_pci_ms.c:			req->int_reg |= MEMSTICK_INT_CED;
drivers/memstick/host/rtsx_pci_ms.c:				host->req->error = rtsx_pci_ms_issue_cmd(host);
drivers/memstick/host/rtsx_pci_ms.c:		host->req->error = -ENOMEDIUM;
drivers/memstick/host/rtsx_pci_ms.c:				host->req->error = -ENOMEDIUM;
drivers/memstick/core/mspro_block.c:		msb->seg_count = blk_rq_map_sg(msb->block_req->q,
drivers/spi/spi-pl022.c:	clk_freq->cpsdvsr = (u8) (best_cpsdvsr & 0xFF);
drivers/spi/spi-pl022.c:	clk_freq->scr = (u8) (best_scr & 0xFF);
drivers/spi/spi-pl022.c:		clk_freq->cpsdvsr, clk_freq->scr);
drivers/tee/optee/supp.c:		req->ret = TEEC_ERROR_COMMUNICATION;
drivers/tee/optee/supp.c:		complete(&req->c);
drivers/tee/optee/supp.c:		list_del(&req->link);
drivers/tee/optee/supp.c:		req->in_queue = false;
drivers/tee/optee/supp.c:		req->ret = TEEC_ERROR_COMMUNICATION;
drivers/tee/optee/supp.c:		complete(&req->c);
drivers/tee/optee/supp.c:	init_completion(&req->c);
drivers/tee/optee/supp.c:	req->func = func;
drivers/tee/optee/supp.c:	req->num_params = num_params;
drivers/tee/optee/supp.c:	req->param = param;
drivers/tee/optee/supp.c:	list_add_tail(&req->link, &supp->reqs);
drivers/tee/optee/supp.c:	req->in_queue = true;
drivers/tee/optee/supp.c:	 * returned from wait_for_completion(&req->c) successfully we have
drivers/tee/optee/supp.c:	while (wait_for_completion_interruptible(&req->c)) {
drivers/tee/optee/supp.c:			if (req->in_queue) {
drivers/tee/optee/supp.c:				list_del(&req->link);
drivers/tee/optee/supp.c:				req->in_queue = false;
drivers/tee/optee/supp.c:			req->ret = TEEC_ERROR_COMMUNICATION;
drivers/tee/optee/supp.c:	ret = req->ret;
drivers/tee/optee/supp.c:	if (num_params < req->num_params) {
drivers/tee/optee/supp.c:	list_del(&req->link);
drivers/tee/optee/supp.c:	req->in_queue = false;
drivers/tee/optee/supp.c:	*func = req->func;
drivers/tee/optee/supp.c:	*num_params = req->num_params + num_meta;
drivers/tee/optee/supp.c:	memcpy(param + num_meta, req->param,
drivers/tee/optee/supp.c:	       sizeof(struct tee_param) * req->num_params);
drivers/tee/optee/supp.c:	if ((num_params - nm) != req->num_params)
drivers/tee/optee/supp.c:	for (n = 0; n < req->num_params; n++) {
drivers/tee/optee/supp.c:		struct tee_param *p = req->param + n;
drivers/tee/optee/supp.c:	req->ret = ret;
drivers/tee/optee/supp.c:	complete(&req->c);
drivers/char/pcmcia/cm4000_cs.c:	DEBUGP(5, dev, "ptsreq->Protocol = 0x%.8x, ptsreq->Flags=0x%.8x, "
drivers/char/pcmcia/cm4000_cs.c:		 "ptsreq->pts1=0x%.2x, ptsreq->pts2=0x%.2x, "
drivers/char/pcmcia/cm4000_cs.c:		 "ptsreq->pts3=0x%.2x\n", (unsigned int)ptsreq->protocol,
drivers/char/pcmcia/cm4000_cs.c:		 (unsigned int)ptsreq->flags, ptsreq->pts1, ptsreq->pts2,
drivers/char/pcmcia/cm4000_cs.c:		 ptsreq->pts3);
drivers/char/pcmcia/cm4000_cs.c:	tmp = ptsreq->protocol;
drivers/char/pcmcia/cm4000_cs.c:				if (copy_to_user(&(atreq->atr_len), &tmp,
drivers/char/pcmcia/cm4000_cs.c:				if (copy_to_user(atreq->atr, dev->atr,
drivers/char/pcmcia/cm4000_cs.c:				if (copy_to_user(&(atreq->atr_len), &tmp, sizeof(int)))
drivers/char/ipmi/ipmi_devintf.c:	if (req->addr_len > sizeof(struct ipmi_addr))
drivers/char/ipmi/ipmi_devintf.c:	if (copy_from_user(&addr, req->addr, req->addr_len))
drivers/char/ipmi/ipmi_devintf.c:	msg.netfn = req->msg.netfn;
drivers/char/ipmi/ipmi_devintf.c:	msg.cmd = req->msg.cmd;
drivers/char/ipmi/ipmi_devintf.c:	msg.data_len = req->msg.data_len;
drivers/char/ipmi/ipmi_devintf.c:	rv = ipmi_validate_addr(&addr, req->addr_len);
drivers/char/ipmi/ipmi_devintf.c:	if (req->msg.data != NULL) {
drivers/char/ipmi/ipmi_devintf.c:		if (req->msg.data_len > IPMI_MAX_MSG_LENGTH) {
drivers/char/ipmi/ipmi_devintf.c:				   req->msg.data,
drivers/char/ipmi/ipmi_devintf.c:				   req->msg.data_len)) {
drivers/char/ipmi/ipmi_devintf.c:				  req->msgid,
drivers/visorbus/visorchipset.c:	req->id = parahotplug_next_id();
drivers/visorbus/visorchipset.c:	req->expiration = parahotplug_next_expiration();
drivers/visorbus/visorchipset.c:	req->msg = *msg;
drivers/visorbus/visorchipset.c:		if (req->id == id) {
drivers/visorbus/visorchipset.c:			req->msg.cmd.device_change_state.state.active = active;
drivers/visorbus/visorchipset.c:			if (req->msg.hdr.flags.response_expected)
drivers/visorbus/visorchipset.c:				       &req->msg.hdr, CONTROLVM_RESP_SUCCESS,
drivers/visorbus/visorchipset.c:				       &req->msg.cmd.device_change_state.state);
drivers/visorbus/visorchipset.c:	struct controlvm_message_packet *cmd = &req->msg.cmd;
drivers/visorbus/visorchipset.c:	sprintf(env_id, "VISOR_PARAHOTPLUG_ID=%d", req->id);
drivers/visorbus/visorchipset.c:	list_add_tail(&req->list, &parahotplug_request_list);
drivers/visorbus/visorchipset.c:		if (!time_after_eq(jiffies, req->expiration))
drivers/visorbus/visorchipset.c:		if (req->msg.hdr.flags.response_expected)
drivers/visorbus/visorchipset.c:				&req->msg.hdr,
drivers/visorbus/visorchipset.c:				&req->msg.cmd.device_change_state.state);
drivers/base/power/qos.c:	struct dev_pm_qos *qos = req->dev->power.qos;
drivers/base/power/qos.c:	switch(req->type) {
drivers/base/power/qos.c:					   &req->data.pnode, action, value);
drivers/base/power/qos.c:					   &req->data.pnode, action, value);
drivers/base/power/qos.c:			req->dev->power.set_latency_tolerance(req->dev, value);
drivers/base/power/qos.c:		ret = freq_qos_apply(&req->data.freq, action, value);
drivers/base/power/qos.c:		ret = pm_qos_update_flags(&qos->flags, &req->data.flr,
drivers/base/power/qos.c:	req->dev = dev;
drivers/base/power/qos.c:	req->type = type;
drivers/base/power/qos.c:	if (req->type == DEV_PM_QOS_MIN_FREQUENCY)
drivers/base/power/qos.c:					   &req->data.freq,
drivers/base/power/qos.c:	else if (req->type == DEV_PM_QOS_MAX_FREQUENCY)
drivers/base/power/qos.c:					   &req->data.freq,
drivers/base/power/qos.c:	if (IS_ERR_OR_NULL(req->dev->power.qos))
drivers/base/power/qos.c:	switch(req->type) {
drivers/base/power/qos.c:		curr_value = req->data.pnode.prio;
drivers/base/power/qos.c:		curr_value = req->data.freq.pnode.prio;
drivers/base/power/qos.c:		curr_value = req->data.flr.flags;
drivers/base/power/qos.c:	trace_dev_pm_qos_update_request(dev_name(req->dev), req->type,
drivers/base/power/qos.c:	if (IS_ERR_OR_NULL(req->dev->power.qos))
drivers/base/power/qos.c:	trace_dev_pm_qos_remove_request(dev_name(req->dev), req->type,
drivers/base/power/qos.c:		req->dev = NULL;
drivers/base/power/qos.c:			dev->power.qos->latency_tolerance_req->data.pnode.prio;
drivers/base/devtmpfs.c:	init_completion(&req->done);
drivers/base/devtmpfs.c:	req->next = requests;
drivers/base/devtmpfs.c:	wait_for_completion(&req->done);
drivers/base/devtmpfs.c:	return req->err;
drivers/base/devtmpfs.c:				struct req *next = req->next;
drivers/base/devtmpfs.c:				req->err = handle(req->name, req->mode,
drivers/base/devtmpfs.c:						  req->uid, req->gid, req->dev);
drivers/base/devtmpfs.c:				complete(&req->done);
drivers/crypto/s5p-sss.c: * @sgl:	sg for joining buffer and req->src scatterlist
drivers/crypto/s5p-sss.c: * @skip:	Skip offset in req->src for current op
drivers/crypto/s5p-sss.c: * @buffer:	For byte(s) from end of req->src in UPDATE op
drivers/crypto/s5p-sss.c:	len = ALIGN(dev->req->cryptlen, AES_BLOCK_SIZE);
drivers/crypto/s5p-sss.c:			dev->req->cryptlen);
drivers/crypto/s5p-sss.c:		s5p_sg_copy_buf(sg_virt(dev->sg_dst_cpy), dev->req->dst,
drivers/crypto/s5p-sss.c:				dev->req->cryptlen, 1);
drivers/crypto/s5p-sss.c:		memcpy_fromio(req->iv, dev->aes_ioaddr + SSS_REG_AES_IV_DATA(0), AES_BLOCK_SIZE);
drivers/crypto/s5p-sss.c:		memcpy_fromio(req->iv, dev->aes_ioaddr + SSS_REG_AES_CNT_DATA(0), AES_BLOCK_SIZE);
drivers/crypto/s5p-sss.c:	req->base.complete(&req->base, err);
drivers/crypto/s5p-sss.c:	len = ALIGN(dev->req->cryptlen, AES_BLOCK_SIZE);
drivers/crypto/s5p-sss.c:	s5p_sg_copy_buf(pages, src, dev->req->cryptlen, 0);
drivers/crypto/s5p-sss.c: * s5p_hash_copy_result() - copy digest into req->result
drivers/crypto/s5p-sss.c:	if (!req->result)
drivers/crypto/s5p-sss.c:	memcpy(req->result, ctx->digest, ctx->nregs * HASH_REG_SIZEOF);
drivers/crypto/s5p-sss.c: *	   either req->nbytes or ctx->bufcnt + req->nbytes is > BUFLEN or
drivers/crypto/s5p-sss.c:		nbytes = req->nbytes;
drivers/crypto/s5p-sss.c:		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, req->src,
drivers/crypto/s5p-sss.c:		/* copy hash_later bytes from end of req->src */
drivers/crypto/s5p-sss.c:		scatterwalk_map_and_copy(ctx->buffer, req->src,
drivers/crypto/s5p-sss.c:					 req->nbytes - hash_later,
drivers/crypto/s5p-sss.c:		ret = s5p_hash_prepare_sgs(ctx, req->src, nbytes - hash_later,
drivers/crypto/s5p-sss.c:			scatterwalk_map_and_copy(ctx->dd->xmit_buf, req->src,
drivers/crypto/s5p-sss.c:	if (req->base.complete)
drivers/crypto/s5p-sss.c:		req->base.complete(&req->base, err);
drivers/crypto/s5p-sss.c:		ctx->op_update, req->nbytes);
drivers/crypto/s5p-sss.c:	struct s5p_hash_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/s5p-sss.c:	if (!req->nbytes)
drivers/crypto/s5p-sss.c:	if (ctx->bufcnt + req->nbytes <= BUFLEN) {
drivers/crypto/s5p-sss.c:		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, req->src,
drivers/crypto/s5p-sss.c:					 0, req->nbytes, 0);
drivers/crypto/s5p-sss.c:		ctx->bufcnt += req->nbytes;
drivers/crypto/s5p-sss.c: * Note: in final req->src do not have any data, and req->nbytes can be
drivers/crypto/s5p-sss.c:		struct s5p_hash_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/s5p-sss.c:					       ctx->bufcnt, req->result);
drivers/crypto/s5p-sss.c: * s5p_hash_finup() - process last req->src and calculate digest
drivers/crypto/s5p-sss.c: * s5p_hash_digest - calculate digest from req->src
drivers/crypto/s5p-sss.c:	sg = req->src;
drivers/crypto/s5p-sss.c:	sg = req->dst;
drivers/crypto/s5p-sss.c:		iv = req->iv;
drivers/crypto/s5p-sss.c:		ctr = req->iv;
drivers/crypto/s5p-sss.c:	dev->ctx = crypto_tfm_ctx(dev->req->base.tfm);
drivers/crypto/s5p-sss.c:	err = crypto_enqueue_request(&dev->queue, &req->base);
drivers/crypto/s5p-sss.c:	if (!req->cryptlen)
drivers/crypto/s5p-sss.c:	if (!IS_ALIGNED(req->cryptlen, AES_BLOCK_SIZE) &&
drivers/crypto/axis/artpec6_crypto.c:		list_add_tail(&req->list, &ac->pending);
drivers/crypto/axis/artpec6_crypto.c:	} else if (req->req->flags & CRYPTO_TFM_REQ_MAY_BACKLOG) {
drivers/crypto/axis/artpec6_crypto.c:		list_add_tail(&req->list, &ac->queue);
drivers/crypto/axis/artpec6_crypto.c:				  &req->base,
drivers/crypto/axis/artpec6_crypto.c:				  req->dst, req->cryptlen);
drivers/crypto/axis/artpec6_crypto.c:	ret = artpec6_crypto_common_init(&req_ctx->common, &req->base,
drivers/crypto/axis/artpec6_crypto.c:				  req->dst, req->cryptlen);
drivers/crypto/axis/artpec6_crypto.c:					    (req->iv + iv_len - 4));
drivers/crypto/axis/artpec6_crypto.c:	unsigned int nblks = ALIGN(req->cryptlen, AES_BLOCK_SIZE) /
drivers/crypto/axis/artpec6_crypto.c:			skcipher_request_set_callback(subreq, req->base.flags,
drivers/crypto/axis/artpec6_crypto.c:			skcipher_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/axis/artpec6_crypto.c:						   req->cryptlen, req->iv);
drivers/crypto/axis/artpec6_crypto.c:	ret = artpec6_crypto_common_init(&req_ctx->common, &req->base,
drivers/crypto/axis/artpec6_crypto.c:	if (req->cryptlen < AES_BLOCK_SIZE)
drivers/crypto/axis/artpec6_crypto.c:				  &req->base,
drivers/crypto/axis/artpec6_crypto.c:	struct artpec6_hashalg_context *ctx = crypto_tfm_ctx(areq->base.tfm);
drivers/crypto/axis/artpec6_crypto.c:		size_t total_bytes = areq->nbytes + req_ctx->partial_bytes;
drivers/crypto/axis/artpec6_crypto.c:		artpec6_crypto_walk_init(&walk, areq->src);
drivers/crypto/axis/artpec6_crypto.c:			size_t sg_rem = areq->nbytes - sg_skip;
drivers/crypto/axis/artpec6_crypto.c:			sg_pcopy_to_buffer(areq->src, sg_nents(areq->src),
drivers/crypto/axis/artpec6_crypto.c:		error = artpec6_crypto_setup_in_descr(common, areq->result,
drivers/crypto/axis/artpec6_crypto.c:		ret = artpec6_crypto_setup_out_descr(common, areq->iv, iv_len,
drivers/crypto/axis/artpec6_crypto.c:	artpec6_crypto_walk_init(&walk, areq->src);
drivers/crypto/axis/artpec6_crypto.c:	ret = artpec6_crypto_setup_sg_descrs_out(common, &walk, areq->cryptlen);
drivers/crypto/axis/artpec6_crypto.c:	artpec6_crypto_walk_init(&walk, areq->dst);
drivers/crypto/axis/artpec6_crypto.c:	ret = artpec6_crypto_setup_sg_descrs_in(common, &walk, areq->cryptlen);
drivers/crypto/axis/artpec6_crypto.c:		size_t pad = ALIGN(areq->cryptlen, AES_BLOCK_SIZE) -
drivers/crypto/axis/artpec6_crypto.c:			     areq->cryptlen;
drivers/crypto/axis/artpec6_crypto.c:	struct artpec6_cryptotfm_context *ctx = crypto_tfm_ctx(areq->base.tfm);
drivers/crypto/axis/artpec6_crypto.c:	input_length = areq->cryptlen;
drivers/crypto/axis/artpec6_crypto.c:		__cpu_to_be64(8*areq->assoclen);
drivers/crypto/axis/artpec6_crypto.c:	memcpy(req_ctx->hw_ctx.J0, areq->iv, crypto_aead_ivsize(cipher));
drivers/crypto/axis/artpec6_crypto.c:		artpec6_crypto_walk_init(&walk, areq->src);
drivers/crypto/axis/artpec6_crypto.c:		count = areq->assoclen;
drivers/crypto/axis/artpec6_crypto.c:		if (!IS_ALIGNED(areq->assoclen, 16)) {
drivers/crypto/axis/artpec6_crypto.c:			size_t assoc_pad = 16 - (areq->assoclen % 16);
drivers/crypto/axis/artpec6_crypto.c:		size_t output_len = areq->cryptlen;
drivers/crypto/axis/artpec6_crypto.c:		artpec6_crypto_walk_init(&walk, areq->dst);
drivers/crypto/axis/artpec6_crypto.c:		count = artpec6_crypto_walk_advance(&walk, areq->assoclen);
drivers/crypto/axis/artpec6_crypto.c:		list_move_tail(&req->list, &ac->pending);
drivers/crypto/axis/artpec6_crypto.c:		list_add_tail(&req->complete_in_progress, completions);
drivers/crypto/axis/artpec6_crypto.c:		struct artpec6_crypto_dma_descriptors *dma = req->dma;
drivers/crypto/axis/artpec6_crypto.c:		stataddr = dma->stat_dma_addr + 4 * (req->dma->in_cnt - 1);
drivers/crypto/axis/artpec6_crypto.c:		stat = req->dma->stat[req->dma->in_cnt-1];
drivers/crypto/axis/artpec6_crypto.c:		list_move_tail(&req->list, &complete_done);
drivers/crypto/axis/artpec6_crypto.c:		req->complete(req->req);
drivers/crypto/axis/artpec6_crypto.c:		req->req->complete(req->req, -EINPROGRESS);
drivers/crypto/axis/artpec6_crypto.c:	req->complete(req, 0);
drivers/crypto/axis/artpec6_crypto.c:	scatterwalk_map_and_copy(cipher_req->iv, cipher_req->src,
drivers/crypto/axis/artpec6_crypto.c:				 cipher_req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/axis/artpec6_crypto.c:	req->complete(req, 0);
drivers/crypto/axis/artpec6_crypto.c:	scatterwalk_map_and_copy(cipher_req->iv, cipher_req->dst,
drivers/crypto/axis/artpec6_crypto.c:				 cipher_req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/axis/artpec6_crypto.c:	req->complete(req, 0);
drivers/crypto/axis/artpec6_crypto.c:		sg_pcopy_to_buffer(areq->src,
drivers/crypto/axis/artpec6_crypto.c:				   sg_nents(areq->src),
drivers/crypto/axis/artpec6_crypto.c:				   areq->assoclen + areq->cryptlen -
drivers/crypto/axis/artpec6_crypto.c:	req->complete(req, result);
drivers/crypto/axis/artpec6_crypto.c:	req->complete(req, 0);
drivers/crypto/axis/artpec6_crypto.c:					  &req->base,
drivers/crypto/virtio/virtio_crypto_algs.c:	if (vc_sym_req->type == VIRTIO_CRYPTO_SYM_OP_CIPHER) {
drivers/crypto/virtio/virtio_crypto_algs.c:		switch (vc_req->status) {
drivers/crypto/virtio/virtio_crypto_algs.c:		ablk_req = vc_sym_req->skcipher_req;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct virtio_crypto_skcipher_ctx *ctx = vc_sym_req->skcipher_ctx;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct virtio_crypto_request *vc_req = &vc_sym_req->base;
drivers/crypto/virtio/virtio_crypto_algs.c:	src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/virtio/virtio_crypto_algs.c:	dst_nents = sg_nents(req->dst);
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->req_data = req_data;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->type = VIRTIO_CRYPTO_SYM_OP_CIPHER;
drivers/crypto/virtio/virtio_crypto_algs.c:	if (vc_sym_req->encrypt) {
drivers/crypto/virtio/virtio_crypto_algs.c:			cpu_to_le32(req->cryptlen);
drivers/crypto/virtio/virtio_crypto_algs.c:	dst_len = virtio_crypto_alg_sg_nents_length(req->dst);
drivers/crypto/virtio/virtio_crypto_algs.c:	dst_len = min_t(unsigned int, req->cryptlen, dst_len);
drivers/crypto/virtio/virtio_crypto_algs.c:			req->cryptlen, dst_len);
drivers/crypto/virtio/virtio_crypto_algs.c:	if (unlikely(req->cryptlen + dst_len + ivsize +
drivers/crypto/virtio/virtio_crypto_algs.c:		sizeof(vc_req->status) > vcrypto->max_size)) {
drivers/crypto/virtio/virtio_crypto_algs.c:	memcpy(iv, req->iv, ivsize);
drivers/crypto/virtio/virtio_crypto_algs.c:	if (!vc_sym_req->encrypt)
drivers/crypto/virtio/virtio_crypto_algs.c:		scatterwalk_map_and_copy(req->iv, req->src,
drivers/crypto/virtio/virtio_crypto_algs.c:					 req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->iv = iv;
drivers/crypto/virtio/virtio_crypto_algs.c:	for (sg = req->src; src_nents; sg = sg_next(sg), src_nents--)
drivers/crypto/virtio/virtio_crypto_algs.c:	for (sg = req->dst; sg; sg = sg_next(sg))
drivers/crypto/virtio/virtio_crypto_algs.c:	sg_init_one(&status_sg, &vc_req->status, sizeof(vc_req->status));
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->sgs = sgs;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct virtio_crypto_request *vc_req = &vc_sym_req->base;
drivers/crypto/virtio/virtio_crypto_algs.c:	if (!req->cryptlen)
drivers/crypto/virtio/virtio_crypto_algs.c:	if (req->cryptlen % AES_BLOCK_SIZE)
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->dataq = data_vq;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->alg_cb = virtio_crypto_dataq_sym_callback;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->skcipher_ctx = ctx;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->skcipher_req = req;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->encrypt = true;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct virtio_crypto_request *vc_req = &vc_sym_req->base;
drivers/crypto/virtio/virtio_crypto_algs.c:	if (!req->cryptlen)
drivers/crypto/virtio/virtio_crypto_algs.c:	if (req->cryptlen % AES_BLOCK_SIZE)
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->dataq = data_vq;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_req->alg_cb = virtio_crypto_dataq_sym_callback;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->skcipher_ctx = ctx;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->skcipher_req = req;
drivers/crypto/virtio/virtio_crypto_algs.c:	vc_sym_req->encrypt = false;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct virtio_crypto_request *vc_req = &vc_sym_req->base;
drivers/crypto/virtio/virtio_crypto_algs.c:	struct data_queue *data_vq = vc_req->dataq;
drivers/crypto/virtio/virtio_crypto_algs.c:	if (vc_sym_req->encrypt)
drivers/crypto/virtio/virtio_crypto_algs.c:		scatterwalk_map_and_copy(req->iv, req->dst,
drivers/crypto/virtio/virtio_crypto_algs.c:					 req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/virtio/virtio_crypto_algs.c:	kfree_sensitive(vc_sym_req->iv);
drivers/crypto/virtio/virtio_crypto_algs.c:	virtcrypto_clear_request(&vc_sym_req->base);
drivers/crypto/virtio/virtio_crypto_algs.c:	crypto_finalize_skcipher_request(vc_sym_req->base.dataq->engine,
drivers/crypto/virtio/virtio_crypto_core.c:		kfree_sensitive(vc_req->req_data);
drivers/crypto/virtio/virtio_crypto_core.c:		kfree(vc_req->sgs);
drivers/crypto/virtio/virtio_crypto_core.c:			if (vc_req->alg_cb)
drivers/crypto/virtio/virtio_crypto_core.c:				vc_req->alg_cb(vc_req, len);
drivers/crypto/virtio/virtio_crypto_core.c:			kfree(vc_req->req_data);
drivers/crypto/virtio/virtio_crypto_core.c:			kfree(vc_req->sgs);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	memcpy(req->iv, rctx->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	if (!req->iv)
drivers/crypto/ccp/ccp-crypto-aes-xts.c:		if (req->cryptlen == xts_unit_sizes[unit].size) {
drivers/crypto/ccp/ccp-crypto-aes-xts.c:					      req->base.flags,
drivers/crypto/ccp/ccp-crypto-aes-xts.c:					      req->base.complete,
drivers/crypto/ccp/ccp-crypto-aes-xts.c:					      req->base.data);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/ccp/ccp-crypto-aes-xts.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	memcpy(rctx->iv, req->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.src = req->src;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.src_len = req->cryptlen;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	rctx->cmd.u.xts.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-aes-xts.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	if (!req->iv)
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	memcpy(rctx->iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	rctx->cmd.u.aes.src = req->src;
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	rctx->cmd.u.aes.src_len = req->cryptlen;
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	rctx->cmd.u.aes.aad_len = req->assoclen;
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	rctx->cmd.u.aes.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-aes-galois.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-des3.c:	struct ccp_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/ccp/ccp-crypto-des3.c:		memcpy(req->iv, rctx->iv, DES3_EDE_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-des3.c:	    (req->cryptlen & (DES3_EDE_BLOCK_SIZE - 1)))
drivers/crypto/ccp/ccp-crypto-des3.c:		if (!req->iv)
drivers/crypto/ccp/ccp-crypto-des3.c:		memcpy(rctx->iv, req->iv, DES3_EDE_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-des3.c:	rctx->cmd.u.des3.src = req->src;
drivers/crypto/ccp/ccp-crypto-des3.c:	rctx->cmd.u.des3.src_len = req->cryptlen;
drivers/crypto/ccp/ccp-crypto-des3.c:	rctx->cmd.u.des3.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-des3.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-main.c:	struct ccp_ctx *ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/ccp/ccp-crypto-main.c:			req->complete(req, -EINPROGRESS);
drivers/crypto/ccp/ccp-crypto-main.c:		backlog->req->complete(backlog->req, -EINPROGRESS);
drivers/crypto/ccp/ccp-crypto-main.c:		req->complete(req, -EINPROGRESS);
drivers/crypto/ccp/ccp-crypto-main.c:	req->complete(req, ret);
drivers/crypto/ccp/ccp-crypto-main.c:		ctx = crypto_tfm_ctx(held->req->tfm);
drivers/crypto/ccp/ccp-crypto-main.c:		held->req->complete(held->req, ret);
drivers/crypto/ccp/ccp-crypto-main.c:			backlog->req->complete(backlog->req, -EINPROGRESS);
drivers/crypto/ccp/ccp-crypto-main.c:	gfp = req->flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL : GFP_ATOMIC;
drivers/crypto/ccp/ccp-crypto-main.c:	crypto_cmd->tfm = req->tfm;
drivers/crypto/ccp/ccp-crypto-main.c:	if (req->flags & CRYPTO_TFM_REQ_MAY_BACKLOG)
drivers/crypto/ccp/ccp-crypto-rsa.c:	req->dst_len = rctx->cmd.u.rsa.key_size >> 3;
drivers/crypto/ccp/ccp-crypto-rsa.c:	rctx->cmd.u.rsa.src = req->src;
drivers/crypto/ccp/ccp-crypto-rsa.c:	rctx->cmd.u.rsa.src_len = req->src_len;
drivers/crypto/ccp/ccp-crypto-rsa.c:	rctx->cmd.u.rsa.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-rsa.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes.c:	struct ccp_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/ccp/ccp-crypto-aes.c:		memcpy(req->iv, rctx->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:	    (req->cryptlen & (AES_BLOCK_SIZE - 1)))
drivers/crypto/ccp/ccp-crypto-aes.c:		if (!req->iv)
drivers/crypto/ccp/ccp-crypto-aes.c:		memcpy(rctx->iv, req->iv, AES_BLOCK_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.src = req->src;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.src_len = req->cryptlen;
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->cmd.u.aes.dst = req->dst;
drivers/crypto/ccp/ccp-crypto-aes.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes.c:	req->iv = rctx->rfc3686_info;
drivers/crypto/ccp/ccp-crypto-aes.c:	memcpy(iv, req->iv, CTR_RFC3686_IV_SIZE);
drivers/crypto/ccp/ccp-crypto-aes.c:	rctx->rfc3686_info = req->iv;
drivers/crypto/ccp/ccp-crypto-aes.c:	req->iv = rctx->rfc3686_iv;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	if (req->result && rctx->final)
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		memcpy(req->result, rctx->iv, digest_size);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	rctx->src = req->src;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	sg_count = (nbytes) ? sg_nents(req->src) + 2 : 2;
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	gfp = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	return ccp_do_cmac_update(req, req->nbytes, 0);
drivers/crypto/ccp/ccp-crypto-aes-cmac.c:	return ccp_do_cmac_update(req, req->nbytes, 1);
drivers/crypto/ccp/ccp-crypto-sha.c:	if (req->result && rctx->final)
drivers/crypto/ccp/ccp-crypto-sha.c:		memcpy(req->result, rctx->ctx, digest_size);
drivers/crypto/ccp/ccp-crypto-sha.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_count, req->src,
drivers/crypto/ccp/ccp-crypto-sha.c:	rctx->src = req->src;
drivers/crypto/ccp/ccp-crypto-sha.c:		gfp = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/ccp/ccp-crypto-sha.c:		sg_count = sg_nents(req->src) + 1;
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = ccp_crypto_sg_table_add(&rctx->data_sg, req->src);
drivers/crypto/ccp/ccp-crypto-sha.c:		sg = req->src;
drivers/crypto/ccp/ccp-crypto-sha.c:	ret = ccp_crypto_enqueue_request(&req->base, &rctx->cmd);
drivers/crypto/ccp/ccp-crypto-sha.c:	return ccp_do_sha_update(req, req->nbytes, 0);
drivers/crypto/ccp/ccp-crypto-sha.c:	return ccp_do_sha_update(req, req->nbytes, 1);
drivers/crypto/sa2ul.c:		cmdl[upd_info->enc_size.index] |= req->enc_size;
drivers/crypto/sa2ul.c:			((u32)req->enc_offset <<
drivers/crypto/sa2ul.c:			u32 *enc_iv = (u32 *)req->enc_iv;
drivers/crypto/sa2ul.c:		cmdl[upd_info->auth_size.index] |= req->auth_size;
drivers/crypto/sa2ul.c:			((u32)req->auth_offset <<
drivers/crypto/sa2ul.c:				   req->auth_iv,
drivers/crypto/sa2ul.c:			int offset = (req->auth_size & 0xF) ? 4 : 0;
drivers/crypto/sa2ul.c:	if (req->iv) {
drivers/crypto/sa2ul.c:		result = (u32 *)req->iv;
drivers/crypto/sa2ul.c:	struct sa_ctx_info *sa_ctx = req->enc ? &req->ctx->enc : &req->ctx->dec;
drivers/crypto/sa2ul.c:	gfp_flags = req->base->flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/sa2ul.c:	if (req->src != req->dst) {
drivers/crypto/sa2ul.c:	if (req->size >= 256)
drivers/crypto/sa2ul.c:	if (req->type != CRYPTO_ALG_TYPE_AHASH) {
drivers/crypto/sa2ul.c:		if (req->enc)
drivers/crypto/sa2ul.c:			req->type |=
drivers/crypto/sa2ul.c:			req->type |=
drivers/crypto/sa2ul.c:	cmdl[sa_ctx->cmdl_size / sizeof(u32)] = req->type;
drivers/crypto/sa2ul.c:	src = req->src;
drivers/crypto/sa2ul.c:	sg_nents = sg_nents_for_len(src, req->size);
drivers/crypto/sa2ul.c:	split_size = req->size;
drivers/crypto/sa2ul.c:	if (sg_nents == 1 && split_size <= req->src->length) {
drivers/crypto/sa2ul.c:		sg_set_page(src, sg_page(req->src), split_size,
drivers/crypto/sa2ul.c:			    req->src->offset);
drivers/crypto/sa2ul.c:		mapped_sg->sgt.sgl = req->src;
drivers/crypto/sa2ul.c:		dst_nents = sg_nents_for_len(req->dst, req->size);
drivers/crypto/sa2ul.c:		if (dst_nents == 1 && split_size <= req->dst->length) {
drivers/crypto/sa2ul.c:			sg_set_page(dst, sg_page(req->dst), split_size,
drivers/crypto/sa2ul.c:				    req->dst->offset);
drivers/crypto/sa2ul.c:			mapped_sg->sgt.sgl = req->dst;
drivers/crypto/sa2ul.c:	rxd->req = (void *)req->base;
drivers/crypto/sa2ul.c:	rxd->enc = req->enc;
drivers/crypto/sa2ul.c:	rxd->iv_idx = req->ctx->iv_idx;
drivers/crypto/sa2ul.c:	rxd->tx_in->callback = req->callback;
drivers/crypto/sa2ul.c:	dmaengine_desc_set_metadata_len(tx_out, req->mdata_size);
drivers/crypto/sa2ul.c:	struct crypto_alg *alg = req->base.tfm->__crt_alg;
drivers/crypto/sa2ul.c:	if (!req->cryptlen)
drivers/crypto/sa2ul.c:	if (req->cryptlen % alg->cra_blocksize)
drivers/crypto/sa2ul.c:	if (req->cryptlen > SA_MAX_DATA_SZ ||
drivers/crypto/sa2ul.c:	    (req->cryptlen >= SA_UNSAFE_DATA_SZ_MIN &&
drivers/crypto/sa2ul.c:	     req->cryptlen <= SA_UNSAFE_DATA_SZ_MAX)) {
drivers/crypto/sa2ul.c:		skcipher_request_set_callback(subreq, req->base.flags,
drivers/crypto/sa2ul.c:					      req->base.complete,
drivers/crypto/sa2ul.c:					      req->base.data);
drivers/crypto/sa2ul.c:		skcipher_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/sa2ul.c:					   req->cryptlen, req->iv);
drivers/crypto/sa2ul.c:	sa_req.size = req->cryptlen;
drivers/crypto/sa2ul.c:	sa_req.enc_size = req->cryptlen;
drivers/crypto/sa2ul.c:	sa_req.src = req->src;
drivers/crypto/sa2ul.c:	sa_req.dst = req->dst;
drivers/crypto/sa2ul.c:	sa_req.base = &req->base;
drivers/crypto/sa2ul.c:	return sa_cipher_run(req, req->iv, 1);
drivers/crypto/sa2ul.c:	return sa_cipher_run(req, req->iv, 0);
drivers/crypto/sa2ul.c:	result = (u32 *)req->result;
drivers/crypto/sa2ul.c:		memcpy(req->result, sha1_zero_message_hash, sa_digest_size);
drivers/crypto/sa2ul.c:		memcpy(req->result, sha256_zero_message_hash, sa_digest_size);
drivers/crypto/sa2ul.c:		memcpy(req->result, sha512_zero_message_hash, sa_digest_size);
drivers/crypto/sa2ul.c:	auth_len = req->nbytes;
drivers/crypto/sa2ul.c:		subreq->base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:		subreq->nbytes = auth_len;
drivers/crypto/sa2ul.c:		subreq->src = req->src;
drivers/crypto/sa2ul.c:		subreq->result = req->result;
drivers/crypto/sa2ul.c:		subreq->nbytes = 0;
drivers/crypto/sa2ul.c:	sa_req.src = req->src;
drivers/crypto/sa2ul.c:	sa_req.dst = req->src;
drivers/crypto/sa2ul.c:	sa_req.base = &req->base;
drivers/crypto/sa2ul.c:		req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:		req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/sa2ul.c:	rctx->fallback_req.src = req->src;
drivers/crypto/sa2ul.c:		req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:	rctx->fallback_req.result = req->result;
drivers/crypto/sa2ul.c:		req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/sa2ul.c:	rctx->fallback_req.src = req->src;
drivers/crypto/sa2ul.c:	rctx->fallback_req.result = req->result;
drivers/crypto/sa2ul.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/sa2ul.c:	subreq->base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/sa2ul.c:	start = req->assoclen + req->cryptlen;
drivers/crypto/sa2ul.c:	auth_len = req->assoclen + req->cryptlen;
drivers/crypto/sa2ul.c:		scatterwalk_map_and_copy(&mdptr[4], req->dst, start, authsize,
drivers/crypto/sa2ul.c:		scatterwalk_map_and_copy(auth_tag, req->src, start, authsize,
drivers/crypto/sa2ul.c:	enc_size = req->cryptlen;
drivers/crypto/sa2ul.c:	auth_size = req->assoclen + req->cryptlen;
drivers/crypto/sa2ul.c:		aead_request_set_callback(subreq, req->base.flags,
drivers/crypto/sa2ul.c:					  req->base.complete, req->base.data);
drivers/crypto/sa2ul.c:		aead_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/sa2ul.c:				       req->cryptlen, req->iv);
drivers/crypto/sa2ul.c:		aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/sa2ul.c:	sa_req.enc_offset = req->assoclen;
drivers/crypto/sa2ul.c:	sa_req.base = &req->base;
drivers/crypto/sa2ul.c:	sa_req.src = req->src;
drivers/crypto/sa2ul.c:	sa_req.dst = req->dst;
drivers/crypto/sa2ul.c:	return sa_aead_run(req, req->iv, 1);
drivers/crypto/sa2ul.c:	return sa_aead_run(req, req->iv, 0);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		dev_err(SEC_CTX_DEV(req->ctx), "alloc req id fail!\n");
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->qp_ctx = qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	int req_id = req->req_id;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		dev_err(SEC_CTX_DEV(req->ctx), "free request id invalid!\n");
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->qp_ctx = NULL;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aead_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	u8 *mac_out = req->aead_req.out_mac;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct scatterlist *sgl = aead_req->src;
drivers/crypto/hisilicon/sec2/sec_crypto.c:				aead_req->cryptlen + aead_req->assoclen -
drivers/crypto/hisilicon/sec2/sec_crypto.c:		dev_err(SEC_CTX_DEV(req->ctx), "aead verify failure!\n");
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->err_type = bd->type2.error_type;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	ctx = req->ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (unlikely(req->err_type || done != SEC_SQE_DONE ||
drivers/crypto/hisilicon/sec2/sec_crypto.c:			req->err_type, done, flag);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (ctx->alg_type == SEC_AEAD && !req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	    !(req->flag & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/hisilicon/sec2/sec_crypto.c:	ret = hisi_qp_send(qp_ctx->qp, &req->sec_sqe);
drivers/crypto/hisilicon/sec2/sec_crypto.c:		list_add_tail(&req->backlog_head, &qp_ctx->backlog);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aead_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	int req_id = req->req_id;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		copy_size = aead_req->cryptlen + aead_req->assoclen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		copy_size = c_req->c_len;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	c_req->c_in_dma = qp_ctx->res[req_id].pbuf_dma;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (!c_req->c_in_dma) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	c_req->c_out_dma = c_req->c_in_dma;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aead_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	int req_id = req->req_id;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		copy_size = c_req->c_len + aead_req->assoclen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		copy_size = c_req->c_len;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_aead_req *a_req = &req->aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_alg_res *res = &qp_ctx->res[req->req_id];
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->use_pbuf) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:		c_req->c_ivin = res->pbuf + SEC_PBUF_IV_OFFSET;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		c_req->c_ivin_dma = res->pbuf_dma + SEC_PBUF_IV_OFFSET;
drivers/crypto/hisilicon/sec2/sec_crypto.c:			a_req->out_mac = res->pbuf + SEC_PBUF_MAC_OFFSET;
drivers/crypto/hisilicon/sec2/sec_crypto.c:			a_req->out_mac_dma = res->pbuf_dma +
drivers/crypto/hisilicon/sec2/sec_crypto.c:	c_req->c_ivin = res->c_ivin;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	c_req->c_ivin_dma = res->c_ivin_dma;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		a_req->out_mac = res->out_mac;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		a_req->out_mac_dma = res->out_mac_dma;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	c_req->c_in = hisi_acc_sg_buf_map_to_hw_sgl(dev, src,
drivers/crypto/hisilicon/sec2/sec_crypto.c:						    req->req_id,
drivers/crypto/hisilicon/sec2/sec_crypto.c:						    &c_req->c_in_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (IS_ERR(c_req->c_in)) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:		return PTR_ERR(c_req->c_in);
drivers/crypto/hisilicon/sec2/sec_crypto.c:		c_req->c_out = c_req->c_in;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		c_req->c_out_dma = c_req->c_in_dma;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		c_req->c_out = hisi_acc_sg_buf_map_to_hw_sgl(dev, dst,
drivers/crypto/hisilicon/sec2/sec_crypto.c:							     req->req_id,
drivers/crypto/hisilicon/sec2/sec_crypto.c:							     &c_req->c_out_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:		if (IS_ERR(c_req->c_out)) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:			hisi_acc_sg_buf_unmap(dev, src, c_req->c_in);
drivers/crypto/hisilicon/sec2/sec_crypto.c:			return PTR_ERR(c_req->c_out);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->use_pbuf) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:			hisi_acc_sg_buf_unmap(dev, src, c_req->c_in);
drivers/crypto/hisilicon/sec2/sec_crypto.c:		hisi_acc_sg_buf_unmap(dev, dst, c_req->c_out);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sq = req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sq = req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aq = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aq = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sk_req = req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	memcpy(c_req->c_ivin, sk_req->iv, ctx->c_ctx.ivsize);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_sqe *sec_sqe = &req->sec_sqe;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.c_ivin_addr = cpu_to_le64(c_req->c_ivin_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.data_src_addr = cpu_to_le64(c_req->c_in_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.data_dst_addr = cpu_to_le64(c_req->c_out_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (c_req->encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->use_pbuf)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (c_req->c_in_dma != c_req->c_out_dma)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->use_pbuf)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.clen_ivhlen |= cpu_to_le32(c_req->c_len);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.tag = cpu_to_le16((u16)req->req_id);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aead_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sk_req = req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	u32 iv_size = req->ctx->c_ctx.ivsize;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sgl = alg_type == SEC_SKCIPHER ? sk_req->dst : aead_req->dst;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sgl = alg_type == SEC_SKCIPHER ? sk_req->src : aead_req->src;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		iv = sk_req->iv;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		cryptlen = sk_req->cryptlen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		iv = aead_req->iv;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		cryptlen = aead_req->cryptlen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		dev_err(SEC_CTX_DEV(req->ctx), "copy output iv error!\n");
drivers/crypto/hisilicon/sec2/sec_crypto.c:		list_del(&backlog_req->backlog_head);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sk_req = req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (!err && ctx->c_ctx.c_mode == SEC_CMODE_CBC && req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		backlog_sk_req = backlog_req->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		backlog_sk_req->base.complete(&backlog_sk_req->base,
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sk_req->base.complete(&sk_req->base, err);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aead_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	memcpy(c_req->c_ivin, aead_req->iv, ctx->c_ctx.ivsize);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_aead_req *a_req = &req->aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *aq = a_req->aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.alen_ivllen = cpu_to_le32(c_req->c_len + aq->assoclen);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_sqe->type2.mac_addr = cpu_to_le64(a_req->out_mac_dma);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_sqe *sec_sqe = &req->sec_sqe;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sec_auth_bd_fill_ex(auth_ctx, req->c_req.encrypt, req, sec_sqe);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *a_req = req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_aead_req *aead_req = &req->aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_qp_ctx *qp_ctx = req->qp_ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (!err && c->c_ctx.c_mode == SEC_CMODE_CBC && c_req->encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (!err && c_req->encrypt) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:		struct scatterlist *sgl = a_req->dst;
drivers/crypto/hisilicon/sec2/sec_crypto.c:					  aead_req->out_mac,
drivers/crypto/hisilicon/sec2/sec_crypto.c:					  authsize, a_req->cryptlen +
drivers/crypto/hisilicon/sec2/sec_crypto.c:					  a_req->assoclen);
drivers/crypto/hisilicon/sec2/sec_crypto.c:			dev_err(SEC_CTX_DEV(req->ctx), "copy out mac err!\n");
drivers/crypto/hisilicon/sec2/sec_crypto.c:		backlog_aead_req = backlog_req->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		backlog_aead_req->base.complete(&backlog_aead_req->base,
drivers/crypto/hisilicon/sec2/sec_crypto.c:	a_req->base.complete(&a_req->base, err);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->req_id = sec_alloc_req_id(req, qp_ctx);
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (unlikely(req->req_id < 0)) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:		return req->req_id;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct sec_cipher_req *c_req = &req->c_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (ctx->c_ctx.c_mode == SEC_CMODE_CBC && !req->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		(ret == -EBUSY && !(req->flag & CRYPTO_TFM_REQ_MAY_BACKLOG)))) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (ctx->c_ctx.c_mode == SEC_CMODE_CBC && !req->c_req.encrypt) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:			memcpy(req->c_req.sk_req->iv, c_req->c_ivin,
drivers/crypto/hisilicon/sec2/sec_crypto.c:			memcpy(req->aead_req.aead_req->iv, c_req->c_ivin,
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct skcipher_request *sk_req = sreq->c_req.sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (unlikely(!sk_req->src || !sk_req->dst)) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	sreq->c_req.c_len = sk_req->cryptlen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (ctx->pbuf_supported && sk_req->cryptlen <= SEC_PBUF_SZ)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->use_pbuf = true;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->use_pbuf = false;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		if (unlikely(sk_req->cryptlen & (DES3_EDE_BLOCK_SIZE - 1))) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:		if (unlikely(sk_req->cryptlen & (AES_BLOCK_SIZE - 1))) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (!sk_req->cryptlen)
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->flag = sk_req->base.flags;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->c_req.sk_req = sk_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->c_req.encrypt = encrypt;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->ctx = ctx;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	struct aead_request *req = sreq->aead_req.aead_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (unlikely(!req->src || !req->dst || !req->cryptlen ||
drivers/crypto/hisilicon/sec2/sec_crypto.c:		req->assoclen > SEC_MAX_AAD_LEN)) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (ctx->pbuf_supported && (req->cryptlen + req->assoclen) <=
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->use_pbuf = true;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->use_pbuf = false;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (sreq->c_req.encrypt)
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->c_req.c_len = req->cryptlen;
drivers/crypto/hisilicon/sec2/sec_crypto.c:		sreq->c_req.c_len = req->cryptlen - authsize;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	if (unlikely(sreq->c_req.c_len & (AES_BLOCK_SIZE - 1))) {
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->flag = a_req->base.flags;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->aead_req.aead_req = a_req;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->c_req.encrypt = encrypt;
drivers/crypto/hisilicon/sec2/sec_crypto.c:	req->ctx = ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ctx = hpre_req->ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_req->req_id = id;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		ktime_get_ts64(&hpre_req->req_time);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_ctx *ctx = hpre_req->ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	int id = hpre_req->req_id;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	if (hpre_req->req_id >= 0) {
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		hpre_req->req_id = HPRE_INVLD_REQ_ID;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_ctx *ctx = hpre_req->ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		hpre_req->src = NULL;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		hpre_req->dst = NULL;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_ctx *ctx = hpre_req->ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		hpre_req->src = ptr;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		hpre_req->dst = ptr;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_sqe *msg = &hpre_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_ctx *ctx = hpre_req->ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_sqe *sqe = &req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		if (req->src)
drivers/crypto/hisilicon/hpre/hpre_crypto.c:			dma_free_coherent(dev, ctx->key_sz, req->src, tmp);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	if (req->dst) {
drivers/crypto/hisilicon/hpre/hpre_crypto.c:			scatterwalk_map_and_copy(req->dst, dst, 0,
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		dma_free_coherent(dev, ctx->key_sz, req->dst, tmp);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	time_use_us = (reply_time.tv_sec - req->req_time.tv_sec) *
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		(reply_time.tv_nsec - req->req_time.tv_nsec) /
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	areq = req->areq.dh;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	areq->dst_len = ctx->key_sz;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_hw_data_clr_all(ctx, req, areq->dst, areq->src);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	areq = req->areq.rsa;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	areq->dst_len = ctx->key_sz;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_hw_data_clr_all(ctx, req, areq->dst, areq->src);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	req->cb(ctx, resp);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		if (akreq->dst_len < ctx->key_sz) {
drivers/crypto/hisilicon/hpre/hpre_crypto.c:			akreq->dst_len = ctx->key_sz;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		h_req->cb = hpre_rsa_cb;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		h_req->areq.rsa = akreq;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		msg = &h_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		if (kreq->dst_len < ctx->key_sz) {
drivers/crypto/hisilicon/hpre/hpre_crypto.c:			kreq->dst_len = ctx->key_sz;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		h_req->cb = hpre_dh_cb;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		h_req->areq.dh = kreq;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		msg = &h_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	h_req->ctx = ctx;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_sqe *msg = &hpre_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	if (req->src) {
drivers/crypto/hisilicon/hpre/hpre_crypto.c:		ret = hpre_hw_data_init(hpre_req, req->src, req->src_len, 1, 1);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ret = hpre_hw_data_init(hpre_req, req->dst, req->dst_len, 0, 1);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	if (ctx->crt_g2_mode && !req->src)
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_hw_data_clr_all(ctx, hpre_req, req->dst, req->src);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_sqe *msg = &hpre_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ret = hpre_hw_data_init(hpre_req, req->src, req->src_len, 1, 0);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ret = hpre_hw_data_init(hpre_req, req->dst, req->dst_len, 0, 0);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_hw_data_clr_all(ctx, hpre_req, req->dst, req->src);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	struct hpre_sqe *msg = &hpre_req->req;
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ret = hpre_hw_data_init(hpre_req, req->src, req->src_len, 1, 0);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	ret = hpre_hw_data_init(hpre_req, req->dst, req->dst_len, 0, 0);
drivers/crypto/hisilicon/hpre/hpre_crypto.c:	hpre_hw_data_clr_all(ctx, hpre_req, req->dst, req->src);
drivers/crypto/hisilicon/zip/zip_crypto.c:	clear_bit(req->req_id, req_q->req_bitmap);
drivers/crypto/hisilicon/zip/zip_crypto.c:	struct acomp_req *acomp_req = req->req;
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_acc_sg_buf_unmap(dev, acomp_req->src, req->hw_src);
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_acc_sg_buf_unmap(dev, acomp_req->dst, req->hw_dst);
drivers/crypto/hisilicon/zip/zip_crypto.c:	acomp_req->dlen = dlen + head_size;
drivers/crypto/hisilicon/zip/zip_crypto.c:	if (acomp_req->base.complete)
drivers/crypto/hisilicon/zip/zip_crypto.c:	if (!acomp_req->src || !acomp_req->slen)
drivers/crypto/hisilicon/zip/zip_crypto.c:	    (acomp_req->slen < GZIP_HEAD_FEXTRA_SHIFT))
drivers/crypto/hisilicon/zip/zip_crypto.c:	struct acomp_req *a_req = req->req;
drivers/crypto/hisilicon/zip/zip_crypto.c:	if (!a_req->src || !a_req->slen || !a_req->dst || !a_req->dlen)
drivers/crypto/hisilicon/zip/zip_crypto.c:	req->hw_src = hisi_acc_sg_buf_map_to_hw_sgl(dev, a_req->src, pool,
drivers/crypto/hisilicon/zip/zip_crypto.c:						    req->req_id << 1, &input);
drivers/crypto/hisilicon/zip/zip_crypto.c:	if (IS_ERR(req->hw_src)) {
drivers/crypto/hisilicon/zip/zip_crypto.c:			PTR_ERR(req->hw_src));
drivers/crypto/hisilicon/zip/zip_crypto.c:		return PTR_ERR(req->hw_src);
drivers/crypto/hisilicon/zip/zip_crypto.c:	req->dma_src = input;
drivers/crypto/hisilicon/zip/zip_crypto.c:	req->hw_dst = hisi_acc_sg_buf_map_to_hw_sgl(dev, a_req->dst, pool,
drivers/crypto/hisilicon/zip/zip_crypto.c:						    (req->req_id << 1) + 1,
drivers/crypto/hisilicon/zip/zip_crypto.c:	if (IS_ERR(req->hw_dst)) {
drivers/crypto/hisilicon/zip/zip_crypto.c:		ret = PTR_ERR(req->hw_dst);
drivers/crypto/hisilicon/zip/zip_crypto.c:	req->dma_dst = output;
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_zip_fill_sqe(&zip_sqe, qp->req_type, input, output, a_req->slen,
drivers/crypto/hisilicon/zip/zip_crypto.c:			  a_req->dlen, req->sskip, req->dskip);
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_zip_config_tag(&zip_sqe, req->req_id);
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_acc_sg_buf_unmap(dev, a_req->dst, req->hw_dst);
drivers/crypto/hisilicon/zip/zip_crypto.c:	hisi_acc_sg_buf_unmap(dev, a_req->src, req->hw_src);
drivers/crypto/hisilicon/zip/zip_crypto.c:	struct hisi_zip_ctx *ctx = crypto_tfm_ctx(acomp_req->base.tfm);
drivers/crypto/hisilicon/zip/zip_crypto.c:	head_size = add_comp_head(acomp_req->dst, qp_ctx->qp->req_type);
drivers/crypto/hisilicon/zip/zip_crypto.c:	struct hisi_zip_ctx *ctx = crypto_tfm_ctx(acomp_req->base.tfm);
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 |= cfg->c_mode << SEC_BD_W0_C_MODE_S;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w1 |= cfg->c_alg << SEC_BD_W1_C_ALG_S;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w3 |= cfg->key_len << SEC_BD_W3_C_KEY_LEN_S;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 |= cfg->c_width << SEC_BD_W0_C_WIDTH_S;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->cipher_key_addr_lo = lower_32_bits(ctx->pkey);
drivers/crypto/hisilicon/sec/sec_algs.c:	req->cipher_key_addr_hi = upper_32_bits(ctx->pkey);
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_lock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	list_for_each_entry_safe(el, temp, &sec_req->elements, head) {
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_unlock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	struct sec_alg_tfm_ctx *ctx = sec_req->tfm_ctx;
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req_el = list_first_entry(&sec_req->elements, struct sec_request_el,
drivers/crypto/hisilicon/sec/sec_algs.c:		sec_req->err = -EINVAL;
drivers/crypto/hisilicon/sec/sec_algs.c:					   skreq->iv,
drivers/crypto/hisilicon/sec/sec_algs.c:					   skreq->iv,
drivers/crypto/hisilicon/sec/sec_algs.c:		crypto_inc(skreq->iv, 16);
drivers/crypto/hisilicon/sec/sec_algs.c:		    backlog_req->num_elements) ||
drivers/crypto/hisilicon/sec/sec_algs.c:		     backlog_req->num_elements)) {
drivers/crypto/hisilicon/sec/sec_algs.c:			backlog_req->req_base->complete(backlog_req->req_base,
drivers/crypto/hisilicon/sec/sec_algs.c:			list_del(&backlog_req->backlog_head);
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_lock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_unlock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_lock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	done = list_empty(&sec_req->elements);
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_unlock(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:			dma_unmap_single(dev, sec_req->dma_iv,
drivers/crypto/hisilicon/sec/sec_algs.c:		dma_unmap_sg(dev, skreq->src, sec_req->len_in,
drivers/crypto/hisilicon/sec/sec_algs.c:		if (skreq->src != skreq->dst)
drivers/crypto/hisilicon/sec/sec_algs.c:			dma_unmap_sg(dev, skreq->dst, sec_req->len_out,
drivers/crypto/hisilicon/sec/sec_algs.c:		skreq->base.complete(&skreq->base, sec_req->err);
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->cb(resp, sec_req->req_base);
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 &= ~SEC_BD_W0_CIPHER_M;
drivers/crypto/hisilicon/sec/sec_algs.c:		req->w0 |= SEC_CIPHER_ENCRYPT << SEC_BD_W0_CIPHER_S;
drivers/crypto/hisilicon/sec/sec_algs.c:		req->w0 |= SEC_CIPHER_DECRYPT << SEC_BD_W0_CIPHER_S;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 &= ~SEC_BD_W0_C_GRAN_SIZE_19_16_M;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 |= ((el_size >> 16) << SEC_BD_W0_C_GRAN_SIZE_19_16_S) &
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 &= ~SEC_BD_W0_C_GRAN_SIZE_21_20_M;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w0 |= ((el_size >> 20) << SEC_BD_W0_C_GRAN_SIZE_21_20_S) &
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w2 = ((1 << SEC_BD_W2_GRAN_NUM_S) & SEC_BD_W2_GRAN_NUM_M) |
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w3 &= ~SEC_BD_W3_CIPHER_LEN_OFFSET_M;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->w1 |= SEC_BD_W1_ADDR_TYPE;
drivers/crypto/hisilicon/sec/sec_algs.c:	req->data_addr_lo = lower_32_bits(el->dma_in);
drivers/crypto/hisilicon/sec/sec_algs.c:	req->data_addr_hi = upper_32_bits(el->dma_in);
drivers/crypto/hisilicon/sec/sec_algs.c:		req->w0 |= SEC_BD_W0_DE;
drivers/crypto/hisilicon/sec/sec_algs.c:		req->cipher_destin_addr_lo = lower_32_bits(el->dma_out);
drivers/crypto/hisilicon/sec/sec_algs.c:		req->cipher_destin_addr_hi = upper_32_bits(el->dma_out);
drivers/crypto/hisilicon/sec/sec_algs.c:		req->w0 &= ~SEC_BD_W0_DE;
drivers/crypto/hisilicon/sec/sec_algs.c:		req->cipher_destin_addr_lo = lower_32_bits(el->dma_in);
drivers/crypto/hisilicon/sec/sec_algs.c:		req->cipher_destin_addr_hi = upper_32_bits(el->dma_in);
drivers/crypto/hisilicon/sec/sec_algs.c:	bool split = skreq->src != skreq->dst;
drivers/crypto/hisilicon/sec/sec_algs.c:	gfp_t gfp = skreq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL : GFP_ATOMIC;
drivers/crypto/hisilicon/sec/sec_algs.c:	mutex_init(&sec_req->lock);
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->req_base = &skreq->base;
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->err = 0;
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->len_in = sg_nents(skreq->src);
drivers/crypto/hisilicon/sec/sec_algs.c:	ret = sec_alg_alloc_and_calc_split_sizes(skreq->cryptlen, &split_sizes,
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->num_elements = steps;
drivers/crypto/hisilicon/sec/sec_algs.c:	ret = sec_map_and_split_sg(skreq->src, split_sizes, steps, &splits_in,
drivers/crypto/hisilicon/sec/sec_algs.c:				   &splits_in_nents, sec_req->len_in,
drivers/crypto/hisilicon/sec/sec_algs.c:		sec_req->len_out = sg_nents(skreq->dst);
drivers/crypto/hisilicon/sec/sec_algs.c:		ret = sec_map_and_split_sg(skreq->dst, split_sizes, steps,
drivers/crypto/hisilicon/sec/sec_algs.c:					   sec_req->len_out, info->dev, gfp);
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->tfm_ctx = ctx;
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_req->cb = sec_skcipher_alg_callback;
drivers/crypto/hisilicon/sec/sec_algs.c:	INIT_LIST_HEAD(&sec_req->elements);
drivers/crypto/hisilicon/sec/sec_algs.c:		sec_req->dma_iv = dma_map_single(info->dev, skreq->iv,
drivers/crypto/hisilicon/sec/sec_algs.c:		if (dma_mapping_error(info->dev, sec_req->dma_iv)) {
drivers/crypto/hisilicon/sec/sec_algs.c:					       skreq->src != skreq->dst,
drivers/crypto/hisilicon/sec/sec_algs.c:		el->req.cipher_iv_addr_lo = lower_32_bits(sec_req->dma_iv);
drivers/crypto/hisilicon/sec/sec_algs.c:		el->req.cipher_iv_addr_hi = upper_32_bits(sec_req->dma_iv);
drivers/crypto/hisilicon/sec/sec_algs.c:		list_add_tail(&el->head, &sec_req->elements);
drivers/crypto/hisilicon/sec/sec_algs.c:		if ((skreq->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {
drivers/crypto/hisilicon/sec/sec_algs.c:			list_add_tail(&sec_req->backlog_head, &ctx->backlog);
drivers/crypto/hisilicon/sec/sec_algs.c:	list_for_each_entry_safe(el, temp, &sec_req->elements, head) {
drivers/crypto/hisilicon/sec/sec_algs.c:		dma_unmap_single(info->dev, sec_req->dma_iv,
drivers/crypto/hisilicon/sec/sec_algs.c:		sec_unmap_sg_on_err(skreq->dst, steps, splits_out,
drivers/crypto/hisilicon/sec/sec_algs.c:				    splits_out_nents, sec_req->len_out,
drivers/crypto/hisilicon/sec/sec_algs.c:	sec_unmap_sg_on_err(skreq->src, steps, splits_in, splits_in_nents,
drivers/crypto/hisilicon/sec/sec_algs.c:			    sec_req->len_in, info->dev);
drivers/crypto/qce/common.c:	struct crypto_ahash *ahash = __crypto_ahash_cast(async_req->tfm);
drivers/crypto/qce/common.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(async_req->tfm);
drivers/crypto/qce/common.c:	unsigned int blocksize = crypto_tfm_alg_blocksize(async_req->tfm);
drivers/crypto/qce/common.c:	if (!rctx->last_blk && req->nbytes % blocksize)
drivers/crypto/qce/common.c:	qce_write(qce, REG_AUTH_SEG_SIZE, req->nbytes);
drivers/crypto/qce/common.c:	qce_write(qce, REG_SEG_SIZE, req->nbytes);
drivers/crypto/qce/common.c:	struct qce_cipher_ctx *ctx = crypto_tfm_ctx(async_req->tfm);
drivers/crypto/qce/skcipher.c:	diff_dst = (req->src != req->dst) ? true : false;
drivers/crypto/qce/skcipher.c:	rctx->iv = req->iv;
drivers/crypto/qce/skcipher.c:	rctx->cryptlen = req->cryptlen;
drivers/crypto/qce/skcipher.c:	diff_dst = (req->src != req->dst) ? true : false;
drivers/crypto/qce/skcipher.c:	rctx->src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/qce/skcipher.c:		rctx->dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/qce/skcipher.c:	gfp = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/qce/skcipher.c:	sg = qce_sgtable_add(&rctx->dst_tbl, req->dst, req->cryptlen);
drivers/crypto/qce/skcipher.c:		ret = dma_map_sg(qce->dev, req->src, rctx->src_nents, dir_src);
drivers/crypto/qce/skcipher.c:		rctx->src_sg = req->src;
drivers/crypto/qce/skcipher.c:	ret = qce_start(async_req, tmpl->crypto_alg_type, req->cryptlen, 0);
drivers/crypto/qce/skcipher.c:		dma_unmap_sg(qce->dev, req->src, rctx->src_nents, dir_src);
drivers/crypto/qce/skcipher.c:	      req->cryptlen <= aes_sw_max_len) ||
drivers/crypto/qce/skcipher.c:	     (IS_XTS(rctx->flags) && req->cryptlen > QCE_SECTOR_SIZE &&
drivers/crypto/qce/skcipher.c:	      req->cryptlen % QCE_SECTOR_SIZE))) {
drivers/crypto/qce/skcipher.c:					      req->base.flags,
drivers/crypto/qce/skcipher.c:					      req->base.complete,
drivers/crypto/qce/skcipher.c:					      req->base.data);
drivers/crypto/qce/skcipher.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/qce/skcipher.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/qce/skcipher.c:	return tmpl->qce->async_req_enqueue(tmpl->qce, &req->base);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(async_req->tfm);
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	if (req->result && rctx->last_blk)
drivers/crypto/qce/sha.c:		memcpy(req->result, result->auth_iv, digestsize);
drivers/crypto/qce/sha.c:	req->src = rctx->src_orig;
drivers/crypto/qce/sha.c:	req->nbytes = rctx->nbytes_orig;
drivers/crypto/qce/sha.c:	struct qce_sha_ctx *ctx = crypto_tfm_ctx(async_req->tfm);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(async_req->tfm);
drivers/crypto/qce/sha.c:	rctx->src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/qce/sha.c:	ret = dma_map_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	ret = qce_dma_prep_sgs(&qce->dma, req->src, rctx->src_nents,
drivers/crypto/qce/sha.c:	dma_unmap_sg(qce->dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(req->base.tfm);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(req->base.tfm);
drivers/crypto/qce/sha.c:	rctx->count += req->nbytes;
drivers/crypto/qce/sha.c:	total = req->nbytes + rctx->buflen;
drivers/crypto/qce/sha.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buflen, req->src,
drivers/crypto/qce/sha.c:					 0, req->nbytes, 0);
drivers/crypto/qce/sha.c:		rctx->buflen += req->nbytes;
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:		unsigned int src_offset = req->nbytes - hash_later;
drivers/crypto/qce/sha.c:		scatterwalk_map_and_copy(rctx->buf, req->src, src_offset,
drivers/crypto/qce/sha.c:	sg = sg_last = req->src;
drivers/crypto/qce/sha.c:		sg_chain(rctx->sg, 2, req->src);
drivers/crypto/qce/sha.c:		req->src = rctx->sg;
drivers/crypto/qce/sha.c:	req->nbytes = nbytes;
drivers/crypto/qce/sha.c:	return qce->async_req_enqueue(tmpl->qce, &req->base);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(req->base.tfm);
drivers/crypto/qce/sha.c:			memcpy(req->result, tmpl->hash_zero,
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:	req->src = rctx->sg;
drivers/crypto/qce/sha.c:	req->nbytes = rctx->buflen;
drivers/crypto/qce/sha.c:	return qce->async_req_enqueue(tmpl->qce, &req->base);
drivers/crypto/qce/sha.c:	struct qce_alg_template *tmpl = to_ahash_tmpl(req->base.tfm);
drivers/crypto/qce/sha.c:	rctx->src_orig = req->src;
drivers/crypto/qce/sha.c:	rctx->nbytes_orig = req->nbytes;
drivers/crypto/qce/sha.c:			memcpy(req->result, tmpl->hash_zero,
drivers/crypto/qce/sha.c:	return qce->async_req_enqueue(tmpl->qce, &req->base);
drivers/crypto/qce/core.c:	u32 type = crypto_tfm_alg_type(async_req->tfm);
drivers/crypto/qce/core.c:		req->complete(req, qce->result);
drivers/crypto/atmel-aes.c:	if (req->cryptlen < ivsize)
drivers/crypto/atmel-aes.c:		scatterwalk_map_and_copy(req->iv, req->dst,
drivers/crypto/atmel-aes.c:					 req->cryptlen - ivsize, ivsize, 0);
drivers/crypto/atmel-aes.c:		if (req->src == req->dst)
drivers/crypto/atmel-aes.c:			memcpy(req->iv, rctx->lastc, ivsize);
drivers/crypto/atmel-aes.c:			scatterwalk_map_and_copy(req->iv, req->src,
drivers/crypto/atmel-aes.c:						 req->cryptlen - ivsize,
drivers/crypto/atmel-aes.c:	memcpy(req->iv, ctx->iv, ivsize);
drivers/crypto/atmel-aes.c:		dd->areq->complete(dd->areq, err);
drivers/crypto/atmel-aes.c:	ctx = crypto_tfm_ctx(areq->tfm);
drivers/crypto/atmel-aes.c:	bool use_dma = (req->cryptlen >= ATMEL_AES_DMA_THRESHOLD ||
drivers/crypto/atmel-aes.c:	atmel_aes_write_ctrl(dd, use_dma, (void *)req->iv);
drivers/crypto/atmel-aes.c:		return atmel_aes_dma_start(dd, req->src, req->dst,
drivers/crypto/atmel-aes.c:					   req->cryptlen,
drivers/crypto/atmel-aes.c:	return atmel_aes_cpu_start(dd, req->src, req->dst, req->cryptlen,
drivers/crypto/atmel-aes.c:	if (ctx->offset >= req->cryptlen)
drivers/crypto/atmel-aes.c:	datalen = req->cryptlen - ctx->offset;
drivers/crypto/atmel-aes.c:	src = scatterwalk_ffwd(ctx->src, req->src, ctx->offset);
drivers/crypto/atmel-aes.c:	dst = ((req->src == req->dst) ? src :
drivers/crypto/atmel-aes.c:	       scatterwalk_ffwd(ctx->dst, req->dst, ctx->offset));
drivers/crypto/atmel-aes.c:	memcpy(ctx->iv, req->iv, AES_BLOCK_SIZE);
drivers/crypto/atmel-aes.c:	    !(mode & AES_FLAGS_ENCRYPT) && req->src == req->dst) {
drivers/crypto/atmel-aes.c:		if (req->cryptlen >= ivsize)
drivers/crypto/atmel-aes.c:			scatterwalk_map_and_copy(rctx->lastc, req->src,
drivers/crypto/atmel-aes.c:						 req->cryptlen - ivsize,
drivers/crypto/atmel-aes.c:	return atmel_aes_handle_queue(dd, &req->base);
drivers/crypto/atmel-aes.c:	const void *iv = req->iv;
drivers/crypto/atmel-aes.c:	ctx->textlen = req->cryptlen - (enc ? 0 : authsize);
drivers/crypto/atmel-aes.c:	if (likely(req->assoclen != 0 || ctx->textlen != 0))
drivers/crypto/atmel-aes.c:	atmel_aes_write(dd, AES_AADLENR, req->assoclen);
drivers/crypto/atmel-aes.c:	if (unlikely(req->assoclen == 0)) {
drivers/crypto/atmel-aes.c:	padlen = atmel_aes_padlen(req->assoclen, AES_BLOCK_SIZE);
drivers/crypto/atmel-aes.c:	if (unlikely(req->assoclen + padlen > dd->buflen))
drivers/crypto/atmel-aes.c:	sg_copy_to_buffer(req->src, sg_nents(req->src), dd->buf, req->assoclen);
drivers/crypto/atmel-aes.c:	dd->datalen = req->assoclen + padlen;
drivers/crypto/atmel-aes.c:	src = scatterwalk_ffwd(ctx->src, req->src, req->assoclen);
drivers/crypto/atmel-aes.c:	dst = ((req->src == req->dst) ? src :
drivers/crypto/atmel-aes.c:	       scatterwalk_ffwd(ctx->dst, req->dst, req->assoclen));
drivers/crypto/atmel-aes.c:	data[0] = cpu_to_be64(req->assoclen * 8);
drivers/crypto/atmel-aes.c:	offset = req->assoclen + ctx->textlen;
drivers/crypto/atmel-aes.c:		scatterwalk_map_and_copy(otag, req->dst, offset, authsize, 1);
drivers/crypto/atmel-aes.c:		scatterwalk_map_and_copy(itag, req->src, offset, authsize, 0);
drivers/crypto/atmel-aes.c:	return atmel_aes_handle_queue(dd, &req->base);
drivers/crypto/atmel-aes.c:	/* Compute the tweak value from req->iv with ecb(aes). */
drivers/crypto/atmel-aes.c:	atmel_aes_write_block(dd, AES_IDATAR(0), req->iv);
drivers/crypto/atmel-aes.c:	bool use_dma = (req->cryptlen >= ATMEL_AES_DMA_THRESHOLD);
drivers/crypto/atmel-aes.c:		return atmel_aes_dma_start(dd, req->src, req->dst,
drivers/crypto/atmel-aes.c:					   req->cryptlen,
drivers/crypto/atmel-aes.c:	return atmel_aes_cpu_start(dd, req->src, req->dst, req->cryptlen,
drivers/crypto/atmel-aes.c:				      req->src, req->assoclen,
drivers/crypto/atmel-aes.c:	src = scatterwalk_ffwd(rctx->src, req->src, req->assoclen);
drivers/crypto/atmel-aes.c:	if (req->src != req->dst)
drivers/crypto/atmel-aes.c:		dst = scatterwalk_ffwd(rctx->dst, req->dst, req->assoclen);
drivers/crypto/atmel-aes.c:	memcpy(iv, req->iv, sizeof(iv));
drivers/crypto/atmel-aes.c:	offs = req->assoclen + rctx->textlen;
drivers/crypto/atmel-aes.c:		scatterwalk_map_and_copy(odigest, req->dst, offs, authsize, 1);
drivers/crypto/atmel-aes.c:		scatterwalk_map_and_copy(idigest, req->src, offs, authsize, 0);
drivers/crypto/atmel-aes.c:	if (!enc && req->cryptlen < authsize)
drivers/crypto/atmel-aes.c:	rctx->textlen = req->cryptlen - (enc ? 0 : authsize);
drivers/crypto/atmel-aes.c:	if (!rctx->textlen && !req->assoclen)
drivers/crypto/atmel-aes.c:	return atmel_aes_handle_queue(dd, &req->base);
drivers/crypto/caam/caampkc.c:	dma_unmap_sg(dev, req->dst, edesc->dst_nents, DMA_FROM_DEVICE);
drivers/crypto/caam/caampkc.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caampkc.c:	if (req->src_len > key->n_sz) {
drivers/crypto/caam/caampkc.c:		lzeros = caam_rsa_count_leading_zeros(req->src, req->src_len -
drivers/crypto/caam/caampkc.c:		req_ctx->fixup_src = scatterwalk_ffwd(req_ctx->src, req->src,
drivers/crypto/caam/caampkc.c:		req_ctx->fixup_src_len = req->src_len - lzeros;
drivers/crypto/caam/caampkc.c:		diff_size = key->n_sz - req->src_len;
drivers/crypto/caam/caampkc.c:		req_ctx->fixup_src = req->src;
drivers/crypto/caam/caampkc.c:		req_ctx->fixup_src_len = req->src_len;
drivers/crypto/caam/caampkc.c:	dst_nents = sg_nents_for_len(req->dst, req->dst_len);
drivers/crypto/caam/caampkc.c:	mapped_dst_nents = dma_map_sg(dev, req->dst, dst_nents,
drivers/crypto/caam/caampkc.c:		sg_to_sec4_sg_last(req->dst, req->dst_len,
drivers/crypto/caam/caampkc.c:	dma_unmap_sg(dev, req->dst, dst_nents, DMA_FROM_DEVICE);
drivers/crypto/caam/caampkc.c:		pdb->g_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caampkc.c:		pdb->f_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caampkc.c:		pdb->f_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caampkc.c:		pdb->f_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caampkc.c:	if (req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)
drivers/crypto/caam/caampkc.c:	if (req->dst_len < key->n_sz) {
drivers/crypto/caam/caampkc.c:		req->dst_len = key->n_sz;
drivers/crypto/caam/caampkc.c:	if (req->dst_len < key->n_sz) {
drivers/crypto/caam/caampkc.c:		req->dst_len = key->n_sz;
drivers/crypto/caam/caamhash.c:		dma_unmap_sg(dev, req->src, edesc->src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:	memcpy(req->result, state->caam_ctx, digestsize);
drivers/crypto/caam/caamhash.c:		req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamhash.c:	scatterwalk_map_and_copy(state->buf, req->src,
drivers/crypto/caam/caamhash.c:				 req->nbytes - state->next_buflen,
drivers/crypto/caam/caamhash.c:	if (req->result)
drivers/crypto/caam/caamhash.c:				     DUMP_PREFIX_ADDRESS, 16, 4, req->result,
drivers/crypto/caam/caamhash.c:		req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamhash.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamhash.c:		sg_to_sec4_sg_last(req->src, to_hash, sg + first_sg, 0);
drivers/crypto/caam/caamhash.c:		src_dma = sg_dma_address(req->src);
drivers/crypto/caam/caamhash.c:	if (req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)
drivers/crypto/caam/caamhash.c:	int in_len = *buflen + req->nbytes, to_hash;
drivers/crypto/caam/caamhash.c:		int src_len = req->nbytes - *next_buflen;
drivers/crypto/caam/caamhash.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamhash.c:			mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:			dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:			sg_to_sec4_sg_last(req->src, src_len,
drivers/crypto/caam/caamhash.c:		scatterwalk_map_and_copy(buf + *buflen, req->src, 0,
drivers/crypto/caam/caamhash.c:					 req->nbytes, 0);
drivers/crypto/caam/caamhash.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamhash.c:		mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:		dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:				  req->nbytes);
drivers/crypto/caam/caamhash.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamhash.c:		mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:		dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:				  req->nbytes);
drivers/crypto/caam/caamhash.c:	int in_len = *buflen + req->nbytes, to_hash;
drivers/crypto/caam/caamhash.c:		int src_len = req->nbytes - *next_buflen;
drivers/crypto/caam/caamhash.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamhash.c:			mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:			dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:		sg_to_sec4_sg_last(req->src, src_len, edesc->sec4_sg + 1, 0);
drivers/crypto/caam/caamhash.c:		scatterwalk_map_and_copy(buf + *buflen, req->src, 0,
drivers/crypto/caam/caamhash.c:					 req->nbytes, 0);
drivers/crypto/caam/caamhash.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamhash.c:		mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:		dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:				  req->nbytes);
drivers/crypto/caam/caamhash.c:	*next_buflen = req->nbytes & (blocksize - 1);
drivers/crypto/caam/caamhash.c:	to_hash = req->nbytes - *next_buflen;
drivers/crypto/caam/caamhash.c:		src_nents = sg_nents_for_len(req->src,
drivers/crypto/caam/caamhash.c:					     req->nbytes - *next_buflen);
drivers/crypto/caam/caamhash.c:			mapped_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamhash.c:			dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamhash.c:		scatterwalk_map_and_copy(buf, req->src, 0,
drivers/crypto/caam/caamhash.c:					 req->nbytes, 0);
drivers/crypto/caam/caamhash_desc.c:	 * Load from buf and/or src and write to req->result or state->context
drivers/crypto/caam/caamhash_desc.c:	 * Load from buf and/or src and write to req->result or state->context
drivers/crypto/caam/caamalg_qi2.c:	switch (crypto_tfm_alg_type(areq->tfm)) {
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	if (unlikely(req->dst != req->src)) {
drivers/crypto/caam/caamalg_qi2.c:		src_len = req->assoclen + req->cryptlen;
drivers/crypto/caam/caamalg_qi2.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi2.c:		dst_nents = sg_nents_for_len(req->dst, dst_len);
drivers/crypto/caam/caamalg_qi2.c:			mapped_src_nents = dma_map_sg(dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			mapped_dst_nents = dma_map_sg(dev, req->dst, dst_nents,
drivers/crypto/caam/caamalg_qi2.c:				dma_unmap_sg(dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		src_len = req->assoclen + req->cryptlen +
drivers/crypto/caam/caamalg_qi2.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi2.c:		mapped_src_nents = dma_map_sg(dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:	 * Create S/G table: req->assoclen, [IV,] req->src [, req->dst].
drivers/crypto/caam/caamalg_qi2.c:	else if ((req->src == req->dst) && (mapped_src_nents > 1))
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi2.c:		memcpy(iv, req->iv, ivsize);
drivers/crypto/caam/caamalg_qi2.c:			caam_unmap(dev, req->src, req->dst, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		edesc->assoclen = cpu_to_caam32(req->assoclen - ivsize);
drivers/crypto/caam/caamalg_qi2.c:		edesc->assoclen = cpu_to_caam32(req->assoclen);
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi2.c:	sg_to_qm_sg_last(req->src, src_len, sg_table + qm_sg_index, 0);
drivers/crypto/caam/caamalg_qi2.c:		sg_to_qm_sg_last(req->dst, dst_len, sg_table + qm_sg_index, 0);
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi2.c:	out_len = req->assoclen + req->cryptlen +
drivers/crypto/caam/caamalg_qi2.c:	in_len = 4 + ivsize + req->assoclen + req->cryptlen;
drivers/crypto/caam/caamalg_qi2.c:	if (req->dst == req->src) {
drivers/crypto/caam/caamalg_qi2.c:			dpaa2_fl_set_addr(out_fle, sg_dma_address(req->src));
drivers/crypto/caam/caamalg_qi2.c:		dpaa2_fl_set_addr(out_fle, sg_dma_address(req->dst));
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/caam/caamalg_qi2.c:			req->cryptlen);
drivers/crypto/caam/caamalg_qi2.c:	if (unlikely(req->dst != req->src)) {
drivers/crypto/caam/caamalg_qi2.c:		dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/caam/caamalg_qi2.c:				req->cryptlen);
drivers/crypto/caam/caamalg_qi2.c:		mapped_src_nents = dma_map_sg(dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		mapped_dst_nents = dma_map_sg(dev, req->dst, dst_nents,
drivers/crypto/caam/caamalg_qi2.c:			dma_unmap_sg(dev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi2.c:		mapped_src_nents = dma_map_sg(dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:	if (req->src != req->dst)
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi2.c:	memcpy(iv, req->iv, ivsize);
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi2.c:	sg_to_qm_sg(req->src, req->cryptlen, sg_table + 1, 0);
drivers/crypto/caam/caamalg_qi2.c:	if (req->src != req->dst)
drivers/crypto/caam/caamalg_qi2.c:		sg_to_qm_sg(req->dst, req->cryptlen, sg_table + dst_sg_idx, 0);
drivers/crypto/caam/caamalg_qi2.c:		caam_unmap(dev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_len(in_fle, req->cryptlen + ivsize);
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_len(out_fle, req->cryptlen + ivsize);
drivers/crypto/caam/caamalg_qi2.c:	if (req->src == req->dst)
drivers/crypto/caam/caamalg_qi2.c:	caam_unmap(dev, req->src, req->dst, edesc->src_nents, edesc->dst_nents,
drivers/crypto/caam/caamalg_qi2.c:	caam_unmap(dev, req->src, req->dst, edesc->src_nents, edesc->dst_nents,
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc = &ctx->flc[ENCRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc_dma = ctx->flc_dma[ENCRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->cbk = aead_encrypt_done;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->edesc = edesc;
drivers/crypto/caam/caamalg_qi2.c:	    !(ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc = &ctx->flc[DECRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc_dma = ctx->flc_dma[DECRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->cbk = aead_decrypt_done;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->edesc = edesc;
drivers/crypto/caam/caamalg_qi2.c:	    !(ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {
drivers/crypto/caam/caamalg_qi2.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : aead_encrypt(req);
drivers/crypto/caam/caamalg_qi2.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : aead_decrypt(req);
drivers/crypto/caam/caamalg_qi2.c:			     DUMP_PREFIX_ADDRESS, 16, 4, req->iv,
drivers/crypto/caam/caamalg_qi2.c:		     DUMP_PREFIX_ADDRESS, 16, 4, req->dst,
drivers/crypto/caam/caamalg_qi2.c:		     edesc->dst_nents > 1 ? 100 : req->cryptlen, 1);
drivers/crypto/caam/caamalg_qi2.c:	 * The crypto API expects us to set the IV (req->iv) to the last
drivers/crypto/caam/caamalg_qi2.c:		memcpy(req->iv, (u8 *)&edesc->sgt[0] + edesc->qm_sg_bytes,
drivers/crypto/caam/caamalg_qi2.c:			     DUMP_PREFIX_ADDRESS, 16, 4, req->iv,
drivers/crypto/caam/caamalg_qi2.c:		     DUMP_PREFIX_ADDRESS, 16, 4, req->dst,
drivers/crypto/caam/caamalg_qi2.c:		     edesc->dst_nents > 1 ? 100 : req->cryptlen, 1);
drivers/crypto/caam/caamalg_qi2.c:	 * The crypto API expects us to set the IV (req->iv) to the last
drivers/crypto/caam/caamalg_qi2.c:		memcpy(req->iv, (u8 *)&edesc->sgt[0] + edesc->qm_sg_bytes,
drivers/crypto/caam/caamalg_qi2.c:	return !!get_unaligned((u64 *)(req->iv + (ivsize / 2)));
drivers/crypto/caam/caamalg_qi2.c:	if (!req->cryptlen && !ctx->fallback)
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_tfm(&caam_req->fallback_req, ctx->fallback);
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_callback(&caam_req->fallback_req,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.flags,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.complete,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.data);
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_crypt(&caam_req->fallback_req, req->src,
drivers/crypto/caam/caamalg_qi2.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/caam/caamalg_qi2.c:		return crypto_skcipher_encrypt(&caam_req->fallback_req);
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc = &ctx->flc[ENCRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc_dma = ctx->flc_dma[ENCRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->cbk = skcipher_encrypt_done;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->edesc = edesc;
drivers/crypto/caam/caamalg_qi2.c:	    !(ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {
drivers/crypto/caam/caamalg_qi2.c:	if (!req->cryptlen && !ctx->fallback)
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_tfm(&caam_req->fallback_req, ctx->fallback);
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_callback(&caam_req->fallback_req,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.flags,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.complete,
drivers/crypto/caam/caamalg_qi2.c:					      req->base.data);
drivers/crypto/caam/caamalg_qi2.c:		skcipher_request_set_crypt(&caam_req->fallback_req, req->src,
drivers/crypto/caam/caamalg_qi2.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/caam/caamalg_qi2.c:		return crypto_skcipher_decrypt(&caam_req->fallback_req);
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc = &ctx->flc[DECRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->flc_dma = ctx->flc_dma[DECRYPT];
drivers/crypto/caam/caamalg_qi2.c:	caam_req->cbk = skcipher_decrypt_done;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	caam_req->edesc = edesc;
drivers/crypto/caam/caamalg_qi2.c:	    !(ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)) {
drivers/crypto/caam/caamalg_qi2.c:		dma_unmap_sg(dev, req->src, edesc->src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi2.c:	memcpy(req->result, state->caam_ctx, digestsize);
drivers/crypto/caam/caamalg_qi2.c:	req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamalg_qi2.c:	scatterwalk_map_and_copy(state->buf, req->src,
drivers/crypto/caam/caamalg_qi2.c:				 req->nbytes - state->next_buflen,
drivers/crypto/caam/caamalg_qi2.c:	if (req->result)
drivers/crypto/caam/caamalg_qi2.c:				     DUMP_PREFIX_ADDRESS, 16, 4, req->result,
drivers/crypto/caam/caamalg_qi2.c:	req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamalg_qi2.c:	memcpy(req->result, state->caam_ctx, digestsize);
drivers/crypto/caam/caamalg_qi2.c:	req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamalg_qi2.c:	scatterwalk_map_and_copy(state->buf, req->src,
drivers/crypto/caam/caamalg_qi2.c:				 req->nbytes - state->next_buflen,
drivers/crypto/caam/caamalg_qi2.c:	if (req->result)
drivers/crypto/caam/caamalg_qi2.c:				     DUMP_PREFIX_ADDRESS, 16, 4, req->result,
drivers/crypto/caam/caamalg_qi2.c:	req->base.complete(&req->base, ecode);
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	int in_len = *buflen + req->nbytes, to_hash;
drivers/crypto/caam/caamalg_qi2.c:		int src_len = req->nbytes - *next_buflen;
drivers/crypto/caam/caamalg_qi2.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi2.c:			mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			dma_unmap_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			sg_to_qm_sg_last(req->src, src_len,
drivers/crypto/caam/caamalg_qi2.c:		req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:		      req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:		scatterwalk_map_and_copy(buf + *buflen, req->src, 0,
drivers/crypto/caam/caamalg_qi2.c:					 req->nbytes, 0);
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	    (ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:		mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		dma_unmap_sg(ctx->dev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi2.c:	sg_to_qm_sg_last(req->src, req->nbytes, sg_table + qm_sg_src_index, 0);
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_len(in_fle, ctx->ctx_len + buflen + req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:	req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	    (ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:		mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		dma_unmap_sg(ctx->dev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi2.c:		sg_to_qm_sg_last(req->src, req->nbytes, sg_table, 0);
drivers/crypto/caam/caamalg_qi2.c:		dpaa2_fl_set_addr(in_fle, sg_dma_address(req->src));
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_len(in_fle, req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:	req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	    (ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	    (ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	int in_len = *buflen + req->nbytes, to_hash;
drivers/crypto/caam/caamalg_qi2.c:		int src_len = req->nbytes - *next_buflen;
drivers/crypto/caam/caamalg_qi2.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi2.c:			mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			dma_unmap_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		sg_to_qm_sg_last(req->src, src_len, sg_table + 1, 0);
drivers/crypto/caam/caamalg_qi2.c:		req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:		      req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:		scatterwalk_map_and_copy(buf + *buflen, req->src, 0,
drivers/crypto/caam/caamalg_qi2.c:					 req->nbytes, 0);
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:		mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:		dma_unmap_sg(ctx->dev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi2.c:	sg_to_qm_sg_last(req->src, req->nbytes, sg_table + 1, 0);
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_len(in_fle, buflen + req->nbytes);
drivers/crypto/caam/caamalg_qi2.c:	req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:	    !(ret == -EBUSY && req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))
drivers/crypto/caam/caamalg_qi2.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi2.c:	*next_buflen = req->nbytes & (crypto_tfm_alg_blocksize(&ahash->base) -
drivers/crypto/caam/caamalg_qi2.c:	to_hash = req->nbytes - *next_buflen;
drivers/crypto/caam/caamalg_qi2.c:		int src_len = req->nbytes - *next_buflen;
drivers/crypto/caam/caamalg_qi2.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi2.c:			mapped_nents = dma_map_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			dma_unmap_sg(ctx->dev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi2.c:			sg_to_qm_sg_last(req->src, src_len, sg_table, 0);
drivers/crypto/caam/caamalg_qi2.c:			dpaa2_fl_set_addr(in_fle, sg_dma_address(req->src));
drivers/crypto/caam/caamalg_qi2.c:		req_ctx->ctx = &req->base;
drivers/crypto/caam/caamalg_qi2.c:		    !(ret == -EBUSY && req->base.flags &
drivers/crypto/caam/caamalg_qi2.c:		scatterwalk_map_and_copy(buf, req->src, 0,
drivers/crypto/caam/caamalg_qi2.c:					 req->nbytes, 0);
drivers/crypto/caam/caamalg_qi2.c:	dma_unmap_single(priv->dev, req->fd_flt_dma, sizeof(req->fd_flt),
drivers/crypto/caam/caamalg_qi2.c:	req->cbk(req->ctx, dpaa2_fd_get_frc(fd));
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fl_set_flc(&req->fd_flt[1], req->flc_dma);
drivers/crypto/caam/caamalg_qi2.c:	req->fd_flt_dma = dma_map_single(dev, req->fd_flt, sizeof(req->fd_flt),
drivers/crypto/caam/caamalg_qi2.c:	if (dma_mapping_error(dev, req->fd_flt_dma)) {
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fd_set_addr(&fd, req->fd_flt_dma);
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fd_set_len(&fd, dpaa2_fl_get_len(&req->fd_flt[1]));
drivers/crypto/caam/caamalg_qi2.c:	dpaa2_fd_set_flc(&fd, req->flc_dma);
drivers/crypto/caam/caamalg_qi2.c:	dma_unmap_single(dev, req->fd_flt_dma, sizeof(req->fd_flt),
drivers/crypto/caam/qi.c:	qm_fd_set_compound(&fd, qm_sg_entry_get_len(&req->fd_sgt[1]));
drivers/crypto/caam/qi.c:	addr = dma_map_single(qidev, req->fd_sgt, sizeof(req->fd_sgt),
drivers/crypto/caam/qi.c:		ret = qman_enqueue(req->drv_ctx->req_fq, &fd);
drivers/crypto/caam/qi.c:			refcount_inc(&req->drv_ctx->refcnt);
drivers/crypto/caam/qi.c:	refcount_dec(&drv_req->drv_ctx->refcnt);
drivers/crypto/caam/qi.c:	dma_unmap_single(drv_req->drv_ctx->qidev, qm_fd_addr(fd),
drivers/crypto/caam/qi.c:			 sizeof(drv_req->fd_sgt), DMA_BIDIRECTIONAL);
drivers/crypto/caam/qi.c:		drv_req->cbk(drv_req, be32_to_cpu(fd->status));
drivers/crypto/caam/qi.c:		drv_req->cbk(drv_req, JRSTA_SSRC_QI);
drivers/crypto/caam/qi.c:	refcount_dec(&drv_req->drv_ctx->refcnt);
drivers/crypto/caam/qi.c:	dma_unmap_single(drv_req->drv_ctx->qidev, qm_fd_addr(fd),
drivers/crypto/caam/qi.c:			 sizeof(drv_req->fd_sgt), DMA_BIDIRECTIONAL);
drivers/crypto/caam/qi.c:	drv_req->cbk(drv_req, status);
drivers/crypto/caam/caamalg_qi2.h: * @assoclen_dma: bus physical mapped address of req->assoclen
drivers/crypto/caam/caamalg.c:	caam_unmap(dev, req->src, req->dst,
drivers/crypto/caam/caamalg.c:	caam_unmap(dev, req->src, req->dst,
drivers/crypto/caam/caamalg.c:	 * The crypto API expects us to set the IV (req->iv) to the last
drivers/crypto/caam/caamalg.c:		memcpy(req->iv, (u8 *)edesc->sec4_sg + edesc->sec4_sg_bytes,
drivers/crypto/caam/caamalg.c:				     DUMP_PREFIX_ADDRESS, 16, 4, req->iv,
drivers/crypto/caam/caamalg.c:		     DUMP_PREFIX_ADDRESS, 16, 4, req->dst,
drivers/crypto/caam/caamalg.c:		     edesc->dst_nents > 1 ? 100 : req->cryptlen, 1);
drivers/crypto/caam/caamalg.c:		src_dma = edesc->mapped_src_nents ? sg_dma_address(req->src) :
drivers/crypto/caam/caamalg.c:	append_seq_in_ptr(desc, src_dma, req->assoclen + req->cryptlen,
drivers/crypto/caam/caamalg.c:	if (unlikely(req->src != req->dst)) {
drivers/crypto/caam/caamalg.c:			dst_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caamalg.c:				   req->assoclen + req->cryptlen + authsize,
drivers/crypto/caam/caamalg.c:				   req->assoclen + req->cryptlen - authsize,
drivers/crypto/caam/caamalg.c:	append_math_add_imm_u32(desc, REG3, ZERO, IMM, req->assoclen);
drivers/crypto/caam/caamalg.c:	if (encrypt && generic_gcm && !(req->assoclen + req->cryptlen))
drivers/crypto/caam/caamalg.c:	append_data(desc, req->iv, ivsize);
drivers/crypto/caam/caamalg.c:	unsigned int assoclen = req->assoclen;
drivers/crypto/caam/caamalg.c:	append_load_as_imm(desc, req->iv, ivsize, LDST_CLASS_1_CCB |
drivers/crypto/caam/caamalg.c:		append_math_add_imm_u32(desc, REG3, ZERO, IMM, req->assoclen);
drivers/crypto/caam/caamalg.c:		append_math_add_imm_u32(desc, DPOVRD, ZERO, IMM, req->assoclen);
drivers/crypto/caam/caamalg.c:		append_load_as_imm(desc, req->iv, ivsize,
drivers/crypto/caam/caamalg.c:			     DUMP_PREFIX_ADDRESS, 16, 4, req->iv, ivsize, 1);
drivers/crypto/caam/caamalg.c:	       (int)edesc->src_nents > 1 ? 100 : req->cryptlen, req->cryptlen);
drivers/crypto/caam/caamalg.c:		     DUMP_PREFIX_ADDRESS, 16, 4, req->src,
drivers/crypto/caam/caamalg.c:		     edesc->src_nents > 1 ? 100 : req->cryptlen, 1);
drivers/crypto/caam/caamalg.c:		src_dma = sg_dma_address(req->src);
drivers/crypto/caam/caamalg.c:	append_seq_in_ptr(desc, src_dma, req->cryptlen + ivsize, in_options);
drivers/crypto/caam/caamalg.c:	if (likely(req->src == req->dst)) {
drivers/crypto/caam/caamalg.c:		dst_dma = sg_dma_address(req->dst);
drivers/crypto/caam/caamalg.c:	append_seq_out_ptr(desc, dst_dma, req->cryptlen + ivsize, out_options);
drivers/crypto/caam/caamalg.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg.c:	if (unlikely(req->dst != req->src)) {
drivers/crypto/caam/caamalg.c:		src_len = req->assoclen + req->cryptlen;
drivers/crypto/caam/caamalg.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg.c:		dst_nents = sg_nents_for_len(req->dst, dst_len);
drivers/crypto/caam/caamalg.c:		src_len = req->assoclen + req->cryptlen +
drivers/crypto/caam/caamalg.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg.c:	if (likely(req->src == req->dst)) {
drivers/crypto/caam/caamalg.c:		mapped_src_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamalg.c:			mapped_src_nents = dma_map_sg(jrdev, req->src,
drivers/crypto/caam/caamalg.c:			mapped_dst_nents = dma_map_sg(jrdev, req->dst,
drivers/crypto/caam/caamalg.c:				dma_unmap_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamalg.c:		caam_unmap(jrdev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg.c:		sg_to_sec4_sg_last(req->src, src_len,
drivers/crypto/caam/caamalg.c:		sg_to_sec4_sg_last(req->dst, dst_len,
drivers/crypto/caam/caamalg.c:	if (req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)
drivers/crypto/caam/caamalg.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : gcm_encrypt(req);
drivers/crypto/caam/caamalg.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : gcm_decrypt(req);
drivers/crypto/caam/caamalg.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg.c:	src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/caam/caamalg.c:			req->cryptlen);
drivers/crypto/caam/caamalg.c:	if (req->dst != req->src) {
drivers/crypto/caam/caamalg.c:		dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/caam/caamalg.c:				req->cryptlen);
drivers/crypto/caam/caamalg.c:	if (likely(req->src == req->dst)) {
drivers/crypto/caam/caamalg.c:		mapped_src_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamalg.c:		mapped_src_nents = dma_map_sg(jrdev, req->src, src_nents,
drivers/crypto/caam/caamalg.c:		mapped_dst_nents = dma_map_sg(jrdev, req->dst, dst_nents,
drivers/crypto/caam/caamalg.c:			dma_unmap_sg(jrdev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg.c:		if (req->src == req->dst)
drivers/crypto/caam/caamalg.c:		caam_unmap(jrdev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg.c:		memcpy(iv, req->iv, ivsize);
drivers/crypto/caam/caamalg.c:			caam_unmap(jrdev, req->src, req->dst, src_nents,
drivers/crypto/caam/caamalg.c:		sg_to_sec4_sg(req->src, req->cryptlen, edesc->sec4_sg +
drivers/crypto/caam/caamalg.c:	if (req->src != req->dst && (ivsize || mapped_dst_nents > 1))
drivers/crypto/caam/caamalg.c:		sg_to_sec4_sg(req->dst, req->cryptlen, edesc->sec4_sg +
drivers/crypto/caam/caamalg.c:			caam_unmap(jrdev, req->src, req->dst, src_nents,
drivers/crypto/caam/caamalg.c:	return !!get_unaligned((u64 *)(req->iv + (ivsize / 2)));
drivers/crypto/caam/caamalg.c:	if (!req->cryptlen && !ctx->fallback)
drivers/crypto/caam/caamalg.c:					      req->base.flags,
drivers/crypto/caam/caamalg.c:					      req->base.complete,
drivers/crypto/caam/caamalg.c:					      req->base.data);
drivers/crypto/caam/caamalg.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/caam/caamalg.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/caam/caamalg.c:	if (req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)
drivers/crypto/caam/caamalg_qi.c: * @assoclen_dma: bus physical mapped address of req->assoclen
drivers/crypto/caam/caamalg_qi.c:	caam_unmap(dev, req->src, req->dst, edesc->src_nents, edesc->dst_nents,
drivers/crypto/caam/caamalg_qi.c:	caam_unmap(dev, req->src, req->dst, edesc->src_nents, edesc->dst_nents,
drivers/crypto/caam/caamalg_qi.c:	struct aead_request *aead_req = drv_req->app_ctx;
drivers/crypto/caam/caamalg_qi.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi.c:	if (likely(req->src == req->dst)) {
drivers/crypto/caam/caamalg_qi.c:		src_len = req->assoclen + req->cryptlen +
drivers/crypto/caam/caamalg_qi.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi.c:		mapped_src_nents = dma_map_sg(qidev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi.c:		src_len = req->assoclen + req->cryptlen;
drivers/crypto/caam/caamalg_qi.c:		src_nents = sg_nents_for_len(req->src, src_len);
drivers/crypto/caam/caamalg_qi.c:		dst_nents = sg_nents_for_len(req->dst, dst_len);
drivers/crypto/caam/caamalg_qi.c:			mapped_src_nents = dma_map_sg(qidev, req->src,
drivers/crypto/caam/caamalg_qi.c:			mapped_dst_nents = dma_map_sg(qidev, req->dst,
drivers/crypto/caam/caamalg_qi.c:				dma_unmap_sg(qidev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi.c:	 * Create S/G table: req->assoclen, [IV,] req->src [, req->dst].
drivers/crypto/caam/caamalg_qi.c:	else if ((req->src == req->dst) && (mapped_src_nents > 1))
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi.c:		memcpy(iv, req->iv, ivsize);
drivers/crypto/caam/caamalg_qi.c:			caam_unmap(qidev, req->src, req->dst, src_nents,
drivers/crypto/caam/caamalg_qi.c:	edesc->assoclen = cpu_to_caam32(req->assoclen);
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi.c:	sg_to_qm_sg_last(req->src, src_len, sg_table + qm_sg_index, 0);
drivers/crypto/caam/caamalg_qi.c:		sg_to_qm_sg_last(req->dst, dst_len, sg_table + qm_sg_index, 0);
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi.c:	out_len = req->assoclen + req->cryptlen +
drivers/crypto/caam/caamalg_qi.c:	in_len = 4 + ivsize + req->assoclen + req->cryptlen;
drivers/crypto/caam/caamalg_qi.c:	if (req->dst == req->src) {
drivers/crypto/caam/caamalg_qi.c:			dma_to_qm_sg_one(&fd_sgt[0], sg_dma_address(req->src),
drivers/crypto/caam/caamalg_qi.c:		dma_to_qm_sg_one(&fd_sgt[0], sg_dma_address(req->dst), out_len,
drivers/crypto/caam/caamalg_qi.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : aead_crypt(req,
drivers/crypto/caam/caamalg_qi.c:	return crypto_ipsec_check_assoclen(req->assoclen) ? : aead_crypt(req,
drivers/crypto/caam/caamalg_qi.c:	struct skcipher_request *req = drv_req->app_ctx;
drivers/crypto/caam/caamalg_qi.c:			     DUMP_PREFIX_ADDRESS, 16, 4, req->iv,
drivers/crypto/caam/caamalg_qi.c:		     DUMP_PREFIX_ADDRESS, 16, 4, req->dst,
drivers/crypto/caam/caamalg_qi.c:		     edesc->dst_nents > 1 ? 100 : req->cryptlen, 1);
drivers/crypto/caam/caamalg_qi.c:	 * The crypto API expects us to set the IV (req->iv) to the last
drivers/crypto/caam/caamalg_qi.c:		memcpy(req->iv, (u8 *)&edesc->sgt[0] + edesc->qm_sg_bytes,
drivers/crypto/caam/caamalg_qi.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/caam/caamalg_qi.c:	src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/caam/caamalg_qi.c:			req->cryptlen);
drivers/crypto/caam/caamalg_qi.c:	if (unlikely(req->src != req->dst)) {
drivers/crypto/caam/caamalg_qi.c:		dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/caam/caamalg_qi.c:				req->cryptlen);
drivers/crypto/caam/caamalg_qi.c:		mapped_src_nents = dma_map_sg(qidev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi.c:		mapped_dst_nents = dma_map_sg(qidev, req->dst, dst_nents,
drivers/crypto/caam/caamalg_qi.c:			dma_unmap_sg(qidev, req->src, src_nents, DMA_TO_DEVICE);
drivers/crypto/caam/caamalg_qi.c:		mapped_src_nents = dma_map_sg(qidev, req->src, src_nents,
drivers/crypto/caam/caamalg_qi.c:	if (req->src != req->dst)
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi.c:	memcpy(iv, req->iv, ivsize);
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents, 0,
drivers/crypto/caam/caamalg_qi.c:	sg_to_qm_sg(req->src, req->cryptlen, sg_table + 1, 0);
drivers/crypto/caam/caamalg_qi.c:	if (req->src != req->dst)
drivers/crypto/caam/caamalg_qi.c:		sg_to_qm_sg(req->dst, req->cryptlen, sg_table + dst_sg_idx, 0);
drivers/crypto/caam/caamalg_qi.c:		caam_unmap(qidev, req->src, req->dst, src_nents, dst_nents,
drivers/crypto/caam/caamalg_qi.c:				  ivsize + req->cryptlen, 0);
drivers/crypto/caam/caamalg_qi.c:	if (req->src == req->dst)
drivers/crypto/caam/caamalg_qi.c:				     sizeof(*sg_table), req->cryptlen + ivsize,
drivers/crypto/caam/caamalg_qi.c:				     sizeof(*sg_table), req->cryptlen + ivsize,
drivers/crypto/caam/caamalg_qi.c:	return !!get_unaligned((u64 *)(req->iv + (ivsize / 2)));
drivers/crypto/caam/caamalg_qi.c:	if (!req->cryptlen && !ctx->fallback)
drivers/crypto/caam/caamalg_qi.c:					      req->base.flags,
drivers/crypto/caam/caamalg_qi.c:					      req->base.complete,
drivers/crypto/caam/caamalg_qi.c:					      req->base.data);
drivers/crypto/caam/caamalg_qi.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/caam/caamalg_qi.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/caam/caamalg_desc.c: * both of which are specified in req->src and req->dst
drivers/crypto/caam/caamalg_desc.c:/* For skcipher encrypt and decrypt, read from req->src and write to req->dst */
drivers/crypto/mxs-dcp.c:	struct scatterlist *dst = req->dst;
drivers/crypto/mxs-dcp.c:	struct scatterlist *src = req->src;
drivers/crypto/mxs-dcp.c:	const int nents = sg_nents(req->src);
drivers/crypto/mxs-dcp.c:		memcpy(key + AES_KEYSIZE_128, req->iv, AES_KEYSIZE_128);
drivers/crypto/mxs-dcp.c:	for_each_sg(req->src, src, nents, i) {
drivers/crypto/mxs-dcp.c:		limit_hit = tlen > req->cryptlen;
drivers/crypto/mxs-dcp.c:			len = req->cryptlen - (tlen - len);
drivers/crypto/mxs-dcp.c:			memcpy(req->iv, out_buf+(last_out_len-AES_BLOCK_SIZE),
drivers/crypto/mxs-dcp.c:			memcpy(req->iv, in_buf+(last_out_len-AES_BLOCK_SIZE),
drivers/crypto/mxs-dcp.c:	skcipher_request_set_callback(&rctx->fallback_req, req->base.flags,
drivers/crypto/mxs-dcp.c:				      req->base.complete, req->base.data);
drivers/crypto/mxs-dcp.c:	skcipher_request_set_crypt(&rctx->fallback_req, req->src, req->dst,
drivers/crypto/mxs-dcp.c:				   req->cryptlen, req->iv);
drivers/crypto/mxs-dcp.c:	struct crypto_async_request *arq = &req->base;
drivers/crypto/mxs-dcp.c:	ret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);
drivers/crypto/mxs-dcp.c:	src = req->src;
drivers/crypto/mxs-dcp.c:	len = req->nbytes;
drivers/crypto/mxs-dcp.c:		if (!req->result)
drivers/crypto/mxs-dcp.c:			req->result[i] = out_buf[halg->digestsize - i - 1];
drivers/crypto/mxs-dcp.c:	if (!req->nbytes && !fini)
drivers/crypto/mxs-dcp.c:	ret = crypto_enqueue_request(&sdcp->queue[actx->chan], &req->base);
drivers/crypto/mxs-dcp.c:	ahash_request_set_crypt(req, NULL, req->result, 0);
drivers/crypto/mxs-dcp.c:	req->nbytes = 0;
drivers/crypto/omap-sham.c:	u32 *hash = (u32 *)req->result;
drivers/crypto/omap-sham.c:		nbytes += req->nbytes - rctx->offset;
drivers/crypto/omap-sham.c:	if (update && req->nbytes && (!IS_ALIGNED(rctx->bufcnt, bs))) {
drivers/crypto/omap-sham.c:		if (len > req->nbytes)
drivers/crypto/omap-sham.c:			len = req->nbytes;
drivers/crypto/omap-sham.c:		scatterwalk_map_and_copy(rctx->buffer + rctx->bufcnt, req->src,
drivers/crypto/omap-sham.c:	ret = omap_sham_align_sgs(req->src, nbytes, bs, final, rctx);
drivers/crypto/omap-sham.c:					 req->src,
drivers/crypto/omap-sham.c:					 req->nbytes - hash_later,
drivers/crypto/omap-sham.c:	struct omap_sham_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/omap-sham.c:	       crypto_shash_finup(shash, req->result, ds, req->result);
drivers/crypto/omap-sham.c:	if (!req->nbytes)
drivers/crypto/omap-sham.c:	if (ctx->bufcnt + req->nbytes <= ctx->buflen) {
drivers/crypto/omap-sham.c:		scatterwalk_map_and_copy(ctx->buffer + ctx->bufcnt, req->src,
drivers/crypto/omap-sham.c:					 0, req->nbytes, 0);
drivers/crypto/omap-sham.c:		ctx->bufcnt += req->nbytes;
drivers/crypto/omap-sham.c:	struct omap_sham_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/omap-sham.c:				       ctx->bufcnt - offset, req->result);
drivers/crypto/ixp4xx_crypto.c:	int decryptlen = req->assoclen + req->cryptlen - authsize;
drivers/crypto/ixp4xx_crypto.c:			req->dst, decryptlen, authsize, 1);
drivers/crypto/ixp4xx_crypto.c:		req->base.complete(&req->base, failed);
drivers/crypto/ixp4xx_crypto.c:		req->base.complete(&req->base, failed);
drivers/crypto/ixp4xx_crypto.c:	unsigned int nbytes = req->cryptlen;
drivers/crypto/ixp4xx_crypto.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/ixp4xx_crypto.c:	BUG_ON(ivsize && !req->iv);
drivers/crypto/ixp4xx_crypto.c:	memcpy(crypt->iv, req->iv, ivsize);
drivers/crypto/ixp4xx_crypto.c:	if (req->src != req->dst) {
drivers/crypto/ixp4xx_crypto.c:		if (!chainup_buffers(dev, req->dst, nbytes, &dst_hook,
drivers/crypto/ixp4xx_crypto.c:	if (!chainup_buffers(dev, req->src, nbytes, &src_hook,
drivers/crypto/ixp4xx_crypto.c:	if (req->src != req->dst) {
drivers/crypto/ixp4xx_crypto.c:	u8 *info = req->iv;
drivers/crypto/ixp4xx_crypto.c:	req->iv = iv;
drivers/crypto/ixp4xx_crypto.c:	req->iv = info;
drivers/crypto/ixp4xx_crypto.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/ixp4xx_crypto.c:		cryptlen = req->cryptlen;
drivers/crypto/ixp4xx_crypto.c:		/* req->cryptlen includes the authsize when decrypting */
drivers/crypto/ixp4xx_crypto.c:		cryptlen = req->cryptlen -authsize;
drivers/crypto/ixp4xx_crypto.c:	crypt->auth_len = req->assoclen + cryptlen;
drivers/crypto/ixp4xx_crypto.c:	BUG_ON(ivsize && !req->iv);
drivers/crypto/ixp4xx_crypto.c:	memcpy(crypt->iv, req->iv, ivsize);
drivers/crypto/ixp4xx_crypto.c:	buf = chainup_buffers(dev, req->src, crypt->auth_len,
drivers/crypto/ixp4xx_crypto.c:	if (req->src != req->dst) {
drivers/crypto/ixp4xx_crypto.c:		buf = chainup_buffers(dev, req->dst, crypt->auth_len,
drivers/crypto/ixp4xx_crypto.c:				req->src, cryptlen, authsize, 0);
drivers/crypto/ixp4xx_crypto.c:	return aead_perform(req, 1, req->assoclen, req->cryptlen, req->iv);
drivers/crypto/ixp4xx_crypto.c:	return aead_perform(req, 0, req->assoclen, req->cryptlen, req->iv);
drivers/crypto/vmx/aes_xts.c:	if (req->cryptlen < AES_BLOCK_SIZE)
drivers/crypto/vmx/aes_xts.c:	if (!crypto_simd_usable() || (req->cryptlen % XTS_BLOCK_SIZE) != 0) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	unsigned int ileft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	unsigned int oleft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (!areq->cryptlen)
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (!areq->src || !areq->dst) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv && ivsize > 0 && mode & SS_DECRYPTION) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		scatterwalk_map_and_copy(backup_iv, areq->src, areq->cryptlen - ivsize, ivsize, 0);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		algt->stat_bytes += areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			v = *(u32 *)(areq->iv + i * 4);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	ileft = areq->cryptlen / 4;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	oleft = areq->cryptlen / 4;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			sg_miter_start(&mi, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		sg_miter_start(&mo, areq->dst, sg_nents(areq->dst),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			memcpy(areq->iv, backup_iv, ivsize);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			scatterwalk_map_and_copy(areq->iv, areq->dst, areq->cryptlen - ivsize,
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	skcipher_request_set_callback(&ctx->fallback_req, areq->base.flags,
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:				      areq->base.complete, areq->base.data);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	skcipher_request_set_crypt(&ctx->fallback_req, areq->src, areq->dst,
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:				   areq->cryptlen, areq->iv);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	struct scatterlist *in_sg = areq->src;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	struct scatterlist *out_sg = areq->dst;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	unsigned int ileft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	unsigned int oleft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (!areq->cryptlen)
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (!areq->src || !areq->dst) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->cryptlen % algt->alg.crypto.base.cra_blocksize)
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv && ivsize > 0 && mode & SS_DECRYPTION) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		scatterwalk_map_and_copy(backup_iv, areq->src, areq->cryptlen - ivsize, ivsize, 0);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		algt->stat_bytes += areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			v = *(u32 *)(areq->iv + i * 4);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	ileft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	oleft = areq->cryptlen;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			sg_miter_start(&mi, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:		sg_miter_start(&mo, areq->dst, sg_nents(areq->dst),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:	if (areq->iv) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			memcpy(areq->iv, backup_iv, ivsize);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-cipher.c:			scatterwalk_map_and_copy(areq->iv, areq->dst, areq->cryptlen - ivsize,
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c: * if op->len + areq->nbytes < 64
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	 * i is the total bytes read from SGs, to be compared to areq->nbytes
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	 * SG->length could be greater than areq->nbytes
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	struct scatterlist *in_sg = areq->src;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		__func__, crypto_tfm_alg_name(areq->base.tfm),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		op->byte_count, areq->nbytes, op->mode,
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	if (unlikely(!areq->nbytes) && !(op->flags & SS_HASH_FINAL))
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	if (unlikely(areq->nbytes > UINT_MAX - op->len)) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	if (op->len + areq->nbytes < 64 && !(op->flags & SS_HASH_FINAL)) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		copied = sg_pcopy_to_buffer(areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:					    op->buf + op->len, areq->nbytes, 0);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		end = ((areq->nbytes + op->len) / 64) * 64 - op->len;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		if (end > areq->nbytes || areq->nbytes - end > 63) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:				end, areq->nbytes);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		if (areq->nbytes < 4)
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:			end = ((areq->nbytes + op->len) / 4) * 4 - op->len;
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	if (i == 1 && !op->len && areq->nbytes)
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	sg_miter_start(&mi, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:			in_r = min_t(size_t, mi.length - in_i, areq->nbytes - i);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:	if ((areq->nbytes - i) < 64) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:		while (i < areq->nbytes && in_i < mi.length && op->len < 64) {
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:			in_r = min(areq->nbytes - i, 64 - op->len);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:				    i, SS_TIMEOUT, v, areq->nbytes);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:				    i, SS_TIMEOUT, v, areq->nbytes);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:				put_unaligned_le32(v, areq->result + i * 4);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:				put_unaligned_be32(v, areq->result + i * 4);
drivers/crypto/allwinner/sun4i-ss/sun4i-ss-hash.c:			put_unaligned_le32(v, areq->result + i * 4);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (sg_nents(areq->src) > MAX_SG || sg_nents(areq->dst) > MAX_SG)
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->cryptlen < crypto_skcipher_ivsize(tfm))
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->cryptlen == 0 || areq->cryptlen % 16)
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	sg = areq->src;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	sg = areq->dst;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	skcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:				      areq->base.complete, areq->base.data);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	skcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:				   areq->cryptlen, areq->iv);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		crypto_tfm_alg_name(areq->base.tfm),
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		areq->cryptlen,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		rctx->op_dir, areq->iv, crypto_skcipher_ivsize(tfm),
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		cet->t_dlen = cpu_to_le32(areq->cryptlen);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		cet->t_dlen = cpu_to_le32(areq->cryptlen / 4);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->iv && crypto_skcipher_ivsize(tfm) > 0) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			offset = areq->cryptlen - ivsize;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			scatterwalk_map_and_copy(rctx->backup_iv, areq->src,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		memcpy(rctx->bounce_iv, areq->iv, ivsize);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		nr_sgs = dma_map_sg(ce->dev, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		nr_sgs = dma_map_sg(ce->dev, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		nr_sgd = dma_map_sg(ce->dev, areq->dst, sg_nents(areq->dst),
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	len = areq->cryptlen;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	for_each_sg(areq->src, sg, nr_sgs, i) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			areq->cryptlen, i, cet->t_src[i].len, sg->offset, todo);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	len = areq->cryptlen;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	for_each_sg(areq->dst, sg, nr_sgd, i) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			areq->cryptlen, i, cet->t_dst[i].len, sg->offset, todo);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	chan->timeout = areq->cryptlen;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		dma_unmap_sg(ce->dev, areq->src, nr_sgs, DMA_BIDIRECTIONAL);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			dma_unmap_sg(ce->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		dma_unmap_sg(ce->dev, areq->dst, nr_sgd, DMA_FROM_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->iv && ivsize > 0) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		offset = areq->cryptlen - ivsize;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			memcpy(areq->iv, rctx->backup_iv, ivsize);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			scatterwalk_map_and_copy(areq->iv, areq->dst, offset,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	err = sun8i_ce_run_task(ce, flow, crypto_tfm_alg_name(breq->base.tfm));
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		dma_unmap_sg(ce->dev, areq->src, nr_sgs, DMA_BIDIRECTIONAL);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			dma_unmap_sg(ce->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		dma_unmap_sg(ce->dev, areq->dst, nr_sgd, DMA_FROM_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:	if (areq->iv && ivsize > 0) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:		offset = areq->cryptlen - ivsize;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			memcpy(areq->iv, rctx->backup_iv, ivsize);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-cipher.c:			scatterwalk_map_and_copy(areq->iv, areq->dst, offset,
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	if (areq->nbytes == 0)
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	if (sg_nents(areq->src) > MAX_SG - 1)
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	sg = areq->src;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	nr_sgs = sg_nents(areq->src);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	for_each_sg(areq->src, sg, nr_sgs, i) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	dev_dbg(ce->dev, "%s %s len=%d\n", __func__, crypto_tfm_alg_name(areq->base.tfm), areq->nbytes);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	nr_sgs = dma_map_sg(ce->dev, areq->src, sg_nents(areq->src), DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	len = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	for_each_sg(areq->src, sg, nr_sgs, i) {
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	byte_count = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:		cet->t_dlen = cpu_to_le32((areq->nbytes + j * 4) * 8);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:		cet->t_dlen = cpu_to_le32(areq->nbytes / 4 + j);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	chan->timeout = areq->nbytes;
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	err = sun8i_ce_run_task(ce, flow, crypto_tfm_alg_name(areq->base.tfm));
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	dma_unmap_sg(ce->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ce/sun8i-ce-hash.c:	memcpy(areq->result, result, algt->alg.hash.halg.digestsize);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.base.flags = areq->base.flags &
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.nbytes = areq->nbytes;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.src = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	rctx->fallback_req.result = areq->result;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	if (areq->nbytes == 0)
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	if (sg_nents(areq->src) > MAX_SG - 1)
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	sg = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	nr_sgs = sg_nents(areq->src);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	for_each_sg(areq->src, sg, nr_sgs, i) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	nr_sgs = dma_map_sg(ss->dev, areq->src, sg_nents(areq->src), DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	len = areq->nbytes;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	for_each_sg(areq->src, sg, nr_sgs, i) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	byte_count = areq->nbytes;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	err = sun8i_ss_run_hash_task(ss, rctx, crypto_tfm_alg_name(areq->base.tfm));
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	dma_unmap_sg(ss->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-hash.c:	memcpy(areq->result, result, algt->alg.hash.halg.digestsize);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	struct scatterlist *in_sg = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	struct scatterlist *out_sg = areq->dst;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (areq->cryptlen == 0 || areq->cryptlen % 16)
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (sg_nents(areq->src) > 8 || sg_nents(areq->dst) > 8)
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	sg = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	sg = areq->dst;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	in_sg = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	out_sg = areq->dst;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	skcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:				      areq->base.complete, areq->base.data);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	skcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:				   areq->cryptlen, areq->iv);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		crypto_tfm_alg_name(areq->base.tfm),
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		areq->cryptlen,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		rctx->op_dir, areq->iv, crypto_skcipher_ivsize(tfm),
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (areq->iv && crypto_skcipher_ivsize(tfm) > 0) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:			offset = areq->cryptlen - ivsize;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:			scatterwalk_map_and_copy(backup_iv, areq->src, offset,
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		memcpy(rctx->biv, areq->iv, ivsize);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		nr_sgs = dma_map_sg(ss->dev, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		nr_sgs = dma_map_sg(ss->dev, areq->src, sg_nents(areq->src),
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		nr_sgd = dma_map_sg(ss->dev, areq->dst, sg_nents(areq->dst),
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	len = areq->cryptlen;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	sg = areq->src;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:			areq->cryptlen, i, rctx->t_src[i].len, sg->offset, todo);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	len = areq->cryptlen;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	sg = areq->dst;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:			areq->cryptlen, i, rctx->t_dst[i].len, sg->offset, todo);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	err = sun8i_ss_run_task(ss, rctx, crypto_tfm_alg_name(areq->base.tfm));
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		dma_unmap_sg(ss->dev, areq->src, nr_sgs, DMA_BIDIRECTIONAL);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		dma_unmap_sg(ss->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:		dma_unmap_sg(ss->dev, areq->dst, nr_sgd, DMA_FROM_DEVICE);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:	if (areq->iv && ivsize > 0) {
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:			offset = areq->cryptlen - ivsize;
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:				memcpy(areq->iv, backup_iv, ivsize);
drivers/crypto/allwinner/sun8i-ss/sun8i-ss-cipher.c:				scatterwalk_map_and_copy(areq->iv, areq->dst, offset,
drivers/crypto/atmel-sha.c:	if ((dd->is_async || dd->force_complete) && req->base.complete)
drivers/crypto/atmel-sha.c:		req->base.complete(&req->base, err);
drivers/crypto/atmel-sha.c:	if (!req->result)
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA1_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA224_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA256_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA384_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:		memcpy(req->result, ctx->digest, SHA512_DIGEST_SIZE);
drivers/crypto/atmel-sha.c:	ctx = crypto_tfm_ctx(async_req->tfm);
drivers/crypto/atmel-sha.c:						ctx->op, req->nbytes);
drivers/crypto/atmel-sha.c:	struct atmel_sha_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/atmel-sha.c:	if (!req->nbytes)
drivers/crypto/atmel-sha.c:	ctx->total = req->nbytes;
drivers/crypto/atmel-sha.c:	ctx->sg = req->src;
drivers/crypto/atmel-sha.c:	 * req->result might not be sizeof(u32) aligned, so copy the
drivers/crypto/atmel-sha.c:	 * req->result.
drivers/crypto/atmel-sha.c:	if (!req->nbytes)
drivers/crypto/atmel-sha.c:	if (req->nbytes > ATMEL_SHA_DMA_THRESHOLD &&
drivers/crypto/atmel-sha.c:	    atmel_sha_dma_check_aligned(dd, req->src, req->nbytes))
drivers/crypto/atmel-sha.c:	atmel_sha_write(dd, SHA_MSR, req->nbytes);
drivers/crypto/atmel-sha.c:	atmel_sha_write(dd, SHA_BCR, req->nbytes);
drivers/crypto/atmel-sha.c:		return atmel_sha_dma_start(dd, req->src, req->nbytes,
drivers/crypto/atmel-sha.c:	return atmel_sha_cpu_start(dd, req->src, req->nbytes, false, true,
drivers/crypto/atmel-sha.c:	struct ahash_request *req = areq->data;
drivers/crypto/atmel-sha.c:	 * Force atmel_sha_complete() to call req->base.complete(), ie
drivers/crypto/atmel-sha.c:	/* Prevent atmel_sha_complete() from calling req->base.complete(). */
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:	rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:	rctx->fallback_req.base.flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:	rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:	rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:	if (unlikely(req->nbytes > (1 << 16))) {
drivers/crypto/n2_core.c:			req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:		rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:		rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:		rctx->fallback_req.result = req->result;
drivers/crypto/n2_core.c:		memcpy(req->result, hash_loc, result_size);
drivers/crypto/n2_core.c:	struct n2_ahash_alg *n2alg = n2_ahash_alg(req->base.tfm);
drivers/crypto/n2_core.c:	if (unlikely(req->nbytes == 0)) {
drivers/crypto/n2_core.c:		memcpy(req->result, n2alg->hash_zero, ds);
drivers/crypto/n2_core.c:	struct n2_hmac_alg *n2alg = n2_hmac_alg(req->base.tfm);
drivers/crypto/n2_core.c:	if (unlikely(req->nbytes == 0) ||
drivers/crypto/n2_core.c:			req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP;
drivers/crypto/n2_core.c:		rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/n2_core.c:		rctx->fallback_req.src = req->src;
drivers/crypto/n2_core.c:		rctx->fallback_req.result = req->result;
drivers/crypto/omap-aes-gcm.c:			    dd->aead_req->assoclen, dd->total,
drivers/crypto/omap-aes-gcm.c:					 dd->aead_req->dst,
drivers/crypto/omap-aes-gcm.c:					 dd->total + dd->aead_req->assoclen,
drivers/crypto/omap-aes-gcm.c:	assoclen = req->assoclen;
drivers/crypto/omap-aes-gcm.c:	cryptlen = req->cryptlen;
drivers/crypto/omap-aes-gcm.c:		tmp = req->src;
drivers/crypto/omap-aes-gcm.c:		tmp = scatterwalk_ffwd(sg_arr, req->src, req->assoclen);
drivers/crypto/omap-aes-gcm.c:	dd->out_sg = req->dst;
drivers/crypto/omap-aes-gcm.c:	dd->orig_out = req->dst;
drivers/crypto/omap-aes-gcm.c:	dd->out_sg = scatterwalk_ffwd(sg_arr, req->dst, req->assoclen);
drivers/crypto/omap-aes-gcm.c:	if (req->src == req->dst || dd->out_sg == sg_arr)
drivers/crypto/omap-aes-gcm.c:		scatterwalk_map_and_copy(tag, dd->aead_req->src,
drivers/crypto/omap-aes-gcm.c:					 dd->total + dd->aead_req->assoclen,
drivers/crypto/omap-aes-gcm.c:		assoclen = req->assoclen - 8;
drivers/crypto/omap-aes-gcm.c:		assoclen = req->assoclen;
drivers/crypto/omap-aes-gcm.c:	if (assoclen + req->cryptlen == 0) {
drivers/crypto/omap-aes-gcm.c:		scatterwalk_map_and_copy(rctx->auth_tag, req->dst, 0, authlen,
drivers/crypto/omap-aes-gcm.c:	memcpy(rctx->iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/omap-aes-gcm.c:	memcpy(rctx->iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/omap-aes-gcm.c:	memcpy(rctx->iv + 4, req->iv, 8);
drivers/crypto/omap-aes-gcm.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
drivers/crypto/omap-aes-gcm.c:	memcpy(rctx->iv + 4, req->iv, 8);
drivers/crypto/omap-aes-gcm.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
drivers/crypto/ccree/cc_buffer_mgr.c:	u32 skip = req->assoclen + req->cryptlen;
drivers/crypto/ccree/cc_buffer_mgr.c:	cc_copy_sg_portion(dev, areq_ctx->backup_mac, req->src,
drivers/crypto/ccree/cc_buffer_mgr.c:	dev_dbg(dev, "Unmapped req->src=%pK\n", sg_virt(src));
drivers/crypto/ccree/cc_buffer_mgr.c:		dev_dbg(dev, "Unmapped req->dst=%pK\n", sg_virt(dst));
drivers/crypto/ccree/cc_buffer_mgr.c:	dev_dbg(dev, "Unmapping src sgl: req->src=%pK areq_ctx->src.nents=%u areq_ctx->assoc.nents=%u assoclen:%u cryptlen=%u\n",
drivers/crypto/ccree/cc_buffer_mgr.c:		sg_virt(req->src), areq_ctx->src.nents, areq_ctx->assoc.nents,
drivers/crypto/ccree/cc_buffer_mgr.c:		areq_ctx->assoclen, req->cryptlen);
drivers/crypto/ccree/cc_buffer_mgr.c:	dma_unmap_sg(dev, req->src, areq_ctx->src.mapped_nents,
drivers/crypto/ccree/cc_buffer_mgr.c:	if (req->src != req->dst) {
drivers/crypto/ccree/cc_buffer_mgr.c:		dev_dbg(dev, "Unmapping dst sgl: req->dst=%pK\n",
drivers/crypto/ccree/cc_buffer_mgr.c:			sg_virt(req->dst));
drivers/crypto/ccree/cc_buffer_mgr.c:		dma_unmap_sg(dev, req->dst, areq_ctx->dst.mapped_nents,
drivers/crypto/ccree/cc_buffer_mgr.c:	    req->src == req->dst) {
drivers/crypto/ccree/cc_buffer_mgr.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_buffer_mgr.c:	if (!req->iv) {
drivers/crypto/ccree/cc_buffer_mgr.c:	areq_ctx->gen_ctx.iv = kmemdup(req->iv, hw_iv_size, flags);
drivers/crypto/ccree/cc_buffer_mgr.c:			hw_iv_size, req->iv);
drivers/crypto/ccree/cc_buffer_mgr.c:		hw_iv_size, req->iv, &areq_ctx->gen_ctx.iv_dma_addr);
drivers/crypto/ccree/cc_buffer_mgr.c:	mapped_nents = sg_nents_for_len(req->src, areq_ctx->assoclen);
drivers/crypto/ccree/cc_buffer_mgr.c:		cc_add_sg_entry(dev, sg_data, areq_ctx->assoc.nents, req->src,
drivers/crypto/ccree/cc_buffer_mgr.c:	if ((req->src == req->dst) || direct == DRV_CRYPTO_DIRECTION_DECRYPT) {
drivers/crypto/ccree/cc_buffer_mgr.c:	if (req->src == req->dst) {
drivers/crypto/ccree/cc_buffer_mgr.c:	unsigned int size_for_map = req->assoclen + req->cryptlen;
drivers/crypto/ccree/cc_buffer_mgr.c:	u32 size_to_skip = req->assoclen;
drivers/crypto/ccree/cc_buffer_mgr.c:	areq_ctx->src_sgl = req->src;
drivers/crypto/ccree/cc_buffer_mgr.c:	areq_ctx->dst_sgl = req->dst;
drivers/crypto/ccree/cc_buffer_mgr.c:	src_mapped_nents = cc_get_sgl_nents(dev, req->src, size_for_map,
drivers/crypto/ccree/cc_buffer_mgr.c:	if (req->src != req->dst) {
drivers/crypto/ccree/cc_buffer_mgr.c:		size_for_map = req->assoclen + req->cryptlen;
drivers/crypto/ccree/cc_buffer_mgr.c:		rc = cc_map_sg(dev, req->dst, size_for_map, DMA_BIDIRECTIONAL,
drivers/crypto/ccree/cc_buffer_mgr.c:	dst_mapped_nents = cc_get_sgl_nents(dev, req->dst, size_for_map,
drivers/crypto/ccree/cc_buffer_mgr.c:		if (req->src == req->dst) {
drivers/crypto/ccree/cc_buffer_mgr.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_buffer_mgr.c:	    req->src == req->dst)
drivers/crypto/ccree/cc_buffer_mgr.c:				req->cryptlen :
drivers/crypto/ccree/cc_buffer_mgr.c:				(req->cryptlen - authsize);
drivers/crypto/ccree/cc_buffer_mgr.c:	size_to_map = req->cryptlen + req->assoclen;
drivers/crypto/ccree/cc_buffer_mgr.c:	   (req->src == req->dst)) {
drivers/crypto/ccree/cc_buffer_mgr.c:	rc = cc_map_sg(dev, req->src, size_to_map, DMA_BIDIRECTIONAL,
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, false);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, false);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_result(dev, state, digestsize, req->result);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, false);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_result(dev, state, digestsize, req->result);
drivers/crypto/ccree/cc_hash.c:	struct scatterlist *src = req->src;
drivers/crypto/ccree/cc_hash.c:	unsigned int nbytes = req->nbytes;
drivers/crypto/ccree/cc_hash.c:	u8 *result = req->result;
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:	struct scatterlist *src = req->src;
drivers/crypto/ccree/cc_hash.c:	unsigned int nbytes = req->nbytes;
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:	struct scatterlist *src = req->src;
drivers/crypto/ccree/cc_hash.c:	unsigned int nbytes = req->nbytes;
drivers/crypto/ccree/cc_hash.c:	u8 *result = req->result;
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:	dev_dbg(dev, "===== init (%d) ====\n", req->nbytes);
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	if (req->nbytes == 0) {
drivers/crypto/ccree/cc_hash.c:	rc = cc_map_hash_request_update(ctx->drvdata, state, req->src,
drivers/crypto/ccree/cc_hash.c:					req->nbytes, block_size, flags);
drivers/crypto/ccree/cc_hash.c:				req->nbytes);
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	if (cc_map_hash_request_final(ctx->drvdata, state, req->src,
drivers/crypto/ccree/cc_hash.c:				      req->nbytes, 0, flags)) {
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_result(dev, state, digestsize, req->result);
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	dev_dbg(dev, "===== finup xcbc(%d) ====\n", req->nbytes);
drivers/crypto/ccree/cc_hash.c:	if (state->xcbc_count > 0 && req->nbytes == 0) {
drivers/crypto/ccree/cc_hash.c:	if (cc_map_hash_request_final(ctx->drvdata, state, req->src,
drivers/crypto/ccree/cc_hash.c:				      req->nbytes, 1, flags)) {
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:	if (req->nbytes == 0) {
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_result(dev, state, digestsize, req->result);
drivers/crypto/ccree/cc_hash.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_hash.c:	dev_dbg(dev, "===== -digest mac (%d) ====\n",  req->nbytes);
drivers/crypto/ccree/cc_hash.c:	if (cc_map_hash_request_final(ctx->drvdata, state, req->src,
drivers/crypto/ccree/cc_hash.c:				      req->nbytes, 1, flags)) {
drivers/crypto/ccree/cc_hash.c:	if (req->nbytes == 0) {
drivers/crypto/ccree/cc_hash.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, idx, &req->base);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_hash_request(dev, state, req->src, true);
drivers/crypto/ccree/cc_hash.c:		cc_unmap_result(dev, state, digestsize, req->result);
drivers/crypto/ccree/cc_request_mgr.c:		req = creq->user_arg;
drivers/crypto/ccree/cc_request_mgr.c:			creq->user_cb(dev, req, -EINPROGRESS);
drivers/crypto/ccree/cc_request_mgr.c:	bool backlog_ok = req->flags & CRYPTO_TFM_REQ_MAY_BACKLOG;
drivers/crypto/ccree/cc_request_mgr.c:	init_completion(&cc_req->seq_compl);
drivers/crypto/ccree/cc_request_mgr.c:	cc_req->user_cb = request_mgr_complete;
drivers/crypto/ccree/cc_request_mgr.c:	cc_req->user_arg = &cc_req->seq_compl;
drivers/crypto/ccree/cc_request_mgr.c:	wait_for_completion(&cc_req->seq_compl);
drivers/crypto/ccree/cc_request_mgr.c:		if (cc_req->cpp.is_cpp) {
drivers/crypto/ccree/cc_request_mgr.c:				cc_req->cpp.slot, cc_req->cpp.alg);
drivers/crypto/ccree/cc_request_mgr.c:			mask = cc_cpp_int_mask(cc_req->cpp.alg,
drivers/crypto/ccree/cc_request_mgr.c:					       cc_req->cpp.slot);
drivers/crypto/ccree/cc_request_mgr.c:		if (cc_req->user_cb)
drivers/crypto/ccree/cc_request_mgr.c:			cc_req->user_cb(dev, cc_req->user_arg, rc);
drivers/crypto/ccree/cc_cipher.c:	struct scatterlist *dst = req->dst;
drivers/crypto/ccree/cc_cipher.c:	struct scatterlist *src = req->src;
drivers/crypto/ccree/cc_cipher.c:		memcpy(req->iv, req_ctx->iv, ivsize);
drivers/crypto/ccree/cc_cipher.c:	struct scatterlist *dst = req->dst;
drivers/crypto/ccree/cc_cipher.c:	struct scatterlist *src = req->src;
drivers/crypto/ccree/cc_cipher.c:	unsigned int nbytes = req->cryptlen;
drivers/crypto/ccree/cc_cipher.c:	void *iv = req->iv;
drivers/crypto/ccree/cc_cipher.c:	gfp_t flags = cc_gfp_flags(&req->base);
drivers/crypto/ccree/cc_cipher.c:			     &req->base);
drivers/crypto/ccree/cc_aead.c:	areq->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:			sg_zero_buffer(areq->dst, sg_nents(areq->dst),
drivers/crypto/ccree/cc_aead.c:				       areq->cryptlen, areq->assoclen);
drivers/crypto/ccree/cc_aead.c:		u32 skip = areq->cryptlen + areq_ctx->dst_offset;
drivers/crypto/ccree/cc_aead.c:		set_din_type(&desc[idx], DMA_DLLI, sg_dma_address(areq->src),
drivers/crypto/ccree/cc_aead.c:			(req->cryptlen - ctx->authsize) : req->cryptlen;
drivers/crypto/ccree/cc_aead.c:	    req->cryptlen < ctx->authsize)
drivers/crypto/ccree/cc_aead.c:	unsigned int lp = req->iv[0];
drivers/crypto/ccree/cc_aead.c:	/* Note: The code assume that req->iv[0] already contains the value
drivers/crypto/ccree/cc_aead.c:				req->cryptlen :
drivers/crypto/ccree/cc_aead.c:				(req->cryptlen - ctx->authsize);
drivers/crypto/ccree/cc_aead.c:		dev_dbg(dev, "illegal iv value %X\n", req->iv[0]);
drivers/crypto/ccree/cc_aead.c:	memcpy(b0, req->iv, AES_BLOCK_SIZE);
drivers/crypto/ccree/cc_aead.c:	memset(req->iv + 15 - req->iv[0], 0, req->iv[0] + 1);
drivers/crypto/ccree/cc_aead.c:	req->iv[15] = 1;
drivers/crypto/ccree/cc_aead.c:	memcpy(ctr_count_0, req->iv, AES_BLOCK_SIZE);
drivers/crypto/ccree/cc_aead.c:	memcpy(areq_ctx->ctr_iv + CCM_BLOCK_IV_OFFSET, req->iv,
drivers/crypto/ccree/cc_aead.c:	req->iv = areq_ctx->ctr_iv;
drivers/crypto/ccree/cc_aead.c:				req->cryptlen :
drivers/crypto/ccree/cc_aead.c:				(req->cryptlen - ctx->authsize);
drivers/crypto/ccree/cc_aead.c:	memcpy(req->iv + 12, &counter, 4);
drivers/crypto/ccree/cc_aead.c:	memcpy(req_ctx->gcm_iv_inc2, req->iv, 16);
drivers/crypto/ccree/cc_aead.c:	memcpy(req->iv + 12, &counter, 4);
drivers/crypto/ccree/cc_aead.c:	memcpy(req_ctx->gcm_iv_inc1, req->iv, 16);
drivers/crypto/ccree/cc_aead.c:	memcpy(areq_ctx->ctr_iv + GCM_BLOCK_RFC4_IV_OFFSET, req->iv,
drivers/crypto/ccree/cc_aead.c:	req->iv = areq_ctx->ctr_iv;
drivers/crypto/ccree/cc_aead.c:		ctx, req, req->iv, sg_virt(req->src), req->src->offset,
drivers/crypto/ccree/cc_aead.c:		sg_virt(req->dst), req->dst->offset, req->cryptlen);
drivers/crypto/ccree/cc_aead.c:			req->cryptlen, areq_ctx->assoclen);
drivers/crypto/ccree/cc_aead.c:		memcpy(areq_ctx->ctr_iv + CTR_RFC3686_NONCE_SIZE, req->iv,
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->ctr_iv;
drivers/crypto/ccree/cc_aead.c:		if (areq_ctx->ctr_iv != req->iv) {
drivers/crypto/ccree/cc_aead.c:			memcpy(areq_ctx->ctr_iv, req->iv,
drivers/crypto/ccree/cc_aead.c:			req->iv = areq_ctx->ctr_iv;
drivers/crypto/ccree/cc_aead.c:	rc = cc_send_request(ctx->drvdata, &cc_req, desc, seq_len, &req->base);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen - CCM_BLOCK_IV_SIZE;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen - CCM_BLOCK_IV_SIZE;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen - GCM_BLOCK_RFC4_IV_SIZE;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen - GCM_BLOCK_RFC4_IV_SIZE;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_aead.c:	rc = crypto_ipsec_check_assoclen(req->assoclen);
drivers/crypto/ccree/cc_aead.c:	areq_ctx->backup_iv = req->iv;
drivers/crypto/ccree/cc_aead.c:	areq_ctx->assoclen = req->assoclen;
drivers/crypto/ccree/cc_aead.c:		req->iv = areq_ctx->backup_iv;
drivers/crypto/ccree/cc_driver.h:	return (req->flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/cavium/cpt/cptvf_algs.c:	req->complete(req, !status);
drivers/crypto/cavium/cpt/cptvf_algs.c:	req_info->req.param1 = req->cryptlen; /* Encryption Data length */
drivers/crypto/cavium/cpt/cptvf_algs.c:	update_input_iv(req_info, req->iv, enc_iv_len, &argcnt);
drivers/crypto/cavium/cpt/cptvf_algs.c:	update_input_data(req_info, req->src, req->cryptlen, &argcnt);
drivers/crypto/cavium/cpt/cptvf_algs.c:	req_info->callback_arg = (void *)&req->base;
drivers/crypto/cavium/cpt/cptvf_algs.c:	update_output_iv(req_info, req->iv, enc_iv_len, &argcnt);
drivers/crypto/cavium/cpt/cptvf_algs.c:	update_output_data(req_info, req->dst, req->cryptlen, &argcnt);
drivers/crypto/cavium/cpt/cptvf_algs.c:	req_info->may_sleep = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) != 0;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	if (req->incnt > MAX_SG_IN_CNT || req->outcnt > MAX_SG_OUT_CNT) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	g_sz_bytes = ((req->incnt + 3) / 4) * sizeof(struct sglist_component);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->gather_components = kzalloc(g_sz_bytes, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	ret = setup_sgio_components(cptvf, req->in,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:				    req->incnt,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	s_sz_bytes = ((req->outcnt + 3) / 4) * sizeof(struct sglist_component);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->scatter_components = kzalloc(s_sz_bytes, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	ret = setup_sgio_components(cptvf, req->out,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:				    req->outcnt,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->in_buffer = kzalloc(info->dlen, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	((__be16 *)info->in_buffer)[0] = cpu_to_be16(req->outcnt);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	((__be16 *)info->in_buffer)[1] = cpu_to_be16(req->incnt);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->out_buffer = kzalloc(COMPLETION_CODE_SIZE, req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		for (i = 0; i < req->outcnt; i++) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:			if (req->out[i].dma_addr)
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:						 req->out[i].dma_addr,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:						 req->out[i].size,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:		for (i = 0; i < req->incnt; i++) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:			if (req->in[i].dma_addr)
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:						 req->in[i].dma_addr,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:						 req->in[i].size,
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info = kzalloc(sizeof(*info), req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	cpt_req = (struct cptvf_request *)&req->req;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	ctrl = (union ctrl_info *)&req->ctrl;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	cpt_req->dlen = info->dlen;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	info->completion_addr = kzalloc(sizeof(union cpt_res_s), req->may_sleep ? GFP_KERNEL : GFP_ATOMIC);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	vq_cmd.cmd.s.opcode = cpu_to_be16(cpt_req->opcode.flags);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	vq_cmd.cmd.s.param1 = cpu_to_be16(cpt_req->param1);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	vq_cmd.cmd.s.param2 = cpu_to_be16(cpt_req->param2);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	vq_cmd.cmd.s.dlen   = cpu_to_be16(cpt_req->dlen);
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	pentry->callback = req->callback;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	pentry->callback_arg = req->callback_arg;
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	if ((cptvf->vftype == SE_TYPES) && (!req->ctrl.s.se_req)) {
drivers/crypto/cavium/cpt/cptvf_reqmanager.c:	} else if ((cptvf->vftype == AE_TYPES) && (req->ctrl.s.se_req)) {
drivers/crypto/cavium/nitrox/nitrox_aead.c:	nitrox_creq_copy_iv(nkreq->src, iv, ivsize);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	kfree(nkreq->src);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	kfree(nkreq->dst);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->flags = rctx->flags;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->gfp = (rctx->flags & CRYPTO_TFM_REQ_MAY_SLEEP) ? GFP_KERNEL :
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->ctrl.value = 0;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->opcode = FLEXI_CRYPTO_ENCRYPT_HMAC;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->ctrl.s.arg = rctx->ctrl_arg;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->gph.param0 = cpu_to_be16(rctx->cryptlen);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->gph.param1 = cpu_to_be16(rctx->cryptlen + rctx->assoclen);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->gph.param2 = cpu_to_be16(rctx->ivsize + rctx->assoclen);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->gph.param3 = cpu_to_be16(param3.param);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->ctx_handle = rctx->ctx_handle;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	creq->ctrl.s.ctxl = sizeof(struct flexi_crypto_context);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	areq->base.complete(&areq->base, err);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	if (!nitrox_aes_gcm_assoclen_supported(areq->assoclen))
drivers/crypto/cavium/nitrox/nitrox_aead.c:	memcpy(fctx->crypto.iv, areq->iv, GCM_AES_SALT_SIZE);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->cryptlen = areq->cryptlen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->assoclen = areq->assoclen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->srclen = areq->assoclen + areq->cryptlen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->iv = &areq->iv[GCM_AES_SALT_SIZE];
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->flags = areq->base.flags;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->src = areq->src;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->dst = areq->dst;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	if (!nitrox_aes_gcm_assoclen_supported(areq->assoclen))
drivers/crypto/cavium/nitrox/nitrox_aead.c:	memcpy(fctx->crypto.iv, areq->iv, GCM_AES_SALT_SIZE);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->cryptlen = areq->cryptlen - aead->authsize;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->assoclen = areq->assoclen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->srclen = areq->cryptlen + areq->assoclen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->iv = &areq->iv[GCM_AES_SALT_SIZE];
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->flags = areq->base.flags;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->src = areq->src;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	rctx->dst = areq->dst;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	unsigned int assoclen = areq->assoclen - GCM_RFC4106_IV_SIZE;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	if (areq->assoclen != 16 && areq->assoclen != 20)
drivers/crypto/cavium/nitrox/nitrox_aead.c:	scatterwalk_map_and_copy(rctx->assoc, areq->src, 0, assoclen, 0);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	sg = scatterwalk_ffwd(rctx->src + 1, areq->src, areq->assoclen);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	if (areq->src != areq->dst) {
drivers/crypto/cavium/nitrox/nitrox_aead.c:		sg = scatterwalk_ffwd(rctx->dst + 1, areq->dst, areq->assoclen);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->dst = (areq->src == areq->dst) ? rctx->src : rctx->dst;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	areq->base.complete(&areq->base, err);
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->cryptlen = areq->cryptlen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->assoclen = areq->assoclen - GCM_RFC4106_IV_SIZE;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->iv = areq->iv;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->flags = areq->base.flags;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->cryptlen = areq->cryptlen - aead->authsize;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->assoclen = areq->assoclen - GCM_RFC4106_IV_SIZE;
drivers/crypto/cavium/nitrox/nitrox_aead.c:		areq->cryptlen - GCM_RFC4106_IV_SIZE + areq->assoclen;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->iv = areq->iv;
drivers/crypto/cavium/nitrox/nitrox_aead.c:	aead_rctx->flags = areq->base.flags;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	struct scatterlist *sg = req->src;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	nents = dma_map_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	for_each_sg(req->src, sg, nents, i)
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->in.sg = req->src;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	dma_unmap_sg(dev, req->src, nents, DMA_BIDIRECTIONAL);
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	nents = dma_map_sg(dev, req->dst, sg_nents(req->dst),
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->out.sg = req->dst;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	dma_unmap_sg(dev, req->dst, nents, DMA_BIDIRECTIONAL);
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr = kzalloc(sizeof(*sr), req->gfp);
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->flags = req->flags;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->gfp = req->gfp;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->resp.orh = req->orh;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->resp.completion = req->comp;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	if (req->ctx_handle) {
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:		ctx_ptr = (u8 *)(uintptr_t)req->ctx_handle;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->instr.irh.s.ctxl = (req->ctrl.s.ctxl / 8);
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->instr.irh.s.ctxc = req->ctrl.s.ctxc;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->instr.irh.s.arg = req->ctrl.s.arg;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->instr.irh.s.opcode = req->opcode;
drivers/crypto/cavium/nitrox/nitrox_reqmgr.c:	sr->instr.fdata[0] = *((u64 *)&req->gph);
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	nkreq->src = alloc_req_buf(nents, ivsize, creq->gfp);
drivers/crypto/cavium/nitrox/nitrox_req.h:	if (!nkreq->src)
drivers/crypto/cavium/nitrox/nitrox_req.h:	char *iv = nkreq->src;
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	creq->src = nitrox_creq_src_sg(iv, ivsize);
drivers/crypto/cavium/nitrox/nitrox_req.h:	sg = creq->src;
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	nkreq->dst = alloc_req_buf(nents, extralen, creq->gfp);
drivers/crypto/cavium/nitrox/nitrox_req.h:	if (!nkreq->dst)
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	creq->orh = (u64 *)(nkreq->dst);
drivers/crypto/cavium/nitrox/nitrox_req.h:	set_orh_value(creq->orh);
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	creq->comp = (u64 *)(nkreq->dst + ORH_HLEN);
drivers/crypto/cavium/nitrox/nitrox_req.h:	set_comp_value(creq->comp);
drivers/crypto/cavium/nitrox/nitrox_req.h:	struct se_crypto_request *creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_req.h:	char *iv = nkreq->src;
drivers/crypto/cavium/nitrox/nitrox_req.h:	creq->dst = nitrox_creq_dst_sg(nkreq->dst);
drivers/crypto/cavium/nitrox/nitrox_req.h:	sg = creq->dst;
drivers/crypto/cavium/nitrox/nitrox_req.h:	sg = create_single_sg(sg, creq->orh, ORH_HLEN);
drivers/crypto/cavium/nitrox/nitrox_req.h:	create_single_sg(sg, creq->comp, COMP_HLEN);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	kfree(nkreq->src);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	kfree(nkreq->dst);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	unsigned int start = skreq->cryptlen - ivsize;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	if (nkreq->creq.ctrl.s.arg == ENCRYPT) {
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:		scatterwalk_map_and_copy(skreq->iv, skreq->dst, start, ivsize,
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:		if (skreq->src != skreq->dst) {
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:			scatterwalk_map_and_copy(skreq->iv, skreq->src, start,
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:			memcpy(skreq->iv, nkreq->iv_out, ivsize);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:			kfree(nkreq->iv_out);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	int nents = sg_nents(skreq->src) + 1;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	nitrox_creq_copy_iv(nkreq->src, skreq->iv, ivsize);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	nitrox_creq_set_src_sg(nkreq, nents, ivsize, skreq->src,
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:			       skreq->cryptlen);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	int nents = sg_nents(skreq->dst) + 3;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	nitrox_creq_set_dst_sg(nkreq, nents, ivsize, skreq->dst,
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:			       skreq->cryptlen);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq = &nkreq->creq;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->flags = skreq->base.flags;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->gfp = (skreq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->ctrl.value = 0;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->opcode = FLEXI_CRYPTO_ENCRYPT_HMAC;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->ctrl.s.arg = (enc ? ENCRYPT : DECRYPT);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->gph.param0 = cpu_to_be16(skreq->cryptlen);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->gph.param1 = 0;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->gph.param2 = cpu_to_be16(ivsize);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->gph.param3 = 0;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->ctx_handle = nctx->u.ctx_handle;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	creq->ctrl.s.ctxl = sizeof(struct flexi_crypto_context);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	gfp_t flags = (skreq->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	unsigned int start = skreq->cryptlen - ivsize;
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	if (skreq->src != skreq->dst)
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	nkreq->iv_out = kmalloc(ivsize, flags);
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	if (!nkreq->iv_out)
drivers/crypto/cavium/nitrox/nitrox_skcipher.c:	scatterwalk_map_and_copy(nkreq->iv_out, skreq->src, start, ivsize, 0);
drivers/crypto/img-hash.c:	ctx->bufcnt = sg_copy_to_buffer(hdev->req->src, sg_nents(ctx->sg),
drivers/crypto/img-hash.c:					ctx->buffer, hdev->req->nbytes);
drivers/crypto/img-hash.c:	ctx->total = hdev->req->nbytes;
drivers/crypto/img-hash.c:	if (!req->result)
drivers/crypto/img-hash.c:	memcpy(req->result, ctx->digest, ctx->digsize);
drivers/crypto/img-hash.c:	if (req->base.complete)
drivers/crypto/img-hash.c:		req->base.complete(&req->base, err);
drivers/crypto/img-hash.c:	if (req->nbytes >= IMG_HASH_DMA_THRESHOLD) {
drivers/crypto/img-hash.c:			req->nbytes);
drivers/crypto/img-hash.c:			req->nbytes);
drivers/crypto/img-hash.c:	nbits = (u64)hdev->req->nbytes << 3;
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags =	req->base.flags
drivers/crypto/img-hash.c:		 ctx->op, req->nbytes);
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/img-hash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/img-hash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/img-hash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	rctx->fallback_req.base.flags = req->base.flags
drivers/crypto/img-hash.c:	ctx->total = req->nbytes;
drivers/crypto/img-hash.c:	ctx->sg = req->src;
drivers/crypto/img-hash.c:	ctx->sgfirst = req->src;
drivers/crypto/atmel-ecc.c:	n_sz = min_t(size_t, ctx->n_sz, req->dst_len);
drivers/crypto/atmel-ecc.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst, n_sz),
drivers/crypto/atmel-ecc.c:	nbytes = min_t(size_t, ATMEL_ECC_PUBKEY_SIZE, req->dst_len);
drivers/crypto/atmel-ecc.c:	copied = sg_copy_from_buffer(req->dst,
drivers/crypto/atmel-ecc.c:				     sg_nents_for_len(req->dst, nbytes),
drivers/crypto/atmel-ecc.c:	if (req->src_len != ATMEL_ECC_PUBKEY_SIZE)
drivers/crypto/atmel-ecc.c:	gfp = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ? GFP_KERNEL :
drivers/crypto/atmel-ecc.c:	ret = atmel_i2c_init_ecdh_cmd(&work_data->cmd, req->src);
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		dma_size = req->cryptlen + ZYNQMP_AES_KEY_SIZE
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		dma_size = req->cryptlen + GCM_AES_IV_SIZE;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	data_size = req->cryptlen;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	scatterwalk_map_and_copy(kbuf, req->src, 0, req->cryptlen, 0);
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	memcpy(kbuf + data_size, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	hwreq->src = dma_addr_data;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	hwreq->dst = dma_addr_data;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	hwreq->iv = hwreq->src + data_size;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	hwreq->keysrc = tfm_ctx->keysrc;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	hwreq->op = rq_ctx->op;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	if (hwreq->op == ZYNQMP_AES_ENCRYPT)
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		hwreq->size = data_size;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		hwreq->size = data_size - ZYNQMP_AES_AUTH_SIZE;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	if (hwreq->keysrc == ZYNQMP_AES_KUP_KEY) {
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		hwreq->key = hwreq->src + data_size + GCM_AES_IV_SIZE;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		hwreq->key = 0;
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		if (hwreq->op == ZYNQMP_AES_ENCRYPT)
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		sg_copy_from_buffer(req->dst, sg_nents(req->dst),
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	if (req->assoclen != 0 ||
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	    req->cryptlen < ZYNQMP_AES_MIN_INPUT_BLK_SIZE) {
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	if ((req->cryptlen % ZYNQMP_AES_WORD_LEN) != 0)
drivers/crypto/xilinx/zynqmp-aes-gcm.c:	    req->cryptlen <= ZYNQMP_AES_AUTH_SIZE) {
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		aead_request_set_callback(subreq, areq->base.flags,
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		aead_request_set_crypt(subreq, areq->src, areq->dst,
drivers/crypto/xilinx/zynqmp-aes-gcm.c:				       areq->cryptlen, areq->iv);
drivers/crypto/xilinx/zynqmp-aes-gcm.c:		aead_request_set_ad(subreq, areq->assoclen);
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_comn_req_hdr_cd_pars *cd_pars = &req->cd_pars;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_comn_req_hdr *header = &req->comn_hdr;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_cipher_cd_ctrl_hdr *cd_ctrl = (void *)&req->cd_ctrl;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_comn_req_hdr_cd_pars *cd_pars = &req->cd_pars;
drivers/crypto/qat/qat_common/qat_algs.c:	struct icp_qat_fw_comn_req_hdr_cd_pars *cd_pars = &req->cd_pars;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_buf_list *bl = qat_req->buf.bl;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_buf_list *blout = qat_req->buf.blout;
drivers/crypto/qat/qat_common/qat_algs.c:	dma_addr_t blp = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:	dma_addr_t blpout = qat_req->buf.bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:	size_t sz = qat_req->buf.sz;
drivers/crypto/qat/qat_common/qat_algs.c:	size_t sz_out = qat_req->buf.sz_out;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->buf.bl = bufl;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->buf.blp = blp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->buf.sz = sz;
drivers/crypto/qat/qat_common/qat_algs.c:		qat_req->buf.blout = buflout;
drivers/crypto/qat/qat_common/qat_algs.c:		qat_req->buf.bloutp = bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:		qat_req->buf.sz_out = sz_out;
drivers/crypto/qat/qat_common/qat_algs.c:		qat_req->buf.bloutp = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:		qat_req->buf.sz_out = 0;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_aead_ctx *ctx = qat_req->aead_ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	struct aead_request *areq = qat_req->aead_req;
drivers/crypto/qat/qat_common/qat_algs.c:	areq->base.complete(&areq->base, res);
drivers/crypto/qat/qat_common/qat_algs.c:	struct skcipher_request *sreq = qat_req->skcipher_req;
drivers/crypto/qat/qat_common/qat_algs.c:	memcpy(qat_req->iv, sreq->iv, AES_BLOCK_SIZE);
drivers/crypto/qat/qat_common/qat_algs.c:	iv_lo = be64_to_cpu(qat_req->iv_lo);
drivers/crypto/qat/qat_common/qat_algs.c:	iv_hi = be64_to_cpu(qat_req->iv_hi);
drivers/crypto/qat/qat_common/qat_algs.c:	iv_lo += DIV_ROUND_UP(sreq->cryptlen, AES_BLOCK_SIZE);
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->iv_lo = cpu_to_be64(iv_lo);
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->iv_hi = cpu_to_be64(iv_hi);
drivers/crypto/qat/qat_common/qat_algs.c:	struct skcipher_request *sreq = qat_req->skcipher_req;
drivers/crypto/qat/qat_common/qat_algs.c:	int offset = sreq->cryptlen - AES_BLOCK_SIZE;
drivers/crypto/qat/qat_common/qat_algs.c:	if (qat_req->encryption)
drivers/crypto/qat/qat_common/qat_algs.c:		sgl = sreq->dst;
drivers/crypto/qat/qat_common/qat_algs.c:		sgl = sreq->src;
drivers/crypto/qat/qat_common/qat_algs.c:	scatterwalk_map_and_copy(qat_req->iv, sgl, offset, AES_BLOCK_SIZE, 0);
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_skcipher_ctx *ctx = qat_req->skcipher_ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_skcipher_ctx *ctx = qat_req->skcipher_ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	struct skcipher_request *sreq = qat_req->skcipher_req;
drivers/crypto/qat/qat_common/qat_algs.c:	if (qat_req->encryption)
drivers/crypto/qat/qat_common/qat_algs.c:	memcpy(sreq->iv, qat_req->iv, AES_BLOCK_SIZE);
drivers/crypto/qat/qat_common/qat_algs.c:	sreq->base.complete(&sreq->base, res);
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->cb(qat_resp, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_len = areq->cryptlen - digst_size;
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, areq->src, areq->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->aead_ctx = ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->aead_req = areq;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->cb = qat_aead_alg_callback;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.opaque_data = (u64)(__force long)qat_req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.src_data_addr = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.dest_data_addr = qat_req->buf.bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param = (void *)&qat_req->req.serv_specif_rqpars;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param->cipher_offset = areq->assoclen;
drivers/crypto/qat/qat_common/qat_algs.c:	memcpy(cipher_param->u.cipher_IV_array, areq->iv, AES_BLOCK_SIZE);
drivers/crypto/qat/qat_common/qat_algs.c:	auth_param->auth_len = areq->assoclen + cipher_param->cipher_length;
drivers/crypto/qat/qat_common/qat_algs.c:	u8 *iv = areq->iv;
drivers/crypto/qat/qat_common/qat_algs.c:	if (areq->cryptlen % AES_BLOCK_SIZE != 0)
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, areq->src, areq->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->aead_ctx = ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->aead_req = areq;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->cb = qat_aead_alg_callback;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.opaque_data = (u64)(__force long)qat_req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.src_data_addr = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.dest_data_addr = qat_req->buf.bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param = (void *)&qat_req->req.serv_specif_rqpars;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param->cipher_length = areq->cryptlen;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param->cipher_offset = areq->assoclen;
drivers/crypto/qat/qat_common/qat_algs.c:	auth_param->auth_len = areq->assoclen + areq->cryptlen;
drivers/crypto/qat/qat_common/qat_algs.c:	struct qat_alg_skcipher_ctx *ctx = qat_req->skcipher_ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	u8 *iv = qat_req->skcipher_req->iv;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param = (void *)&qat_req->req.serv_specif_rqpars;
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen == 0)
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, req->src, req->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->skcipher_ctx = ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->skcipher_req = req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->cb = qat_skcipher_alg_callback;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.opaque_data = (u64)(__force long)qat_req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.src_data_addr = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.dest_data_addr = qat_req->buf.bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->encryption = true;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param = (void *)&qat_req->req.serv_specif_rqpars;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param->cipher_length = req->cryptlen;
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen % AES_BLOCK_SIZE != 0)
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen < XTS_BLOCK_SIZE)
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen == 0)
drivers/crypto/qat/qat_common/qat_algs.c:	ret = qat_alg_sgl_to_bufl(ctx->inst, req->src, req->dst, qat_req);
drivers/crypto/qat/qat_common/qat_algs.c:	msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->skcipher_ctx = ctx;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->skcipher_req = req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->cb = qat_skcipher_alg_callback;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.opaque_data = (u64)(__force long)qat_req;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.src_data_addr = qat_req->buf.blp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->req.comn_mid.dest_data_addr = qat_req->buf.bloutp;
drivers/crypto/qat/qat_common/qat_algs.c:	qat_req->encryption = false;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param = (void *)&qat_req->req.serv_specif_rqpars;
drivers/crypto/qat/qat_common/qat_algs.c:	cipher_param->cipher_length = req->cryptlen;
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen % AES_BLOCK_SIZE != 0)
drivers/crypto/qat/qat_common/qat_algs.c:	if (req->cryptlen < XTS_BLOCK_SIZE)
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct kpp_request *areq = req->areq.dh;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(req->ctx.dh->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (areq->src) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (req->src_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_free_coherent(dev, req->ctx.dh->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					  req->src_align, req->in.dh.in.b);
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, req->in.dh.in.b,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 req->ctx.dh->p_size, DMA_TO_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	areq->dst_len = req->ctx.dh->p_size;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_align) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		scatterwalk_map_and_copy(req->dst_align, areq->dst, 0,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 areq->dst_len, 1);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, req->ctx.dh->p_size, req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  req->out.dh.r);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, req->out.dh.r, req->ctx.dh->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_unmap_single(dev, req->phy_in, sizeof(struct qat_dh_input_params),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_unmap_single(dev, req->phy_out,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct icp_qat_fw_pke_request *msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->p_size;
drivers/crypto/qat/qat_common/qat_asym_algs.c:						    !req->src && ctx->g2);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->cb = qat_dh_cb;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->ctx.dh = ctx;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->areq.dh = req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->src) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.dh.in.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.dh.in.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in_g2.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in_g2.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.b = ctx->dma_g;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.xa = ctx->dma_xa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->src) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (sg_is_last(req->src) && req->src_len == ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->src_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->in.dh.in.b = dma_map_single(dev,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							     sg_virt(req->src),
drivers/crypto/qat/qat_common/qat_asym_algs.c:							     req->src_len,
drivers/crypto/qat/qat_common/qat_asym_algs.c:						       qat_req->in.dh.in.b)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			int shift = ctx->p_size - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:			qat_req->src_align = dma_alloc_coherent(dev,
drivers/crypto/qat/qat_common/qat_asym_algs.c:								&qat_req->in.dh.in.b,
drivers/crypto/qat/qat_common/qat_asym_algs.c:			if (unlikely(!qat_req->src_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			scatterwalk_map_and_copy(qat_req->src_align + shift,
drivers/crypto/qat/qat_common/qat_asym_algs.c:						 req->src, 0, req->src_len, 0);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->p_size) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->out.dh.r = dma_map_single(dev, sg_virt(req->dst),
drivers/crypto/qat/qat_common/qat_asym_algs.c:						   req->dst_len,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(dma_mapping_error(dev, qat_req->out.dh.r)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_alloc_coherent(dev, ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							&qat_req->out.dh.r,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(!qat_req->dst_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.dh.in_tab[n_input_params] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->out.dh.out_tab[1] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_in = dma_map_single(dev, &qat_req->in.dh.in.b,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 sizeof(qat_req->in.dh.in.b),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_in)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_out = dma_map_single(dev, &qat_req->out.dh.r,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					  sizeof(qat_req->out.dh.r),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_out)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.src_data_addr = qat_req->phy_in;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.dest_data_addr = qat_req->phy_out;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_out))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_out,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_in))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_in,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (qat_req->dst_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->p_size, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  qat_req->out.dh.r);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (!dma_mapping_error(dev, qat_req->out.dh.r))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->out.dh.r, ctx->p_size,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->src) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (qat_req->src_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_free_coherent(dev, ctx->p_size, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					  qat_req->in.dh.in.b);
drivers/crypto/qat/qat_common/qat_asym_algs.c:			if (!dma_mapping_error(dev, qat_req->in.dh.in.b))
drivers/crypto/qat/qat_common/qat_asym_algs.c:				dma_unmap_single(dev, qat_req->in.dh.in.b,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct akcipher_request *areq = req->areq.rsa;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct device *dev = &GET_DEV(req->ctx.rsa->inst->accel_dev);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->src_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, req->ctx.rsa->key_sz, req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  req->in.rsa.enc.m);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, req->in.rsa.enc.m, req->ctx.rsa->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	areq->dst_len = req->ctx.rsa->key_sz;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_align) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		scatterwalk_map_and_copy(req->dst_align, areq->dst, 0,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 areq->dst_len, 1);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, req->ctx.rsa->key_sz, req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  req->out.rsa.enc.c);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, req->out.rsa.enc.c, req->ctx.rsa->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_unmap_single(dev, req->phy_in, sizeof(struct qat_rsa_input_params),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	dma_unmap_single(dev, req->phy_out,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	areq->cb(resp);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct icp_qat_fw_pke_request *msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->key_sz;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->cb = qat_rsa_cb;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->ctx.rsa = ctx;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->areq.rsa = req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.rsa.enc.e = ctx->dma_e;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.rsa.enc.n = ctx->dma_n;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->src) && req->src_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.enc.m = dma_map_single(dev, sg_virt(req->src),
drivers/crypto/qat/qat_common/qat_asym_algs.c:						   req->src_len, DMA_TO_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(dma_mapping_error(dev, qat_req->in.rsa.enc.m)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		int shift = ctx->key_sz - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = dma_alloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							&qat_req->in.rsa.enc.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(!qat_req->src_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		scatterwalk_map_and_copy(qat_req->src_align + shift, req->src,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 0, req->src_len, 0);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->out.rsa.enc.c = dma_map_single(dev, sg_virt(req->dst),
drivers/crypto/qat/qat_common/qat_asym_algs.c:							req->dst_len,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(dma_mapping_error(dev, qat_req->out.rsa.enc.c)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_alloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							&qat_req->out.rsa.enc.c,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(!qat_req->dst_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->in.rsa.in_tab[3] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->out.rsa.out_tab[1] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_in = dma_map_single(dev, &qat_req->in.rsa.enc.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 sizeof(qat_req->in.rsa.enc.m),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_in)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_out = dma_map_single(dev, &qat_req->out.rsa.enc.c,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					  sizeof(qat_req->out.rsa.enc.c),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_out)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.src_data_addr = qat_req->phy_in;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.dest_data_addr = qat_req->phy_out;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_out))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_out,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_in))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_in,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (qat_req->dst_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  qat_req->out.rsa.enc.c);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (!dma_mapping_error(dev, qat_req->out.rsa.enc.c))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->out.rsa.enc.c,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (qat_req->src_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  qat_req->in.rsa.enc.m);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (!dma_mapping_error(dev, qat_req->in.rsa.enc.m))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->in.rsa.enc.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	struct icp_qat_fw_pke_request *msg = &qat_req->req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (req->dst_len < ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		req->dst_len = ctx->key_sz;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->cb = qat_rsa_cb;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->ctx.rsa = ctx;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->areq.rsa = req;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.p = ctx->dma_p;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.q = ctx->dma_q;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.dp = ctx->dma_dp;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.dq = ctx->dma_dq;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec_crt.qinv = ctx->dma_qinv;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec.d = ctx->dma_d;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec.n = ctx->dma_n;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->src) && req->src_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.dec.c = dma_map_single(dev, sg_virt(req->src),
drivers/crypto/qat/qat_common/qat_asym_algs.c:						   req->dst_len, DMA_TO_DEVICE);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(dma_mapping_error(dev, qat_req->in.rsa.dec.c)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		int shift = ctx->key_sz - req->src_len;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->src_align = dma_alloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							&qat_req->in.rsa.dec.c,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(!qat_req->src_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		scatterwalk_map_and_copy(qat_req->src_align + shift, req->src,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 0, req->src_len, 0);
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (sg_is_last(req->dst) && req->dst_len == ctx->key_sz) {
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = NULL;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->out.rsa.dec.m = dma_map_single(dev, sg_virt(req->dst),
drivers/crypto/qat/qat_common/qat_asym_algs.c:						    req->dst_len,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(dma_mapping_error(dev, qat_req->out.rsa.dec.m)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->dst_align = dma_alloc_coherent(dev, ctx->key_sz,
drivers/crypto/qat/qat_common/qat_asym_algs.c:							&qat_req->out.rsa.dec.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (unlikely(!qat_req->dst_align))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.in_tab[6] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:		qat_req->in.rsa.in_tab[3] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->out.rsa.out_tab[1] = 0;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_in = dma_map_single(dev, &qat_req->in.rsa.dec.c,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					 sizeof(qat_req->in.rsa.dec.c),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_in)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	qat_req->phy_out = dma_map_single(dev, &qat_req->out.rsa.dec.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:					  sizeof(qat_req->out.rsa.dec.m),
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (unlikely(dma_mapping_error(dev, qat_req->phy_out)))
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.src_data_addr = qat_req->phy_in;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	msg->pke_mid.dest_data_addr = qat_req->phy_out;
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_out))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_out,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (!dma_mapping_error(dev, qat_req->phy_in))
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_unmap_single(dev, qat_req->phy_in,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (qat_req->dst_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->dst_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  qat_req->out.rsa.dec.m);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (!dma_mapping_error(dev, qat_req->out.rsa.dec.m))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->out.rsa.dec.m,
drivers/crypto/qat/qat_common/qat_asym_algs.c:	if (qat_req->src_align)
drivers/crypto/qat/qat_common/qat_asym_algs.c:		dma_free_coherent(dev, ctx->key_sz, qat_req->src_align,
drivers/crypto/qat/qat_common/qat_asym_algs.c:				  qat_req->in.rsa.dec.c);
drivers/crypto/qat/qat_common/qat_asym_algs.c:		if (!dma_mapping_error(dev, qat_req->in.rsa.dec.c))
drivers/crypto/qat/qat_common/qat_asym_algs.c:			dma_unmap_single(dev, qat_req->in.rsa.dec.c,
drivers/crypto/amcc/crypto4xx_core.c:					  req->cryptlen, req->dst);
drivers/crypto/amcc/crypto4xx_core.c:		crypto4xx_memcpy_from_le32((u32 *)req->iv,
drivers/crypto/amcc/crypto4xx_core.c:	ctx  = crypto_tfm_ctx(ahash_req->base.tfm);
drivers/crypto/amcc/crypto4xx_core.c:	crypto4xx_copy_digest_to_dst(ahash_req->result, pd_uinfo,
drivers/crypto/amcc/crypto4xx_core.c:				     crypto_tfm_ctx(ahash_req->base.tfm));
drivers/crypto/amcc/crypto4xx_core.c:		scatterwalk_map_and_copy(icv, dst, aead_req->cryptlen,
drivers/crypto/amcc/crypto4xx_core.c:		scatterwalk_map_and_copy(icv, aead_req->src,
drivers/crypto/amcc/crypto4xx_core.c:			aead_req->assoclen + aead_req->cryptlen -
drivers/crypto/amcc/crypto4xx_core.c:	switch (crypto_tfm_alg_type(pd_uinfo->async_req->tfm)) {
drivers/crypto/amcc/crypto4xx_core.c:	if (req->flags & CRYPTO_TFM_REQ_MAY_BACKLOG) {
drivers/crypto/amcc/crypto4xx_core.c:		((crypto_tfm_alg_type(req->tfm) == CRYPTO_ALG_TYPE_AHASH) ||
drivers/crypto/amcc/crypto4xx_core.c:		 (crypto_tfm_alg_type(req->tfm) == CRYPTO_ALG_TYPE_AEAD) ?
drivers/crypto/amcc/crypto4xx_alg.c:	if (check_blocksize && !IS_ALIGNED(req->cryptlen, AES_BLOCK_SIZE))
drivers/crypto/amcc/crypto4xx_alg.c:		crypto4xx_memcpy_to_le32(iv, req->iv, ivlen);
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:		req->cryptlen, iv, ivlen, decrypt ? ctx->sa_in : ctx->sa_out,
drivers/crypto/amcc/crypto4xx_alg.c:		cpu_to_le32p((u32 *) req->iv),
drivers/crypto/amcc/crypto4xx_alg.c:		cpu_to_le32p((u32 *) (req->iv + 4)),
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  req->cryptlen, iv, AES_IV_SIZE,
drivers/crypto/amcc/crypto4xx_alg.c:		cpu_to_le32p((u32 *) req->iv),
drivers/crypto/amcc/crypto4xx_alg.c:		cpu_to_le32p((u32 *) (req->iv + 4)),
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  req->cryptlen, iv, AES_IV_SIZE,
drivers/crypto/amcc/crypto4xx_alg.c:	unsigned int counter = be32_to_cpup((__be32 *)(req->iv + iv_len - 4));
drivers/crypto/amcc/crypto4xx_alg.c:	unsigned int nblks = ALIGN(req->cryptlen, AES_BLOCK_SIZE) /
drivers/crypto/amcc/crypto4xx_alg.c:		skcipher_request_set_callback(subreq, req->base.flags,
drivers/crypto/amcc/crypto4xx_alg.c:		skcipher_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:			req->cryptlen, req->iv);
drivers/crypto/amcc/crypto4xx_alg.c:	if (req->assoclen & 0x3 || req->assoclen > 1020)
drivers/crypto/amcc/crypto4xx_alg.c:	if (is_ccm && !(req->iv[0] == 1 || req->iv[0] == 3))
drivers/crypto/amcc/crypto4xx_alg.c:	aead_request_set_callback(subreq, req->base.flags,
drivers/crypto/amcc/crypto4xx_alg.c:				  req->base.complete, req->base.data);
drivers/crypto/amcc/crypto4xx_alg.c:	aead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
drivers/crypto/amcc/crypto4xx_alg.c:			       req->iv);
drivers/crypto/amcc/crypto4xx_alg.c:	aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/amcc/crypto4xx_alg.c:	struct crypto4xx_ctx *ctx  = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/amcc/crypto4xx_alg.c:	unsigned int len = req->cryptlen;
drivers/crypto/amcc/crypto4xx_alg.c:	if (req->iv[0] == 1) {
drivers/crypto/amcc/crypto4xx_alg.c:	crypto4xx_memcpy_to_le32(iv, req->iv, 16 - (req->iv[0] + 1));
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  sa, ctx->sa_len, req->assoclen, rctx->dst);
drivers/crypto/amcc/crypto4xx_alg.c:	struct crypto4xx_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/amcc/crypto4xx_alg.c:	unsigned int len = req->cryptlen;
drivers/crypto/amcc/crypto4xx_alg.c:	crypto4xx_memcpy_to_le32(iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, req->dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  ctx->sa_len, req->assoclen, rctx->dst);
drivers/crypto/amcc/crypto4xx_alg.c:	struct crypto4xx_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/amcc/crypto4xx_alg.c:			__crypto_ahash_cast(req->base.tfm));
drivers/crypto/amcc/crypto4xx_alg.c:	struct crypto4xx_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/amcc/crypto4xx_alg.c:	sg_init_one(&dst, req->result, ds);
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, &dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  req->nbytes, NULL, 0, ctx->sa_in,
drivers/crypto/amcc/crypto4xx_alg.c:	struct crypto4xx_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/amcc/crypto4xx_alg.c:	sg_init_one(&dst, req->result, ds);
drivers/crypto/amcc/crypto4xx_alg.c:	return crypto4xx_build_pd(&req->base, ctx, req->src, &dst,
drivers/crypto/amcc/crypto4xx_alg.c:				  req->nbytes, NULL, 0, ctx->sa_in,
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src), temp,
drivers/crypto/chelsio/chcr_algo.c:				authsize, req->assoclen +
drivers/crypto/chelsio/chcr_algo.c:				req->cryptlen - authsize);
drivers/crypto/chelsio/chcr_algo.c:	req->base.complete(&req->base, err);
drivers/crypto/chelsio/chcr_algo.c:	skcipher_request_set_callback(&reqctx->fallback_req, req->base.flags,
drivers/crypto/chelsio/chcr_algo.c:				      req->base.complete, req->base.data);
drivers/crypto/chelsio/chcr_algo.c:	skcipher_request_set_crypt(&reqctx->fallback_req, req->src, req->dst,
drivers/crypto/chelsio/chcr_algo.c:				   req->cryptlen, iv);
drivers/crypto/chelsio/chcr_algo.c:	struct crypto_tfm *tfm = req->tfm;
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->wreq.op_to_cctx_size = FILL_WR_OP_CCTX_SIZE;
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->wreq.pld_size_hash_size =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->wreq.len16_pkd =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->wreq.cookie = cpu_to_be64((uintptr_t)req);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->wreq.rx_chid_to_rx_q_id = FILL_WR_RX_Q_ID(rx_channel_id, qid,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->ulptx.cmd_dest = FILL_ULPTX_CMD_DEST(tx_channel_id, fid);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->ulptx.len = htonl((DIV_ROUND_UP(len16, 16) -
drivers/crypto/chelsio/chcr_algo.c:				((sizeof(chcr_req->wreq)) >> 4)));
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sc_imm.cmd_more = FILL_CMD_MORE(!imm);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sc_imm.len = cpu_to_be32(sizeof(struct cpl_tx_sec_pdu) +
drivers/crypto/chelsio/chcr_algo.c:					   sizeof(chcr_req->key_ctx) + sc_len);
drivers/crypto/chelsio/chcr_algo.c:	gfp_t flags = wrparam->req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ?
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.op_ivinsrtofst =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.pldlen = htonl(IV + wrparam->bytes);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.aadstart_cipherstop_hi =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.cipherstop_lo_authinsert =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.seqno_numivs = FILL_SEC_CPL_SCMD0_SEQNO(reqctx->op, 0,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.ivgen_hdrlen = FILL_SEC_CPL_IVGEN_HDRLEN(0, 0, 0,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->key_ctx.ctx_hdr = ablkctx->key_ctx_hdr;
drivers/crypto/chelsio/chcr_algo.c:		generate_copy_rrkey(ablkctx, &chcr_req->key_ctx);
drivers/crypto/chelsio/chcr_algo.c:			memcpy(chcr_req->key_ctx.key, ablkctx->key,
drivers/crypto/chelsio/chcr_algo.c:			memcpy(chcr_req->key_ctx.key, ablkctx->key +
drivers/crypto/chelsio/chcr_algo.c:			memcpy(chcr_req->key_ctx.key +
drivers/crypto/chelsio/chcr_algo.c:	create_wreq(c_ctx(tfm), chcr_req, &(wrparam->req->base), reqctx->imm, 0,
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(wrparam->req->src,
drivers/crypto/chelsio/chcr_algo.c:			sg_nents(wrparam->req->src), wrparam->req->iv, 16,
drivers/crypto/chelsio/chcr_algo.c:		ctr_add_iv(iv, req->iv, (reqctx->processed /
drivers/crypto/chelsio/chcr_algo.c:			memcpy(iv, req->iv, AES_BLOCK_SIZE);
drivers/crypto/chelsio/chcr_algo.c:		ctr_add_iv(iv, req->iv, DIV_ROUND_UP(reqctx->processed,
drivers/crypto/chelsio/chcr_algo.c:	if (req->cryptlen == reqctx->processed) {
drivers/crypto/chelsio/chcr_algo.c:		err = chcr_final_cipher_iv(req, fw6_pld, req->iv);
drivers/crypto/chelsio/chcr_algo.c:		if ((bytes + reqctx->processed) >= req->cryptlen)
drivers/crypto/chelsio/chcr_algo.c:			bytes  = req->cryptlen - reqctx->processed;
drivers/crypto/chelsio/chcr_algo.c:		bytes  = req->cryptlen - reqctx->processed;
drivers/crypto/chelsio/chcr_algo.c:		memcpy(req->iv, reqctx->init_iv, IV);
drivers/crypto/chelsio/chcr_algo.c:		err = chcr_cipher_fallback(ablkctx->sw_cipher, req, req->iv,
drivers/crypto/chelsio/chcr_algo.c:		CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
drivers/crypto/chelsio/chcr_algo.c:		CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
drivers/crypto/chelsio/chcr_algo.c:	req->base.complete(&req->base, err);
drivers/crypto/chelsio/chcr_algo.c:	if (!req->iv)
drivers/crypto/chelsio/chcr_algo.c:	    (req->cryptlen == 0) ||
drivers/crypto/chelsio/chcr_algo.c:	    (req->cryptlen % crypto_skcipher_blocksize(tfm))) {
drivers/crypto/chelsio/chcr_algo.c:		if (req->cryptlen == 0 && subtype != CRYPTO_ALG_SUB_TYPE_XTS)
drivers/crypto/chelsio/chcr_algo.c:		else if (req->cryptlen % crypto_skcipher_blocksize(tfm) &&
drivers/crypto/chelsio/chcr_algo.c:		       ablkctx->enckey_len, req->cryptlen, ivsize);
drivers/crypto/chelsio/chcr_algo.c:	if (req->cryptlen < (SGE_MAX_WR_LEN - (sizeof(struct chcr_wr) +
drivers/crypto/chelsio/chcr_algo.c:		dnents = sg_nents_xlen(req->dst, req->cryptlen,
drivers/crypto/chelsio/chcr_algo.c:		reqctx->imm = (transhdr_len + IV + req->cryptlen) <=
drivers/crypto/chelsio/chcr_algo.c:		bytes = IV + req->cryptlen;
drivers/crypto/chelsio/chcr_algo.c:		bytes = chcr_sg_ent_in_wr(req->src, req->dst, 0,
drivers/crypto/chelsio/chcr_algo.c:		if ((bytes + reqctx->processed) >= req->cryptlen)
drivers/crypto/chelsio/chcr_algo.c:			bytes  = req->cryptlen - reqctx->processed;
drivers/crypto/chelsio/chcr_algo.c:		bytes = req->cryptlen;
drivers/crypto/chelsio/chcr_algo.c:		bytes = adjust_ctr_overflow(req->iv, bytes);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(reqctx->iv + CTR_RFC3686_NONCE_SIZE, req->iv,
drivers/crypto/chelsio/chcr_algo.c:		memcpy(reqctx->iv, req->iv, IV);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(reqctx->init_iv, req->iv, IV);
drivers/crypto/chelsio/chcr_algo.c:					   reqctx->iv : req->iv,
drivers/crypto/chelsio/chcr_algo.c:	reqctx->srcsg = req->src;
drivers/crypto/chelsio/chcr_algo.c:	reqctx->dstsg = req->dst;
drivers/crypto/chelsio/chcr_algo.c:	reqctx->partial_req = !!(req->cryptlen - reqctx->processed);
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)))) {
drivers/crypto/chelsio/chcr_algo.c:		CRYPTO_ALG_SUB_TYPE_CBC && req->base.flags ==
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))))
drivers/crypto/chelsio/chcr_algo.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.op_ivinsrtofst =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.pldlen = htonl(param->bfr_len + param->sg_len);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.aadstart_cipherstop_hi =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.cipherstop_lo_authinsert =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.seqno_numivs =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.ivgen_hdrlen =
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key, req_ctx->partial_hash,
drivers/crypto/chelsio/chcr_algo.c:		memcpy(chcr_req->key_ctx.key +
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->key_ctx.ctx_hdr = FILL_KEY_CTX_HDR(CHCR_KEYCTX_NO_KEY,
drivers/crypto/chelsio/chcr_algo.c:					     sizeof(chcr_req->key_ctx)) >> 4));
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.scmd1 = cpu_to_be64((u64)param->scmd1);
drivers/crypto/chelsio/chcr_algo.c:	create_wreq(h_ctx(tfm), chcr_req, &req->base, req_ctx->hctx_wr.imm,
drivers/crypto/chelsio/chcr_algo.c:	unsigned int nbytes = req->nbytes;
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src), req_ctx->reqbfr
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)))) {
drivers/crypto/chelsio/chcr_algo.c:	params.sg_len = chcr_hash_ent_in_wr(req->src, !!req_ctx->reqlen,
drivers/crypto/chelsio/chcr_algo.c:	if (params.sg_len > req->nbytes)
drivers/crypto/chelsio/chcr_algo.c:		params.sg_len = req->nbytes;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->hctx_wr.srcsg = req->src;
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:				   req_ctx->reqbfr, remainder, req->nbytes -
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->hctx_wr.srcsg = req->src;
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)))) {
drivers/crypto/chelsio/chcr_algo.c:	params.sg_len = chcr_hash_ent_in_wr(req->src, !!req_ctx->reqlen,
drivers/crypto/chelsio/chcr_algo.c:	if (params.sg_len < req->nbytes) {
drivers/crypto/chelsio/chcr_algo.c:		params.sg_len = req->nbytes;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->hctx_wr.srcsg = req->src;
drivers/crypto/chelsio/chcr_algo.c:	if ((req_ctx->reqlen + req->nbytes) == 0) {
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG)))) {
drivers/crypto/chelsio/chcr_algo.c:	params.sg_len = chcr_hash_ent_in_wr(req->src, !!req_ctx->reqlen,
drivers/crypto/chelsio/chcr_algo.c:	if (params.sg_len < req->nbytes) {
drivers/crypto/chelsio/chcr_algo.c:		params.sg_len = req->nbytes;
drivers/crypto/chelsio/chcr_algo.c:		params.scmd1 = req->nbytes + req_ctx->data_len;
drivers/crypto/chelsio/chcr_algo.c:	req_ctx->hctx_wr.srcsg = req->src;
drivers/crypto/chelsio/chcr_algo.c:	if (req->nbytes == 0) {
drivers/crypto/chelsio/chcr_algo.c:	if ((params.sg_len + hctx_wr->processed) > req->nbytes)
drivers/crypto/chelsio/chcr_algo.c:		params.sg_len = req->nbytes - hctx_wr->processed;
drivers/crypto/chelsio/chcr_algo.c:	    ((params.sg_len + hctx_wr->processed) < req->nbytes)) {
drivers/crypto/chelsio/chcr_algo.c:				 req->nbytes)) {
drivers/crypto/chelsio/chcr_algo.c:			memcpy(req->result, input + sizeof(struct cpl_fw6_pld),
drivers/crypto/chelsio/chcr_algo.c:	req->base.complete(&req->base, err);
drivers/crypto/chelsio/chcr_algo.c:	struct crypto_tfm *tfm = req->tfm;
drivers/crypto/chelsio/chcr_algo.c:	if (reqctx->op && req->cryptlen < authsize)
drivers/crypto/chelsio/chcr_algo.c:	if (((req->cryptlen - (op_type ? authsize : 0)) == 0) ||
drivers/crypto/chelsio/chcr_algo.c:	    (req->assoclen > aadmax) ||
drivers/crypto/chelsio/chcr_algo.c:	aead_request_set_callback(subreq, req->base.flags,
drivers/crypto/chelsio/chcr_algo.c:				  req->base.complete, req->base.data);
drivers/crypto/chelsio/chcr_algo.c:	aead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
drivers/crypto/chelsio/chcr_algo.c:				 req->iv);
drivers/crypto/chelsio/chcr_algo.c:	aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/chelsio/chcr_algo.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
drivers/crypto/chelsio/chcr_algo.c:	if (req->cryptlen == 0)
drivers/crypto/chelsio/chcr_algo.c:	dnents = sg_nents_xlen(req->dst, req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	snents = sg_nents_xlen(req->src, req->assoclen + req->cryptlen,
drivers/crypto/chelsio/chcr_algo.c:		- sizeof(chcr_req->key_ctx);
drivers/crypto/chelsio/chcr_algo.c:	reqctx->imm = (transhdr_len + req->assoclen + req->cryptlen) <
drivers/crypto/chelsio/chcr_algo.c:	temp = reqctx->imm ? roundup(req->assoclen + req->cryptlen, 16)
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.op_ivinsrtofst =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.pldlen = htonl(req->assoclen + IV + req->cryptlen);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.aadstart_cipherstop_hi = FILL_SEC_CPL_CIPHERSTOP_HI(
drivers/crypto/chelsio/chcr_algo.c:					null ? 0 : IV + req->assoclen,
drivers/crypto/chelsio/chcr_algo.c:					req->assoclen + IV + 1,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.cipherstop_lo_authinsert = FILL_SEC_CPL_AUTHINSERT(
drivers/crypto/chelsio/chcr_algo.c:					null ? 0 : req->assoclen + IV + 1,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.seqno_numivs = FILL_SEC_CPL_SCMD0_SEQNO(reqctx->op,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.ivgen_hdrlen =  FILL_SEC_CPL_IVGEN_HDRLEN(0, 0, 1,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->key_ctx.ctx_hdr = aeadctx->key_ctx_hdr;
drivers/crypto/chelsio/chcr_algo.c:		memcpy(chcr_req->key_ctx.key, aeadctx->key,
drivers/crypto/chelsio/chcr_algo.c:		memcpy(chcr_req->key_ctx.key, actx->dec_rrkey,
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key + roundup(aeadctx->enckey_len, 16),
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr + CTR_RFC3686_NONCE_SIZE, req->iv,
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr, req->iv, IV);
drivers/crypto/chelsio/chcr_algo.c:		kctx_len + (reqctx->imm ? (req->assoclen + req->cryptlen) : 0);
drivers/crypto/chelsio/chcr_algo.c:	create_wreq(a_ctx(tfm), chcr_req, &req->base, reqctx->imm, size,
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		src_len = req->assoclen + req->cryptlen + (op_type ?
drivers/crypto/chelsio/chcr_algo.c:		src_len = req->assoclen + req->cryptlen;
drivers/crypto/chelsio/chcr_algo.c:		dst_len = req->assoclen + req->cryptlen + (op_type ?
drivers/crypto/chelsio/chcr_algo.c:	if (!req->cryptlen || !src_len || !dst_len)
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->src,
drivers/crypto/chelsio/chcr_algo.c:				sg_nents_for_len(req->src, src_len),
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->src,
drivers/crypto/chelsio/chcr_algo.c:				   sg_nents_for_len(req->src, src_len),
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->dst,
drivers/crypto/chelsio/chcr_algo.c:				   sg_nents_for_len(req->dst, dst_len),
drivers/crypto/chelsio/chcr_algo.c:			dma_unmap_sg(dev, req->src,
drivers/crypto/chelsio/chcr_algo.c:				     sg_nents_for_len(req->src, src_len),
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		src_len = req->assoclen + req->cryptlen + (op_type ?
drivers/crypto/chelsio/chcr_algo.c:		src_len = req->assoclen + req->cryptlen;
drivers/crypto/chelsio/chcr_algo.c:		dst_len = req->assoclen + req->cryptlen + (op_type ?
drivers/crypto/chelsio/chcr_algo.c:	if (!req->cryptlen || !src_len || !dst_len)
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->src,
drivers/crypto/chelsio/chcr_algo.c:			     sg_nents_for_len(req->src, src_len),
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->src,
drivers/crypto/chelsio/chcr_algo.c:			     sg_nents_for_len(req->src, src_len),
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->dst,
drivers/crypto/chelsio/chcr_algo.c:			     sg_nents_for_len(req->dst, dst_len),
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:				   buf, req->cryptlen + req->assoclen, 0);
drivers/crypto/chelsio/chcr_algo.c:		ulptx_walk_add_sg(&ulp_walk, req->src, req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:				  req->assoclen,  0);
drivers/crypto/chelsio/chcr_algo.c:	temp = req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	dsgl_walk_add_sg(&dsgl_walk, req->dst, temp, 0);
drivers/crypto/chelsio/chcr_algo.c:		sg_pcopy_to_buffer(req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:	if (!req->nbytes)
drivers/crypto/chelsio/chcr_algo.c:	error = dma_map_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:	if (!req->nbytes)
drivers/crypto/chelsio/chcr_algo.c:	dma_unmap_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:		error = dma_map_sg(dev, req->dst, sg_nents(req->dst),
drivers/crypto/chelsio/chcr_algo.c:			dma_unmap_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:	if (req->src == req->dst) {
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->src, sg_nents(req->src),
drivers/crypto/chelsio/chcr_algo.c:		dma_unmap_sg(dev, req->dst, sg_nents(req->dst),
drivers/crypto/chelsio/chcr_algo.c:	if (req->assoclen)
drivers/crypto/chelsio/chcr_algo.c:			 req->cryptlen - m : req->cryptlen, l);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr + 4, req->iv, 8);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr, req->iv, 16);
drivers/crypto/chelsio/chcr_algo.c:		assoclen = req->assoclen - 8;
drivers/crypto/chelsio/chcr_algo.c:		assoclen = req->assoclen;
drivers/crypto/chelsio/chcr_algo.c:	auth_offset = req->cryptlen ?
drivers/crypto/chelsio/chcr_algo.c:		(req->assoclen + IV + 1 + ccm_xtra) : 0;
drivers/crypto/chelsio/chcr_algo.c:		if (crypto_aead_authsize(tfm) != req->cryptlen)
drivers/crypto/chelsio/chcr_algo.c:		htonl(req->assoclen + IV + req->cryptlen + ccm_xtra);
drivers/crypto/chelsio/chcr_algo.c:				req->assoclen + IV + 1 + ccm_xtra, 0);
drivers/crypto/chelsio/chcr_algo.c:		if (crypto_ccm_check_iv(req->iv)) {
drivers/crypto/chelsio/chcr_algo.c:		if (req->assoclen != 16 && req->assoclen != 20) {
drivers/crypto/chelsio/chcr_algo.c:			       req->assoclen);
drivers/crypto/chelsio/chcr_algo.c:	unsigned int sub_type, assoclen = req->assoclen;
drivers/crypto/chelsio/chcr_algo.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
drivers/crypto/chelsio/chcr_algo.c:	dnents = sg_nents_xlen(req->dst, req->assoclen + req->cryptlen
drivers/crypto/chelsio/chcr_algo.c:	snents = sg_nents_xlen(req->src, req->assoclen + req->cryptlen,
drivers/crypto/chelsio/chcr_algo.c:	reqctx->imm = (transhdr_len + req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	temp = reqctx->imm ? roundup(req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	fill_sec_cpl_for_aead(&chcr_req->sec_cpl, dst_size, req, reqctx->op);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->key_ctx.ctx_hdr = aeadctx->key_ctx_hdr;
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key, aeadctx->key, aeadctx->enckey_len);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key + roundup(aeadctx->enckey_len, 16),
drivers/crypto/chelsio/chcr_algo.c:		kctx_len + (reqctx->imm ? (req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	create_wreq(a_ctx(tfm), chcr_req, &req->base, reqctx->imm, 0,
drivers/crypto/chelsio/chcr_algo.c:	unsigned int dst_size = 0, temp = 0, kctx_len, assoclen = req->assoclen;
drivers/crypto/chelsio/chcr_algo.c:	gfp_t flags = req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP ? GFP_KERNEL :
drivers/crypto/chelsio/chcr_algo.c:		assoclen = req->assoclen - 8;
drivers/crypto/chelsio/chcr_algo.c:	dnents = sg_nents_xlen(req->dst, req->assoclen + req->cryptlen +
drivers/crypto/chelsio/chcr_algo.c:	snents = sg_nents_xlen(req->src, req->assoclen + req->cryptlen,
drivers/crypto/chelsio/chcr_algo.c:	reqctx->imm = (transhdr_len + req->assoclen + req->cryptlen) <=
drivers/crypto/chelsio/chcr_algo.c:	temp = reqctx->imm ? roundup(req->assoclen + req->cryptlen, 16) :
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.op_ivinsrtofst = FILL_SEC_CPL_OP_IVINSR(
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.pldlen =
drivers/crypto/chelsio/chcr_algo.c:		htonl(req->assoclen + IV + req->cryptlen);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.aadstart_cipherstop_hi = FILL_SEC_CPL_CIPHERSTOP_HI(
drivers/crypto/chelsio/chcr_algo.c:					req->assoclen + IV + 1, 0);
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.cipherstop_lo_authinsert =
drivers/crypto/chelsio/chcr_algo.c:			FILL_SEC_CPL_AUTHINSERT(0, req->assoclen + IV + 1,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.seqno_numivs =
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->sec_cpl.ivgen_hdrlen =  FILL_SEC_CPL_IVGEN_HDRLEN(0, 0, 1,
drivers/crypto/chelsio/chcr_algo.c:	chcr_req->key_ctx.ctx_hdr = aeadctx->key_ctx_hdr;
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key, aeadctx->key, aeadctx->enckey_len);
drivers/crypto/chelsio/chcr_algo.c:	memcpy(chcr_req->key_ctx.key + roundup(aeadctx->enckey_len, 16),
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr + 4, req->iv, GCM_RFC4106_IV_SIZE);
drivers/crypto/chelsio/chcr_algo.c:		memcpy(ivptr, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/chelsio/chcr_algo.c:		kctx_len + (reqctx->imm ? (req->assoclen + req->cryptlen) : 0);
drivers/crypto/chelsio/chcr_algo.c:	create_wreq(a_ctx(tfm), chcr_req, &req->base, reqctx->imm, size,
drivers/crypto/chelsio/chcr_algo.c:		(!(req->base.flags & CRYPTO_TFM_REQ_MAY_BACKLOG))) {
drivers/crypto/chelsio/chcr_algo.c:	    crypto_ipsec_check_assoclen(req->assoclen) != 0) {
drivers/crypto/chelsio/chcr_algo.c:		       req->assoclen);
drivers/crypto/nx/nx-aes-ecb.c:		to_process = req->cryptlen - processed;
drivers/crypto/nx/nx-aes-ecb.c:		rc = nx_build_sg_lists(nx_ctx, NULL, req->dst, req->src,
drivers/crypto/nx/nx-aes-ecb.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ecb.c:	} while (processed < req->cryptlen);
drivers/crypto/nx/nx-aes-cbc.c:		to_process = req->cryptlen - processed;
drivers/crypto/nx/nx-aes-cbc.c:		rc = nx_build_sg_lists(nx_ctx, req->iv, req->dst, req->src,
drivers/crypto/nx/nx-aes-cbc.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-cbc.c:		memcpy(req->iv, csbcpb->cpb.aes_cbc.cv, AES_BLOCK_SIZE);
drivers/crypto/nx/nx-aes-cbc.c:	} while (processed < req->cryptlen);
drivers/crypto/nx/nx-aes-ctr.c:		to_process = req->cryptlen - processed;
drivers/crypto/nx/nx-aes-ctr.c:		rc = nx_build_sg_lists(nx_ctx, iv, req->dst, req->src,
drivers/crypto/nx/nx-aes-ctr.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ctr.c:	} while (processed < req->cryptlen);
drivers/crypto/nx/nx-aes-ctr.c:	memcpy(iv + CTR_RFC3686_NONCE_SIZE, req->iv, CTR_RFC3686_IV_SIZE);
drivers/crypto/nx/nx-aes-ccm.c:			scatterwalk_map_and_copy(b1 + 2, req->src, 0,
drivers/crypto/nx/nx-aes-ccm.c:			scatterwalk_map_and_copy(b1 + 6, req->src, 0,
drivers/crypto/nx/nx-aes-ccm.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ccm.c:						    req->src, processed,
drivers/crypto/nx/nx-aes-ccm.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/nx/nx-aes-ccm.c:	unsigned int nbytes = req->cryptlen;
drivers/crypto/nx/nx-aes-ccm.c:				 req->src, nbytes + req->assoclen, authsize,
drivers/crypto/nx/nx-aes-ccm.c:		rc = nx_build_sg_lists(nx_ctx, iv, req->dst, req->src,
drivers/crypto/nx/nx-aes-ccm.c:				       &to_process, processed + req->assoclen,
drivers/crypto/nx/nx-aes-ccm.c:			   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/nx/nx-aes-ccm.c:	unsigned int nbytes = req->cryptlen;
drivers/crypto/nx/nx-aes-ccm.c:		rc = nx_build_sg_lists(nx_ctx, iv, req->dst, req->src,
drivers/crypto/nx/nx-aes-ccm.c:				       &to_process, processed + req->assoclen,
drivers/crypto/nx/nx-aes-ccm.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-ccm.c:				 req->dst, nbytes + req->assoclen, authsize,
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/nx/nx-aes-ccm.c:	memcpy(iv + 4, req->iv, 8);
drivers/crypto/nx/nx-aes-ccm.c:	return ccm_nx_encrypt(req, iv, req->assoclen - 8);
drivers/crypto/nx/nx-aes-ccm.c:	rc = crypto_ccm_check_iv(req->iv);
drivers/crypto/nx/nx-aes-ccm.c:	return ccm_nx_encrypt(req, req->iv, req->assoclen);
drivers/crypto/nx/nx-aes-ccm.c:	struct nx_crypto_ctx *nx_ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/nx/nx-aes-ccm.c:	memcpy(iv + 4, req->iv, 8);
drivers/crypto/nx/nx-aes-ccm.c:	return ccm_nx_decrypt(req, iv, req->assoclen - 8);
drivers/crypto/nx/nx-aes-ccm.c:	rc = crypto_ccm_check_iv(req->iv);
drivers/crypto/nx/nx-aes-ccm.c:	return ccm_nx_decrypt(req, req->iv, req->assoclen);
drivers/crypto/nx/nx-aes-gcm.c:		scatterwalk_start(&walk, req->src);
drivers/crypto/nx/nx-aes-gcm.c:					  req->src, processed, &to_process);
drivers/crypto/nx/nx-aes-gcm.c:				req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-gcm.c:					  req->src, processed, &to_process);
drivers/crypto/nx/nx-aes-gcm.c:				req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-gcm.c:			   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-gcm.c:	unsigned int nbytes = req->cryptlen;
drivers/crypto/nx/nx-aes-gcm.c:		rc = nx_build_sg_lists(nx_ctx, rctx->iv, req->dst,
drivers/crypto/nx/nx-aes-gcm.c:				       req->src, &to_process,
drivers/crypto/nx/nx-aes-gcm.c:				       processed + req->assoclen,
drivers/crypto/nx/nx-aes-gcm.c:				   req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP);
drivers/crypto/nx/nx-aes-gcm.c:			req->dst, req->assoclen + nbytes,
drivers/crypto/nx/nx-aes-gcm.c:			itag, req->src, req->assoclen + nbytes,
drivers/crypto/nx/nx-aes-gcm.c:	memcpy(iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/nx/nx-aes-gcm.c:	return gcm_aes_nx_crypt(req, 1, req->assoclen);
drivers/crypto/nx/nx-aes-gcm.c:	memcpy(iv, req->iv, GCM_AES_IV_SIZE);
drivers/crypto/nx/nx-aes-gcm.c:	return gcm_aes_nx_crypt(req, 0, req->assoclen);
drivers/crypto/nx/nx-aes-gcm.c:	memcpy(iv + NX_GCM4106_NONCE_LEN, req->iv, 8);
drivers/crypto/nx/nx-aes-gcm.c:	if (req->assoclen < 8)
drivers/crypto/nx/nx-aes-gcm.c:	return gcm_aes_nx_crypt(req, 1, req->assoclen - 8);
drivers/crypto/nx/nx-aes-gcm.c:	memcpy(iv + NX_GCM4106_NONCE_LEN, req->iv, 8);
drivers/crypto/nx/nx-aes-gcm.c:	if (req->assoclen < 8)
drivers/crypto/nx/nx-aes-gcm.c:	return gcm_aes_nx_crypt(req, 0, req->assoclen - 8);
drivers/crypto/atmel-tdes.c:	if (dd->req->iv && (valmr & TDES_MR_OPMOD_MASK) != TDES_MR_OPMOD_ECB)
drivers/crypto/atmel-tdes.c:		atmel_tdes_write_n(dd, TDES_IV1R, (void *)dd->req->iv, 2);
drivers/crypto/atmel-tdes.c:	if (req->cryptlen < ivsize)
drivers/crypto/atmel-tdes.c:		scatterwalk_map_and_copy(req->iv, req->dst,
drivers/crypto/atmel-tdes.c:					 req->cryptlen - ivsize, ivsize, 0);
drivers/crypto/atmel-tdes.c:		if (req->src == req->dst)
drivers/crypto/atmel-tdes.c:			memcpy(req->iv, rctx->lastc, ivsize);
drivers/crypto/atmel-tdes.c:			scatterwalk_map_and_copy(req->iv, req->src,
drivers/crypto/atmel-tdes.c:						 req->cryptlen - ivsize,
drivers/crypto/atmel-tdes.c:	req->base.complete(&req->base, err);
drivers/crypto/atmel-tdes.c:		ret = crypto_enqueue_request(&dd->queue, &req->base);
drivers/crypto/atmel-tdes.c:	dd->total = req->cryptlen;
drivers/crypto/atmel-tdes.c:	dd->in_sg = req->src;
drivers/crypto/atmel-tdes.c:	dd->out_sg = req->dst;
drivers/crypto/atmel-tdes.c:		if (!IS_ALIGNED(req->cryptlen, CFB8_BLOCK_SIZE)) {
drivers/crypto/atmel-tdes.c:		if (!IS_ALIGNED(req->cryptlen, CFB16_BLOCK_SIZE)) {
drivers/crypto/atmel-tdes.c:		if (!IS_ALIGNED(req->cryptlen, CFB32_BLOCK_SIZE)) {
drivers/crypto/atmel-tdes.c:		if (!IS_ALIGNED(req->cryptlen, DES_BLOCK_SIZE)) {
drivers/crypto/atmel-tdes.c:	    !(mode & TDES_FLAGS_ENCRYPT) && req->src == req->dst) {
drivers/crypto/atmel-tdes.c:		if (req->cryptlen >= ivsize)
drivers/crypto/atmel-tdes.c:			scatterwalk_map_and_copy(rctx->lastc, req->src,
drivers/crypto/atmel-tdes.c:						 req->cryptlen - ivsize,
drivers/crypto/ux500/hash/hash_core.c:		if (req->nbytes < HASH_DMA_ALIGN_SIZE) {
drivers/crypto/ux500/hash/hash_core.c:			if (req->nbytes >= HASH_DMA_PERFORMANCE_MIN_SIZE &&
drivers/crypto/ux500/hash/hash_core.c:			    hash_dma_valid_data(req->src, req->nbytes)) {
drivers/crypto/ux500/hash/hash_core.c:		HASH_SET_NBLW((req->nbytes * 8) % 32);
drivers/crypto/ux500/hash/hash_core.c:	ctx->device->dma.nents = hash_get_nents(req->src, req->nbytes, NULL);
drivers/crypto/ux500/hash/hash_core.c:	bytes_written = hash_dma_write(ctx, req->src, req->nbytes);
drivers/crypto/ux500/hash/hash_core.c:	if (bytes_written != req->nbytes) {
drivers/crypto/ux500/hash/hash_core.c:	memcpy(req->result, digest, ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:	} else if (req->nbytes == 0 && ctx->keylen == 0) {
drivers/crypto/ux500/hash/hash_core.c:			memcpy(req->result, &zero_hash[0], ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:	} else if (req->nbytes == 0 && ctx->keylen > 0) {
drivers/crypto/ux500/hash/hash_core.c:	memcpy(req->result, digest, ctx->digestsize);
drivers/crypto/ux500/hash/hash_core.c:	pr_debug("%s: data size: %d\n", __func__, req->nbytes);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->datalen = areq->cryptlen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->outlen = areq->cryptlen;
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device->dma.nents_src = get_nents(areq->src, ctx->datalen);
drivers/crypto/ux500/cryp/cryp_core.c:	ctx->device->dma.nents_dst = get_nents(areq->dst, ctx->outlen);
drivers/crypto/ux500/cryp/cryp_core.c:	bytes_written = cryp_dma_write(ctx, areq->src, ctx->datalen);
drivers/crypto/ux500/cryp/cryp_core.c:	bytes_read = cryp_dma_read(ctx, areq->dst, bytes_written);
drivers/crypto/omap-des.c:	if ((dd->flags & FLAGS_CBC) && dd->req->iv)
drivers/crypto/omap-des.c:		omap_des_write_n(dd, DES_REG_IV(dd, 0), (void *)dd->req->iv, 2);
drivers/crypto/omap-des.c:	dd->total = req->cryptlen;
drivers/crypto/omap-des.c:	dd->total_save = req->cryptlen;
drivers/crypto/omap-des.c:	dd->in_sg = req->src;
drivers/crypto/omap-des.c:	dd->out_sg = req->dst;
drivers/crypto/omap-des.c:	dd->orig_out = req->dst;
drivers/crypto/omap-des.c:	if (req->src == req->dst)
drivers/crypto/omap-des.c:	if ((dd->flags & FLAGS_CBC) && dd->req->iv)
drivers/crypto/omap-des.c:			((u32 *)dd->req->iv)[i] =
drivers/crypto/omap-des.c:	pr_debug("nbytes: %d, enc: %d, cbc: %d\n", req->cryptlen,
drivers/crypto/omap-des.c:	if (!req->cryptlen)
drivers/crypto/omap-des.c:	if (!IS_ALIGNED(req->cryptlen, DES_BLOCK_SIZE))
drivers/crypto/sahara.c:		req->cryptlen, req->src, req->dst);
drivers/crypto/sahara.c:	dev->total = req->cryptlen;
drivers/crypto/sahara.c:	dev->in_sg = req->src;
drivers/crypto/sahara.c:	dev->out_sg = req->dst;
drivers/crypto/sahara.c:	if ((dev->flags & FLAGS_CBC) && req->iv)
drivers/crypto/sahara.c:		memcpy(dev->iv_base, req->iv, AES_KEYSIZE_128);
drivers/crypto/sahara.c:		req->cryptlen, !!(mode & FLAGS_ENCRYPT), !!(mode & FLAGS_CBC));
drivers/crypto/sahara.c:	if (!IS_ALIGNED(req->cryptlen, AES_BLOCK_SIZE)) {
drivers/crypto/sahara.c:	err = crypto_enqueue_request(&dev->queue, &req->base);
drivers/crypto/sahara.c:					      req->base.flags,
drivers/crypto/sahara.c:					      req->base.complete,
drivers/crypto/sahara.c:					      req->base.data);
drivers/crypto/sahara.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/sahara.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/sahara.c:					      req->base.flags,
drivers/crypto/sahara.c:					      req->base.complete,
drivers/crypto/sahara.c:					      req->base.data);
drivers/crypto/sahara.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/sahara.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/sahara.c:					      req->base.flags,
drivers/crypto/sahara.c:					      req->base.complete,
drivers/crypto/sahara.c:					      req->base.data);
drivers/crypto/sahara.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/sahara.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/sahara.c:					      req->base.flags,
drivers/crypto/sahara.c:					      req->base.complete,
drivers/crypto/sahara.c:					      req->base.data);
drivers/crypto/sahara.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/sahara.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/sahara.c:	len = rctx->buf_cnt + req->nbytes;
drivers/crypto/sahara.c:		scatterwalk_map_and_copy(rctx->buf + rctx->buf_cnt, req->src,
drivers/crypto/sahara.c:					 0, req->nbytes, 0);
drivers/crypto/sahara.c:		rctx->buf_cnt += req->nbytes;
drivers/crypto/sahara.c:		unsigned int offset = req->nbytes - hash_later;
drivers/crypto/sahara.c:		scatterwalk_map_and_copy(rctx->buf, req->src, offset,
drivers/crypto/sahara.c:	req->nbytes = req->nbytes - hash_later;
drivers/crypto/sahara.c:	sahara_walk_and_recalc(req->src, req->nbytes);
drivers/crypto/sahara.c:	if (rctx->buf_cnt && req->nbytes) {
drivers/crypto/sahara.c:		sg_chain(rctx->in_sg_chain, 2, req->src);
drivers/crypto/sahara.c:		rctx->total = req->nbytes + rctx->buf_cnt;
drivers/crypto/sahara.c:		req->src = rctx->in_sg_chain;
drivers/crypto/sahara.c:		if (req->src)
drivers/crypto/sahara.c:			rctx->in_sg = req->src;
drivers/crypto/sahara.c:		rctx->in_sg = req->src;
drivers/crypto/sahara.c:		rctx->total = req->nbytes;
drivers/crypto/sahara.c:		req->src = rctx->in_sg;
drivers/crypto/sahara.c:	if (req->result)
drivers/crypto/sahara.c:		memcpy(req->result, rctx->context, rctx->digest_size);
drivers/crypto/sahara.c:			if (crypto_tfm_alg_type(async_req->tfm) ==
drivers/crypto/sahara.c:			async_req->complete(async_req, ret);
drivers/crypto/sahara.c:	if (!req->nbytes && !last)
drivers/crypto/sahara.c:	ret = crypto_enqueue_request(&dev->queue, &req->base);
drivers/crypto/sahara.c:	req->nbytes = 0;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pr_debug("Gather list size %d\n", req->incnt);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	for (i = 0; i < req->incnt; i++) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			 req->in[i].size, req->in[i].vptr,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			 (void *) req->in[i].dma_addr);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			 req->in[i].size);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:				     req->in[i].vptr, req->in[i].size, false);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pr_debug("Scatter list size %d\n", req->outcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	for (i = 0; i < req->outcnt; i++) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			 req->out[i].size, req->out[i].vptr,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			 (void *) req->out[i].dma_addr);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:		pr_debug("Buffer hexdump (%d bytes)\n", req->out[i].size);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:				     req->out[i].vptr, req->out[i].size, false);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	if (unlikely(req->incnt > OTX_CPT_MAX_SG_IN_CNT ||
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:		     req->outcnt > OTX_CPT_MAX_SG_OUT_CNT)) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	g_sz_bytes = ((req->incnt + 3) / 4) *
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	s_sz_bytes = ((req->outcnt + 3) / 4) *
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	((__be16 *)info->in_buffer)[0] = cpu_to_be16(req->outcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	((__be16 *)info->in_buffer)[1] = cpu_to_be16(req->incnt);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	if (setup_sgio_components(pdev, req->in, req->incnt,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	if (setup_sgio_components(pdev, req->out, req->outcnt,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	struct otx_cptvf_request *cpt_req = &req->req;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	union otx_cpt_ctrl_info *ctrl = &req->ctrl;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	gfp = (req->areq->flags & CRYPTO_TFM_REQ_MAY_SLEEP) ? GFP_KERNEL :
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	cpt_req->dlen = info->dlen;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pentry->callback = req->callback;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pentry->areq = req->areq;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	iq_cmd.cmd.s.opcode = cpu_to_be16(cpt_req->opcode.flags);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	iq_cmd.cmd.s.param1 = cpu_to_be16(cpt_req->param1);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	iq_cmd.cmd.s.param2 = cpu_to_be16(cpt_req->param2);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	iq_cmd.cmd.s.dlen   = cpu_to_be16(cpt_req->dlen);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	pr_debug("Dptr hexdump (%d bytes)\n", cpt_req->dlen);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			     cpt_req->dlen, false);
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:	if ((cptvf->vftype == OTX_CPT_SE_TYPES) && (!req->ctrl.s.se_req)) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:		   (req->ctrl.s.se_req)) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.c:			if (req->is_trunc_hmac &&
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	req = container_of(cpt_req->areq, struct aead_request, base);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		if (cpt_req->req_type == OTX_CPT_AEAD_ENC_DEC_NULL_REQ &&
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		    !cpt_req->is_enc)
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		areq->complete(areq, status);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		start = sreq->cryptlen - ivsize;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:			scatterwalk_map_and_copy(sreq->iv, sreq->dst, start,
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:			if (sreq->src != sreq->dst) {
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:				scatterwalk_map_and_copy(sreq->iv, sreq->src,
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:				memcpy(sreq->iv, req_info->iv_out, ivsize);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		areq->complete(areq, status);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	u32 start = req->cryptlen - ivsize;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		    req->src == req->dst) {
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:			scatterwalk_map_and_copy(req_info->iv_out, req->src,
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	req_info->req.param1 = req->cryptlen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	memcpy(fctx->enc.encr_iv, req->iv, crypto_skcipher_ivsize(stfm));
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	update_input_data(req_info, req->src, req->cryptlen, &argcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	update_output_data(req_info, req->dst, 0, req->cryptlen, &argcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	if (req->cryptlen > OTX_CPT_MAX_REQ_SIZE)
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	req_info->areq = &req->base;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	rctx->ctrl_word.e.enc_data_offset = req->assoclen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		memcpy(fctx->enc.encr_iv, req->iv, crypto_aead_ivsize(tfm));
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		rctx->ctrl_word.e.iv_offset = req->assoclen - AES_GCM_IV_OFFSET;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		req_info->req.param1 = req->cryptlen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		req_info->req.param2 = req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		req_info->req.param1 = req->cryptlen - mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		req_info->req.param2 = req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	u32 inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	update_input_data(req_info, req->src, inputlen, &argcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		outputlen = req->cryptlen +  req->assoclen + mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		outputlen = req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	update_output_data(req_info, req->dst, 0, outputlen, &argcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	update_input_data(req_info, req->src, inputlen, &argcnt);
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	if (req->src != req->dst) {
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		ptr = kmalloc(inputlen, (req_info->areq->flags &
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		status = sg_copy_to_buffer(req->src, sg_nents(req->src), ptr,
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		status = sg_copy_from_buffer(req->dst, sg_nents(req->dst), ptr,
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		dst = req->dst;
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:		status = sg_copy_buffer(req->src, sg_nents(req->src),
drivers/crypto/marvell/octeontx/otx_cptvf_algs.c:	req_info->areq = &req->base;
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:		for (i = 0; i < req->outcnt; i++) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:			if (req->out[i].dma_addr)
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:						 req->out[i].dma_addr,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:						 req->out[i].size,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:		for (i = 0; i < req->incnt; i++) {
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:			if (req->in[i].dma_addr)
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:						 req->in[i].dma_addr,
drivers/crypto/marvell/octeontx/otx_cptvf_reqmgr.h:						 req->in[i].size,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	req = container_of(cpt_req->areq, struct aead_request, base);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:			if (cpt_req->req_type ==
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:			    !cpt_req->is_enc)
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		areq->complete(areq, status);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		start = sreq->cryptlen - ivsize;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:			scatterwalk_map_and_copy(sreq->iv, sreq->dst, start,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:			if (sreq->src != sreq->dst) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:				scatterwalk_map_and_copy(sreq->iv, sreq->src,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:				memcpy(sreq->iv, req_info->iv_out, ivsize);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		areq->complete(areq, status);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	u32 start = req->cryptlen - ivsize;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		    req->src == req->dst) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:			scatterwalk_map_and_copy(req_info->iv_out, req->src,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	req_info->req.param1 = req->cryptlen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	memcpy(fctx->enc.encr_iv, req->iv, crypto_skcipher_ivsize(stfm));
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	update_input_data(req_info, req->src, req->cryptlen, &argcnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	update_output_data(req_info, req->dst, 0, req->cryptlen, &argcnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:					      req->base.flags,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:					      req->base.complete,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:					      req->base.data);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		skcipher_request_set_crypt(&rctx->sk_fbk_req, req->src,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	if (req->cryptlen == 0)
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	if (!IS_ALIGNED(req->cryptlen, ctx->enc_align_len))
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	if (req->cryptlen > OTX2_CPT_MAX_REQ_SIZE)
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	req_info->areq = &req->base;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	rctx->ctrl_word.e.enc_data_offset = req->assoclen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		if (req->assoclen > 248 || !IS_ALIGNED(req->assoclen, 8))
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		memcpy(fctx->enc.encr_iv, req->iv, crypto_aead_ivsize(tfm));
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		if (crypto_ipsec_check_assoclen(req->assoclen))
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		rctx->ctrl_word.e.iv_offset = req->assoclen - AES_GCM_IV_OFFSET;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		req_info->req.param1 = req->cryptlen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		req_info->req.param2 = req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		req_info->req.param1 = req->cryptlen - mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		req_info->req.param2 = req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	u32 inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	update_input_data(req_info, req->src, inputlen, &argcnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		outputlen = req->cryptlen +  req->assoclen + mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		outputlen = req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	update_output_data(req_info, req->dst, 0, outputlen, &argcnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	update_input_data(req_info, req->src, inputlen, &argcnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		inputlen =  req->cryptlen + req->assoclen - mac_len;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	if (req->src != req->dst) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		ptr = kmalloc(inputlen, (req_info->areq->flags &
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		status = sg_copy_to_buffer(req->src, sg_nents(req->src), ptr,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		status = sg_copy_from_buffer(req->dst, sg_nents(req->dst), ptr,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		dst = req->dst;
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		status = sg_copy_buffer(req->src, sg_nents(req->src),
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		aead_request_set_callback(&rctx->fbk_req, req->base.flags,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:					  req->base.complete, req->base.data);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:		aead_request_set_crypt(&rctx->fbk_req, req->src,
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:				       req->dst, req->cryptlen, req->iv);
drivers/crypto/marvell/octeontx2/otx2_cptvf_algs.c:	req_info->areq = &req->base;
drivers/crypto/marvell/octeontx2/otx2_cptpf_main.c:	req->sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cptpf_main.c:	req->id = MBOX_MSG_VF_FLR;
drivers/crypto/marvell/octeontx2/otx2_cptpf_main.c:	req->pcifunc &= RVU_PFVF_FUNC_MASK;
drivers/crypto/marvell/octeontx2/otx2_cptpf_main.c:	req->pcifunc |= (vf + 1) & RVU_PFVF_FUNC_MASK;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->id = MBOX_MSG_READY;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->pcifunc = 0;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.id = MBOX_MSG_ATTACH_RESOURCES;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.pcifunc = 0;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->cptlfs = lfs->lfs_num;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.id = MBOX_MSG_DETACH_RESOURCES;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->hdr.pcifunc = 0;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->id = MBOX_MSG_MSIX_OFFSET;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cpt_mbox_common.c:	req->pcifunc = 0;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->hdr.id = MBOX_MSG_GET_ENG_GRP_NUM;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->hdr.sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->hdr.pcifunc = OTX2_CPT_RVU_PFFUNC(cptvf->vf_id, 0);
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->eng_type = eng_type;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->id = MBOX_MSG_GET_KVF_LIMITS;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->sig = OTX2_MBOX_REQ_SIG;
drivers/crypto/marvell/octeontx2/otx2_cptvf_mbox.c:	req->pcifunc = OTX2_CPT_RVU_PFFUNC(cptvf->vf_id, 0);
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	msg->id = req->id;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	msg->pcifunc = req->pcifunc;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	msg->sig = req->sig;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	msg->ver = req->ver;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	rsp->hdr.pcifunc = req->pcifunc;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	rsp->hdr.pcifunc = req->pcifunc;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	rsp->eng_type = grp_req->eng_type;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:						grp_req->eng_type);
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	rsp->hdr.pcifunc = req->pcifunc;
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	if (req->sig != OTX2_MBOX_REQ_SIG)
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	switch (req->id) {
drivers/crypto/marvell/octeontx2/otx2_cptpf_mbox.c:	otx2_reply_invalid_msg(&cptpf->vfpf_mbox, vf->vf_id, 0, req->id);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pr_debug("Gather list size %d\n", req->in_cnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	for (i = 0; i < req->in_cnt; i++) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			 req->in[i].size, req->in[i].vptr,
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			 (void *) req->in[i].dma_addr);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			 req->in[i].size);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:				     req->in[i].vptr, req->in[i].size, false);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pr_debug("Scatter list size %d\n", req->out_cnt);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	for (i = 0; i < req->out_cnt; i++) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			 req->out[i].size, req->out[i].vptr,
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			 (void *) req->out[i].dma_addr);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:		pr_debug("Buffer hexdump (%d bytes)\n", req->out[i].size);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:				     req->out[i].vptr, req->out[i].size, false);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	if (unlikely(req->in_cnt > OTX2_CPT_MAX_SG_IN_CNT ||
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:		     req->out_cnt > OTX2_CPT_MAX_SG_OUT_CNT)) {
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	g_sz_bytes = ((req->in_cnt + 3) / 4) *
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	s_sz_bytes = ((req->out_cnt + 3) / 4) *
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	((u16 *)info->in_buffer)[0] = req->out_cnt;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	((u16 *)info->in_buffer)[1] = req->in_cnt;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	if (setup_sgio_components(pdev, req->in, req->in_cnt,
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	if (setup_sgio_components(pdev, req->out, req->out_cnt,
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	struct otx2_cptvf_request *cpt_req = &req->req;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	union otx2_cpt_ctrl_info *ctrl = &req->ctrl;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	gfp = (req->areq->flags & CRYPTO_TFM_REQ_MAY_SLEEP) ? GFP_KERNEL :
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	cpt_req->dlen = info->dlen;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pentry->callback = req->callback;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pentry->areq = req->areq;
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	iq_cmd.cmd.s.opcode = cpu_to_be16(cpt_req->opcode.flags);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	iq_cmd.cmd.s.param1 = cpu_to_be16(cpt_req->param1);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	iq_cmd.cmd.s.param2 = cpu_to_be16(cpt_req->param2);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	iq_cmd.cmd.s.dlen   = cpu_to_be16(cpt_req->dlen);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:	pr_debug("Dptr hexdump (%d bytes)\n", cpt_req->dlen);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			     cpt_req->dlen, false);
drivers/crypto/marvell/octeontx2/otx2_cptvf_reqmgr.c:			if (info->req->is_trunc_hmac &&
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:		for (i = 0; i < req->out_cnt; i++) {
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:			if (req->out[i].dma_addr)
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:						 req->out[i].dma_addr,
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:						 req->out[i].size,
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:		for (i = 0; i < req->in_cnt; i++) {
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:			if (req->in[i].dma_addr)
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:						 req->in[i].dma_addr,
drivers/crypto/marvell/octeontx2/otx2_cpt_reqmgr.h:						 req->in[i].size,
drivers/crypto/marvell/cesa/cesa.h:	list_add_tail(&req->list, &engine->complete_queue);
drivers/crypto/marvell/cesa/cesa.h:		list_del(&req->list);
drivers/crypto/marvell/cesa/cesa.h:	return req->chain.first ? CESA_DMA_REQ : CESA_STD_REQ;
drivers/crypto/marvell/cesa/tdma.c:	struct mv_cesa_engine *engine = dreq->engine;
drivers/crypto/marvell/cesa/tdma.c:	writel_relaxed(dreq->chain.first->cur_dma,
drivers/crypto/marvell/cesa/tdma.c:	for (tdma = dreq->chain.first; tdma;) {
drivers/crypto/marvell/cesa/tdma.c:	dreq->chain.first = NULL;
drivers/crypto/marvell/cesa/tdma.c:	dreq->chain.last = NULL;
drivers/crypto/marvell/cesa/tdma.c:	for (tdma = dreq->chain.first; tdma; tdma = tdma->next) {
drivers/crypto/marvell/cesa/tdma.c:		engine->chain.first = dreq->chain.first;
drivers/crypto/marvell/cesa/tdma.c:		engine->chain.last  = dreq->chain.last;
drivers/crypto/marvell/cesa/tdma.c:		last->next = dreq->chain.first;
drivers/crypto/marvell/cesa/tdma.c:		engine->chain.last = dreq->chain.last;
drivers/crypto/marvell/cesa/tdma.c:		    !(dreq->chain.first->flags & CESA_TDMA_SET_STATE))
drivers/crypto/marvell/cesa/tdma.c:			last->next_dma = cpu_to_le32(dreq->chain.first->cur_dma);
drivers/crypto/marvell/cesa/tdma.c:			ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_req_dma_iter_init(&iter->base, req->cryptlen);
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_sg_dma_iter_init(&iter->src, req->src, DMA_TO_DEVICE);
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_sg_dma_iter_init(&iter->dst, req->dst, DMA_FROM_DEVICE);
drivers/crypto/marvell/cesa/cipher.c:	if (req->dst != req->src) {
drivers/crypto/marvell/cesa/cipher.c:		dma_unmap_sg(cesa_dev->dev, req->dst, creq->dst_nents,
drivers/crypto/marvell/cesa/cipher.c:		dma_unmap_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:		dma_unmap_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_dma_cleanup(&creq->base);
drivers/crypto/marvell/cesa/cipher.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_skcipher_std_req *sreq = &creq->std;
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_engine *engine = creq->base.engine;
drivers/crypto/marvell/cesa/cipher.c:	size_t  len = min_t(size_t, req->cryptlen - sreq->offset,
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_adjust_op(engine, &sreq->op);
drivers/crypto/marvell/cesa/cipher.c:		memcpy(engine->sram_pool, &sreq->op, sizeof(sreq->op));
drivers/crypto/marvell/cesa/cipher.c:		memcpy_toio(engine->sram, &sreq->op, sizeof(sreq->op));
drivers/crypto/marvell/cesa/cipher.c:	len = mv_cesa_sg_copy_to_sram(engine, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:				      sreq->offset);
drivers/crypto/marvell/cesa/cipher.c:	sreq->size = len;
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_set_crypt_op_len(&sreq->op, len);
drivers/crypto/marvell/cesa/cipher.c:	if (!sreq->skip_ctx) {
drivers/crypto/marvell/cesa/cipher.c:			memcpy(engine->sram_pool, &sreq->op, sizeof(sreq->op));
drivers/crypto/marvell/cesa/cipher.c:			memcpy_toio(engine->sram, &sreq->op, sizeof(sreq->op));
drivers/crypto/marvell/cesa/cipher.c:		sreq->skip_ctx = true;
drivers/crypto/marvell/cesa/cipher.c:		memcpy(engine->sram_pool, &sreq->op, sizeof(sreq->op.desc));
drivers/crypto/marvell/cesa/cipher.c:		memcpy_toio(engine->sram, &sreq->op, sizeof(sreq->op.desc));
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_skcipher_std_req *sreq = &creq->std;
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_engine *engine = creq->base.engine;
drivers/crypto/marvell/cesa/cipher.c:	len = mv_cesa_sg_copy_from_sram(engine, req->dst, creq->dst_nents,
drivers/crypto/marvell/cesa/cipher.c:					CESA_SA_DATA_SRAM_OFFSET, sreq->size,
drivers/crypto/marvell/cesa/cipher.c:					sreq->offset);
drivers/crypto/marvell/cesa/cipher.c:	sreq->offset += len;
drivers/crypto/marvell/cesa/cipher.c:	if (sreq->offset < req->cryptlen)
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/cipher.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/cipher.c:		mv_cesa_dma_step(&creq->base);
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_dma_prepare(basereq, basereq->engine);
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_skcipher_std_req *sreq = &creq->std;
drivers/crypto/marvell/cesa/cipher.c:	sreq->size = 0;
drivers/crypto/marvell/cesa/cipher.c:	sreq->offset = 0;
drivers/crypto/marvell/cesa/cipher.c:	creq->base.engine = engine;
drivers/crypto/marvell/cesa/cipher.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_engine *engine = creq->base.engine;
drivers/crypto/marvell/cesa/cipher.c:	atomic_sub(skreq->cryptlen, &engine->load);
drivers/crypto/marvell/cesa/cipher.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ) {
drivers/crypto/marvell/cesa/cipher.c:		basereq = &creq->base;
drivers/crypto/marvell/cesa/cipher.c:		memcpy(skreq->iv, basereq->chain.last->op->ctx.skcipher.iv,
drivers/crypto/marvell/cesa/cipher.c:		memcpy(skreq->iv,
drivers/crypto/marvell/cesa/cipher.c:		memcpy_fromio(skreq->iv,
drivers/crypto/marvell/cesa/cipher.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/cipher.c:	basereq->chain.first = NULL;
drivers/crypto/marvell/cesa/cipher.c:	basereq->chain.last = NULL;
drivers/crypto/marvell/cesa/cipher.c:	if (req->src != req->dst) {
drivers/crypto/marvell/cesa/cipher.c:		ret = dma_map_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:		ret = dma_map_sg(cesa_dev->dev, req->dst, creq->dst_nents,
drivers/crypto/marvell/cesa/cipher.c:		ret = dma_map_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_tdma_desc_iter_init(&basereq->chain);
drivers/crypto/marvell/cesa/cipher.c:		op = mv_cesa_dma_add_op(&basereq->chain, op_templ, skip_ctx,
drivers/crypto/marvell/cesa/cipher.c:		ret = mv_cesa_dma_add_op_transfers(&basereq->chain, &iter.base,
drivers/crypto/marvell/cesa/cipher.c:		ret = mv_cesa_dma_add_dummy_launch(&basereq->chain, flags);
drivers/crypto/marvell/cesa/cipher.c:		ret = mv_cesa_dma_add_op_transfers(&basereq->chain, &iter.base,
drivers/crypto/marvell/cesa/cipher.c:	ret = mv_cesa_dma_add_result_op(&basereq->chain,
drivers/crypto/marvell/cesa/cipher.c:	basereq->chain.last->flags |= CESA_TDMA_END_OF_REQ;
drivers/crypto/marvell/cesa/cipher.c:	if (req->dst != req->src)
drivers/crypto/marvell/cesa/cipher.c:		dma_unmap_sg(cesa_dev->dev, req->dst, creq->dst_nents,
drivers/crypto/marvell/cesa/cipher.c:	dma_unmap_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/cipher.c:		     req->dst != req->src ? DMA_TO_DEVICE : DMA_BIDIRECTIONAL);
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_skcipher_std_req *sreq = &creq->std;
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/cipher.c:	sreq->op = *op_templ;
drivers/crypto/marvell/cesa/cipher.c:	sreq->skip_ctx = false;
drivers/crypto/marvell/cesa/cipher.c:	basereq->chain.first = NULL;
drivers/crypto/marvell/cesa/cipher.c:	basereq->chain.last = NULL;
drivers/crypto/marvell/cesa/cipher.c:	if (!IS_ALIGNED(req->cryptlen, blksize))
drivers/crypto/marvell/cesa/cipher.c:	creq->src_nents = sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/marvell/cesa/cipher.c:	if (creq->src_nents < 0) {
drivers/crypto/marvell/cesa/cipher.c:		return creq->src_nents;
drivers/crypto/marvell/cesa/cipher.c:	creq->dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/marvell/cesa/cipher.c:	if (creq->dst_nents < 0) {
drivers/crypto/marvell/cesa/cipher.c:		return creq->dst_nents;
drivers/crypto/marvell/cesa/cipher.c:	engine = mv_cesa_select_engine(req->cryptlen);
drivers/crypto/marvell/cesa/cipher.c:	mv_cesa_skcipher_prepare(&req->base, engine);
drivers/crypto/marvell/cesa/cipher.c:	ret = mv_cesa_queue_req(&req->base, &creq->base);
drivers/crypto/marvell/cesa/cipher.c:	if (mv_cesa_req_needs_cleanup(&req->base, ret))
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_des_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/cipher.c:	memcpy(tmpl->ctx.skcipher.iv, req->iv, DES_BLOCK_SIZE);
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_des3_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/cipher.c:	memcpy(tmpl->ctx.skcipher.iv, req->iv, DES3_EDE_BLOCK_SIZE);
drivers/crypto/marvell/cesa/cipher.c:	struct mv_cesa_aes_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/cipher.c:	memcpy(tmpl->ctx.skcipher.iv, req->iv, AES_BLOCK_SIZE);
drivers/crypto/marvell/cesa/hash.c:	unsigned int len = req->nbytes + creq->cache_ptr;
drivers/crypto/marvell/cesa/hash.c:	if (!creq->last_req)
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_sg_dma_iter_init(&iter->src, req->src, DMA_TO_DEVICE);
drivers/crypto/marvell/cesa/hash.c:	iter->src.op_offset = creq->cache_ptr;
drivers/crypto/marvell/cesa/hash.c:	req->cache = dma_pool_alloc(cesa_dev->dma->cache_pool, flags,
drivers/crypto/marvell/cesa/hash.c:				    &req->cache_dma);
drivers/crypto/marvell/cesa/hash.c:	if (!req->cache)
drivers/crypto/marvell/cesa/hash.c:	if (!req->cache)
drivers/crypto/marvell/cesa/hash.c:	dma_pool_free(cesa_dev->dma->cache_pool, req->cache,
drivers/crypto/marvell/cesa/hash.c:		      req->cache_dma);
drivers/crypto/marvell/cesa/hash.c:	if (req->padding)
drivers/crypto/marvell/cesa/hash.c:	req->padding = dma_pool_alloc(cesa_dev->dma->padding_pool, flags,
drivers/crypto/marvell/cesa/hash.c:				      &req->padding_dma);
drivers/crypto/marvell/cesa/hash.c:	if (!req->padding)
drivers/crypto/marvell/cesa/hash.c:	if (!req->padding)
drivers/crypto/marvell/cesa/hash.c:	dma_pool_free(cesa_dev->dma->padding_pool, req->padding,
drivers/crypto/marvell/cesa/hash.c:		      req->padding_dma);
drivers/crypto/marvell/cesa/hash.c:	req->padding = NULL;
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_ahash_dma_free_padding(&creq->req.dma);
drivers/crypto/marvell/cesa/hash.c:	dma_unmap_sg(cesa_dev->dev, req->src, creq->src_nents, DMA_TO_DEVICE);
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_ahash_dma_free_cache(&creq->req.dma);
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_dma_cleanup(&creq->base);
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/hash.c:	index = creq->len & CESA_HASH_BLOCK_SIZE_MSK;
drivers/crypto/marvell/cesa/hash.c:	if (creq->algo_le) {
drivers/crypto/marvell/cesa/hash.c:		__le64 bits = cpu_to_le64(creq->len << 3);
drivers/crypto/marvell/cesa/hash.c:		__be64 bits = cpu_to_be64(creq->len << 3);
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_std_req *sreq = &creq->req.std;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_engine *engine = creq->base.engine;
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_adjust_op(engine, &creq->op_tmpl);
drivers/crypto/marvell/cesa/hash.c:		memcpy(engine->sram_pool, &creq->op_tmpl,
drivers/crypto/marvell/cesa/hash.c:		       sizeof(creq->op_tmpl));
drivers/crypto/marvell/cesa/hash.c:		memcpy_toio(engine->sram, &creq->op_tmpl,
drivers/crypto/marvell/cesa/hash.c:			    sizeof(creq->op_tmpl));
drivers/crypto/marvell/cesa/hash.c:	if (!sreq->offset) {
drivers/crypto/marvell/cesa/hash.c:			writel_relaxed(creq->state[i],
drivers/crypto/marvell/cesa/hash.c:	if (creq->cache_ptr) {
drivers/crypto/marvell/cesa/hash.c:			       creq->cache, creq->cache_ptr);
drivers/crypto/marvell/cesa/hash.c:				    creq->cache, creq->cache_ptr);
drivers/crypto/marvell/cesa/hash.c:	len = min_t(size_t, req->nbytes + creq->cache_ptr - sreq->offset,
drivers/crypto/marvell/cesa/hash.c:	if (!creq->last_req) {
drivers/crypto/marvell/cesa/hash.c:	if (len - creq->cache_ptr)
drivers/crypto/marvell/cesa/hash.c:		sreq->offset += mv_cesa_sg_copy_to_sram(
drivers/crypto/marvell/cesa/hash.c:			engine, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/hash.c:			CESA_SA_DATA_SRAM_OFFSET + creq->cache_ptr,
drivers/crypto/marvell/cesa/hash.c:			len - creq->cache_ptr, sreq->offset);
drivers/crypto/marvell/cesa/hash.c:	op = &creq->op_tmpl;
drivers/crypto/marvell/cesa/hash.c:	if (creq->last_req && sreq->offset == req->nbytes &&
drivers/crypto/marvell/cesa/hash.c:	    creq->len <= CESA_SA_DESC_MAC_SRC_TOTAL_LEN_MAX) {
drivers/crypto/marvell/cesa/hash.c:		    creq->len <= CESA_SA_DESC_MAC_SRC_TOTAL_LEN_MAX) {
drivers/crypto/marvell/cesa/hash.c:			mv_cesa_set_mac_op_total_len(op, creq->len);
drivers/crypto/marvell/cesa/hash.c:					memcpy(creq->cache,
drivers/crypto/marvell/cesa/hash.c:					memcpy_fromio(creq->cache,
drivers/crypto/marvell/cesa/hash.c:				i = mv_cesa_ahash_pad_req(creq, creq->cache);
drivers/crypto/marvell/cesa/hash.c:					       creq->cache, i);
drivers/crypto/marvell/cesa/hash.c:						    creq->cache, i);
drivers/crypto/marvell/cesa/hash.c:	creq->cache_ptr = new_cache_ptr;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_std_req *sreq = &creq->req.std;
drivers/crypto/marvell/cesa/hash.c:	if (sreq->offset < (req->nbytes - creq->cache_ptr))
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_dma_prepare(basereq, basereq->engine);
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_std_req *sreq = &creq->req.std;
drivers/crypto/marvell/cesa/hash.c:	sreq->offset = 0;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_req *base = &creq->base;
drivers/crypto/marvell/cesa/hash.c:		for (i = 0; i < ARRAY_SIZE(creq->state); i++)
drivers/crypto/marvell/cesa/hash.c:			writel_relaxed(creq->state[i], engine->regs +
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/hash.c:		return mv_cesa_dma_process(&creq->base, status);
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_engine *engine = creq->base.engine;
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ &&
drivers/crypto/marvell/cesa/hash.c:	    (creq->base.chain.last->flags & CESA_TDMA_TYPE_MSK) ==
drivers/crypto/marvell/cesa/hash.c:		data = creq->base.chain.last->op->ctx.hash.hash;
drivers/crypto/marvell/cesa/hash.c:			creq->state[i] = le32_to_cpu(data[i]);
drivers/crypto/marvell/cesa/hash.c:		memcpy(ahashreq->result, data, digsize);
drivers/crypto/marvell/cesa/hash.c:			creq->state[i] = readl_relaxed(engine->regs +
drivers/crypto/marvell/cesa/hash.c:		if (creq->last_req) {
drivers/crypto/marvell/cesa/hash.c:			if (creq->algo_le) {
drivers/crypto/marvell/cesa/hash.c:				__le32 *result = (void *)ahashreq->result;
drivers/crypto/marvell/cesa/hash.c:					result[i] = cpu_to_le32(creq->state[i]);
drivers/crypto/marvell/cesa/hash.c:				__be32 *result = (void *)ahashreq->result;
drivers/crypto/marvell/cesa/hash.c:					result[i] = cpu_to_be32(creq->state[i]);
drivers/crypto/marvell/cesa/hash.c:	atomic_sub(ahashreq->nbytes, &engine->load);
drivers/crypto/marvell/cesa/hash.c:	creq->base.engine = engine;
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_get_type(&creq->base) == CESA_DMA_REQ)
drivers/crypto/marvell/cesa/hash.c:	if (creq->last_req)
drivers/crypto/marvell/cesa/hash.c:	if (creq->cache_ptr)
drivers/crypto/marvell/cesa/hash.c:		sg_pcopy_to_buffer(ahashreq->src, creq->src_nents,
drivers/crypto/marvell/cesa/hash.c:				   creq->cache,
drivers/crypto/marvell/cesa/hash.c:				   creq->cache_ptr,
drivers/crypto/marvell/cesa/hash.c:				   ahashreq->nbytes - creq->cache_ptr);
drivers/crypto/marvell/cesa/hash.c:	creq->op_tmpl = *tmpl;
drivers/crypto/marvell/cesa/hash.c:	creq->len = 0;
drivers/crypto/marvell/cesa/hash.c:	creq->algo_le = algo_le;
drivers/crypto/marvell/cesa/hash.c:	if (creq->cache_ptr + req->nbytes < CESA_MAX_HASH_BLOCK_SIZE &&
drivers/crypto/marvell/cesa/hash.c:	    !creq->last_req) {
drivers/crypto/marvell/cesa/hash.c:		if (!req->nbytes)
drivers/crypto/marvell/cesa/hash.c:		sg_pcopy_to_buffer(req->src, creq->src_nents,
drivers/crypto/marvell/cesa/hash.c:				   creq->cache + creq->cache_ptr,
drivers/crypto/marvell/cesa/hash.c:				   req->nbytes, 0);
drivers/crypto/marvell/cesa/hash.c:		creq->cache_ptr += req->nbytes;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_dma_req *ahashdreq = &creq->req.dma;
drivers/crypto/marvell/cesa/hash.c:	if (!creq->cache_ptr)
drivers/crypto/marvell/cesa/hash.c:	memcpy(ahashdreq->cache, creq->cache, creq->cache_ptr);
drivers/crypto/marvell/cesa/hash.c:					     ahashdreq->cache_dma,
drivers/crypto/marvell/cesa/hash.c:					     creq->cache_ptr,
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_dma_req *ahashdreq = &creq->req.dma;
drivers/crypto/marvell/cesa/hash.c:	if (creq->len <= CESA_SA_DESC_MAC_SRC_TOTAL_LEN_MAX && frag_len) {
drivers/crypto/marvell/cesa/hash.c:		op = mv_cesa_dma_add_frag(chain, &creq->op_tmpl, frag_len,
drivers/crypto/marvell/cesa/hash.c:		mv_cesa_set_mac_op_total_len(op, creq->len);
drivers/crypto/marvell/cesa/hash.c:	trailerlen = mv_cesa_ahash_pad_req(creq, ahashdreq->padding);
drivers/crypto/marvell/cesa/hash.c:						ahashdreq->padding_dma,
drivers/crypto/marvell/cesa/hash.c:		op = mv_cesa_dma_add_frag(chain, &creq->op_tmpl, frag_len + len,
drivers/crypto/marvell/cesa/hash.c:					    ahashdreq->padding_dma +
drivers/crypto/marvell/cesa/hash.c:	return mv_cesa_dma_add_frag(chain, &creq->op_tmpl, trailerlen - padoff,
drivers/crypto/marvell/cesa/hash.c:	gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_req *basereq = &creq->base;
drivers/crypto/marvell/cesa/hash.c:	basereq->chain.first = NULL;
drivers/crypto/marvell/cesa/hash.c:	basereq->chain.last = NULL;
drivers/crypto/marvell/cesa/hash.c:	if (!mv_cesa_mac_op_is_first_frag(&creq->op_tmpl))
drivers/crypto/marvell/cesa/hash.c:	if (creq->src_nents) {
drivers/crypto/marvell/cesa/hash.c:		ret = dma_map_sg(cesa_dev->dev, req->src, creq->src_nents,
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_tdma_desc_iter_init(&basereq->chain);
drivers/crypto/marvell/cesa/hash.c:	ret = mv_cesa_ahash_dma_add_cache(&basereq->chain, creq, flags);
drivers/crypto/marvell/cesa/hash.c:			ret = mv_cesa_dma_add_op_transfers(&basereq->chain,
drivers/crypto/marvell/cesa/hash.c:			op = mv_cesa_dma_add_frag(&basereq->chain,
drivers/crypto/marvell/cesa/hash.c:						  &creq->op_tmpl,
drivers/crypto/marvell/cesa/hash.c:	if (creq->last_req)
drivers/crypto/marvell/cesa/hash.c:		op = mv_cesa_ahash_dma_last_req(&basereq->chain, &iter, creq,
drivers/crypto/marvell/cesa/hash.c:		op = mv_cesa_dma_add_frag(&basereq->chain, &creq->op_tmpl,
drivers/crypto/marvell/cesa/hash.c:	type = basereq->chain.last->flags & CESA_TDMA_TYPE_MSK;
drivers/crypto/marvell/cesa/hash.c:		ret = mv_cesa_dma_add_dummy_end(&basereq->chain, flags);
drivers/crypto/marvell/cesa/hash.c:	if (!creq->last_req)
drivers/crypto/marvell/cesa/hash.c:		creq->cache_ptr = req->nbytes + creq->cache_ptr -
drivers/crypto/marvell/cesa/hash.c:		creq->cache_ptr = 0;
drivers/crypto/marvell/cesa/hash.c:	basereq->chain.last->flags |= CESA_TDMA_END_OF_REQ;
drivers/crypto/marvell/cesa/hash.c:		basereq->chain.last->flags |= CESA_TDMA_BREAK_CHAIN;
drivers/crypto/marvell/cesa/hash.c:		basereq->chain.first->flags |= CESA_TDMA_SET_STATE;
drivers/crypto/marvell/cesa/hash.c:	dma_unmap_sg(cesa_dev->dev, req->src, creq->src_nents, DMA_TO_DEVICE);
drivers/crypto/marvell/cesa/hash.c:	creq->src_nents = sg_nents_for_len(req->src, req->nbytes);
drivers/crypto/marvell/cesa/hash.c:	if (creq->src_nents < 0) {
drivers/crypto/marvell/cesa/hash.c:		return creq->src_nents;
drivers/crypto/marvell/cesa/hash.c:	engine = mv_cesa_select_engine(req->nbytes);
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_ahash_prepare(&req->base, engine);
drivers/crypto/marvell/cesa/hash.c:	ret = mv_cesa_queue_req(&req->base, &creq->base);
drivers/crypto/marvell/cesa/hash.c:	if (mv_cesa_req_needs_cleanup(&req->base, ret))
drivers/crypto/marvell/cesa/hash.c:	creq->len += req->nbytes;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_op_ctx *tmpl = &creq->op_tmpl;
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_set_mac_op_total_len(tmpl, creq->len);
drivers/crypto/marvell/cesa/hash.c:	creq->last_req = true;
drivers/crypto/marvell/cesa/hash.c:	req->nbytes = 0;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_op_ctx *tmpl = &creq->op_tmpl;
drivers/crypto/marvell/cesa/hash.c:	creq->len += req->nbytes;
drivers/crypto/marvell/cesa/hash.c:	mv_cesa_set_mac_op_total_len(tmpl, creq->len);
drivers/crypto/marvell/cesa/hash.c:	creq->last_req = true;
drivers/crypto/marvell/cesa/hash.c:	*len = creq->len;
drivers/crypto/marvell/cesa/hash.c:	memcpy(hash, creq->state, digsize);
drivers/crypto/marvell/cesa/hash.c:	memcpy(cache, creq->cache, creq->cache_ptr);
drivers/crypto/marvell/cesa/hash.c:		mv_cesa_update_op_cfg(&creq->op_tmpl,
drivers/crypto/marvell/cesa/hash.c:	creq->len = len;
drivers/crypto/marvell/cesa/hash.c:	memcpy(creq->state, hash, digsize);
drivers/crypto/marvell/cesa/hash.c:	creq->cache_ptr = 0;
drivers/crypto/marvell/cesa/hash.c:	memcpy(creq->cache, cache, cache_ptr);
drivers/crypto/marvell/cesa/hash.c:	creq->cache_ptr = cache_ptr;
drivers/crypto/marvell/cesa/hash.c:	creq->state[0] = MD5_H0;
drivers/crypto/marvell/cesa/hash.c:	creq->state[1] = MD5_H1;
drivers/crypto/marvell/cesa/hash.c:	creq->state[2] = MD5_H2;
drivers/crypto/marvell/cesa/hash.c:	creq->state[3] = MD5_H3;
drivers/crypto/marvell/cesa/hash.c:	creq->state[0] = SHA1_H0;
drivers/crypto/marvell/cesa/hash.c:	creq->state[1] = SHA1_H1;
drivers/crypto/marvell/cesa/hash.c:	creq->state[2] = SHA1_H2;
drivers/crypto/marvell/cesa/hash.c:	creq->state[3] = SHA1_H3;
drivers/crypto/marvell/cesa/hash.c:	creq->state[4] = SHA1_H4;
drivers/crypto/marvell/cesa/hash.c:	creq->state[0] = SHA256_H0;
drivers/crypto/marvell/cesa/hash.c:	creq->state[1] = SHA256_H1;
drivers/crypto/marvell/cesa/hash.c:	creq->state[2] = SHA256_H2;
drivers/crypto/marvell/cesa/hash.c:	creq->state[3] = SHA256_H3;
drivers/crypto/marvell/cesa/hash.c:	creq->state[4] = SHA256_H4;
drivers/crypto/marvell/cesa/hash.c:	creq->state[5] = SHA256_H5;
drivers/crypto/marvell/cesa/hash.c:	creq->state[6] = SHA256_H6;
drivers/crypto/marvell/cesa/hash.c:	creq->state[7] = SHA256_H7;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_ahash_result *result = req->data;
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_hmac_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_hmac_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/hash.c:	struct mv_cesa_hmac_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/marvell/cesa/cesa.c:	ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/marvell/cesa/cesa.c:	ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/marvell/cesa/cesa.c:	req->complete(req, res);
drivers/crypto/marvell/cesa/cesa.c:		ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/marvell/cesa/cesa.c:			ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/marvell/cesa/cesa.c:	struct mv_cesa_engine *engine = creq->engine;
drivers/crypto/talitos.c:	unsigned int cryptlen = areq->cryptlen - (encrypt ? 0 : authsize);
drivers/crypto/talitos.c:	talitos_sg_unmap(dev, edesc, areq->src, areq->dst,
drivers/crypto/talitos.c:			 cryptlen + authsize, areq->assoclen);
drivers/crypto/talitos.c:		sg_pcopy_to_buffer(areq->dst, dst_nents, ctx->iv, ivsize,
drivers/crypto/talitos.c:				   areq->assoclen + cryptlen - ivsize);
drivers/crypto/talitos.c:	unsigned int cryptlen = areq->cryptlen - (encrypt ? 0 : authsize);
drivers/crypto/talitos.c:		sg_copy_to_buffer(areq->src, sg_count, edesc->buf,
drivers/crypto/talitos.c:				  areq->assoclen + cryptlen);
drivers/crypto/talitos.c:		sg_count = dma_map_sg(dev, areq->src, sg_count,
drivers/crypto/talitos.c:				      (areq->src == areq->dst) ?
drivers/crypto/talitos.c:	ret = talitos_sg_map(dev, areq->src, areq->assoclen, edesc,
drivers/crypto/talitos.c:	ret = talitos_sg_map_ext(dev, areq->src, cryptlen, edesc, &desc->ptr[4],
drivers/crypto/talitos.c:				 sg_count, areq->assoclen, tbl_off, elen,
drivers/crypto/talitos.c:	if (areq->src != areq->dst) {
drivers/crypto/talitos.c:			dma_map_sg(dev, areq->dst, sg_count, DMA_FROM_DEVICE);
drivers/crypto/talitos.c:	ret = talitos_sg_map_ext(dev, areq->dst, cryptlen, edesc, &desc->ptr[5],
drivers/crypto/talitos.c:				 sg_count, areq->assoclen, tbl_off, elen,
drivers/crypto/talitos.c:		talitos_sg_map(dev, areq->dst, authsize, edesc, &desc->ptr[6],
drivers/crypto/talitos.c:			       sg_count, areq->assoclen + cryptlen, tbl_off);
drivers/crypto/talitos.c:	unsigned int cryptlen = areq->cryptlen - (encrypt ? 0 : authsize);
drivers/crypto/talitos.c:	return talitos_edesc_alloc(ctx->dev, areq->src, areq->dst,
drivers/crypto/talitos.c:				   iv, areq->assoclen, cryptlen,
drivers/crypto/talitos.c:				   areq->base.flags, encrypt);
drivers/crypto/talitos.c:	edesc = aead_edesc_alloc(req, req->iv, 0, true);
drivers/crypto/talitos.c:	edesc = aead_edesc_alloc(req, req->iv, 1, false);
drivers/crypto/talitos.c:	sg_pcopy_to_buffer(req->src, edesc->src_nents ? : 1, icvdata, authsize,
drivers/crypto/talitos.c:			   req->assoclen + req->cryptlen - authsize);
drivers/crypto/talitos.c:	talitos_sg_unmap(dev, edesc, areq->src, areq->dst, areq->cryptlen, 0);
drivers/crypto/talitos.c:	memcpy(areq->iv, ctx->iv, ivsize);
drivers/crypto/talitos.c:	areq->base.complete(&areq->base, err);
drivers/crypto/talitos.c:	unsigned int cryptlen = areq->cryptlen;
drivers/crypto/talitos.c:		sg_copy_to_buffer(areq->src, sg_count, edesc->buf,
drivers/crypto/talitos.c:		sg_count = dma_map_sg(dev, areq->src, sg_count,
drivers/crypto/talitos.c:				      (areq->src == areq->dst) ?
drivers/crypto/talitos.c:	sg_count = talitos_sg_map_ext(dev, areq->src, cryptlen, edesc, &desc->ptr[3],
drivers/crypto/talitos.c:	if (areq->src != areq->dst) {
drivers/crypto/talitos.c:			dma_map_sg(dev, areq->dst, sg_count, DMA_FROM_DEVICE);
drivers/crypto/talitos.c:	ret = talitos_sg_map(dev, areq->dst, cryptlen, edesc, &desc->ptr[4],
drivers/crypto/talitos.c:	return talitos_edesc_alloc(ctx->dev, areq->src, areq->dst,
drivers/crypto/talitos.c:				   areq->iv, 0, areq->cryptlen, 0, ivsize, 0,
drivers/crypto/talitos.c:				   areq->base.flags, encrypt);
drivers/crypto/talitos.c:	if (!areq->cryptlen)
drivers/crypto/talitos.c:	if (areq->cryptlen % blocksize)
drivers/crypto/talitos.c:	if (!areq->cryptlen)
drivers/crypto/talitos.c:	if (areq->cryptlen % blocksize)
drivers/crypto/talitos.c:		memcpy(areq->result, req_ctx->hw_context,
drivers/crypto/talitos.c:	areq->base.complete(&areq->base, err);
drivers/crypto/talitos.c:				   nbytes, 0, 0, 0, areq->base.flags, false);
drivers/crypto/talitos.c:		nents = sg_nents_for_len(areq->src, nbytes);
drivers/crypto/talitos.c:		sg_copy_to_buffer(areq->src, nents,
drivers/crypto/talitos.c:			sg_chain(req_ctx->bufsl, 2, areq->src);
drivers/crypto/talitos.c:		nents = sg_nents_for_len(areq->src, offset);
drivers/crypto/talitos.c:		sg_copy_to_buffer(areq->src, nents,
drivers/crypto/talitos.c:		req_ctx->psrc = scatterwalk_ffwd(req_ctx->bufsl, areq->src,
drivers/crypto/talitos.c:		req_ctx->psrc = areq->src;
drivers/crypto/talitos.c:		nents = sg_nents_for_len(areq->src, nbytes);
drivers/crypto/talitos.c:		sg_pcopy_to_buffer(areq->src, nents,
drivers/crypto/talitos.c:	return ahash_process_req(areq, areq->nbytes);
drivers/crypto/talitos.c:	return ahash_process_req(areq, areq->nbytes);
drivers/crypto/talitos.c:	return ahash_process_req(areq, areq->nbytes);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	struct scatterlist *src_sg = areq->src;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	struct scatterlist *dst_sg = areq->dst;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	if (areq->cryptlen == 0)
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	skcipher_request_set_callback(&rctx->fallback_req, areq->base.flags,
drivers/crypto/amlogic/amlogic-gxl-cipher.c:				      areq->base.complete, areq->base.data);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	skcipher_request_set_crypt(&rctx->fallback_req, areq->src, areq->dst,
drivers/crypto/amlogic/amlogic-gxl-cipher.c:				   areq->cryptlen, areq->iv);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	struct scatterlist *src_sg = areq->src;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	struct scatterlist *dst_sg = areq->dst;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		crypto_tfm_alg_name(areq->base.tfm),
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		areq->cryptlen,
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	if (areq->iv && ivsize > 0) {
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		if (ivsize > areq->cryptlen) {
drivers/crypto/amlogic/amlogic-gxl-cipher.c:			dev_err(mc->dev, "invalid ivsize=%d vs len=%d\n", ivsize, areq->cryptlen);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		memcpy(bkeyiv + 32, areq->iv, ivsize);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:			offset = areq->cryptlen - ivsize;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:			scatterwalk_map_and_copy(backup_iv, areq->src, offset,
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		nr_sgs = dma_map_sg(mc->dev, areq->src, sg_nents(areq->src),
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		nr_sgs = dma_map_sg(mc->dev, areq->src, sg_nents(areq->src),
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		nr_sgd = dma_map_sg(mc->dev, areq->dst, sg_nents(areq->dst),
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	src_sg = areq->src;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	dst_sg = areq->dst;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	len = areq->cryptlen;
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	if (areq->src == areq->dst) {
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		dma_unmap_sg(mc->dev, areq->src, nr_sgs, DMA_BIDIRECTIONAL);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		dma_unmap_sg(mc->dev, areq->src, nr_sgs, DMA_TO_DEVICE);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:		dma_unmap_sg(mc->dev, areq->dst, nr_sgd, DMA_FROM_DEVICE);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:	if (areq->iv && ivsize > 0) {
drivers/crypto/amlogic/amlogic-gxl-cipher.c:			memcpy(areq->iv, backup_iv, ivsize);
drivers/crypto/amlogic/amlogic-gxl-cipher.c:			scatterwalk_map_and_copy(areq->iv, areq->dst,
drivers/crypto/amlogic/amlogic-gxl-cipher.c:						 areq->cryptlen - ivsize,
drivers/crypto/inside-secure/safexcel_hash.c:	return req->len - req->processed;
drivers/crypto/inside-secure/safexcel_hash.c:	if (unlikely(req->digest == CONTEXT_CONTROL_DIGEST_XCM)) {
drivers/crypto/inside-secure/safexcel_hash.c:		if (req->xcbcmac)
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(ctx->base.ctxr->data, req->state, req->state_sz);
drivers/crypto/inside-secure/safexcel_hash.c:		if (!req->finish && req->xcbcmac)
drivers/crypto/inside-secure/safexcel_hash.c:				CONTEXT_CONTROL_SIZE(req->state_sz /
drivers/crypto/inside-secure/safexcel_hash.c:				CONTEXT_CONTROL_SIZE(req->state_sz /
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (!req->processed) {
drivers/crypto/inside-secure/safexcel_hash.c:		if (req->finish)
drivers/crypto/inside-secure/safexcel_hash.c:			cdesc->control_data.control0 |= req->digest |
drivers/crypto/inside-secure/safexcel_hash.c:			cdesc->control_data.control0 |= req->digest |
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(ctx->base.ctxr->data, req->state, req->state_sz);
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->finish) {
drivers/crypto/inside-secure/safexcel_hash.c:		if ((req->digest == CONTEXT_CONTROL_DIGEST_PRECOMPUTED) ||
drivers/crypto/inside-secure/safexcel_hash.c:		    req->hmac_zlen || (req->processed != req->block_sz)) {
drivers/crypto/inside-secure/safexcel_hash.c:			count = req->processed / EIP197_COUNTER_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:		if ((req->digest == CONTEXT_CONTROL_DIGEST_PRECOMPUTED) ||
drivers/crypto/inside-secure/safexcel_hash.c:		    req->hmac_zlen ||
drivers/crypto/inside-secure/safexcel_hash.c:		    (req->processed != req->block_sz)) {
drivers/crypto/inside-secure/safexcel_hash.c:				CONTEXT_CONTROL_SIZE((req->state_sz >> 2) + 1) |
drivers/crypto/inside-secure/safexcel_hash.c:			if (req->hmac_zlen)
drivers/crypto/inside-secure/safexcel_hash.c:			ctx->base.ctxr->data[req->state_sz >> 2] =
drivers/crypto/inside-secure/safexcel_hash.c:			req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:			req->hmac_zlen = false;
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(ctx->base.ctxr->data + (req->state_sz >> 2),
drivers/crypto/inside-secure/safexcel_hash.c:			       &ctx->base.opad, req->state_sz);
drivers/crypto/inside-secure/safexcel_hash.c:				CONTEXT_CONTROL_SIZE(req->state_sz >> 1) |
drivers/crypto/inside-secure/safexcel_hash.c:			CONTEXT_CONTROL_SIZE(req->state_sz >> 2) |
drivers/crypto/inside-secure/safexcel_hash.c:	if (sreq->nents) {
drivers/crypto/inside-secure/safexcel_hash.c:		dma_unmap_sg(priv->dev, areq->src, sreq->nents, DMA_TO_DEVICE);
drivers/crypto/inside-secure/safexcel_hash.c:		sreq->nents = 0;
drivers/crypto/inside-secure/safexcel_hash.c:	if (sreq->result_dma) {
drivers/crypto/inside-secure/safexcel_hash.c:		dma_unmap_single(priv->dev, sreq->result_dma, sreq->digest_sz,
drivers/crypto/inside-secure/safexcel_hash.c:		sreq->result_dma = 0;
drivers/crypto/inside-secure/safexcel_hash.c:	if (sreq->cache_dma) {
drivers/crypto/inside-secure/safexcel_hash.c:		dma_unmap_single(priv->dev, sreq->cache_dma, sreq->cache_sz,
drivers/crypto/inside-secure/safexcel_hash.c:		sreq->cache_dma = 0;
drivers/crypto/inside-secure/safexcel_hash.c:		sreq->cache_sz = 0;
drivers/crypto/inside-secure/safexcel_hash.c:	if (sreq->finish) {
drivers/crypto/inside-secure/safexcel_hash.c:		if (sreq->hmac &&
drivers/crypto/inside-secure/safexcel_hash.c:		    (sreq->digest != CONTEXT_CONTROL_DIGEST_HMAC)) {
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(sreq->cache, sreq->state,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(sreq->state, &ctx->base.opad, sreq->digest_sz);
drivers/crypto/inside-secure/safexcel_hash.c:			sreq->len = sreq->block_sz +
drivers/crypto/inside-secure/safexcel_hash.c:			sreq->processed = sreq->block_sz;
drivers/crypto/inside-secure/safexcel_hash.c:			sreq->hmac = 0;
drivers/crypto/inside-secure/safexcel_hash.c:			areq->nbytes = 0;
drivers/crypto/inside-secure/safexcel_hash.c:		if (unlikely(sreq->digest == CONTEXT_CONTROL_DIGEST_XCM &&
drivers/crypto/inside-secure/safexcel_hash.c:			*(__le32 *)areq->result = ~sreq->state[0];
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sreq->state,
drivers/crypto/inside-secure/safexcel_hash.c:		memcpy(sreq->cache, sreq->cache_next, cache_len);
drivers/crypto/inside-secure/safexcel_hash.c:		cache_len = queued - areq->nbytes;
drivers/crypto/inside-secure/safexcel_hash.c:	if (!req->finish && !req->last_req) {
drivers/crypto/inside-secure/safexcel_hash.c:		sg_pcopy_to_buffer(areq->src, sg_nents(areq->src),
drivers/crypto/inside-secure/safexcel_hash.c:				   req->cache_next, extra,
drivers/crypto/inside-secure/safexcel_hash.c:				   areq->nbytes - extra);
drivers/crypto/inside-secure/safexcel_hash.c:	if (unlikely(req->xcbcmac && req->processed > AES_BLOCK_SIZE)) {
drivers/crypto/inside-secure/safexcel_hash.c:				sg_pcopy_to_buffer(areq->src,
drivers/crypto/inside-secure/safexcel_hash.c:					sg_nents(areq->src),
drivers/crypto/inside-secure/safexcel_hash.c:					req->cache + cache_len,
drivers/crypto/inside-secure/safexcel_hash.c:			memset(req->cache + cache_len + skip, 0, extra);
drivers/crypto/inside-secure/safexcel_hash.c:				req->cache[cache_len + skip] = 0x80;
drivers/crypto/inside-secure/safexcel_hash.c:					u32 *cache = (void *)req->cache;
drivers/crypto/inside-secure/safexcel_hash.c:		crypto_xor(req->cache, (const u8 *)req->state, AES_BLOCK_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:		req->cache_dma = dma_map_single(priv->dev, req->cache,
drivers/crypto/inside-secure/safexcel_hash.c:		if (dma_mapping_error(priv->dev, req->cache_dma))
drivers/crypto/inside-secure/safexcel_hash.c:		req->cache_sz = cache_len;
drivers/crypto/inside-secure/safexcel_hash.c:						 req->cache_dma, cache_len,
drivers/crypto/inside-secure/safexcel_hash.c:	req->nents = dma_map_sg(priv->dev, areq->src,
drivers/crypto/inside-secure/safexcel_hash.c:				sg_nents_for_len(areq->src,
drivers/crypto/inside-secure/safexcel_hash.c:						 areq->nbytes),
drivers/crypto/inside-secure/safexcel_hash.c:	if (!req->nents) {
drivers/crypto/inside-secure/safexcel_hash.c:	for_each_sg(areq->src, sg, req->nents, i) {
drivers/crypto/inside-secure/safexcel_hash.c:	safexcel_hash_token(first_cdesc, len, req->digest_sz, ctx->cbcmac);
drivers/crypto/inside-secure/safexcel_hash.c:	req->result_dma = dma_map_single(priv->dev, req->state, req->digest_sz,
drivers/crypto/inside-secure/safexcel_hash.c:	if (dma_mapping_error(priv->dev, req->result_dma)) {
drivers/crypto/inside-secure/safexcel_hash.c:	rdesc = safexcel_add_rdesc(priv, ring, 1, 1, req->result_dma,
drivers/crypto/inside-secure/safexcel_hash.c:				   req->digest_sz);
drivers/crypto/inside-secure/safexcel_hash.c:	safexcel_rdr_req_set(priv, ring, rdesc, &areq->base);
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed += len - extra;
drivers/crypto/inside-secure/safexcel_hash.c:	dma_unmap_single(priv->dev, req->result_dma, req->digest_sz,
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nents) {
drivers/crypto/inside-secure/safexcel_hash.c:		dma_unmap_sg(priv->dev, areq->src, req->nents, DMA_TO_DEVICE);
drivers/crypto/inside-secure/safexcel_hash.c:		req->nents = 0;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->cache_dma) {
drivers/crypto/inside-secure/safexcel_hash.c:		dma_unmap_single(priv->dev, req->cache_dma, req->cache_sz,
drivers/crypto/inside-secure/safexcel_hash.c:		req->cache_dma = 0;
drivers/crypto/inside-secure/safexcel_hash.c:		req->cache_sz = 0;
drivers/crypto/inside-secure/safexcel_hash.c:	BUG_ON(!(priv->flags & EIP197_TRC_CACHE) && req->needs_inv);
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->needs_inv) {
drivers/crypto/inside-secure/safexcel_hash.c:		req->needs_inv = false;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->needs_inv)
drivers/crypto/inside-secure/safexcel_hash.c:	ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/inside-secure/safexcel_hash.c:	crypto_enqueue_request(&priv->ring[ring].queue, &req->base);
drivers/crypto/inside-secure/safexcel_hash.c:	if (cache_len + areq->nbytes <= HASH_CACHE_SIZE) {
drivers/crypto/inside-secure/safexcel_hash.c:		sg_pcopy_to_buffer(areq->src, sg_nents(areq->src),
drivers/crypto/inside-secure/safexcel_hash.c:				   req->cache + cache_len,
drivers/crypto/inside-secure/safexcel_hash.c:				   areq->nbytes, 0);
drivers/crypto/inside-secure/safexcel_hash.c:	req->needs_inv = false;
drivers/crypto/inside-secure/safexcel_hash.c:		   ((req->not_first && !req->xcbcmac) ||
drivers/crypto/inside-secure/safexcel_hash.c:		     memcmp(ctx->base.ctxr->data, req->state, req->state_sz) ||
drivers/crypto/inside-secure/safexcel_hash.c:		     (req->finish && req->hmac &&
drivers/crypto/inside-secure/safexcel_hash.c:		      memcmp(ctx->base.ctxr->data + (req->state_sz>>2),
drivers/crypto/inside-secure/safexcel_hash.c:			     &ctx->base.opad, req->state_sz))))
drivers/crypto/inside-secure/safexcel_hash.c:			req->needs_inv = true;
drivers/crypto/inside-secure/safexcel_hash.c:						 EIP197_GFP_FLAGS(areq->base),
drivers/crypto/inside-secure/safexcel_hash.c:	req->not_first = true;
drivers/crypto/inside-secure/safexcel_hash.c:	ret = crypto_enqueue_request(&priv->ring[ring].queue, &areq->base);
drivers/crypto/inside-secure/safexcel_hash.c:	if (!areq->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	req->len += areq->nbytes;
drivers/crypto/inside-secure/safexcel_hash.c:	if ((ret && !req->finish) || req->last_req)
drivers/crypto/inside-secure/safexcel_hash.c:	req->finish = true;
drivers/crypto/inside-secure/safexcel_hash.c:	if (unlikely(!req->len && !areq->nbytes)) {
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, md5_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sha1_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sha224_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sha256_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sha384_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result, sha512_zero_message_hash,
drivers/crypto/inside-secure/safexcel_hash.c:			memcpy(areq->result,
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (unlikely(req->digest == CONTEXT_CONTROL_DIGEST_XCM &&
drivers/crypto/inside-secure/safexcel_hash.c:			    req->len == sizeof(u32) && !areq->nbytes)) {
drivers/crypto/inside-secure/safexcel_hash.c:		memcpy(areq->result, &ctx->base.ipad, sizeof(u32));
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (unlikely(ctx->cbcmac && req->len == AES_BLOCK_SIZE &&
drivers/crypto/inside-secure/safexcel_hash.c:			    !areq->nbytes)) {
drivers/crypto/inside-secure/safexcel_hash.c:		memset(areq->result, 0, AES_BLOCK_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (unlikely(req->xcbcmac && req->len == AES_BLOCK_SIZE &&
drivers/crypto/inside-secure/safexcel_hash.c:			    !areq->nbytes)) {
drivers/crypto/inside-secure/safexcel_hash.c:			u32 *result = (void *)areq->result;
drivers/crypto/inside-secure/safexcel_hash.c:		areq->result[0] ^= 0x80;			// 10- padding
drivers/crypto/inside-secure/safexcel_hash.c:		crypto_cipher_encrypt_one(ctx->kaes, areq->result, areq->result);
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (unlikely(req->hmac &&
drivers/crypto/inside-secure/safexcel_hash.c:			    (req->len == req->block_sz) &&
drivers/crypto/inside-secure/safexcel_hash.c:			    !areq->nbytes)) {
drivers/crypto/inside-secure/safexcel_hash.c:		memset(req->cache, 0, req->block_sz);
drivers/crypto/inside-secure/safexcel_hash.c:		req->cache[0] = 0x80;
drivers/crypto/inside-secure/safexcel_hash.c:		if (req->len_is_le) {
drivers/crypto/inside-secure/safexcel_hash.c:			req->cache[req->block_sz-8] = (req->block_sz << 3) &
drivers/crypto/inside-secure/safexcel_hash.c:			req->cache[req->block_sz-7] = (req->block_sz >> 5);
drivers/crypto/inside-secure/safexcel_hash.c:			req->cache[req->block_sz-2] = (req->block_sz >> 5);
drivers/crypto/inside-secure/safexcel_hash.c:			req->cache[req->block_sz-1] = (req->block_sz << 3) &
drivers/crypto/inside-secure/safexcel_hash.c:		req->len += req->block_sz; /* plus 1 hash block */
drivers/crypto/inside-secure/safexcel_hash.c:		req->hmac_zlen = true;
drivers/crypto/inside-secure/safexcel_hash.c:		req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	} else if (req->hmac) {
drivers/crypto/inside-secure/safexcel_hash.c:		req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	req->finish = true;
drivers/crypto/inside-secure/safexcel_hash.c:	export->len = req->len;
drivers/crypto/inside-secure/safexcel_hash.c:	export->processed = req->processed;
drivers/crypto/inside-secure/safexcel_hash.c:	export->digest = req->digest;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(export->state, req->state, req->state_sz);
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(export->cache, req->cache, HASH_CACHE_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len = export->len;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed = export->processed;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = export->digest;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->cache, export->cache, HASH_CACHE_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, export->state, req->state_sz);
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA1_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA1_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA1_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA1_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA1_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA1_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA1_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA1_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA1_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	struct safexcel_ahash_result *result = req->data;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->last_req = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA256_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA256_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA512_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA512_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = MD5_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = MD5_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = MD5_HMAC_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, MD5_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= MD5_HMAC_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= MD5_HMAC_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = MD5_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = MD5_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = MD5_HMAC_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->len_is_le = true; /* MD5 is little endian! ... */
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state[0]	= cpu_to_le32(~ctx->base.ipad.word[0]);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= sizeof(u32);
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= sizeof(u32);
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_XCM;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = sizeof(u32);
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = sizeof(u32);
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = sizeof(u32);
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, ctx->key_sz);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= AES_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= AES_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest   = CONTEXT_CONTROL_DIGEST_XCM;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = ctx->key_sz;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = AES_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = AES_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->xcbcmac  = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SM3_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SM3_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SM3_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SM3_DIGEST_SIZE);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SM3_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SM3_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_PRECOMPUTED;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SM3_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SM3_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SM3_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_INITIAL;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_224_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_224_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_224_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:		ahash_request_set_callback(subreq, req->base.flags,
drivers/crypto/inside-secure/safexcel_hash.c:					   req->base.complete, req->base.data);
drivers/crypto/inside-secure/safexcel_hash.c:		ahash_request_set_crypt(subreq, req->src, req->result,
drivers/crypto/inside-secure/safexcel_hash.c:					req->nbytes);
drivers/crypto/inside-secure/safexcel_hash.c:	ctx->do_fallback |= !req->nbytes;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_INITIAL;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_INITIAL;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_384_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_384_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_384_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_INITIAL;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA3_224_BLOCK_SIZE / 2);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA3_224_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA3_224_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_224_BLOCK_SIZE / 2;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_224_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_224_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA3_256_BLOCK_SIZE / 2);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA3_256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA3_256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_256_BLOCK_SIZE / 2;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_256_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_256_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA3_384_BLOCK_SIZE / 2);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA3_384_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA3_384_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_384_BLOCK_SIZE / 2;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_384_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_384_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel_hash.c:	memcpy(req->state, &ctx->base.ipad, SHA3_512_BLOCK_SIZE / 2);
drivers/crypto/inside-secure/safexcel_hash.c:	req->len	= SHA3_512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->processed	= SHA3_512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest = CONTEXT_CONTROL_DIGEST_HMAC;
drivers/crypto/inside-secure/safexcel_hash.c:	req->state_sz = SHA3_512_BLOCK_SIZE / 2;
drivers/crypto/inside-secure/safexcel_hash.c:	req->digest_sz = SHA3_512_DIGEST_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->block_sz = SHA3_512_BLOCK_SIZE;
drivers/crypto/inside-secure/safexcel_hash.c:	req->hmac = true;
drivers/crypto/inside-secure/safexcel_hash.c:	if (req->nbytes)
drivers/crypto/inside-secure/safexcel.c:		ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/inside-secure/safexcel.c:	struct safexcel_inv_result *result = req->data;
drivers/crypto/inside-secure/safexcel.c:		ctx = crypto_tfm_ctx(req->tfm);
drivers/crypto/inside-secure/safexcel.c:			req->complete(req, ret);
drivers/crypto/inside-secure/safexcel_cipher.c:				(sreq->direction == SAFEXCEL_ENCRYPT ?
drivers/crypto/inside-secure/safexcel_cipher.c:		if (sreq->direction == SAFEXCEL_ENCRYPT &&
drivers/crypto/inside-secure/safexcel_cipher.c:		else if (sreq->direction == SAFEXCEL_ENCRYPT)
drivers/crypto/inside-secure/safexcel_cipher.c:		if (sreq->direction == SAFEXCEL_ENCRYPT)
drivers/crypto/inside-secure/safexcel_cipher.c:	if (unlikely(!sreq->rdescs))
drivers/crypto/inside-secure/safexcel_cipher.c:	while (sreq->rdescs--) {
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, src, sreq->nr_src, DMA_BIDIRECTIONAL);
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, src, sreq->nr_src, DMA_TO_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, dst, sreq->nr_dst, DMA_FROM_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:	    (sreq->direction == SAFEXCEL_ENCRYPT)) {
drivers/crypto/inside-secure/safexcel_cipher.c:		sg_pcopy_to_buffer(dst, sreq->nr_dst, areq->iv,
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->nr_src = sg_nents_for_len(src, totlen_src);
drivers/crypto/inside-secure/safexcel_cipher.c:		if (sreq->direction == SAFEXCEL_DECRYPT)
drivers/crypto/inside-secure/safexcel_cipher.c:		   (sreq->direction == SAFEXCEL_DECRYPT)) {
drivers/crypto/inside-secure/safexcel_cipher.c:		sg_pcopy_to_buffer(src, sreq->nr_src, areq->iv,
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->nr_dst = sg_nents_for_len(dst, totlen_dst);
drivers/crypto/inside-secure/safexcel_cipher.c:		sreq->nr_src = max(sreq->nr_src, sreq->nr_dst);
drivers/crypto/inside-secure/safexcel_cipher.c:		sreq->nr_dst = sreq->nr_src;
drivers/crypto/inside-secure/safexcel_cipher.c:		    (sreq->nr_src <= 0))) {
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_map_sg(priv->dev, src, sreq->nr_src, DMA_BIDIRECTIONAL);
drivers/crypto/inside-secure/safexcel_cipher.c:		if (unlikely(totlen_src && (sreq->nr_src <= 0))) {
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_map_sg(priv->dev, src, sreq->nr_src, DMA_TO_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:		if (unlikely(totlen_dst && (sreq->nr_dst <= 0))) {
drivers/crypto/inside-secure/safexcel_cipher.c:			dma_unmap_sg(priv->dev, src, sreq->nr_src,
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_map_sg(priv->dev, dst, sreq->nr_dst, DMA_FROM_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:	for_each_sg(src, sg, sreq->nr_src, i) {
drivers/crypto/inside-secure/safexcel_cipher.c:				    sreq->direction, cryptlen,
drivers/crypto/inside-secure/safexcel_cipher.c:	for_each_sg(dst, sg, sreq->nr_dst, i) {
drivers/crypto/inside-secure/safexcel_cipher.c:		bool last = (i == sreq->nr_dst - 1);
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, src, sreq->nr_src, DMA_BIDIRECTIONAL);
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, src, sreq->nr_src, DMA_TO_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:		dma_unmap_sg(priv->dev, dst, sreq->nr_dst, DMA_FROM_DEVICE);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (unlikely(!sreq->rdescs))
drivers/crypto/inside-secure/safexcel_cipher.c:	while (sreq->rdescs--) {
drivers/crypto/inside-secure/safexcel_cipher.c:	if (sreq->needs_inv) {
drivers/crypto/inside-secure/safexcel_cipher.c:		sreq->needs_inv = false;
drivers/crypto/inside-secure/safexcel_cipher.c:		err = safexcel_handle_req_result(priv, ring, async, req->src,
drivers/crypto/inside-secure/safexcel_cipher.c:						 req->dst, req->cryptlen, sreq,
drivers/crypto/inside-secure/safexcel_cipher.c:	if (sreq->needs_inv) {
drivers/crypto/inside-secure/safexcel_cipher.c:		sreq->needs_inv = false;
drivers/crypto/inside-secure/safexcel_cipher.c:		err = safexcel_handle_req_result(priv, ring, async, req->src,
drivers/crypto/inside-secure/safexcel_cipher.c:						 req->dst,
drivers/crypto/inside-secure/safexcel_cipher.c:						 req->cryptlen + crypto_aead_authsize(tfm),
drivers/crypto/inside-secure/safexcel_cipher.c:	struct safexcel_cipher_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/inside-secure/safexcel_cipher.c:	BUG_ON(!(priv->flags & EIP197_TRC_CACHE) && sreq->needs_inv);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (sreq->needs_inv) {
drivers/crypto/inside-secure/safexcel_cipher.c:		memcpy(input_iv, req->iv, crypto_skcipher_ivsize(skcipher));
drivers/crypto/inside-secure/safexcel_cipher.c:		ret = safexcel_send_req(async, ring, sreq, req->src,
drivers/crypto/inside-secure/safexcel_cipher.c:					req->dst, req->cryptlen, 0, 0, input_iv,
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->rdescs = *results;
drivers/crypto/inside-secure/safexcel_cipher.c:	struct safexcel_cipher_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/inside-secure/safexcel_cipher.c:	BUG_ON(!(priv->flags & EIP197_TRC_CACHE) && sreq->needs_inv);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (sreq->needs_inv)
drivers/crypto/inside-secure/safexcel_cipher.c:		ret = safexcel_send_req(async, ring, sreq, req->src, req->dst,
drivers/crypto/inside-secure/safexcel_cipher.c:					req->cryptlen, req->assoclen,
drivers/crypto/inside-secure/safexcel_cipher.c:					crypto_aead_authsize(tfm), req->iv,
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->rdescs = *results;
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->needs_inv = true;
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_cipher_exit_inv(tfm, &req->base, sreq, &result);
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_cipher_exit_inv(tfm, &req->base, sreq, &result);
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->needs_inv = false;
drivers/crypto/inside-secure/safexcel_cipher.c:	sreq->direction = dir;
drivers/crypto/inside-secure/safexcel_cipher.c:			sreq->needs_inv = true;
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_ENCRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_DECRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen < XTS_BLOCK_SIZE)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen < XTS_BLOCK_SIZE)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->iv[0] < 1 || req->iv[0] > 7)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_ENCRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->iv[0] < 1 || req->iv[0] > 7)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_DECRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:		    req->assoclen >= EIP197_AEAD_IPSEC_IV_SIZE) &&
drivers/crypto/inside-secure/safexcel_cipher.c:		   req->cryptlen > POLY1305_DIGEST_SIZE)) {
drivers/crypto/inside-secure/safexcel_cipher.c:		return safexcel_queue_req(&req->base, creq, dir);
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_callback(subreq, req->base.flags, req->base.complete,
drivers/crypto/inside-secure/safexcel_cipher.c:				  req->base.data);
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
drivers/crypto/inside-secure/safexcel_cipher.c:			       req->iv);
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:		return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:		return safexcel_queue_req(&req->base, skcipher_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, aead_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	if ((req->cryptlen - crypto_aead_authsize(tfm)) & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, aead_request_ctx(req),
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_callback(subreq, req->base.flags, req->base.complete,
drivers/crypto/inside-secure/safexcel_cipher.c:				  req->base.data);
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_crypt(subreq, req->src, req->dst, req->cryptlen,
drivers/crypto/inside-secure/safexcel_cipher.c:			       req->iv);
drivers/crypto/inside-secure/safexcel_cipher.c:	aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->cryptlen & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:	else if (req->cryptlen || req->assoclen) /* If input length > 0 only */
drivers/crypto/inside-secure/safexcel_cipher.c:		return safexcel_queue_req(&req->base, creq, SAFEXCEL_ENCRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	if ((req->cryptlen - crypto_aead_authsize(tfm)) & (SM4_BLOCK_SIZE - 1))
drivers/crypto/inside-secure/safexcel_cipher.c:	else if (req->cryptlen > crypto_aead_authsize(tfm) || req->assoclen)
drivers/crypto/inside-secure/safexcel_cipher.c:		return safexcel_queue_req(&req->base, creq, SAFEXCEL_DECRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
drivers/crypto/inside-secure/safexcel_cipher.c:	return crypto_ipsec_check_assoclen(req->assoclen) ?:
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->assoclen != 16 && req->assoclen != 20)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_ENCRYPT);
drivers/crypto/inside-secure/safexcel_cipher.c:	if (req->assoclen != 16 && req->assoclen != 20)
drivers/crypto/inside-secure/safexcel_cipher.c:	return safexcel_queue_req(&req->base, creq, SAFEXCEL_DECRYPT);
drivers/crypto/bcm/cipher.h:	 * operation. Cannot be stored in req->result for truncated hashes,
drivers/crypto/bcm/cipher.c:		sg_copy_part_to_buf(req->dst, rctx->msg_buf.iv_ctr,
drivers/crypto/bcm/cipher.c:			sg_copy_part_to_buf(req->src, rctx->msg_buf.iv_ctr,
drivers/crypto/bcm/cipher.c:	err = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);
drivers/crypto/bcm/cipher.c:	dump_sg(req->dst, rctx->total_received, payload_len);
drivers/crypto/bcm/cipher.c:				sg_copy_part_to_buf(req->src, dest, new_len,
drivers/crypto/bcm/cipher.c:	/* if you sent a prebuf then that wasn't from this req->src */
drivers/crypto/bcm/cipher.c:	err = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);
drivers/crypto/bcm/cipher.c:		rc = do_shash("md5", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:		rc = do_shash("sha1", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:		rc = do_shash("sha224", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:		rc = do_shash("sha256", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:		rc = do_shash("sha384", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:		rc = do_shash("sha512", req->result, ctx->opad, blocksize,
drivers/crypto/bcm/cipher.c:			      req->result, ctx->digestsize, NULL, 0);
drivers/crypto/bcm/cipher.c:	memcpy(req->result, rctx->msg_buf.digest, ctx->digestsize);
drivers/crypto/bcm/cipher.c:			__swab32s((u32 *)req->result);
drivers/crypto/bcm/cipher.c:			__swab32s(((u32 *)req->result) + 1);
drivers/crypto/bcm/cipher.c:			__swab32s(((u32 *)req->result) + 2);
drivers/crypto/bcm/cipher.c:			__swab32s(((u32 *)req->result) + 3);
drivers/crypto/bcm/cipher.c:			__swab32s(((u32 *)req->result) + 4);
drivers/crypto/bcm/cipher.c:	flow_dump("  digest ", req->result, ctx->digestsize);
drivers/crypto/bcm/cipher.c:		flow_dump("  hmac: ", req->result, ctx->digestsize);
drivers/crypto/bcm/cipher.c:		 * Don't write directly to req->dst, because SPU may pad the
drivers/crypto/bcm/cipher.c:	aead_parms.assoc_size = req->assoclen;
drivers/crypto/bcm/cipher.c:		spu->spu_ccm_update_iv(digestsize, &cipher_parms, req->assoclen,
drivers/crypto/bcm/cipher.c:		sg_copy_part_to_buf(req->src, rctx->msg_buf.digest, digestsize,
drivers/crypto/bcm/cipher.c:				    req->assoclen + rctx->total_sent -
drivers/crypto/bcm/cipher.c:	err = mailbox_send_message(mssg, req->base.flags, rctx->chan_idx);
drivers/crypto/bcm/cipher.c:	if (req->assoclen)
drivers/crypto/bcm/cipher.c:			    req->assoclen);
drivers/crypto/bcm/cipher.c:	result_len = req->cryptlen;
drivers/crypto/bcm/cipher.c:		icv_offset = req->assoclen + rctx->total_sent;
drivers/crypto/bcm/cipher.c:		sg_copy_part_from_buf(req->dst, rctx->msg_buf.digest,
drivers/crypto/bcm/cipher.c:	dump_sg(req->dst, req->assoclen, result_len);
drivers/crypto/bcm/cipher.c:		areq->complete(areq, err);
drivers/crypto/bcm/cipher.c:	rctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:	rctx->parent = &req->base;
drivers/crypto/bcm/cipher.c:	rctx->total_todo = req->cryptlen;
drivers/crypto/bcm/cipher.c:	rctx->src_sg = req->src;
drivers/crypto/bcm/cipher.c:	rctx->dst_sg = req->dst;
drivers/crypto/bcm/cipher.c:		memcpy(rctx->msg_buf.iv_ctr, req->iv, rctx->iv_ctr_len);
drivers/crypto/bcm/cipher.c:	flow_log("skcipher_encrypt() nbytes:%u\n", req->cryptlen);
drivers/crypto/bcm/cipher.c:	flow_log("skcipher_decrypt() nbytes:%u\n", req->cryptlen);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_enqueue() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	rctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:	rctx->parent = &req->base;
drivers/crypto/bcm/cipher.c:	rctx->src_sg = req->src;
drivers/crypto/bcm/cipher.c:		err = do_shash((unsigned char *)alg_name, req->result,
drivers/crypto/bcm/cipher.c:		gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:	flow_log("ahash_update() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	if (!req->nbytes)
drivers/crypto/bcm/cipher.c:	rctx->total_todo += req->nbytes;
drivers/crypto/bcm/cipher.c:		if (req->src)
drivers/crypto/bcm/cipher.c:			nents = sg_nents(req->src);
drivers/crypto/bcm/cipher.c:		gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:		tmpbuf = kmalloc(req->nbytes, gfp);
drivers/crypto/bcm/cipher.c:		if (sg_copy_to_buffer(req->src, nents, tmpbuf, req->nbytes) !=
drivers/crypto/bcm/cipher.c:				req->nbytes) {
drivers/crypto/bcm/cipher.c:		ret = crypto_shash_update(ctx->shash, tmpbuf, req->nbytes);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_final() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:		ret = crypto_shash_final(ctx->shash, req->result);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_finup() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	rctx->total_todo += req->nbytes;
drivers/crypto/bcm/cipher.c:		if (req->src) {
drivers/crypto/bcm/cipher.c:			nents = sg_nents(req->src);
drivers/crypto/bcm/cipher.c:		gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:		tmpbuf = kmalloc(req->nbytes, gfp);
drivers/crypto/bcm/cipher.c:		if (sg_copy_to_buffer(req->src, nents, tmpbuf, req->nbytes) !=
drivers/crypto/bcm/cipher.c:				req->nbytes) {
drivers/crypto/bcm/cipher.c:		ret = crypto_shash_finup(ctx->shash, tmpbuf, req->nbytes,
drivers/crypto/bcm/cipher.c:					 req->result);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_digest() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_hmac_update() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	if (!req->nbytes)
drivers/crypto/bcm/cipher.c:	flow_log("ahash_hmac_final() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_hmac_finupl() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	flow_log("ahash_hmac_digest() nbytes:%u\n", req->nbytes);
drivers/crypto/bcm/cipher.c:	    (req->assoclen == 0)) {
drivers/crypto/bcm/cipher.c:		if ((rctx->is_encrypt && (req->cryptlen == 0)) ||
drivers/crypto/bcm/cipher.c:		    (!rctx->is_encrypt && (req->cryptlen == ctx->digestsize))) {
drivers/crypto/bcm/cipher.c:	    (req->assoclen == 0)) {
drivers/crypto/bcm/cipher.c:	    req->assoclen != 16 && req->assoclen != 20) {
drivers/crypto/bcm/cipher.c:	payload_len = req->cryptlen;
drivers/crypto/bcm/cipher.c:		payload_len += req->assoclen;
drivers/crypto/bcm/cipher.c:	areq->tfm = crypto_aead_tfm(aead);
drivers/crypto/bcm/cipher.c:	areq->complete = rctx->old_complete;
drivers/crypto/bcm/cipher.c:	areq->data = rctx->old_data;
drivers/crypto/bcm/cipher.c:	areq->complete(areq, err);
drivers/crypto/bcm/cipher.c:		rctx->old_complete = req->base.complete;
drivers/crypto/bcm/cipher.c:		rctx->old_data = req->base.data;
drivers/crypto/bcm/cipher.c:			req->base.data = rctx->old_data;
drivers/crypto/bcm/cipher.c:	if (req->assoclen > MAX_ASSOC_SIZE) {
drivers/crypto/bcm/cipher.c:		     __func__, req->assoclen, MAX_ASSOC_SIZE);
drivers/crypto/bcm/cipher.c:	rctx->gfp = (req->base.flags & (CRYPTO_TFM_REQ_MAY_BACKLOG |
drivers/crypto/bcm/cipher.c:	rctx->parent = &req->base;
drivers/crypto/bcm/cipher.c:	rctx->total_todo = req->cryptlen;
drivers/crypto/bcm/cipher.c:	rctx->assoc = req->src;
drivers/crypto/bcm/cipher.c:	if (spu_sg_at_offset(req->src, req->assoclen, &rctx->src_sg,
drivers/crypto/bcm/cipher.c:	if (req->dst == req->src) {
drivers/crypto/bcm/cipher.c:		 * Expect req->dst to have room for assoc data followed by
drivers/crypto/bcm/cipher.c:		if (spu_sg_at_offset(req->dst, req->assoclen, &rctx->dst_sg,
drivers/crypto/bcm/cipher.c:	flow_log("  src sg: %p\n", req->src);
drivers/crypto/bcm/cipher.c:	flow_log("  assoc:  %p, assoclen %u\n", rctx->assoc, req->assoclen);
drivers/crypto/bcm/cipher.c:	flow_log("  dst sg: %p\n", req->dst);
drivers/crypto/bcm/cipher.c:	flow_dump("  iv: ", req->iv, rctx->iv_ctr_len);
drivers/crypto/bcm/cipher.c:		       req->iv,
drivers/crypto/bcm/cipher.c:	flow_log("%s() cryptlen:%u %08x\n", __func__, req->cryptlen,
drivers/crypto/bcm/cipher.c:		 req->cryptlen);
drivers/crypto/bcm/cipher.c:	dump_sg(req->src, 0, req->cryptlen + req->assoclen);
drivers/crypto/bcm/cipher.c:	flow_log("  assoc_len:%u\n", req->assoclen);
drivers/crypto/bcm/cipher.c:	flow_log("%s() cryptlen:%u\n", __func__, req->cryptlen);
drivers/crypto/bcm/cipher.c:	dump_sg(req->src, 0, req->cryptlen + req->assoclen);
drivers/crypto/bcm/cipher.c:	flow_log("  assoc_len:%u\n", req->assoclen);
drivers/crypto/hifn_795x.c:	unsigned int nbytes = req->cryptlen, offset, copy, diff;
drivers/crypto/hifn_795x.c:		dst = &req->dst[idx];
drivers/crypto/hifn_795x.c:				dst = &req->dst[idx];
drivers/crypto/hifn_795x.c:	struct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/hifn_795x.c:	unsigned int nbytes = req->cryptlen, idx = 0;
drivers/crypto/hifn_795x.c:		dst = &req->dst[idx];
drivers/crypto/hifn_795x.c:	err = hifn_setup_dma(dev, ctx, rctx, req->src, req->dst, req->cryptlen, req);
drivers/crypto/hifn_795x.c:		unsigned int nbytes = req->cryptlen;
drivers/crypto/hifn_795x.c:			dst = &req->dst[idx];
drivers/crypto/hifn_795x.c:	req->base.complete(&req->base, error);
drivers/crypto/hifn_795x.c:	struct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/hifn_795x.c:	if (dev->started + DIV_ROUND_UP(req->cryptlen, PAGE_SIZE) <= HIFN_QUEUE_LENGTH)
drivers/crypto/hifn_795x.c:		err = crypto_enqueue_request(&dev->queue, &req->base);
drivers/crypto/hifn_795x.c:	struct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/hifn_795x.c:	if (req->iv && mode != ACRYPTO_MODE_ECB) {
drivers/crypto/hifn_795x.c:	rctx->iv = req->iv;
drivers/crypto/hifn_795x.c:	struct hifn_context *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	/* Unmap req->src (if mapped). */
drivers/crypto/keembay/keembay-ocs-hcu-core.c:		dma_unmap_sg(dev, req->src, rctx->sg_dma_nents, DMA_TO_DEVICE);
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	nents = sg_nents_for_len(req->src, rctx->sg_data_total - remainder);
drivers/crypto/keembay/keembay-ocs-hcu-core.c:		rctx->sg_dma_nents = dma_map_sg(dev, req->src, nents,
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	for_each_sg(req->src, rctx->sg, rctx->sg_dma_nents, i) {
drivers/crypto/keembay/keembay-ocs-hcu-core.c:				  rctx->dma_list, req->result, rctx->dig_sz);
drivers/crypto/keembay/keembay-ocs-hcu-core.c:					req->result, rctx->dig_sz);
drivers/crypto/keembay/keembay-ocs-hcu-core.c:		rc = ocs_hcu_hash_final(hcu_dev, &rctx->hash_ctx, req->result,
drivers/crypto/keembay/keembay-ocs-hcu-core.c:			rctx->buffer[rctx->blk_sz + i] = req->result[i];
drivers/crypto/keembay/keembay-ocs-hcu-core.c:				    rctx->blk_sz + rctx->dig_sz, req->result,
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	if (!req->nbytes)
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	rctx->sg_data_total = req->nbytes;
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	rctx->sg = req->src;
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	rctx->sg_data_total = req->nbytes;
drivers/crypto/keembay/keembay-ocs-hcu-core.c:	rctx->sg = req->src;
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (req->cryptlen % AES_BLOCK_SIZE != 0)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (req->cryptlen % AES_BLOCK_SIZE != 0)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (!req->iv || iv_size != AES_BLOCK_SIZE)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		 * NOTE: Since req->cryptlen == 0 case was already handled in
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (!req->iv || iv_size != AES_BLOCK_SIZE)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (req->cryptlen < AES_BLOCK_SIZE)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		if (!req->iv || iv_size != AES_BLOCK_SIZE)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		skcipher_request_set_callback(subreq, req->base.flags, NULL,
drivers/crypto/keembay/keembay-ocs-aes-core.c:		skcipher_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					   req->cryptlen, req->iv);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	if (!req->cryptlen && mode != OCS_MODE_CTS)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dma_unmap_sg(dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dma_unmap_sg(dev, req->dst, rctx->dst_nents, rctx->in_place ?
drivers/crypto/keembay/keembay-ocs-aes-core.c:		scatterwalk_map_and_copy(rctx->last_ct_blk, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					 req->cryptlen - iv_size, iv_size, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		sg_swap_blocks(req->dst, rctx->dst_nents,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       req->cryptlen - (2 * AES_BLOCK_SIZE));
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    req->cryptlen, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->src_nents =  sg_nents_for_len(req->src, req->cryptlen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->src_dma_count = dma_map_sg(tctx->aes_dev->dev, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    req->cryptlen, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    req->cryptlen, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       rctx->src_dll.dma_addr, req->cryptlen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->dst_nents = sg_nents_for_len(req->dst, req->cryptlen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:			  req->cryptlen > AES_BLOCK_SIZE &&
drivers/crypto/keembay/keembay-ocs-aes-core.c:			  req->cryptlen % AES_BLOCK_SIZE == 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->in_place = (req->src == req->dst);
drivers/crypto/keembay/keembay-ocs-aes-core.c:			req->cryptlen, req->iv, iv_size);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		sg_swap_blocks(req->dst, rctx->dst_nents,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       req->cryptlen - AES_BLOCK_SIZE,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       req->cryptlen - (2 * AES_BLOCK_SIZE));
drivers/crypto/keembay/keembay-ocs-aes-core.c:	/* For CBC copy IV to req->IV. */
drivers/crypto/keembay/keembay-ocs-aes-core.c:			scatterwalk_map_and_copy(req->iv, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:						 req->cryptlen - iv_size,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			memcpy(req->iv, rctx->last_ct_blk, iv_size);
drivers/crypto/keembay/keembay-ocs-aes-core.c:			scatterwalk_map_and_copy(req->iv, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:						 req->cryptlen - iv_size,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	if (instruction == OCS_DECRYPT && req->cryptlen < tag_size)
drivers/crypto/keembay/keembay-ocs-aes-core.c:	if (!req->iv)
drivers/crypto/keembay/keembay-ocs-aes-core.c:		aead_request_set_callback(subreq, req->base.flags,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					  req->base.complete, req->base.data);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		aead_request_set_crypt(subreq, req->src, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:				       req->cryptlen, req->iv);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		aead_request_set_ad(subreq, req->assoclen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dma_unmap_sg(dev, req->src, rctx->src_nents, DMA_TO_DEVICE);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dma_unmap_sg(dev, req->dst, rctx->dst_nents, rctx->in_place ?
drivers/crypto/keembay/keembay-ocs-aes-core.c: * - DMA map req->src and req->dst
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->src_nents = sg_nents_for_len(req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					   req->assoclen + req->cryptlen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		/* req->cryptlen includes both CT and tag. */
drivers/crypto/keembay/keembay-ocs-aes-core.c:		in_size = req->cryptlen - tag_size;
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dst_size = req->assoclen + out_size;
drivers/crypto/keembay/keembay-ocs-aes-core.c:		sg_pcopy_to_buffer(req->src, rctx->src_nents, rctx->in_tag,
drivers/crypto/keembay/keembay-ocs-aes-core.c:				   tag_size, req->assoclen + in_size);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		in_size = req->cryptlen;
drivers/crypto/keembay/keembay-ocs-aes-core.c:		dst_size = req->assoclen + in_size + tag_size;
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->dst_nents = sg_nents_for_len(req->dst, dst_size);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->in_place = (req->src == req->dst) ? 1 : 0;
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->dst_dma_count = dma_map_sg(tctx->aes_dev->dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    &rctx->aad_dst_dll, req->assoclen,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    out_size, req->assoclen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:						    req->assoclen, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:		rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->dst,
drivers/crypto/keembay/keembay-ocs-aes-core.c:						    req->assoclen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rctx->src_dma_count = dma_map_sg(tctx->aes_dev->dev, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    req->assoclen, 0);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	rc = ocs_create_linked_list_from_sg(tctx->aes_dev, req->src,
drivers/crypto/keembay/keembay-ocs-aes-core.c:					    req->assoclen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:	if (req->assoclen == 0)
drivers/crypto/keembay/keembay-ocs-aes-core.c:			       rctx->aad_src_dll.dma_addr, req->cryptlen);
drivers/crypto/keembay/keembay-ocs-aes-core.c:				    req->iv,
drivers/crypto/keembay/keembay-ocs-aes-core.c:				    rctx->aad_src_dll.dma_addr, req->assoclen,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			    req->iv,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			    rctx->aad_src_dll.dma_addr, req->assoclen,
drivers/crypto/keembay/keembay-ocs-aes-core.c:	sg_pcopy_from_buffer(req->dst, rctx->dst_nents, rctx->out_tag,
drivers/crypto/keembay/keembay-ocs-aes-core.c:			     tag_size, req->assoclen + req->cryptlen);
drivers/crypto/omap-aes.c:	if ((dd->flags & (FLAGS_CBC | FLAGS_CTR)) && dd->req->iv)
drivers/crypto/omap-aes.c:		omap_aes_write_n(dd, AES_REG_IV(dd, 0), (void *)dd->req->iv, 4);
drivers/crypto/omap-aes.c:	if ((dd->flags & (FLAGS_GCM)) && dd->aead_req->iv) {
drivers/crypto/omap-aes.c:	dd->total = req->cryptlen;
drivers/crypto/omap-aes.c:	dd->total_save = req->cryptlen;
drivers/crypto/omap-aes.c:	dd->in_sg = req->src;
drivers/crypto/omap-aes.c:	dd->out_sg = req->dst;
drivers/crypto/omap-aes.c:	dd->orig_out = req->dst;
drivers/crypto/omap-aes.c:	if (req->src == req->dst)
drivers/crypto/omap-aes.c:		omap_aes_copy_ivout(dd, dd->req->iv);
drivers/crypto/omap-aes.c:	if ((req->cryptlen % AES_BLOCK_SIZE) && !(mode & FLAGS_CTR))
drivers/crypto/omap-aes.c:	pr_debug("nbytes: %d, enc: %d, cbc: %d\n", req->cryptlen,
drivers/crypto/omap-aes.c:	if (req->cryptlen < aes_fallback_sz) {
drivers/crypto/omap-aes.c:					      req->base.flags,
drivers/crypto/omap-aes.c:					      req->base.complete,
drivers/crypto/omap-aes.c:					      req->base.data);
drivers/crypto/omap-aes.c:		skcipher_request_set_crypt(&rctx->fallback_req, req->src,
drivers/crypto/omap-aes.c:					   req->dst, req->cryptlen, req->iv);
drivers/crypto/stm32/stm32-hash.c:	rctx->sg = hdev->req->src;
drivers/crypto/stm32/stm32-hash.c:	rctx->total = hdev->req->nbytes;
drivers/crypto/stm32/stm32-hash.c:	if (req->nbytes <= HASH_DMA_THRESHOLD)
drivers/crypto/stm32/stm32-hash.c:	if (sg_nents(req->src) > 1) {
drivers/crypto/stm32/stm32-hash.c:		for_each_sg(req->src, sg, sg_nents(req->src), i) {
drivers/crypto/stm32/stm32-hash.c:	if (req->src->offset % 4)
drivers/crypto/stm32/stm32-hash.c:	if (!req->result)
drivers/crypto/stm32/stm32-hash.c:	memcpy(req->result, rctx->digest, rctx->digcnt);
drivers/crypto/stm32/stm32-hash.c:		rctx->op, req->nbytes);
drivers/crypto/stm32/stm32-hash.c:	struct stm32_hash_ctx *ctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/stm32/stm32-hash.c:	if (!req->nbytes || !(rctx->flags & HASH_FLAGS_CPU))
drivers/crypto/stm32/stm32-hash.c:	rctx->total = req->nbytes;
drivers/crypto/stm32/stm32-hash.c:	rctx->sg = req->src;
drivers/crypto/stm32/stm32-cryp.c:	__be32 *tmp = (void *)req->iv;
drivers/crypto/stm32/stm32-cryp.c:	return is_encrypt(cryp) ? cryp->areq->cryptlen :
drivers/crypto/stm32/stm32-cryp.c:				  cryp->areq->cryptlen - cryp->authsize;
drivers/crypto/stm32/stm32-cryp.c:	memcpy(iv, cryp->areq->iv, 12);
drivers/crypto/stm32/stm32-cryp.c:	memcpy(iv, cryp->areq->iv, AES_BLOCK_SIZE);
drivers/crypto/stm32/stm32-cryp.c:	if (cryp->areq->assoclen)
drivers/crypto/stm32/stm32-cryp.c:		if (cryp->areq->assoclen) {
drivers/crypto/stm32/stm32-cryp.c:		stm32_cryp_hw_write_iv(cryp, (__be32 *)cryp->req->iv);
drivers/crypto/stm32/stm32-cryp.c:		cryp->total_in = req->cryptlen;
drivers/crypto/stm32/stm32-cryp.c:		cryp->total_in = areq->assoclen + areq->cryptlen;
drivers/crypto/stm32/stm32-cryp.c:	cryp->in_sg = req ? req->src : areq->src;
drivers/crypto/stm32/stm32-cryp.c:	cryp->out_sg = req ? req->dst : areq->dst;
drivers/crypto/stm32/stm32-cryp.c:		scatterwalk_advance(&cryp->out_walk, cryp->areq->assoclen);
drivers/crypto/stm32/stm32-cryp.c:		cryp->total_out -= cryp->areq->assoclen;
drivers/crypto/stm32/stm32-cryp.c:	if (unlikely(!cryp->areq->assoclen &&
drivers/crypto/stm32/stm32-cryp.c:		size_bit = cryp->areq->assoclen * 8;
drivers/crypto/stm32/stm32-cryp.c:		size_bit = is_encrypt(cryp) ? cryp->areq->cryptlen :
drivers/crypto/stm32/stm32-cryp.c:				cryp->areq->cryptlen - AES_BLOCK_SIZE;
drivers/crypto/stm32/stm32-cryp.c:		memcpy(iv, cryp->areq->iv, AES_BLOCK_SIZE);
drivers/crypto/stm32/stm32-cryp.c:				cryp->areq->assoclen) {
drivers/crypto/stm32/stm32-cryp.c:	alen = cryp->areq->assoclen;
drivers/crypto/stm32/stm32-cryp.c:		if (cryp->areq->assoclen <= 65280) {
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		memcpy(req->result, sha1_zero_message_hash, rk_digest_size);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		memcpy(req->result, sha256_zero_message_hash, rk_digest_size);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		memcpy(req->result, md5_zero_message_hash, rk_digest_size);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.nbytes = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.src = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.result = req->result;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	rctx->fallback_req.base.flags = req->base.flags &
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	struct rk_ahash_ctx *tctx = crypto_tfm_ctx(req->base.tfm);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	if (!req->nbytes)
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		return dev->enqueue(dev, &req->base);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev->total = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev->left_bytes = req->nbytes;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev->sg_src = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev->first = req->src;
drivers/crypto/rockchip/rk3288_crypto_ahash.c:	dev->src_nents = sg_nents(req->src);
drivers/crypto/rockchip/rk3288_crypto_ahash.c:		memcpy_fromio(req->result, dev->reg + RK_CRYPTO_HASH_DOUT_0,
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	if (!IS_ALIGNED(req->cryptlen, dev->align_size))
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		return dev->enqueue(dev, &req->base);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		memcpy_toio(dev->reg + RK_CRYPTO_TDES_IV_0, req->iv, ivsize);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		memcpy_toio(dev->reg + RK_CRYPTO_AES_IV_0, req->iv, ivsize);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		sg_pcopy_to_buffer(dev->first, dev->src_nents, req->iv,
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->left_bytes = req->cryptlen;
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->total = req->cryptlen;
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->sg_src = req->src;
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->first = req->src;
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->src_nents = sg_nents(req->src);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->sg_dst = req->dst;
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:	dev->dst_nents = sg_nents(req->dst);
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:			memcpy(req->iv, sg_virt(dev->sg_dst) +
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:			memcpy(req->iv, dev->addr_vir +
drivers/crypto/rockchip/rk3288_crypto_skcipher.c:		if (!sg_pcopy_from_buffer(req->dst, dev->dst_nents,
drivers/opp/of.c:	 * voltage like <freq-kHz vol-uV>.
drivers/rtc/rtc-ac100.c:		tmp = ac100_clkout_round_rate(hw, req->rate, prate);
drivers/rtc/rtc-ac100.c:		if (tmp > req->rate)
drivers/rtc/rtc-ac100.c:		if (req->rate - tmp < req->rate - best) {
drivers/rtc/rtc-ac100.c:	req->best_parent_hw = best_parent;
drivers/rtc/rtc-ac100.c:	req->best_parent_rate = best;
drivers/rtc/rtc-ac100.c:	req->rate = best;
drivers/rtc/rtc-cmos.c:	val = of_get_property(node, "freq-reg", NULL);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->cmd = CPL_ABORT_NO_RST;
drivers/target/iscsi/cxgbit/cxgbit_cm.c:		      req->tcpopt.tstamp,
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	if (req->tcpopt.tstamp)
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	if (req->tcpopt.sack)
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	hlen = ntohl(req->hdr_len);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	unsigned int stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	u16 peer_mss = ntohs(req->tcpopt.mss);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:				      PASS_OPEN_TOS_G(ntohl(req->tos_stid)));
drivers/target/iscsi/cxgbit/cxgbit_cm.c:				       PASS_OPEN_TOS_G(ntohl(req->tos_stid)),
drivers/target/iscsi/cxgbit/cxgbit_cm.c:		sizeof(struct tcphdr) +	(req->tcpopt.tstamp ? 12 : 0);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	csk->tos = PASS_OPEN_TOS_G(ntohl(req->tos_stid));
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->reply_ctrl = htons(NO_REPLY_V(0) | QUEUENO_V(csk->rss_qid));
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->word_cookie = htons(0);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->mask = cpu_to_be64(0x3 << 4);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->val = cpu_to_be64(((hcrc ? ULP_CRC_HEADER : 0) |
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->reply_ctrl = htons(NO_REPLY_V(0) | QUEUENO_V(csk->rss_qid));
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->word_cookie = htons(0);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->mask = cpu_to_be64(0x3 << 8);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	req->val = cpu_to_be64(pg_idx << 8);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	u16 tcp_opt = be16_to_cpu(req->tcp_opt);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	u32 snd_isn = be32_to_cpu(req->snd_isn);
drivers/target/iscsi/cxgbit/cxgbit_cm.c:	u32 rcv_isn = be32_to_cpu(req->rcv_isn);
drivers/target/iscsi/cxgbit/cxgbit_target.c:	req->op_to_immdlen = cpu_to_be32(FW_WR_OP_V(opcode) |
drivers/target/iscsi/cxgbit/cxgbit_target.c:	req->flowid_len16 = cpu_to_be32(FW_WR_FLOWID_V(csk->tid) |
drivers/target/iscsi/cxgbit/cxgbit_target.c:	req->plen = htonl(len);
drivers/target/iscsi/cxgbit/cxgbit_target.c:	req->tunnel_to_proxy = htonl((wr_ulp_mode) | force |
drivers/target/iscsi/cxgbit/cxgbit_target.c:			req->wr.wr_hi |= htonl(FW_WR_COMPL_F);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login_req->flags, login_req->itt, login_req->cmdsn,
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login_req->exp_statsn, login_req->cid, pdu_cb->dlen);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->leading_connection = (!login_req->tsih) ? 1 : 0;
drivers/target/iscsi/cxgbit/cxgbit_target.c:				login_req->flags);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->version_min	= login_req->min_version;
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->version_max	= login_req->max_version;
drivers/target/iscsi/cxgbit/cxgbit_target.c:		memcpy(login->isid, login_req->isid, 6);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->cmd_sn		= be32_to_cpu(login_req->cmdsn);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->init_task_tag	= login_req->itt;
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->initial_exp_statsn = be32_to_cpu(login_req->exp_statsn);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->cid		= be16_to_cpu(login_req->cid);
drivers/target/iscsi/cxgbit/cxgbit_target.c:		login->tsih		= be16_to_cpu(login_req->tsih);
drivers/target/iscsi/cxgbit/cxgbit_ddp.c:	req->wr.wr_hi = htonl(FW_WR_OP_V(FW_ULPTX_WR) |
drivers/target/iscsi/cxgbit/cxgbit_ddp.c:	req->cmd = htonl(ULPTX_CMD_V(ULP_TX_MEM_WRITE) |
drivers/target/iscsi/cxgbit/cxgbit_ddp.c:	req->dlen = htonl(ULP_MEMIO_DATA_LEN_V(dlen >> 5));
drivers/target/iscsi/cxgbit/cxgbit_ddp.c:	req->lock_addr = htonl(ULP_MEMIO_ADDR_V(pm_addr >> 5));
drivers/target/iscsi/cxgbit/cxgbit_ddp.c:	req->len16 = htonl(DIV_ROUND_UP(wr_len - sizeof(req->wr), 16));
drivers/target/iscsi/iscsi_target_erl1.c:		if (cmd->se_cmd.se_tmr_req->response) {
drivers/target/iscsi/iscsi_target.c:	cmd->tmr_req->se_tmr_req = cmd->se_cmd.se_tmr_req;
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->ref_cmd		= ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->exp_data_sn		= be32_to_cpu(hdr->exp_datasn);
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->ref_cmd		= ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->exp_data_sn		= be32_to_cpu(hdr->exp_datasn);
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->conn_recovery		= cr;
drivers/target/iscsi/iscsi_target_tmr.c:	tmr_req->task_reassign		= 1;
drivers/target/iscsi/iscsi_target_tmr.c:	struct iscsi_cmd *cmd = tmr_req->ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	if (!tmr_req->exp_data_sn) {
drivers/target/iscsi/iscsi_target_tmr.c:		cmd->acked_data_sn = (tmr_req->exp_data_sn - 1);
drivers/target/iscsi/iscsi_target_tmr.c:	if (!tmr_req->exp_data_sn) {
drivers/target/iscsi/iscsi_target_tmr.c:		cmd->acked_data_sn = (tmr_req->exp_data_sn - 1);
drivers/target/iscsi/iscsi_target_tmr.c:	dr->data_sn = dr->begrun = tmr_req->exp_data_sn;
drivers/target/iscsi/iscsi_target_tmr.c:	struct iscsi_cmd *cmd = tmr_req->ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	if (!tmr_req->ref_cmd) {
drivers/target/iscsi/iscsi_target_tmr.c:	cmd = tmr_req->ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	if (tmr_req->task_reassign &&
drivers/target/iscsi/iscsi_target_tmr.c:	struct iscsi_cmd *cmd = tmr_req->ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:	if (!tmr_req->exp_data_sn)
drivers/target/iscsi/iscsi_target_tmr.c:		if (r2t->r2t_sn >= tmr_req->exp_data_sn)
drivers/target/iscsi/iscsi_target_tmr.c:	cmd->r2t_sn = tmr_req->exp_data_sn;
drivers/target/iscsi/iscsi_target_tmr.c:		if (r2t->r2t_sn < tmr_req->exp_data_sn)
drivers/target/iscsi/iscsi_target_tmr.c:				tmr_req->exp_data_sn, r2t->r2t_sn,
drivers/target/iscsi/iscsi_target_tmr.c:	struct iscsi_cmd *ref_cmd = tmr_req->ref_cmd;
drivers/target/iscsi/iscsi_target_tmr.c:		if (tmr_req->exp_data_sn > ref_cmd->data_sn) {
drivers/target/iscsi/iscsi_target_tmr.c:				" DataSN: 0x%08x.\n", tmr_req->exp_data_sn,
drivers/target/iscsi/iscsi_target_tmr.c:		    (tmr_req->exp_data_sn <= ref_cmd->acked_data_sn)) {
drivers/target/iscsi/iscsi_target_tmr.c:				" protocol error\n", tmr_req->exp_data_sn,
drivers/target/iscsi/iscsi_target_tmr.c:		if (tmr_req->exp_data_sn > ref_cmd->r2t_sn) {
drivers/target/iscsi/iscsi_target_tmr.c:				" R2TSN: 0x%08x.\n", tmr_req->exp_data_sn,
drivers/target/iscsi/iscsi_target_nego.c:	payload_length = ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_nego.c:	switch (login_req->opcode & ISCSI_OPCODE_MASK) {
drivers/target/iscsi/iscsi_target_nego.c:				login_req->opcode & ISCSI_OPCODE_MASK);
drivers/target/iscsi/iscsi_target_nego.c:	if ((login_req->flags & ISCSI_FLAG_LOGIN_CONTINUE) &&
drivers/target/iscsi/iscsi_target_nego.c:	    (login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT)) {
drivers/target/iscsi/iscsi_target_nego.c:	req_csg = ISCSI_LOGIN_CURRENT_STAGE(login_req->flags);
drivers/target/iscsi/iscsi_target_nego.c:	req_nsg = ISCSI_LOGIN_NEXT_STAGE(login_req->flags);
drivers/target/iscsi/iscsi_target_nego.c:	   ((login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT) &&
drivers/target/iscsi/iscsi_target_nego.c:		pr_err("Illegal login_req->flags Combination, CSG: %d,"
drivers/target/iscsi/iscsi_target_nego.c:			req_nsg, (login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT));
drivers/target/iscsi/iscsi_target_nego.c:	if ((login_req->max_version != login->version_max) ||
drivers/target/iscsi/iscsi_target_nego.c:	    (login_req->min_version != login->version_min)) {
drivers/target/iscsi/iscsi_target_nego.c:			login_req->max_version, login_req->min_version);
drivers/target/iscsi/iscsi_target_nego.c:	if (memcmp(login_req->isid, login->isid, 6) != 0) {
drivers/target/iscsi/iscsi_target_nego.c:	if (login_req->itt != login->init_task_tag) {
drivers/target/iscsi/iscsi_target_nego.c:			" 0x%08x, protocol error.\n", login_req->itt);
drivers/target/iscsi/iscsi_target_nego.c:	payload_length = ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_nego.c:		if ((login_req->flags & ISCSI_FLAG_LOGIN_NEXT_STAGE1) &&
drivers/target/iscsi/iscsi_target_nego.c:		    (login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT)) {
drivers/target/iscsi/iscsi_target_nego.c:	payload_length = ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_nego.c:		if ((login_req->flags & ISCSI_FLAG_LOGIN_NEXT_STAGE1) &&
drivers/target/iscsi/iscsi_target_nego.c:		    (login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT)) {
drivers/target/iscsi/iscsi_target_nego.c:	payload_length = ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_nego.c:		if ((login_req->flags & ISCSI_FLAG_LOGIN_NEXT_STAGE3) &&
drivers/target/iscsi/iscsi_target_nego.c:		    (login_req->flags & ISCSI_FLAG_LOGIN_TRANSIT))
drivers/target/iscsi/iscsi_target_nego.c:		switch (ISCSI_LOGIN_CURRENT_STAGE(login_req->flags)) {
drivers/target/iscsi/iscsi_target_nego.c:				ISCSI_LOGIN_CURRENT_STAGE(login_req->flags));
drivers/target/iscsi/iscsi_target_nego.c:	payload_length = ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_login.c:	payload_length	= ntoh24(login_req->dlength);
drivers/target/iscsi/iscsi_target_login.c:		login_req->flags, login_req->itt, login_req->cmdsn,
drivers/target/iscsi/iscsi_target_login.c:		login_req->exp_statsn, login_req->cid, payload_length);
drivers/target/iscsi/iscsi_target_login.c:		login->leading_connection = (!login_req->tsih) ? 1 : 0;
drivers/target/iscsi/iscsi_target_login.c:		login->current_stage	= ISCSI_LOGIN_CURRENT_STAGE(login_req->flags);
drivers/target/iscsi/iscsi_target_login.c:		login->version_min	= login_req->min_version;
drivers/target/iscsi/iscsi_target_login.c:		login->version_max	= login_req->max_version;
drivers/target/iscsi/iscsi_target_login.c:		memcpy(login->isid, login_req->isid, 6);
drivers/target/iscsi/iscsi_target_login.c:		login->cmd_sn		= be32_to_cpu(login_req->cmdsn);
drivers/target/iscsi/iscsi_target_login.c:		login->init_task_tag	= login_req->itt;
drivers/target/iscsi/iscsi_target_login.c:		login->initial_exp_statsn = be32_to_cpu(login_req->exp_statsn);
drivers/target/iscsi/iscsi_target_login.c:		login->cid		= be16_to_cpu(login_req->cid);
drivers/target/iscsi/iscsi_target_login.c:		login->tsih		= be16_to_cpu(login_req->tsih);
drivers/target/loopback/tcm_loop.c:	ret = se_cmd->se_tmr_req->response;
drivers/target/target_core_pscsi.c:	while (req->bio) {
drivers/target/target_core_pscsi.c:		bio = req->bio;
drivers/target/target_core_pscsi.c:		req->bio = bio->bi_next;
drivers/target/target_core_pscsi.c:	req->biotail = NULL;
drivers/target/target_core_pscsi.c:	req->end_io = pscsi_req_done;
drivers/target/target_core_pscsi.c:	req->end_io_data = cmd;
drivers/target/target_core_pscsi.c:		req->timeout = PS_TIMEOUT_DISK;
drivers/target/target_core_pscsi.c:		req->timeout = PS_TIMEOUT_OTHER;
drivers/target/target_core_pscsi.c:	struct se_cmd *cmd = req->end_io_data;
drivers/target/target_core_transport.c:			cmd->se_tmr_req->response = TMR_FUNCTION_REJECTED;
drivers/target/target_core_transport.c:	se_cmd->se_tmr_req->response = TMR_LUN_DOES_NOT_EXIST;
drivers/target/target_core_transport.c:		se_cmd->se_tmr_req->ref_task_tag = tag;
drivers/target/target_core_transport.c:				    cmd->se_tmr_req->function,
drivers/target/target_core_transport.c:				    cmd->se_tmr_req->ref_task_tag, cmd->tag);
drivers/target/sbp/sbp_target.c:	ret = sbp_run_transaction(req->card, TCODE_READ_QUADLET_REQUEST,
drivers/target/sbp/sbp_target.c:			req->node_addr, req->generation, req->speed,
drivers/target/sbp/sbp_target.c:	ret = sbp_run_transaction(req->card, TCODE_READ_QUADLET_REQUEST,
drivers/target/sbp/sbp_target.c:			req->node_addr, req->generation, req->speed,
drivers/target/sbp/sbp_target.c:			LOGIN_ORB_LUN(be32_to_cpu(req->orb.misc)), &ret);
drivers/target/sbp/sbp_target.c:			LOGIN_ORB_LUN(be32_to_cpu(req->orb.misc)));
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	if (LOGIN_ORB_EXCLUSIVE(be32_to_cpu(req->orb.misc)) &&
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:			req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		sess->node_id = req->node_addr;
drivers/target/sbp/sbp_target.c:		sess->card = fw_card_get(req->card);
drivers/target/sbp/sbp_target.c:		sess->generation = req->generation;
drivers/target/sbp/sbp_target.c:		sess->speed = req->speed;
drivers/target/sbp/sbp_target.c:		1 << LOGIN_ORB_RECONNECT(be32_to_cpu(req->orb.misc)),
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	login->status_fifo_addr = sbp2_pointer_to_addr(&req->orb.status_fifo);
drivers/target/sbp/sbp_target.c:	login->exclusive = LOGIN_ORB_EXCLUSIVE(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:			LOGIN_ORB_RESPONSE_LENGTH(be32_to_cpu(req->orb.length)),
drivers/target/sbp/sbp_target.c:		sbp2_pointer_to_addr(&req->orb.ptr2), response,
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		RECONNECT_ORB_LOGIN_ID(be32_to_cpu(req->orb.misc)));
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	login->sess->generation = req->generation;
drivers/target/sbp/sbp_target.c:	login->sess->node_id = req->node_addr;
drivers/target/sbp/sbp_target.c:	login->sess->card = fw_card_get(req->card);
drivers/target/sbp/sbp_target.c:	login->sess->speed = req->speed;
drivers/target/sbp/sbp_target.c:	req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	id = LOGOUT_ORB_LOGIN_ID(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	if (req->node_addr != login->sess->node_id) {
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:			req->orb_pointer,
drivers/target/sbp/sbp_target.c:			sbp2_pointer_to_addr(&req->orb.next_orb),
drivers/target/sbp/sbp_target.c:			sbp2_pointer_to_addr(&req->orb.data_descriptor),
drivers/target/sbp/sbp_target.c:			be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	if (req->orb_pointer >> 32)
drivers/target/sbp/sbp_target.c:	switch (ORB_REQUEST_FORMAT(be32_to_cpu(req->orb.misc))) {
drivers/target/sbp/sbp_target.c:			req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:			req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->se_cmd.map_tag = tag;
drivers/target/sbp/sbp_target.c:	req->se_cmd.map_cpu = cpu;
drivers/target/sbp/sbp_target.c:	req->se_cmd.tag = next_orb;
drivers/target/sbp/sbp_target.c:		req->login = agent->login;
drivers/target/sbp/sbp_target.c:		req->orb_pointer = next_orb;
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(STATUS_BLOCK_ORB_OFFSET_HIGH(
drivers/target/sbp/sbp_target.c:					req->orb_pointer >> 32));
drivers/target/sbp/sbp_target.c:		req->status.orb_low = cpu_to_be32(
drivers/target/sbp/sbp_target.c:				req->orb_pointer & 0xfffffffc);
drivers/target/sbp/sbp_target.c:				req->orb_pointer, &req->orb, sizeof(req->orb));
drivers/target/sbp/sbp_target.c:			req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:		if (be32_to_cpu(req->orb.next_orb.high) & 0x80000000) {
drivers/target/sbp/sbp_target.c:			req->status.status |= cpu_to_be32(STATUS_BLOCK_SRC(
drivers/target/sbp/sbp_target.c:			next_orb = sbp2_pointer_to_addr(&req->orb.next_orb);
drivers/target/sbp/sbp_target.c:			req->status.status |= cpu_to_be32(STATUS_BLOCK_SRC(
drivers/target/sbp/sbp_target.c:			INIT_WORK(&req->work, tgt_agent_process_work);
drivers/target/sbp/sbp_target.c:			queue_work(system_unbound_wq, &req->work);
drivers/target/sbp/sbp_target.c:	struct sbp_login_descriptor *login = req->login;
drivers/target/sbp/sbp_target.c:	cmd_len = scsi_command_size(req->orb.command_block);
drivers/target/sbp/sbp_target.c:	req->cmd_buf = kmalloc(cmd_len, GFP_KERNEL);
drivers/target/sbp/sbp_target.c:	if (!req->cmd_buf)
drivers/target/sbp/sbp_target.c:	memcpy(req->cmd_buf, req->orb.command_block,
drivers/target/sbp/sbp_target.c:		min_t(int, cmd_len, sizeof(req->orb.command_block)));
drivers/target/sbp/sbp_target.c:	if (cmd_len > sizeof(req->orb.command_block)) {
drivers/target/sbp/sbp_target.c:		copy_len = cmd_len - sizeof(req->orb.command_block);
drivers/target/sbp/sbp_target.c:				req->orb_pointer + sizeof(req->orb),
drivers/target/sbp/sbp_target.c:				req->cmd_buf + sizeof(req->orb.command_block),
drivers/target/sbp/sbp_target.c:	if (!CMDBLK_ORB_PG_TBL_PRESENT(be32_to_cpu(req->orb.misc)))
drivers/target/sbp/sbp_target.c:	pg_tbl_sz = CMDBLK_ORB_DATA_SIZE(be32_to_cpu(req->orb.misc)) *
drivers/target/sbp/sbp_target.c:			sbp2_pointer_to_addr(&req->orb.data_descriptor),
drivers/target/sbp/sbp_target.c:	req->pg_tbl = pg_tbl;
drivers/target/sbp/sbp_target.c:	data_size = CMDBLK_ORB_DATA_SIZE(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	direction = CMDBLK_ORB_DIRECTION(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	if (req->pg_tbl) {
drivers/target/sbp/sbp_target.c:					req->pg_tbl[idx].segment_length);
drivers/target/sbp/sbp_target.c:	struct sbp_login_descriptor *login = req->login;
drivers/target/sbp/sbp_target.c:	unpacked_lun = req->login->login_lun;
drivers/target/sbp/sbp_target.c:			req->orb_pointer, unpacked_lun, data_length, data_dir);
drivers/target/sbp/sbp_target.c:	req->se_cmd.tag = req->orb_pointer;
drivers/target/sbp/sbp_target.c:	if (target_submit_cmd(&req->se_cmd, sess->se_sess, req->cmd_buf,
drivers/target/sbp/sbp_target.c:			      req->sense_buf, unpacked_lun, data_length,
drivers/target/sbp/sbp_target.c:	req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	struct sbp_session *sess = req->login->sess;
drivers/target/sbp/sbp_target.c:	if (req->se_cmd.data_direction == DMA_FROM_DEVICE) {
drivers/target/sbp/sbp_target.c:	max_payload = 4 << CMDBLK_ORB_MAX_PAYLOAD(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	speed = CMDBLK_ORB_SPEED(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	pg_size = CMDBLK_ORB_PG_SIZE(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:	if (req->pg_tbl) {
drivers/target/sbp/sbp_target.c:		pte = req->pg_tbl;
drivers/target/sbp/sbp_target.c:		num_pte = CMDBLK_ORB_DATA_SIZE(be32_to_cpu(req->orb.misc));
drivers/target/sbp/sbp_target.c:		offset = sbp2_pointer_to_addr(&req->orb.data_descriptor);
drivers/target/sbp/sbp_target.c:		length = req->se_cmd.data_length;
drivers/target/sbp/sbp_target.c:	sg_miter_start(&iter, req->se_cmd.t_data_sg, req->se_cmd.t_data_nents,
drivers/target/sbp/sbp_target.c:	struct sbp_login_descriptor *login = req->login;
drivers/target/sbp/sbp_target.c:	length = (((be32_to_cpu(req->status.status) >> 24) & 0x07) + 1) * 4;
drivers/target/sbp/sbp_target.c:			login->status_fifo_addr, &req->status, length);
drivers/target/sbp/sbp_target.c:			req->orb_pointer);
drivers/target/sbp/sbp_target.c:	target_put_sess_cmd(&req->se_cmd);
drivers/target/sbp/sbp_target.c:	struct se_cmd *se_cmd = &req->se_cmd;
drivers/target/sbp/sbp_target.c:	u8 *sense = req->sense_buf;
drivers/target/sbp/sbp_target.c:	u8 *status = req->status.data;
drivers/target/sbp/sbp_target.c:		req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	struct se_cmd *se_cmd = &req->se_cmd;
drivers/target/sbp/sbp_target.c:		req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	struct se_cmd *se_cmd = &req->se_cmd;
drivers/target/sbp/sbp_target.c:	kfree(req->pg_tbl);
drivers/target/sbp/sbp_target.c:	kfree(req->cmd_buf);
drivers/target/sbp/sbp_target.c:	ret = sbp_run_transaction(req->card, TCODE_READ_BLOCK_REQUEST,
drivers/target/sbp/sbp_target.c:		req->node_addr, req->generation, req->speed,
drivers/target/sbp/sbp_target.c:		agent->orb_offset, &req->orb, sizeof(req->orb));
drivers/target/sbp/sbp_target.c:		sbp2_pointer_to_addr(&req->orb.ptr1),
drivers/target/sbp/sbp_target.c:		sbp2_pointer_to_addr(&req->orb.ptr2),
drivers/target/sbp/sbp_target.c:		be32_to_cpu(req->orb.misc), be32_to_cpu(req->orb.length),
drivers/target/sbp/sbp_target.c:		sbp2_pointer_to_addr(&req->orb.status_fifo));
drivers/target/sbp/sbp_target.c:	if (!ORB_NOTIFY(be32_to_cpu(req->orb.misc)) ||
drivers/target/sbp/sbp_target.c:		ORB_REQUEST_FORMAT(be32_to_cpu(req->orb.misc)) != 0) {
drivers/target/sbp/sbp_target.c:	switch (MANAGEMENT_ORB_FUNCTION(be32_to_cpu(req->orb.misc))) {
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:			MANAGEMENT_ORB_FUNCTION(be32_to_cpu(req->orb.misc)));
drivers/target/sbp/sbp_target.c:		req->status.status = cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	req->status.orb_low = cpu_to_be32(agent->orb_offset);
drivers/target/sbp/sbp_target.c:	ret = sbp_run_transaction(req->card, TCODE_WRITE_BLOCK_REQUEST,
drivers/target/sbp/sbp_target.c:		req->node_addr, req->generation, req->speed,
drivers/target/sbp/sbp_target.c:		sbp2_pointer_to_addr(&req->orb.status_fifo),
drivers/target/sbp/sbp_target.c:		&req->status, 8 + status_data_len);
drivers/target/sbp/sbp_target.c:	fw_card_put(req->card);
drivers/target/sbp/sbp_target.c:		req->card = fw_card_get(card);
drivers/target/sbp/sbp_target.c:		req->generation = generation;
drivers/target/sbp/sbp_target.c:		req->node_addr = source;
drivers/target/sbp/sbp_target.c:		req->speed = fw_get_request_speed(request);
drivers/target/sbp/sbp_target.c:		req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:		req->status.status |= cpu_to_be32(
drivers/target/sbp/sbp_target.c:	return transport_generic_free_cmd(&req->se_cmd, 0);
drivers/nfc/st21nfca/dep.c:	gb_len = atr_req->length - sizeof(struct st21nfca_atr_req);
drivers/nfc/st21nfca/dep.c:	skb = alloc_skb(atr_req->length + 1, GFP_KERNEL);
drivers/nfc/st21nfca/dep.c:	atr_res->length = atr_req->length + 1;
drivers/nfc/st21nfca/dep.c:	memcpy(atr_res->nfcid3, atr_req->nfcid3, 6);
drivers/nfc/st21nfca/dep.c:		memcpy(atr_res->gbi, atr_req->gbi, gb_len);
drivers/nfc/st21nfca/dep.c:	if (atr_req->length < sizeof(struct st21nfca_atr_req)) {
drivers/nfc/st21nfca/dep.c:			      NFC_COMM_PASSIVE, atr_req->gbi, gb_len);
drivers/nfc/st21nfca/dep.c:	psl_res->did = psl_req->did;
drivers/nfc/st21nfca/dep.c:	if (ST21NFCA_PSL_REQ_SEND_SPEED(psl_req->brs) &&
drivers/nfc/st21nfca/dep.c:	    ST21NFCA_PSL_REQ_RECV_SPEED(psl_req->brs)) {
drivers/nfc/st21nfca/dep.c:	if (ST21NFCA_NFC_DEP_DID_BIT_SET(dep_req->pfb))
drivers/nfc/st21nfca/dep.c:	if (ST21NFCA_NFC_DEP_NAD_BIT_SET(dep_req->pfb))
drivers/nfc/st21nfca/dep.c:	switch (ST21NFCA_NFC_DEP_PFB_TYPE(dep_req->pfb)) {
drivers/nfc/st21nfca/dep.c:				ST21NFCA_NFC_DEP_PFB_PNI(dep_req->pfb);
drivers/nfc/st21nfca/dep.c:	psl_req->length = sizeof(struct st21nfca_psl_req);
drivers/nfc/st21nfca/dep.c:	psl_req->cmd0 = ST21NFCA_NFCIP1_REQ;
drivers/nfc/st21nfca/dep.c:	psl_req->cmd1 = ST21NFCA_NFCIP1_PSL_REQ;
drivers/nfc/st21nfca/dep.c:	psl_req->did = did;
drivers/nfc/st21nfca/dep.c:	psl_req->brs = (0x30 & bsi << 4) | (bri & 0x03);
drivers/nfc/st21nfca/dep.c:	psl_req->fsl = lri;
drivers/nfc/st21nfca/dep.c:	atr_req->cmd0 = ST21NFCA_NFCIP1_REQ;
drivers/nfc/st21nfca/dep.c:	atr_req->cmd1 = ST21NFCA_NFCIP1_ATR_REQ;
drivers/nfc/st21nfca/dep.c:	memset(atr_req->nfcid3, 0, NFC_NFCID3_MAXSIZE);
drivers/nfc/st21nfca/dep.c:		memcpy(atr_req->nfcid3, target->sensf_res,
drivers/nfc/st21nfca/dep.c:		get_random_bytes(atr_req->nfcid3, NFC_NFCID3_MAXSIZE);
drivers/nfc/st21nfca/dep.c:	atr_req->did = 0x0;
drivers/nfc/st21nfca/dep.c:	atr_req->bsi = 0x00;
drivers/nfc/st21nfca/dep.c:	atr_req->bri = 0x00;
drivers/nfc/st21nfca/dep.c:	atr_req->ppi = ST21NFCA_LR_BITS_PAYLOAD_SIZE_254B;
drivers/nfc/st21nfca/dep.c:		atr_req->ppi |= ST21NFCA_GB_BIT;
drivers/nfc/st21nfca/dep.c:	atr_req->length = sizeof(struct st21nfca_atr_req) + hdev->gb_len;
drivers/nfc/st21nfca/dep.c:	info->dep_info.bri = atr_req->bri;
drivers/nfc/st21nfca/dep.c:	info->dep_info.bsi = atr_req->bsi;
drivers/nfc/st21nfca/dep.c:	info->dep_info.lri = ST21NFCA_PP2LRI(atr_req->ppi);
drivers/phy/qualcomm/phy-qcom-qmp.c:	switch (req->rate) {
drivers/phy/qualcomm/phy-qcom-qmp.c:	switch (req->rate) {
drivers/perf/fsl_imx8_ddr_perf.c:	IMX8_DDR_PMU_EVENT_ATTR(hp-req-nocredit, 0x24),
drivers/perf/fsl_imx8_ddr_perf.c:	IMX8_DDR_PMU_EVENT_ATTR(lp-req-nocredit, 0x26),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(input-req-async-fifo-stall,	0x12),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(output-req-async-fifo-stall,	0x13),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-all,		0x01),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-rd,		0x02),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-req-buf-alloc-wr,		0x03),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-rd-shared-req-issued,		0x10),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-rd-exclusive-req-issued,	0x11),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-wr-invalidate-req-issued-stashable, 0x12),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-wr-invalidate-req-issued-nonstashable, 0x13),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-wr-back-req-issued-stashable,	0x14),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-wr-back-req-issued-nonstashable, 0x15),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(pa-req-buffer-full,		0x28),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(cswlf-outbound-req-fifo-full,	0x29),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(cswlf-inbound-req-backpressure,	0x2f),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(req-receive,			0x01),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-recv,			0x02),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-recv-2,			0x03),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(wr-req-recv,			0x04),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(wr-req-recv-2,			0x05),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-sent-to-mcu,		0x06),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-sent-to-mcu-2,		0x07),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-sent-to-spec-mcu,		0x08),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(rd-req-sent-to-spec-mcu-2,		0x09),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(glbl-ack-go-recv-any-rd-req-2,	0x0e),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(wr-req-sent-to-mcu,		0x0f),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(mcb-csw-req-stall,			0x15),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(mcu-req-intf-blocked,		0x16),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(mcu-req-table-full,		0x1a),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(mcu-req-from-lastload,		0x21),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(mcu-req-from-bypass,		0x22),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(hprd-lprd-wr-req-vld,		0x12),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(lprd-req-vld,			0x13),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(hprd-req-vld,			0x14),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(hprd-lprd-req-vld,			0x15),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(wr-req-vld,			0x16),
drivers/perf/xgene_pmu.c:	XGENE_PMU_EVENT_ATTR(partial-wr-req-vld,		0x17),
drivers/iio/adc/twl4030-madc.c: * req->rbuf will be filled with read values of channels based on the
drivers/iio/adc/twl4030-madc.c:	if (req->method < TWL4030_MADC_RT || req->method > TWL4030_MADC_SW2) {
drivers/iio/adc/twl4030-madc.c:	if (twl4030_madc->requests[req->method].active) {
drivers/iio/adc/twl4030-madc.c:	method = &twl4030_conversion_methods[req->method];
drivers/iio/adc/twl4030-madc.c:	ret = twl_i2c_write_u16(TWL4030_MODULE_MADC, req->channels, method->sel);
drivers/iio/adc/twl4030-madc.c:	if (req->do_avg) {
drivers/iio/adc/twl4030-madc.c:		ret = twl_i2c_write_u16(TWL4030_MODULE_MADC, req->channels,
drivers/iio/adc/twl4030-madc.c:	if (req->method == TWL4030_MADC_RT) {
drivers/iio/adc/twl4030-madc.c:	ret = twl4030_madc_start_conversion(twl4030_madc, req->method);
drivers/iio/adc/twl4030-madc.c:	twl4030_madc->requests[req->method].active = true;
drivers/iio/adc/twl4030-madc.c:		twl4030_madc->requests[req->method].active = false;
drivers/iio/adc/twl4030-madc.c:					 req->channels, req->rbuf, req->raw);
drivers/iio/adc/twl4030-madc.c:	twl4030_madc->requests[req->method].active = false;
drivers/iio/adc/cpcap-adc.c:	switch (req->channel) {
drivers/iio/adc/cpcap-adc.c:	switch (req->timing) {
drivers/iio/adc/cpcap-adc.c:	if (req->timing == CPCAP_ADC_TIMING_IMM) {
drivers/iio/adc/cpcap-adc.c:	req->timing = CPCAP_ADC_TIMING_IMM;
drivers/iio/adc/cpcap-adc.c:	const struct cpcap_adc_conversion_tbl *conv_tbl = req->conv_tbl;
drivers/iio/adc/cpcap-adc.c:	const struct cpcap_adc_phasing_tbl *phase_tbl = req->phase_tbl;
drivers/iio/adc/cpcap-adc.c:	int index = req->channel;
drivers/iio/adc/cpcap-adc.c:	switch (req->channel) {
drivers/iio/adc/cpcap-adc.c:		index = req->bank_index;
drivers/iio/adc/cpcap-adc.c:		req->result -= phase_tbl[index].offset;
drivers/iio/adc/cpcap-adc.c:		req->result -= CPCAP_FOUR_POINT_TWO_ADC;
drivers/iio/adc/cpcap-adc.c:		req->result *= phase_tbl[index].multiplier;
drivers/iio/adc/cpcap-adc.c:		req->result /= phase_tbl[index].divider;
drivers/iio/adc/cpcap-adc.c:		req->result += CPCAP_FOUR_POINT_TWO_ADC;
drivers/iio/adc/cpcap-adc.c:		index = req->bank_index;
drivers/iio/adc/cpcap-adc.c:		req->result += conv_tbl[index].cal_offset;
drivers/iio/adc/cpcap-adc.c:		req->result += conv_tbl[index].align_offset;
drivers/iio/adc/cpcap-adc.c:		req->result *= phase_tbl[index].multiplier;
drivers/iio/adc/cpcap-adc.c:		req->result /= phase_tbl[index].divider;
drivers/iio/adc/cpcap-adc.c:		req->result += phase_tbl[index].offset;
drivers/iio/adc/cpcap-adc.c:	if (req->result < phase_tbl[index].min)
drivers/iio/adc/cpcap-adc.c:		req->result = phase_tbl[index].min;
drivers/iio/adc/cpcap-adc.c:	else if (req->result > phase_tbl[index].max)
drivers/iio/adc/cpcap-adc.c:		req->result = phase_tbl[index].max;
drivers/iio/adc/cpcap-adc.c:	const struct cpcap_adc_conversion_tbl *conv_tbl = req->conv_tbl;
drivers/iio/adc/cpcap-adc.c:	int index = req->channel;
drivers/iio/adc/cpcap-adc.c:	switch (req->channel) {
drivers/iio/adc/cpcap-adc.c:	if ((req->channel == CPCAP_ADC_AD0) ||
drivers/iio/adc/cpcap-adc.c:	    (req->channel == CPCAP_ADC_AD3)) {
drivers/iio/adc/cpcap-adc.c:		req->result =
drivers/iio/adc/cpcap-adc.c:			cpcap_adc_table_to_millicelcius(req->result);
drivers/iio/adc/cpcap-adc.c:	req->result *= conv_tbl[index].multiplier;
drivers/iio/adc/cpcap-adc.c:	req->result /= conv_tbl[index].divider;
drivers/iio/adc/cpcap-adc.c:	req->result += conv_tbl[index].conv_offset;
drivers/iio/adc/cpcap-adc.c:	addr = CPCAP_REG_ADCD0 + req->bank_index * 4;
drivers/iio/adc/cpcap-adc.c:	error = regmap_read(ddata->reg, addr, &req->result);
drivers/iio/adc/cpcap-adc.c:	req->result &= 0x3ff;
drivers/iio/adc/cpcap-adc.c:	req->channel = channel;
drivers/iio/adc/cpcap-adc.c:	req->phase_tbl = bank_phasing;
drivers/iio/adc/cpcap-adc.c:	req->conv_tbl = bank_conversion;
drivers/iio/adc/cpcap-adc.c:		req->bank_index = channel;
drivers/iio/adc/cpcap-adc.c:		req->bank_index = channel - 8;
drivers/iio/adc/cpcap-adc.c:		req->bank_index = CPCAP_ADC_BATTP;
drivers/iio/adc/cpcap-adc.c:		req->bank_index = CPCAP_ADC_BATTI;
drivers/iio/pressure/zpa2326.c:	err = regmap_write(regs, ZPA2326_CTRL_REG3_REG, freq->odr);
drivers/iio/pressure/zpa2326.c:	zpa2326_dbg(indio_dev, "one shot mode setup @%dHz", freq->hz);
drivers/iio/dac/ad5755.c:	if (!of_property_read_u32(np, "adi,dc-dc-freq-hz", &tmp)) {
drivers/thermal/devfreq_cooling.c:	for (i = 0, freq = ULONG_MAX; i < num_opps; i++, freq--) {
drivers/thermal/devfreq_cooling.c:	snprintf(dev_name, sizeof(dev_name), "thermal-devfreq-%d", dfc->id);
drivers/thermal/devfreq_cooling.c:	dev = dfc->devfreq->dev.parent;
drivers/thermal/cpufreq_cooling.c: * "thermal-cpufreq-%x". This api can support multiple instances of cpufreq
drivers/thermal/cpufreq_cooling.c:	snprintf(dev_name, sizeof(dev_name), "thermal-cpufreq-%d",
drivers/thermal/cpufreq_cooling.c: * "thermal-cpufreq-%x". This api can support multiple instances of cpufreq
drivers/thermal/cpufreq_cooling.c: * "thermal-cpufreq-%x". This api can support multiple instances of cpufreq
drivers/thermal/cpufreq_cooling.c: * This interface function unregisters the "thermal-cpufreq-%x" cooling device.
drivers/thermal/tegra/tegra-bpmp-thermal.c:	if (req->type != CMD_THERMAL_HOST_TRIP_REACHED) {
drivers/thermal/tegra/tegra-bpmp-thermal.c:			__func__, req->type);
drivers/thermal/tegra/tegra-bpmp-thermal.c:		if (tegra->zones[i]->idx != req->host_trip_reached.zone)
drivers/thermal/tegra/tegra-bpmp-thermal.c:		req->host_trip_reached.zone);
drivers/mfd/ezx-pcap.c:	tmp |= (req->ch[0] << PCAP_ADC_ADA1_SHIFT);
drivers/mfd/ezx-pcap.c:	tmp |= (req->ch[1] << PCAP_ADC_ADA2_SHIFT);
drivers/mfd/ezx-pcap.c:	req->callback(req->data, res);
drivers/mfd/ezx-pcap.c:	req->bank = bank;
drivers/mfd/ezx-pcap.c:	req->flags = flags;
drivers/mfd/ezx-pcap.c:	req->ch[0] = ch[0];
drivers/mfd/ezx-pcap.c:	req->ch[1] = ch[1];
drivers/mfd/ezx-pcap.c:	req->callback = callback;
drivers/mfd/ezx-pcap.c:	req->data = data;
drivers/mfd/ezx-pcap.c:	req->res[0] = res[0];
drivers/mfd/ezx-pcap.c:	req->res[1] = res[1];
drivers/mfd/ezx-pcap.c:	complete(&req->completion);
drivers/mfd/pcf50633-adc.c:	req->result = result;
drivers/mfd/pcf50633-adc.c:	complete(&req->completion);
drivers/mfd/pcf50633-adc.c:	req->mux = mux;
drivers/mfd/pcf50633-adc.c:	req->avg = avg;
drivers/mfd/pcf50633-adc.c:	req->callback = callback;
drivers/mfd/pcf50633-adc.c:	req->callback_param = callback_param;
drivers/mfd/pcf50633-adc.c:	req->callback(pcf, req->callback_param, res);
drivers/mfd/wm831x-auxadc.c:	init_completion(&req->done);
drivers/mfd/wm831x-auxadc.c:	req->input = input;
drivers/mfd/wm831x-auxadc.c:	req->val = -ETIMEDOUT;
drivers/mfd/wm831x-auxadc.c:	list_add(&req->list, &wm831x->auxadc_pending);
drivers/mfd/wm831x-auxadc.c:	wait_for_completion_timeout(&req->done, msecs_to_jiffies(500));
drivers/mfd/wm831x-auxadc.c:	ret = req->val;
drivers/mfd/wm831x-auxadc.c:	list_del(&req->list);
drivers/mfd/wm831x-auxadc.c:		if (req->input == input) {
drivers/mfd/wm831x-auxadc.c:			req->val = val;
drivers/mfd/wm831x-auxadc.c:			complete(&req->done);
drivers/virt/acrn/ioreq.c:	polling_mode = acrn_req->completion_polling;
drivers/virt/acrn/ioreq.c:	smp_store_release(&acrn_req->processed, ACRN_IOREQ_STATE_COMPLETE);
drivers/virt/acrn/ioreq.c:	return ((req->type == ACRN_IOREQ_TYPE_PORTIO) &&
drivers/virt/acrn/ioreq.c:		(req->reqs.pio_request.address == 0xcf8));
drivers/virt/acrn/ioreq.c:	return ((req->type == ACRN_IOREQ_TYPE_PORTIO) &&
drivers/virt/acrn/ioreq.c:		((req->reqs.pio_request.address >= 0xcfc) &&
drivers/virt/acrn/ioreq.c:		 (req->reqs.pio_request.address < (0xcfc + 4))));
drivers/virt/acrn/ioreq.c:		WARN_ON(req->reqs.pio_request.size != 4);
drivers/virt/acrn/ioreq.c:		if (req->reqs.pio_request.direction == ACRN_IOREQ_DIR_WRITE)
drivers/virt/acrn/ioreq.c:			vm->pci_conf_addr = req->reqs.pio_request.value;
drivers/virt/acrn/ioreq.c:			req->reqs.pio_request.value = vm->pci_conf_addr;
drivers/virt/acrn/ioreq.c:			if (req->reqs.pio_request.direction ==
drivers/virt/acrn/ioreq.c:				req->reqs.pio_request.value = 0xffffffff;
drivers/virt/acrn/ioreq.c:			offset = req->reqs.pio_request.address - 0xcfc;
drivers/virt/acrn/ioreq.c:			req->type = ACRN_IOREQ_TYPE_PCICFG;
drivers/virt/acrn/ioreq.c:			req->reqs.pci_request.bus =
drivers/virt/acrn/ioreq.c:			req->reqs.pci_request.dev =
drivers/virt/acrn/ioreq.c:			req->reqs.pci_request.func =
drivers/virt/acrn/ioreq.c:			req->reqs.pci_request.reg = pci_reg + offset;
drivers/virt/acrn/ioreq.c:	if (range->type == req->type) {
drivers/virt/acrn/ioreq.c:		switch (req->type) {
drivers/virt/acrn/ioreq.c:			if (req->reqs.mmio_request.address >= range->start &&
drivers/virt/acrn/ioreq.c:			    (req->reqs.mmio_request.address +
drivers/virt/acrn/ioreq.c:			     req->reqs.mmio_request.size - 1) <= range->end)
drivers/virt/acrn/ioreq.c:			if (req->reqs.pio_request.address >= range->start &&
drivers/virt/acrn/ioreq.c:			    (req->reqs.pio_request.address +
drivers/virt/acrn/ioreq.c:			     req->reqs.pio_request.size - 1) <= range->end)
drivers/virt/acrn/ioreq.c:		if (smp_load_acquire(&req->processed) ==
drivers/virt/acrn/ioreq.c:				req->kernel_handled = 1;
drivers/virt/acrn/ioreq.c:				req->kernel_handled = 0;
drivers/virt/acrn/ioreq.c:			smp_store_release(&req->processed,
drivers/virt/acrn/ioeventfd.c:	if (req->type == ACRN_IOREQ_TYPE_MMIO) {
drivers/virt/acrn/ioeventfd.c:		if (req->reqs.mmio_request.direction == ACRN_IOREQ_DIR_READ) {
drivers/virt/acrn/ioeventfd.c:			req->reqs.mmio_request.value = 0;
drivers/virt/acrn/ioeventfd.c:		addr = req->reqs.mmio_request.address;
drivers/virt/acrn/ioeventfd.c:		size = req->reqs.mmio_request.size;
drivers/virt/acrn/ioeventfd.c:		val = req->reqs.mmio_request.value;
drivers/virt/acrn/ioeventfd.c:		if (req->reqs.pio_request.direction == ACRN_IOREQ_DIR_READ) {
drivers/virt/acrn/ioeventfd.c:			req->reqs.pio_request.value = 0;
drivers/virt/acrn/ioeventfd.c:		addr = req->reqs.pio_request.address;
drivers/virt/acrn/ioeventfd.c:		size = req->reqs.pio_request.size;
drivers/virt/acrn/ioeventfd.c:		val = req->reqs.pio_request.value;
drivers/virt/acrn/ioeventfd.c:	p = hsm_ioeventfd_match(client->vm, addr, val, size, req->type);
drivers/virt/vboxguest/vboxguest_utils.c:	req->size = len;
drivers/virt/vboxguest/vboxguest_utils.c:	req->version = VMMDEV_REQUEST_HEADER_VERSION;
drivers/virt/vboxguest/vboxguest_utils.c:	req->request_type = req_type;
drivers/virt/vboxguest/vboxguest_utils.c:	req->rc = VERR_GENERAL_FAILURE;
drivers/virt/vboxguest/vboxguest_utils.c:	req->reserved1 = 0;
drivers/virt/vboxguest/vboxguest_utils.c:	req->requestor = requestor;
drivers/virt/vboxguest/vboxguest_utils.c:	gdev->cancel_req->phys_req_to_cancel = virt_to_phys(call);
drivers/virt/vboxguest/vboxguest_linux.c:	gdev->mouse_status_req->mouse_features = 0;
drivers/virt/vboxguest/vboxguest_linux.c:	gdev->mouse_status_req->pointer_pos_x = 0;
drivers/virt/vboxguest/vboxguest_linux.c:	gdev->mouse_status_req->pointer_pos_y = 0;
drivers/virt/vboxguest/vboxguest_linux.c:				 gdev->mouse_status_req->pointer_pos_x);
drivers/virt/vboxguest/vboxguest_linux.c:				 gdev->mouse_status_req->pointer_pos_y);
drivers/virt/vboxguest/vboxguest_core.c:	req->hypervisor_start = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->hypervisor_size = 0;
drivers/virt/vboxguest/vboxguest_core.c:	if (req->hypervisor_size == 0)
drivers/virt/vboxguest/vboxguest_core.c:	hypervisor_size = req->hypervisor_size;
drivers/virt/vboxguest/vboxguest_core.c:	size = PAGE_ALIGN(req->hypervisor_size) + SZ_4M;
drivers/virt/vboxguest/vboxguest_core.c:		req->header.request_type = VMMDEVREQ_SET_HYPERVISOR_INFO;
drivers/virt/vboxguest/vboxguest_core.c:		req->header.rc = VERR_INTERNAL_ERROR;
drivers/virt/vboxguest/vboxguest_core.c:		req->hypervisor_size = hypervisor_size;
drivers/virt/vboxguest/vboxguest_core.c:		req->hypervisor_start =
drivers/virt/vboxguest/vboxguest_core.c:	req->hypervisor_start = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->hypervisor_size = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->facility = VBOXGUEST_FACILITY_TYPE_VBOXGUEST_DRIVER;
drivers/virt/vboxguest/vboxguest_core.c:		req->status = VBOXGUEST_FACILITY_STATUS_ACTIVE;
drivers/virt/vboxguest/vboxguest_core.c:		req->status = VBOXGUEST_FACILITY_STATUS_INACTIVE;
drivers/virt/vboxguest/vboxguest_core.c:	req->flags = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->header.size = sizeof(*req);
drivers/virt/vboxguest/vboxguest_core.c:	req->inflate = true;
drivers/virt/vboxguest/vboxguest_core.c:	req->pages = VMMDEV_MEMORY_BALLOON_CHUNK_PAGES;
drivers/virt/vboxguest/vboxguest_core.c:		req->phys_page[i] = page_to_phys(pages[i]);
drivers/virt/vboxguest/vboxguest_core.c:	req->header.size = sizeof(*req);
drivers/virt/vboxguest/vboxguest_core.c:	req->inflate = false;
drivers/virt/vboxguest/vboxguest_core.c:	req->pages = VMMDEV_MEMORY_BALLOON_CHUNK_PAGES;
drivers/virt/vboxguest/vboxguest_core.c:		req->phys_page[i] = page_to_phys(pages[i]);
drivers/virt/vboxguest/vboxguest_core.c:	req->event_ack = VMMDEV_EVENT_BALLOON_CHANGE_REQUEST;
drivers/virt/vboxguest/vboxguest_core.c:			devm_kcalloc(gdev->dev, req->phys_mem_chunks,
drivers/virt/vboxguest/vboxguest_core.c:		gdev->mem_balloon.max_chunks = req->phys_mem_chunks;
drivers/virt/vboxguest/vboxguest_core.c:	chunks = req->balloon_chunks;
drivers/virt/vboxguest/vboxguest_core.c:	req->enabled = enabled;
drivers/virt/vboxguest/vboxguest_core.c:	req->interval_ns = 0;
drivers/virt/vboxguest/vboxguest_core.c:	do_div(req->interval_ns, 1000000); /* ns -> ms */
drivers/virt/vboxguest/vboxguest_core.c:	gdev->heartbeat_interval_ms = req->interval_ns;
drivers/virt/vboxguest/vboxguest_core.c:	req->not_mask = U32_MAX & ~fixed_events;
drivers/virt/vboxguest/vboxguest_core.c:	req->or_mask = fixed_events;
drivers/virt/vboxguest/vboxguest_core.c:	req->or_mask = or_mask;
drivers/virt/vboxguest/vboxguest_core.c:	req->not_mask = ~or_mask;
drivers/virt/vboxguest/vboxguest_core.c:	req->not_mask = U32_MAX;
drivers/virt/vboxguest/vboxguest_core.c:	req->or_mask = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->or_mask = caps;
drivers/virt/vboxguest/vboxguest_core.c:	req->not_mask = ~caps;
drivers/virt/vboxguest/vboxguest_core.c:		 req->major, req->minor, req->build, req->revision);
drivers/virt/vboxguest/vboxguest_core.c:	gdev->host_features = req->features;
drivers/virt/vboxguest/vboxguest_core.c:	if (!(req->features & VMMDEV_HVF_HGCM_PHYS_PAGE_LIST)) {
drivers/virt/vboxguest/vboxguest_core.c:	switch (req->request_type) {
drivers/virt/vboxguest/vboxguest_core.c:			req->request_type);
drivers/virt/vboxguest/vboxguest_core.c:			req->request_type);
drivers/virt/vboxguest/vboxguest_core.c:	req->flags = dump->u.in.flags;
drivers/virt/vboxguest/vboxguest_core.c:	req->mouse_features = features;
drivers/virt/vboxguest/vboxguest_core.c:	req->pointer_pos_x = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->pointer_pos_y = 0;
drivers/virt/vboxguest/vboxguest_core.c:	req->header.rc = VERR_INTERNAL_ERROR;
drivers/virt/vboxguest/vboxguest_core.c:	req->events = 0;
drivers/virt/vboxguest/vboxguest_core.c:	events = req->events;
drivers/clk/qcom/clk-rcg2.c:	unsigned long clk_flags, rate = req->rate;
drivers/clk/qcom/clk-rcg2.c:				rate = req->rate;
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_hw = p;
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_rate = rate;
drivers/clk/qcom/clk-rcg2.c:	req->rate = f->freq;
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_hw = clk_hw_get_parent_by_index(hw, index);
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_rate = clk_hw_get_rate(req->best_parent_hw);
drivers/clk/qcom/clk-rcg2.c:	if (req->best_parent_rate == 810000000)
drivers/clk/qcom/clk-rcg2.c:		request = req->rate;
drivers/clk/qcom/clk-rcg2.c:		if ((req->best_parent_rate < (request - delta)) ||
drivers/clk/qcom/clk-rcg2.c:		    (req->best_parent_rate > (request + delta)))
drivers/clk/qcom/clk-rcg2.c:		req->rate = calc_rate(req->best_parent_rate,
drivers/clk/qcom/clk-rcg2.c:	if (req->rate == 0)
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_hw = p = clk_hw_get_parent_by_index(hw, index);
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_rate = parent_rate = clk_hw_round_rate(p, req->rate);
drivers/clk/qcom/clk-rcg2.c:	div = DIV_ROUND_UP((2 * parent_rate), req->rate) - 1;
drivers/clk/qcom/clk-rcg2.c:	req->rate = calc_rate(parent_rate, 0, 0, 0, div);
drivers/clk/qcom/clk-rcg2.c:	unsigned long rate = req->rate;
drivers/clk/qcom/clk-rcg2.c:	p = req->best_parent_hw;
drivers/clk/qcom/clk-rcg2.c:	req->best_parent_rate = parent_rate = clk_hw_round_rate(p, rate);
drivers/clk/qcom/clk-rcg2.c:	req->rate = calc_rate(parent_rate, 0, 0, 0, div);
drivers/clk/qcom/clk-rcg2.c:		request = (req->rate * frac->den) / frac->num;
drivers/clk/qcom/clk-rcg2.c:		src_rate = clk_hw_round_rate(req->best_parent_hw, request);
drivers/clk/qcom/clk-rcg2.c:		req->best_parent_rate = src_rate;
drivers/clk/qcom/clk-rcg2.c:		req->rate = (src_rate * frac->num) / frac->den;
drivers/clk/qcom/clk-rcg2.c:	if (req->rate == clk_hw_get_rate(xo)) {
drivers/clk/qcom/clk-rcg2.c:		req->best_parent_hw = xo;
drivers/clk/qcom/clk-rcg2.c:	parent_req.rate = req->rate * mux_div;
drivers/clk/qcom/clk-rcg2.c:		req->rate = req->best_parent_rate = p0_rate;
drivers/clk/qcom/clk-rcg2.c:		req->best_parent_hw = p0;
drivers/clk/qcom/clk-rcg2.c:	if (req->best_parent_hw == p0) {
drivers/clk/qcom/clk-rcg2.c:			req->best_parent_hw = p2;
drivers/clk/qcom/clk-rcg2.c:			req->best_parent_hw = p1;
drivers/clk/qcom/clk-rcg2.c:	} else if (req->best_parent_hw == p2) {
drivers/clk/qcom/clk-rcg2.c:		req->best_parent_hw = p1;
drivers/clk/qcom/clk-rcg2.c:		req->best_parent_hw = p2;
drivers/clk/qcom/clk-rcg2.c:	ret = __clk_determine_rate(req->best_parent_hw, &parent_req);
drivers/clk/qcom/clk-rcg2.c:	req->rate = req->best_parent_rate = parent_req.rate;
drivers/clk/qcom/clk-rcg2.c:	req->rate /= mux_div;
drivers/clk/qcom/clk-rcg2.c:	rational_best_approximation(req->best_parent_rate, req->rate,
drivers/clk/qcom/clk-rcg2.c:	tmp = req->best_parent_rate * num;
drivers/clk/qcom/clk-rcg2.c:	req->rate = tmp;
drivers/clk/qcom/clk-cpu-8996.c:	if (cpuclk->pll_div_2 && req->rate < DIV_2_THRESHOLD) {
drivers/clk/qcom/clk-cpu-8996.c:		if (req->rate < (DIV_2_THRESHOLD / 2))
drivers/clk/qcom/clk-cpu-8996.c:	req->best_parent_rate = clk_hw_round_rate(parent, req->rate);
drivers/clk/qcom/clk-cpu-8996.c:	req->best_parent_hw = parent;
drivers/clk/qcom/clk-regmap-mux-div.c:	unsigned long req_rate = req->rate;
drivers/clk/qcom/clk-regmap-mux-div.c:				req->rate = best_rate;
drivers/clk/qcom/clk-regmap-mux-div.c:				req->best_parent_rate = parent_rate;
drivers/clk/qcom/clk-regmap-mux-div.c:				req->best_parent_hw = parent;
drivers/clk/qcom/clk-pll.c:	f = find_freq(pll->freq_tbl, req->rate);
drivers/clk/qcom/clk-pll.c:		req->rate = clk_pll_recalc_rate(hw, req->best_parent_rate);
drivers/clk/qcom/clk-pll.c:		req->rate = f->freq;
drivers/clk/qcom/clk-rcg.c:	unsigned long clk_flags, rate = req->rate;
drivers/clk/qcom/clk-rcg.c:	req->best_parent_hw = p;
drivers/clk/qcom/clk-rcg.c:	req->best_parent_rate = rate;
drivers/clk/qcom/clk-rcg.c:	req->rate = f->freq;
drivers/clk/qcom/clk-rcg.c:	req->best_parent_hw = p = clk_hw_get_parent_by_index(hw, index);
drivers/clk/qcom/clk-rcg.c:	req->best_parent_rate = clk_hw_round_rate(p, req->rate);
drivers/clk/qcom/clk-rcg.c:	req->rate = req->best_parent_rate;
drivers/clk/qcom/clk-rcg.c:	p = req->best_parent_hw;
drivers/clk/qcom/clk-rcg.c:	req->best_parent_rate = clk_hw_round_rate(p, req->rate);
drivers/clk/qcom/clk-rcg.c:	req->rate = req->best_parent_rate;
drivers/clk/qcom/clk-rcg.c:		request = (req->rate * frac->den) / frac->num;
drivers/clk/qcom/clk-rcg.c:		src_rate = clk_hw_round_rate(req->best_parent_hw, request);
drivers/clk/qcom/clk-rcg.c:		req->best_parent_rate = src_rate;
drivers/clk/qcom/clk-rcg.c:		req->rate = (src_rate * frac->num) / frac->den;
drivers/clk/qcom/clk-rcg.c:	if (req->rate == 0)
drivers/clk/qcom/clk-rcg.c:	src_rate = clk_hw_get_rate(req->best_parent_hw);
drivers/clk/qcom/clk-rcg.c:	div = src_rate / req->rate;
drivers/clk/qcom/clk-rcg.c:		req->best_parent_rate = src_rate;
drivers/clk/qcom/clk-rcg.c:		req->rate = src_rate / div;
drivers/clk/clk-composite.c:		req->best_parent_hw = NULL;
drivers/clk/clk-composite.c:			req->best_parent_hw = parent;
drivers/clk/clk-composite.c:			req->best_parent_rate = clk_hw_get_rate(parent);
drivers/clk/clk-composite.c:			rate = rate_ops->round_rate(rate_hw, req->rate,
drivers/clk/clk-composite.c:						    &req->best_parent_rate);
drivers/clk/clk-composite.c:			req->rate = rate;
drivers/clk/clk-composite.c:			tmp_rate = rate_ops->round_rate(rate_hw, req->rate,
drivers/clk/clk-composite.c:			rate_diff = abs(req->rate - tmp_rate);
drivers/clk/clk-composite.c:			if (!rate_diff || !req->best_parent_hw
drivers/clk/clk-composite.c:				req->best_parent_hw = parent;
drivers/clk/clk-composite.c:				req->best_parent_rate = parent_rate;
drivers/clk/clk-composite.c:		req->rate = best_rate;
drivers/clk/pxa/clk-pxa.c:	unsigned int clkcfg = freq->clkcfg;
drivers/clk/pxa/clk-pxa.c:	if ((preset_mdrefr & MDREFR_DRI_MASK) > mdrefr_dri(freq->membus_khz)) {
drivers/clk/pxa/clk-pxa.c:		preset_mdrefr |= mdrefr_dri(freq->membus_khz);
drivers/clk/pxa/clk-pxa.c:		mdrefr_dri(freq->membus_khz);
drivers/clk/pxa/clk-pxa.c:	if (freq->div2) {
drivers/clk/pxa/clk-pxa.c:	writel(freq->cccr, cccr);
drivers/clk/pxa/clk-pxa.c:		if (rate == req->rate)
drivers/clk/pxa/clk-pxa.c:		if (rate < req->min_rate)
drivers/clk/pxa/clk-pxa.c:		if (rate > req->max_rate)
drivers/clk/pxa/clk-pxa.c:		if (rate <= req->rate)
drivers/clk/pxa/clk-pxa.c:		if ((rate >= req->rate) && (closest_above == -1))
drivers/clk/pxa/clk-pxa.c:	req->best_parent_hw = NULL;
drivers/clk/pxa/clk-pxa.c:		rate = req->rate;
drivers/clk/pxa/clk-pxa.c:		pr_debug("%s(rate=%lu) no match\n", __func__, req->rate);
drivers/clk/pxa/clk-pxa.c:	pr_debug("%s(rate=%lu) rate=%lu\n", __func__, req->rate, rate);
drivers/clk/pxa/clk-pxa.c:	req->rate = rate;
drivers/clk/hisilicon/clk-hi3620.c:	if ((req->rate <= 13000000) && (mclk->id == HI3620_MMC_CIUCLK1)) {
drivers/clk/hisilicon/clk-hi3620.c:		req->rate = 13000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->best_parent_rate = 26000000;
drivers/clk/hisilicon/clk-hi3620.c:	} else if (req->rate <= 26000000) {
drivers/clk/hisilicon/clk-hi3620.c:		req->rate = 25000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->best_parent_rate = 180000000;
drivers/clk/hisilicon/clk-hi3620.c:	} else if (req->rate <= 52000000) {
drivers/clk/hisilicon/clk-hi3620.c:		req->rate = 50000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->best_parent_rate = 360000000;
drivers/clk/hisilicon/clk-hi3620.c:	} else if (req->rate <= 100000000) {
drivers/clk/hisilicon/clk-hi3620.c:		req->rate = 100000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->best_parent_rate = 720000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->rate = 180000000;
drivers/clk/hisilicon/clk-hi3620.c:		req->best_parent_rate = 1440000000;
drivers/clk/imx/clk-pfdv2.c:					req->best_parent_rate
drivers/clk/imx/clk-pfdv2.c:	unsigned long best_rate = -1UL, rate = req->rate;
drivers/clk/imx/clk-pfdv2.c:	unsigned long best_parent_rate = req->best_parent_rate;
drivers/clk/imx/clk-pfdv2.c:		if (abs(tmp - req->rate) < abs(best_rate - req->rate)) {
drivers/clk/imx/clk-pfdv2.c:	req->best_parent_rate = best_parent_rate;
drivers/clk/imx/clk-pfdv2.c:	req->rate = best_rate;
drivers/clk/imx/clk-sscg-pll.c:	req->max_rate = max;
drivers/clk/imx/clk-sscg-pll.c:	req->min_rate = min;
drivers/clk/imx/clk-sscg-pll.c:		ret = clk_sscg_pll_find_setup(setup, req->rate,
drivers/clk/imx/clk-sscg-pll.c:	req->best_parent_hw = parent_hw;
drivers/clk/imx/clk-sscg-pll.c:	req->best_parent_rate = req->rate;
drivers/clk/imx/clk-sscg-pll.c:	req->rate = setup->fout;
drivers/clk/imx/clk-sscg-pll.c:	uint64_t rate = req->rate;
drivers/clk/imx/clk-sscg-pll.c:	uint64_t min = req->min_rate;
drivers/clk/imx/clk-sscg-pll.c:	uint64_t max = req->max_rate;
drivers/clk/imx/clk-sscg-pll.c:	ret = __clk_sscg_pll_determine_rate(hw, req, req->rate, req->rate,
drivers/clk/at91/clk-master.c:		tmp_diff = abs(tmp_rate - req->rate);
drivers/clk/at91/clk-master.c:	req->best_parent_rate = best_rate;
drivers/clk/at91/clk-master.c:	req->best_parent_hw = parent;
drivers/clk/at91/clk-master.c:	req->rate = best_rate;
drivers/clk/at91/clk-master.c:	tmp_diff = abs(req->rate - tmp_rate);
drivers/clk/at91/clk-master.c:		req->best_parent_rate = parent_rate;
drivers/clk/at91/clk-master.c:		req->best_parent_hw = parent;
drivers/clk/at91/clk-master.c:		req_parent.rate = req->rate * pres;
drivers/clk/at91/clk-master.c:			req_parent.rate = req->rate * 3;
drivers/clk/at91/clk-master.c:			req_parent.rate = req->rate << div;
drivers/clk/at91/clk-master.c:		 __clk_get_name((req->best_parent_hw)->clk),
drivers/clk/at91/clk-master.c:		req->best_parent_rate);
drivers/clk/at91/clk-master.c:	req->rate = best_rate;
drivers/clk/at91/clk-audio-pll.c:		 req->rate, req->best_parent_rate);
drivers/clk/at91/clk-audio-pll.c:	req->rate = clamp(req->rate, AUDIO_PLL_FOUT_MIN, AUDIO_PLL_FOUT_MAX);
drivers/clk/at91/clk-audio-pll.c:	req->min_rate = max(req->min_rate, AUDIO_PLL_FOUT_MIN);
drivers/clk/at91/clk-audio-pll.c:	req->max_rate = min(req->max_rate, AUDIO_PLL_FOUT_MAX);
drivers/clk/at91/clk-audio-pll.c:	ret = clk_audio_pll_frac_compute_frac(req->rate, req->best_parent_rate,
drivers/clk/at91/clk-audio-pll.c:	req->rate = clk_audio_pll_fout(req->best_parent_rate, nd, fracr);
drivers/clk/at91/clk-audio-pll.c:	req->best_parent_hw = clk_hw_get_parent(hw);
drivers/clk/at91/clk-audio-pll.c:		 __func__, req->rate, nd, fracr);
drivers/clk/at91/clk-programmable.c:				if (tmp_rate <= req->rate)
drivers/clk/at91/clk-programmable.c:				if (tmp_rate <= req->rate)
drivers/clk/at91/clk-programmable.c:		if (tmp_rate > req->rate)
drivers/clk/at91/clk-programmable.c:		    (req->rate - tmp_rate) < (req->rate - best_rate)) {
drivers/clk/at91/clk-programmable.c:			req->best_parent_rate = parent_rate;
drivers/clk/at91/clk-programmable.c:			req->best_parent_hw = parent;
drivers/clk/at91/clk-programmable.c:	req->rate = best_rate;
drivers/clk/at91/clk-peripheral.c:	unsigned long tmp_diff = abs(req->rate - tmp_rate);
drivers/clk/at91/clk-peripheral.c:		req->best_parent_rate = parent_rate;
drivers/clk/at91/clk-peripheral.c:		req->best_parent_hw = parent;
drivers/clk/at91/clk-peripheral.c:		if (!best_diff || best_rate <= req->rate)
drivers/clk/at91/clk-peripheral.c:		req_parent.rate = req->rate << shift;
drivers/clk/at91/clk-peripheral.c:		 __clk_get_name((req->best_parent_hw)->clk),
drivers/clk/at91/clk-peripheral.c:		 req->best_parent_rate);
drivers/clk/at91/clk-peripheral.c:	req->rate = best_rate;
drivers/clk/at91/clk-generated.c:	tmp_diff = abs(req->rate - tmp_rate);
drivers/clk/at91/clk-generated.c:		req->best_parent_rate = parent_rate;
drivers/clk/at91/clk-generated.c:		req->best_parent_hw = parent;
drivers/clk/at91/clk-generated.c:		div = DIV_ROUND_CLOSEST(parent_rate, req->rate);
drivers/clk/at91/clk-generated.c:		req_parent.rate = req->rate * div;
drivers/clk/at91/clk-generated.c:		 __clk_get_name((req->best_parent_hw)->clk),
drivers/clk/at91/clk-generated.c:		 req->best_parent_rate);
drivers/clk/at91/clk-generated.c:	req->rate = best_rate;
drivers/clk/at91/clk-usb.c:			tmp_parent_rate = req->rate * div;
drivers/clk/at91/clk-usb.c:			if (tmp_rate < req->rate)
drivers/clk/at91/clk-usb.c:				tmp_diff = req->rate - tmp_rate;
drivers/clk/at91/clk-usb.c:				tmp_diff = tmp_rate - req->rate;
drivers/clk/at91/clk-usb.c:				req->best_parent_rate = tmp_parent_rate;
drivers/clk/at91/clk-usb.c:				req->best_parent_hw = parent;
drivers/clk/at91/clk-usb.c:			if (!best_diff || tmp_rate < req->rate)
drivers/clk/at91/clk-usb.c:	req->rate = best_rate;
drivers/clk/clk-plldig.c:	req->rate = clamp(req->rate, PHI1_MIN_FREQ, PHI1_MAX_FREQ);
drivers/clk/clk-plldig.c:	div = plldig_calc_target_div(data->vco_freq, req->rate);
drivers/clk/clk-plldig.c:	req->rate = DIV_ROUND_UP(data->vco_freq, div);
drivers/clk/mmp/clk-mix.c:			gap = abs(mix_rate - req->rate);
drivers/clk/mmp/clk-mix.c:				gap = abs(mix_rate - req->rate);
drivers/clk/mmp/clk-mix.c:	req->best_parent_rate = parent_rate_best;
drivers/clk/mmp/clk-mix.c:	req->best_parent_hw = parent_best;
drivers/clk/mmp/clk-mix.c:	req->rate = mix_rate_best;
drivers/clk/keystone/sci-clk.c:	if (clk->cached_req && clk->cached_req == req->rate) {
drivers/clk/keystone/sci-clk.c:		req->rate = clk->cached_res;
drivers/clk/keystone/sci-clk.c:						      req->min_rate,
drivers/clk/keystone/sci-clk.c:						      req->rate,
drivers/clk/keystone/sci-clk.c:						      req->max_rate,
drivers/clk/keystone/sci-clk.c:	clk->cached_req = req->rate;
drivers/clk/keystone/sci-clk.c:	req->rate = new_rate;
drivers/clk/renesas/rcar-gen3-cpg.c:	prate = req->best_parent_rate / zclk->fixed_div;
drivers/clk/renesas/rcar-gen3-cpg.c:	min_mult = max(div64_ul(req->min_rate * 32ULL, prate), 1ULL);
drivers/clk/renesas/rcar-gen3-cpg.c:	max_mult = min(div64_ul(req->max_rate * 32ULL, prate), 32ULL);
drivers/clk/renesas/rcar-gen3-cpg.c:	mult = div64_ul(req->rate * 32ULL, prate);
drivers/clk/renesas/rcar-gen3-cpg.c:	req->rate = div_u64((u64)prate * mult, 32);
drivers/clk/renesas/rcar-cpg-lib.c:		calc_rate = DIV_ROUND_CLOSEST(req->best_parent_rate,
drivers/clk/renesas/rcar-cpg-lib.c:		if (calc_rate < req->min_rate || calc_rate > req->max_rate)
drivers/clk/renesas/rcar-cpg-lib.c:		diff = calc_rate > req->rate ? calc_rate - req->rate
drivers/clk/renesas/rcar-cpg-lib.c:					     : req->rate - calc_rate;
drivers/clk/renesas/rcar-cpg-lib.c:	req->rate = best_rate;
drivers/clk/renesas/rcar-gen2-cpg.c:	unsigned long prate = req->best_parent_rate;
drivers/clk/renesas/rcar-gen2-cpg.c:	min_mult = max(div64_ul(req->min_rate * 32ULL, prate), 1ULL);
drivers/clk/renesas/rcar-gen2-cpg.c:	max_mult = min(div64_ul(req->max_rate * 32ULL, prate), 32ULL);
drivers/clk/renesas/rcar-gen2-cpg.c:	mult = div64_ul(req->rate * 32ULL, prate);
drivers/clk/renesas/rcar-gen2-cpg.c:	req->rate = div_u64((u64)prate * mult, 32);
drivers/clk/clk.c:		if (mux_is_better_rate(req->rate, parent_req.rate,
drivers/clk/clk.c:		req->best_parent_hw = best_parent->hw;
drivers/clk/clk.c:	req->best_parent_rate = best;
drivers/clk/clk.c:	req->rate = best;
drivers/clk/clk.c:		req->rate = core->rate;
drivers/clk/clk.c:		rate = core->ops->round_rate(core->hw, req->rate,
drivers/clk/clk.c:					     &req->best_parent_rate);
drivers/clk/clk.c:		req->rate = rate;
drivers/clk/clk.c:		req->best_parent_hw = parent->hw;
drivers/clk/clk.c:		req->best_parent_rate = parent->rate;
drivers/clk/clk.c:		req->best_parent_hw = NULL;
drivers/clk/clk.c:		req->best_parent_rate = 0;
drivers/clk/clk.c:		req->rate = 0;
drivers/clk/clk.c:	req->rate = core->rate;
drivers/clk/clk.c:		req->rate = 0;
drivers/clk/microchip/clk-core.c:		if (req->rate > parent_rate)
drivers/clk/microchip/clk-core.c:		nearest_rate = roclk_round_rate(hw, req->rate, &parent_rate);
drivers/clk/microchip/clk-core.c:		delta = abs(nearest_rate - req->rate);
drivers/clk/microchip/clk-core.c:		if ((nearest_rate >= req->rate) && (delta < best_delta)) {
drivers/clk/microchip/clk-core.c:		       __func__, clk_hw_get_name(hw), req->rate);
drivers/clk/microchip/clk-core.c:		 clk_hw_get_name(hw), req->rate,
drivers/clk/microchip/clk-core.c:	if (req->best_parent_rate)
drivers/clk/microchip/clk-core.c:		req->best_parent_rate = best_parent_rate;
drivers/clk/microchip/clk-core.c:	if (req->best_parent_hw)
drivers/clk/microchip/clk-core.c:		req->best_parent_hw = best_parent_clk;
drivers/clk/sunxi-ng/ccu_mp.c:		req->rate *= 2;
drivers/clk/sunxi-ng/ccu_mp.c:		req->min_rate *= 2;
drivers/clk/sunxi-ng/ccu_mp.c:		req->max_rate *= 2;
drivers/clk/sunxi-ng/ccu_mp.c:		req->rate /= 2;
drivers/clk/sunxi-ng/ccu_mp.c:		req->min_rate /= 2;
drivers/clk/sunxi-ng/ccu_mp.c:		req->max_rate /= 2;
drivers/clk/sunxi-ng/ccu_mux.c:				  req->rate, data);
drivers/clk/sunxi-ng/ccu_mux.c:		tmp_rate = round(cm, parent, &parent_rate, req->rate, data);
drivers/clk/sunxi-ng/ccu_mux.c:		if (tmp_rate == req->rate) {
drivers/clk/sunxi-ng/ccu_mux.c:		if ((req->rate - tmp_rate) < (req->rate - best_rate)) {
drivers/clk/sunxi-ng/ccu_mux.c:	req->best_parent_hw = best_parent;
drivers/clk/sunxi-ng/ccu_mux.c:	req->best_parent_rate = best_parent_rate;
drivers/clk/sunxi-ng/ccu_mux.c:	req->rate = best_rate;
drivers/clk/davinci/pll.c:	struct clk_hw *parent = req->best_parent_hw;
drivers/clk/davinci/pll.c:	unsigned long parent_rate = req->best_parent_rate;
drivers/clk/davinci/pll.c:	unsigned long rate = req->rate;
drivers/clk/davinci/pll.c:	if (rate < req->min_rate)
drivers/clk/davinci/pll.c:	rate = min(rate, req->max_rate);
drivers/clk/davinci/pll.c:		if (best_rate < req->min_rate)
drivers/clk/davinci/pll.c:		req->rate = best_rate;
drivers/clk/davinci/pll.c:		if (r < req->min_rate)
drivers/clk/davinci/pll.c:		if (r > rate || r > req->max_rate)
drivers/clk/davinci/pll.c:			req->rate = best_rate;
drivers/clk/davinci/pll.c:			req->best_parent_rate = parent_rate;
drivers/clk/ti/dpll44xx.c:	if (!req->rate)
drivers/clk/ti/dpll44xx.c:	if (clk_hw_get_rate(dd->clk_bypass) == req->rate &&
drivers/clk/ti/dpll44xx.c:		req->best_parent_hw = dd->clk_bypass;
drivers/clk/ti/dpll44xx.c:		req->rate = omap4_dpll_regm4xen_round_rate(hw, req->rate,
drivers/clk/ti/dpll44xx.c:						&req->best_parent_rate);
drivers/clk/ti/dpll44xx.c:		req->best_parent_hw = dd->clk_ref;
drivers/clk/ti/dpll44xx.c:	req->best_parent_rate = req->rate;
drivers/clk/ti/dpll3xxx.c:	if (!req->rate)
drivers/clk/ti/dpll3xxx.c:	if (clk_hw_get_rate(dd->clk_bypass) == req->rate &&
drivers/clk/ti/dpll3xxx.c:		req->best_parent_hw = dd->clk_bypass;
drivers/clk/ti/dpll3xxx.c:		req->rate = omap2_dpll_round_rate(hw, req->rate,
drivers/clk/ti/dpll3xxx.c:					  &req->best_parent_rate);
drivers/clk/ti/dpll3xxx.c:		req->best_parent_hw = dd->clk_ref;
drivers/clk/ti/dpll3xxx.c:	req->best_parent_rate = req->rate;
drivers/clk/tegra/clk-dfll.c: * success, or -EINVAL if the requested rate in req->rate is too high
drivers/clk/tegra/clk-dfll.c:	req->scale_bits = DFLL_FREQ_REQ_SCALE_MAX - 1;
drivers/clk/tegra/clk-dfll.c:		req->scale_bits = scale - 1;
drivers/clk/tegra/clk-dfll.c:	req->mult_bits = val;
drivers/clk/tegra/clk-dfll.c:	req->dvco_target_rate = MULT_TO_DVCO_RATE(req->mult_bits, td->ref_rate);
drivers/clk/tegra/clk-dfll.c:	req->rate = dfll_scale_dvco_rate(req->scale_bits,
drivers/clk/tegra/clk-dfll.c:					 req->dvco_target_rate);
drivers/clk/tegra/clk-dfll.c:	req->lut_index = find_lut_index_for_rate(td, req->dvco_target_rate);
drivers/clk/tegra/clk-dfll.c:	if (req->lut_index < 0)
drivers/clk/tegra/clk-dfll.c:		return req->lut_index;
drivers/clk/tegra/clk-dfll.c:	force_val = (req->lut_index - td->lut_safe) * coef / td->cg;
drivers/clk/tegra/clk-dfll.c:	val |= req->mult_bits << DFLL_FREQ_REQ_MULT_SHIFT;
drivers/clk/tegra/clk-dfll.c:	val |= req->scale_bits << DFLL_FREQ_REQ_SCALE_SHIFT;
drivers/clk/tegra/clk-dfll.c:		if (req->rate == 0) {
drivers/clk/tegra/clk-dfll.c:	ret = dfll_calculate_rate_request(td, &req, clk_req->rate);
drivers/clk/tegra/clk-sdmmc-mux.c:	unsigned long output_rate = req->best_parent_rate;
drivers/clk/tegra/clk-sdmmc-mux.c:	req->rate = max(req->rate, req->min_rate);
drivers/clk/tegra/clk-sdmmc-mux.c:	req->rate = min(req->rate, req->max_rate);
drivers/clk/tegra/clk-sdmmc-mux.c:	if (!req->rate)
drivers/clk/tegra/clk-sdmmc-mux.c:	div = div_frac_get(req->rate, output_rate, 8, 1, sdmmc_mux->div_flags);
drivers/clk/tegra/clk-sdmmc-mux.c:		req->rate =  DIV_ROUND_UP(output_rate * SDMMC_MUL,
drivers/clk/tegra/clk-sdmmc-mux.c:		req->rate =  output_rate * SDMMC_MUL / (div + SDMMC_MUL);
drivers/clk/tegra/clk-tegra20-emc.c:	emc_rate = emc->round_cb(req->rate, req->min_rate, req->max_rate,
drivers/clk/tegra/clk-tegra20-emc.c:		if (req->best_parent_hw == parent_hw)
drivers/clk/tegra/clk-tegra20-emc.c:			parent_rate = req->best_parent_rate;
drivers/clk/tegra/clk-tegra20-emc.c:		req->best_parent_rate = parent_rate;
drivers/clk/tegra/clk-tegra20-emc.c:		req->best_parent_hw = parent_hw;
drivers/clk/tegra/clk-tegra20-emc.c:		req->rate = emc_rate;
drivers/clk/tegra/clk-tegra20-emc.c:			    req->rate, emc_rate);
drivers/clk/tegra/clk-tegra-super-cclk.c:	long rate = req->rate;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->best_parent_rate = pllp_rate;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->best_parent_hw = pllp_hw;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->rate = rate;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->best_parent_rate = rate;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->best_parent_hw = pllx_hw;
drivers/clk/tegra/clk-tegra-super-cclk.c:		req->rate = rate;
drivers/clk/tegra/clk-tegra124-emc.c:		if (timing->rate < req->rate && i != t - 1)
drivers/clk/tegra/clk-tegra124-emc.c:		if (timing->rate > req->max_rate) {
drivers/clk/tegra/clk-tegra124-emc.c:			req->rate = tegra->timings[i - 1].rate;
drivers/clk/tegra/clk-tegra124-emc.c:		if (timing->rate < req->min_rate)
drivers/clk/tegra/clk-tegra124-emc.c:		req->rate = timing->rate;
drivers/clk/tegra/clk-tegra124-emc.c:		req->rate = timing->rate;
drivers/clk/tegra/clk-tegra124-emc.c:	req->rate = clk_hw_get_rate(hw);
drivers/clk/bcm/clk-iproc-pll.c:	if (req->rate == 0 || req->best_parent_rate == 0)
drivers/clk/bcm/clk-iproc-pll.c:		ret = pll_calc_param(req->rate, req->best_parent_rate,
drivers/clk/bcm/clk-iproc-pll.c:		req->rate = vco_param.rate;
drivers/clk/bcm/clk-iproc-pll.c:		diff = abs(req->rate - pll->vco_param[i].rate);
drivers/clk/bcm/clk-iproc-pll.c:	req->rate = pll->vco_param[best_idx].rate;
drivers/clk/bcm/clk-iproc-pll.c:	if (req->rate == 0)
drivers/clk/bcm/clk-iproc-pll.c:	if (req->rate == req->best_parent_rate)
drivers/clk/bcm/clk-iproc-pll.c:	bestdiv = DIV_ROUND_CLOSEST(req->best_parent_rate, req->rate);
drivers/clk/bcm/clk-iproc-pll.c:		req->rate = req->best_parent_rate;
drivers/clk/bcm/clk-iproc-pll.c:	req->rate = req->best_parent_rate / bestdiv;
drivers/clk/bcm/clk-bcm2835.c:		rate = bcm2835_clock_choose_div_and_prate(hw, i, req->rate,
drivers/clk/bcm/clk-bcm2835.c:		if (rate > best_rate && rate <= req->rate) {
drivers/clk/bcm/clk-bcm2835.c:	req->best_parent_hw = best_parent;
drivers/clk/bcm/clk-bcm2835.c:	req->best_parent_rate = best_prate;
drivers/clk/bcm/clk-bcm2835.c:	req->rate = best_avgrate;
drivers/clk/bcm/clk-raspberrypi.c:	req->rate = clamp(req->rate, req->min_rate, req->max_rate);
drivers/clk/bcm/clk-kona.c:		rate = kona_peri_clk_round_rate(hw, req->rate,
drivers/clk/bcm/clk-kona.c:						&req->best_parent_rate);
drivers/clk/bcm/clk-kona.c:		req->rate = rate;
drivers/clk/bcm/clk-kona.c:	best_rate = kona_peri_clk_round_rate(hw, req->rate, &parent_rate);
drivers/clk/bcm/clk-kona.c:	best_delta = abs(best_rate - req->rate);
drivers/clk/bcm/clk-kona.c:		other_rate = kona_peri_clk_round_rate(hw, req->rate,
drivers/clk/bcm/clk-kona.c:		delta = abs(other_rate - req->rate);
drivers/clk/bcm/clk-kona.c:			req->best_parent_hw = parent;
drivers/clk/bcm/clk-kona.c:			req->best_parent_rate = parent_rate;
drivers/clk/bcm/clk-kona.c:	req->rate = best_rate;
drivers/clk/versatile/clk-vexpress-osc.c:	if (of_property_read_u32_array(pdev->dev.of_node, "freq-range", range,
drivers/clk/sunxi/clk-sunxi.c:	div = req->rate / 6000000;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = 6000000 * div;
drivers/clk/sunxi/clk-sunxi.c:	req->m = 0;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate >= 768000000 || req->rate == 42000000 ||
drivers/clk/sunxi/clk-sunxi.c:			req->rate == 54000000)
drivers/clk/sunxi/clk-sunxi.c:		req->k = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 0;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 3;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 2;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 0;
drivers/clk/sunxi/clk-sunxi.c:	div <<= req->p;
drivers/clk/sunxi/clk-sunxi.c:	div /= (req->k + 1);
drivers/clk/sunxi/clk-sunxi.c:	req->n = div / 4;
drivers/clk/sunxi/clk-sunxi.c:	u32 freq_mhz = req->rate / 1000000;
drivers/clk/sunxi/clk-sunxi.c:	u32 parent_freq_mhz = req->parent_rate / 1000000;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = freq_mhz * 1000000;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 3;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 2;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 0;
drivers/clk/sunxi/clk-sunxi.c:		req->m = 2;
drivers/clk/sunxi/clk-sunxi.c:		req->m = 3;
drivers/clk/sunxi/clk-sunxi.c:		req->m = 1;
drivers/clk/sunxi/clk-sunxi.c:	req->n = freq_mhz * (req->m + 1) / ((req->k + 1) * parent_freq_mhz)
drivers/clk/sunxi/clk-sunxi.c:	if ((req->n + 1) > 31 && (req->m + 1) > 1) {
drivers/clk/sunxi/clk-sunxi.c:		req->n = (req->n + 1) / 2 - 1;
drivers/clk/sunxi/clk-sunxi.c:		req->m = (req->m + 1) / 2 - 1;
drivers/clk/sunxi/clk-sunxi.c:	div = req->rate / 6000000;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = 6000000 * div;
drivers/clk/sunxi/clk-sunxi.c:	req->m = 0;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate >= 768000000 || req->rate == 42000000 ||
drivers/clk/sunxi/clk-sunxi.c:			req->rate == 54000000)
drivers/clk/sunxi/clk-sunxi.c:		req->k = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 0;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 2;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->p = 0;
drivers/clk/sunxi/clk-sunxi.c:	div <<= req->p;
drivers/clk/sunxi/clk-sunxi.c:	div /= (req->k + 1);
drivers/clk/sunxi/clk-sunxi.c:	req->n = div / 4 - 1;
drivers/clk/sunxi/clk-sunxi.c:	div = req->rate / req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = req->parent_rate * div;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 0;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 1;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 2;
drivers/clk/sunxi/clk-sunxi.c:		req->k = 3;
drivers/clk/sunxi/clk-sunxi.c:	req->n = DIV_ROUND_UP(div, (req->k + 1));
drivers/clk/sunxi/clk-sunxi.c:	div = req->rate / req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = req->parent_rate * div;
drivers/clk/sunxi/clk-sunxi.c:	req->k = div / 32;
drivers/clk/sunxi/clk-sunxi.c:	if (req->k > 3)
drivers/clk/sunxi/clk-sunxi.c:		req->k = 3;
drivers/clk/sunxi/clk-sunxi.c:	req->n = DIV_ROUND_UP(div, (req->k + 1)) - 1;
drivers/clk/sunxi/clk-sunxi.c:	if (req->parent_rate < req->rate)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate < 8000)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = 8000;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate > 300000000)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = 300000000;
drivers/clk/sunxi/clk-sunxi.c:	div = order_base_2(DIV_ROUND_UP(req->parent_rate, req->rate));
drivers/clk/sunxi/clk-sunxi.c:	req->rate = req->parent_rate >> div;
drivers/clk/sunxi/clk-sunxi.c:	req->p = div;
drivers/clk/sunxi/clk-sunxi.c:	if (req->parent_rate && req->rate > req->parent_rate)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sunxi.c:	if (req->parent_index == SUN6I_AHB1_PARENT_PLL6) {
drivers/clk/sunxi/clk-sunxi.c:	req->rate = (req->parent_rate / calcm) >> calcp;
drivers/clk/sunxi/clk-sunxi.c:	req->p = calcp;
drivers/clk/sunxi/clk-sunxi.c:	req->m = calcm - 1;
drivers/clk/sunxi/clk-sunxi.c:	req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	if (req->parent_index == SUN6I_AHB1_PARENT_PLL6)
drivers/clk/sunxi/clk-sunxi.c:		req->rate /= req->m + 1;
drivers/clk/sunxi/clk-sunxi.c:	req->rate >>= req->p;
drivers/clk/sunxi/clk-sunxi.c:	if (req->parent_rate < req->rate)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sunxi.c:	req->rate = (req->parent_rate >> calcp) / (calcm + 1);
drivers/clk/sunxi/clk-sunxi.c:	req->m = calcm;
drivers/clk/sunxi/clk-sunxi.c:	req->p = calcp;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate > req->parent_rate)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sunxi.c:	req->rate = (req->parent_rate >> calcp) / calcm;
drivers/clk/sunxi/clk-sunxi.c:	req->m = calcm - 1;
drivers/clk/sunxi/clk-sunxi.c:	req->p = calcp;
drivers/clk/sunxi/clk-sunxi.c:	if (req->rate > req->parent_rate)
drivers/clk/sunxi/clk-sunxi.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sunxi.c:	m = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sunxi.c:	req->rate = req->parent_rate / m;
drivers/clk/sunxi/clk-sunxi.c:	req->m = m - 1;
drivers/clk/sunxi/clk-factors.c:			.rate = req->rate,
drivers/clk/sunxi/clk-factors.c:			parent_rate = clk_hw_round_rate(parent, req->rate);
drivers/clk/sunxi/clk-factors.c:		if (child_rate <= req->rate && child_rate > best_child_rate) {
drivers/clk/sunxi/clk-factors.c:	req->best_parent_hw = best_parent;
drivers/clk/sunxi/clk-factors.c:	req->best_parent_rate = best;
drivers/clk/sunxi/clk-factors.c:	req->rate = best_child_rate;
drivers/clk/sunxi/clk-sun9i-core.c:	n = DIV_ROUND_UP(req->rate, 6000000);
drivers/clk/sunxi/clk-sun9i-core.c:	req->rate = ((24000000 * n) >> p) / (m + 1);
drivers/clk/sunxi/clk-sun9i-core.c:	req->n = n;
drivers/clk/sunxi/clk-sun9i-core.c:	req->m = m;
drivers/clk/sunxi/clk-sun9i-core.c:	req->p = p;
drivers/clk/sunxi/clk-sun9i-core.c:	if (req->parent_rate < req->rate)
drivers/clk/sunxi/clk-sun9i-core.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sun9i-core.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sun9i-core.c:	req->rate = req->parent_rate / div;
drivers/clk/sunxi/clk-sun9i-core.c:	req->m = div;
drivers/clk/sunxi/clk-sun9i-core.c:	if (req->parent_rate < req->rate)
drivers/clk/sunxi/clk-sun9i-core.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sun9i-core.c:	_p = order_base_2(DIV_ROUND_UP(req->parent_rate, req->rate));
drivers/clk/sunxi/clk-sun9i-core.c:	req->rate = req->parent_rate >> _p;
drivers/clk/sunxi/clk-sun9i-core.c:	req->p = _p;
drivers/clk/sunxi/clk-sun9i-core.c:	if (req->parent_rate < req->rate)
drivers/clk/sunxi/clk-sun9i-core.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sun9i-core.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sun9i-core.c:	req->p = order_base_2(div);
drivers/clk/sunxi/clk-sun9i-core.c:	req->m = (req->parent_rate >> req->p) - 1;
drivers/clk/sunxi/clk-sun9i-core.c:	req->rate = (req->parent_rate >> req->p) / (req->m + 1);
drivers/clk/sunxi/clk-sun4i-tcon-ch1.c:		tmp_rate = tcon_ch1_calc_divider(req->rate, parent_rate,
drivers/clk/sunxi/clk-sun4i-tcon-ch1.c:		    (req->rate - tmp_rate) < (req->rate - best_rate)) {
drivers/clk/sunxi/clk-sun4i-tcon-ch1.c:			req->best_parent_rate = parent_rate;
drivers/clk/sunxi/clk-sun4i-tcon-ch1.c:			req->best_parent_hw = parent;
drivers/clk/sunxi/clk-sun4i-tcon-ch1.c:	req->rate = best_rate;
drivers/clk/sunxi/clk-sun6i-ar100.c:	if (req->rate > req->parent_rate)
drivers/clk/sunxi/clk-sun6i-ar100.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-sun6i-ar100.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-sun6i-ar100.c:	req->rate = (req->parent_rate >> shift) / div;
drivers/clk/sunxi/clk-sun6i-ar100.c:	req->m = div - 1;
drivers/clk/sunxi/clk-sun6i-ar100.c:	req->p = shift;
drivers/clk/sunxi/clk-mod0.c:	if (req->rate > req->parent_rate)
drivers/clk/sunxi/clk-mod0.c:		req->rate = req->parent_rate;
drivers/clk/sunxi/clk-mod0.c:	div = DIV_ROUND_UP(req->parent_rate, req->rate);
drivers/clk/sunxi/clk-mod0.c:	req->rate = (req->parent_rate >> calcp) / calcm;
drivers/clk/sunxi/clk-mod0.c:	req->m = calcm - 1;
drivers/clk/sunxi/clk-mod0.c:	req->p = calcp;
drivers/clk/sunxi/clk-sun9i-cpus.c:	unsigned long rate = req->rate;
drivers/clk/sunxi/clk-sun9i-cpus.c:	req->best_parent_hw = best_parent;
drivers/clk/sunxi/clk-sun9i-cpus.c:	req->best_parent_rate = best;
drivers/clk/sunxi/clk-sun9i-cpus.c:	req->rate = best_child_rate;
drivers/i3c/master.c:	pool->slots = kcalloc(req->num_slots, sizeof(*slot), GFP_KERNEL);
drivers/i3c/master.c:	if (req->max_payload_len) {
drivers/i3c/master.c:		pool->payload_buf = kcalloc(req->num_slots,
drivers/i3c/master.c:					    req->max_payload_len, GFP_KERNEL);
drivers/i3c/master.c:	for (i = 0; i < req->num_slots; i++) {
drivers/i3c/master.c:		if (req->max_payload_len)
drivers/i3c/master.c:					  (i * req->max_payload_len);
drivers/i3c/master.c:	ibi->handler = req->handler;
drivers/i3c/master.c:	ibi->max_payload_len = req->max_payload_len;
drivers/i3c/master.c:	ibi->num_slots = req->num_slots;
drivers/i3c/master/mipi-i3c-hci/pio.c:	dev_ibi->max_len = req->max_payload_len;
drivers/i3c/master/mipi-i3c-hci/dma.c:	dev_ibi->max_len = req->max_payload_len;
drivers/i3c/master/mipi-i3c-hci/core.c:	if (req->max_payload_len != 0)
drivers/i3c/device.c:	if (!req->handler || !req->num_slots)
drivers/net/fddi/skfp/ess.c:	req->smt.smt_tid = smc->ess.alloc_trans_id = smt_get_tid(smc) ;
drivers/net/fddi/skfp/ess.c:	req->smt.smt_dest = smt_sba_da ;
drivers/net/fddi/skfp/ess.c:	req->s_type.para.p_type = SMT_P0015 ;
drivers/net/fddi/skfp/ess.c:	req->s_type.para.p_len = sizeof(struct smt_p_0015) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->s_type.res_type = SYNC_BW ;
drivers/net/fddi/skfp/ess.c:	req->cmd.para.p_type = SMT_P0016 ;
drivers/net/fddi/skfp/ess.c:	req->cmd.para.p_len = sizeof(struct smt_p_0016) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->cmd.sba_cmd = REQUEST_ALLOCATION ;
drivers/net/fddi/skfp/ess.c:	req->path.para.p_type = SMT_P320B ;
drivers/net/fddi/skfp/ess.c:	req->path.para.p_len = sizeof(struct smt_p_320b) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->path.mib_index = SBAPATHINDEX ;
drivers/net/fddi/skfp/ess.c:	req->path.path_pad = 0;
drivers/net/fddi/skfp/ess.c:	req->path.path_index = PRIMARY_RING ;
drivers/net/fddi/skfp/ess.c:	req->pl_req.para.p_type = SMT_P0017 ;
drivers/net/fddi/skfp/ess.c:	req->pl_req.para.p_len = sizeof(struct smt_p_0017) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->pl_req.sba_pl_req = smc->mib.fddiESSPayload -
drivers/net/fddi/skfp/ess.c:	req->ov_req.para.p_type = SMT_P0018 ;
drivers/net/fddi/skfp/ess.c:	req->ov_req.para.p_len = sizeof(struct smt_p_0018) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->ov_req.sba_ov_req = smc->mib.fddiESSOverhead -
drivers/net/fddi/skfp/ess.c:	req->payload.para.p_type = SMT_P320F ;
drivers/net/fddi/skfp/ess.c:	req->payload.para.p_len = sizeof(struct smt_p_320f) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->payload.mib_index = SBAPATHINDEX ;
drivers/net/fddi/skfp/ess.c:	req->payload.mib_payload = smc->mib.a[PATH0].fddiPATHSbaPayload ;
drivers/net/fddi/skfp/ess.c:	req->overhead.para.p_type = SMT_P3210 ;
drivers/net/fddi/skfp/ess.c:	req->overhead.para.p_len = sizeof(struct smt_p_3210) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->overhead.mib_index = SBAPATHINDEX ;
drivers/net/fddi/skfp/ess.c:	req->overhead.mib_overhead = smc->mib.a[PATH0].fddiPATHSbaOverhead ;
drivers/net/fddi/skfp/ess.c:	req->a_addr.para.p_type = SMT_P0019 ;
drivers/net/fddi/skfp/ess.c:	req->a_addr.para.p_len = sizeof(struct smt_p_0019) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->a_addr.sba_pad = 0;
drivers/net/fddi/skfp/ess.c:	req->a_addr.alloc_addr = null_addr ;
drivers/net/fddi/skfp/ess.c:	req->cat.para.p_type = SMT_P001A ;
drivers/net/fddi/skfp/ess.c:	req->cat.para.p_len = sizeof(struct smt_p_001a) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->cat.category = smc->mib.fddiESSCategory ;
drivers/net/fddi/skfp/ess.c:	req->tneg.para.p_type = SMT_P001B ;
drivers/net/fddi/skfp/ess.c:	req->tneg.para.p_len = sizeof(struct smt_p_001b) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->tneg.max_t_neg = smc->mib.fddiESSMaxTNeg ;
drivers/net/fddi/skfp/ess.c:	req->segm.para.p_type = SMT_P001C ;
drivers/net/fddi/skfp/ess.c:	req->segm.para.p_len = sizeof(struct smt_p_001c) - PARA_LEN ;
drivers/net/fddi/skfp/ess.c:	req->segm.min_seg_siz = smc->mib.fddiESSMinSegmentSize ;
drivers/net/fddi/skfp/pmf.c:	smt->smt_dest = req->smt_source ;	/* DA == source of request */
drivers/net/fddi/skfp/pmf.c:	smt->smt_class = req->smt_class ;	/* same class (GET/SET) */
drivers/net/fddi/skfp/pmf.c:	smt->smt_tid = req->smt_tid ;		/* same TID */
drivers/net/fddi/skfp/pmf.c:	len = req->smt_len ;
drivers/net/fddi/skfp/pmf.c:		smc->mib.fddiSMTLastSetStationId = req->smt_sid ;
drivers/net/wireless/microchip/wilc1000/hif.c:	if (scan_req->scan_result) {
drivers/net/wireless/microchip/wilc1000/hif.c:		scan_req->scan_result(evt, NULL, scan_req->arg);
drivers/net/wireless/microchip/wilc1000/hif.c:		scan_req->scan_result = NULL;
drivers/net/wireless/microchip/wilc1000/hif.c:	if (scan_req->scan_result)
drivers/net/wireless/microchip/wilc1000/hif.c:		scan_req->scan_result(SCAN_EVENT_NETWORK_FOUND, rcvd_info,
drivers/net/wireless/microchip/wilc1000/hif.c:				      scan_req->arg);
drivers/net/wireless/microchip/wilc1000/hif.c:	if (scan_req->scan_result) {
drivers/net/wireless/microchip/wilc1000/hif.c:		scan_req->scan_result(SCAN_EVENT_ABORTED, NULL, scan_req->arg);
drivers/net/wireless/microchip/wilc1000/hif.c:		scan_req->scan_result = NULL;
drivers/net/wireless/realtek/rtw88/fw.c:	SET_BT_MP_INFO_SEQ(h2c_pkt, req->seq);
drivers/net/wireless/realtek/rtw88/fw.c:	SET_BT_MP_INFO_OP_CODE(h2c_pkt, req->op_code);
drivers/net/wireless/realtek/rtw88/fw.c:	SET_BT_MP_INFO_PARA1(h2c_pkt, req->para1);
drivers/net/wireless/realtek/rtw88/fw.c:	SET_BT_MP_INFO_PARA2(h2c_pkt, req->para2);
drivers/net/wireless/realtek/rtw88/fw.c:	SET_BT_MP_INFO_PARA3(h2c_pkt, req->para3);
drivers/net/wireless/realtek/rtw88/fw.c:	if (!pno_req->inited || !pno_req->match_set_cnt)
drivers/net/wireless/realtek/rtw88/fw.c:	size = sizeof(struct rtw_nlo_info_hdr) + pno_req->match_set_cnt *
drivers/net/wireless/realtek/rtw88/fw.c:	nlo_hdr->nlo_count = pno_req->match_set_cnt;
drivers/net/wireless/realtek/rtw88/fw.c:	nlo_hdr->hidden_ap_count = pno_req->match_set_cnt;
drivers/net/wireless/realtek/rtw88/fw.c:	for (i = 0; i < pno_req->match_set_cnt; i++)
drivers/net/wireless/realtek/rtw88/fw.c:		nlo_hdr->ssid_len[i] = pno_req->match_sets[i].ssid.ssid_len;
drivers/net/wireless/realtek/rtw88/fw.c:	for (i = 0; i < pno_req->match_set_cnt; i++) {
drivers/net/wireless/realtek/rtw88/fw.c:		ssid = &pno_req->match_sets[i].ssid;
drivers/net/wireless/realtek/rtw88/fw.c:	for (i = 0; i < pno_req->match_set_cnt; i++) {
drivers/net/wireless/realtek/rtw88/fw.c:		memcpy(pos, pno_req->match_sets[i].ssid.ssid,
drivers/net/wireless/realtek/rtw88/fw.c:		       pno_req->match_sets[i].ssid.ssid_len);
drivers/net/wireless/realtek/rtw88/fw.c:	struct ieee80211_channel *channels = pno_req->channels;
drivers/net/wireless/realtek/rtw88/fw.c:	int count =  pno_req->channel_cnt;
drivers/net/wireless/realtek/rtw88/fw.c:	for (i = 0 ; i < rtw_pno_req->match_set_cnt; i++) {
drivers/net/wireless/realtek/rtw88/fw.c:		ssid = &rtw_pno_req->match_sets[i].ssid;
drivers/net/wireless/realtek/rtw88/fw.c:	CH_SWITCH_SET_CH_NUM(h2c_pkt, rtw_pno_req->channel_cnt);
drivers/net/wireless/realtek/rtw88/fw.c:	CH_SWITCH_SET_INFO_SIZE(h2c_pkt, rtw_pno_req->channel_cnt * 4);
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->match_set_cnt = nd_config->n_match_sets;
drivers/net/wireless/realtek/rtw88/wow.c:	size = sizeof(*pno_req->match_sets) * pno_req->match_set_cnt;
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->match_sets = kmemdup(nd_config->match_sets, size, GFP_KERNEL);
drivers/net/wireless/realtek/rtw88/wow.c:	if (!pno_req->match_sets)
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->channel_cnt = nd_config->n_channels;
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->channels = kmalloc(size, GFP_KERNEL);
drivers/net/wireless/realtek/rtw88/wow.c:	if (!pno_req->channels)
drivers/net/wireless/realtek/rtw88/wow.c:	for (i = 0 ; i < pno_req->channel_cnt; i++) {
drivers/net/wireless/realtek/rtw88/wow.c:		channel = pno_req->channels + i;
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->scan_plan = *nd_config->scan_plans;
drivers/net/wireless/realtek/rtw88/wow.c:	pno_req->inited = true;
drivers/net/wireless/realtek/rtw88/wow.c:	kfree(pno_req->match_sets);
drivers/net/wireless/realtek/rtw88/wow.c:	if (pno_req->inited) {
drivers/net/wireless/realtek/rtw88/wow.c:		kfree(pno_req->channels);
drivers/net/wireless/realtek/rtw88/wow.c:		kfree(pno_req->match_sets);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	for (i = 0, item = &req->items[0]; i < req->n_items; i++, item++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	cur = &fwctx->req->items[fwctx->curpos];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:					     fwctx->req->domain_nr,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:					     fwctx->req->bus_nr);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	struct brcmf_fw_item *cur = &fwctx->req->items[fwctx->curpos];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	struct brcmf_fw_item *cur = &fwctx->req->items[fwctx->curpos];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	if (cur->type == BRCMF_FW_TYPE_NVRAM && fwctx->req->board_type) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:		strlcat(alt_path, fwctx->req->board_type, BRCMF_FW_NAME_LEN);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	while (ret == 0 && ++fwctx->curpos < fwctx->req->n_items) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	if (!req->n_items)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	for (i = 0, item = &req->items[0]; i < req->n_items; i++, item++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	struct brcmf_fw_item *first = &req->items[0];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:	fwreq->n_items = n_fwnames;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:		fwreq->items[j].path = fwnames[j].path;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/firmware.c:		fwreq->items[j].path = fwnames[j].path;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:	brcmf_dbg(SCAN, "reqid=%llu\n", req->reqid);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:	if (!ssid || !req->ssids || !req->n_ssids)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:	for (i = 0; i < req->n_ssids; i++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:		if (ssid->ssid_len == req->ssids[i].ssid_len) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:			if (!strncmp(ssid->ssid, req->ssids[i].ssid,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:	brcmf_dbg(TRACE, "reqid=%llu\n", req->reqid);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:		brcmf_pno_remove_request(pi, req->reqid);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:		if (!req->n_match_sets)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:		for (j = 0; j < req->n_match_sets; j++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pno.c:			ms = &req->match_sets[j];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		   n_netinfo * sizeof(req->channels[0]) +
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		   n_netinfo * sizeof(*req->ssids);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		req->wiphy = wiphy;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		req->ssids = (void *)(&req->channels[0]) +
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:			     n_netinfo * sizeof(req->channels[0]);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	chan = ieee80211_get_channel(req->wiphy, freq);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	for (i = 0; i < req->n_channels; i++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		if (req->channels[i] == chan)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	if (i == req->n_channels)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		req->channels[req->n_channels++] = chan;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	for (i = 0; i < req->n_ssids; i++) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		if (req->ssids[i].ssid_len == ssid_len &&
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		    !memcmp(req->ssids[i].ssid, ssid, ssid_len))
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	if (i == req->n_ssids) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		memcpy(req->ssids[req->n_ssids].ssid, ssid, ssid_len);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		req->ssids[req->n_ssids++].ssid_len = ssid_len;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		  req->n_match_sets, req->n_ssids);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	if (req->n_match_sets <= 0) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:			  req->n_match_sets);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	if ((alpha2[0] == ccreq->country_abbrev[0]) &&
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	    (alpha2[1] == ccreq->country_abbrev[1])) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	ccreq->rev = cpu_to_le32(country_codes->table[found_index].rev);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	memcpy(ccreq->ccode, country_codes->table[found_index].cc,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	ccreq->country_abbrev[0] = alpha2[0];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	ccreq->country_abbrev[1] = alpha2[1];
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	ccreq->country_abbrev[2] = 0;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	if (req->alpha2[0] == '0' && req->alpha2[1] == '0')
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		if (req->alpha2[i] < 'A' || req->alpha2[i] > 'Z') {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:				 req->alpha2[0], req->alpha2[1]);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	brcmf_dbg(TRACE, "Enter: initiator=%d, alpha=%c%c\n", req->initiator,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:		  req->alpha2[0], req->alpha2[1]);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/cfg80211.c:	err = brcmf_translate_country_code(ifp->drvr, req->alpha2, &ccreq);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fw = fwreq->items[BRCMF_PCIE_FW_CODE].binary;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	nvram = fwreq->items[BRCMF_PCIE_FW_NVRAM].nv_data.data;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	nvram_len = fwreq->items[BRCMF_PCIE_FW_NVRAM].nv_data.len;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->items[BRCMF_PCIE_FW_CODE].type = BRCMF_FW_TYPE_BINARY;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->items[BRCMF_PCIE_FW_NVRAM].type = BRCMF_FW_TYPE_NVRAM;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->items[BRCMF_PCIE_FW_NVRAM].flags = BRCMF_FW_REQF_OPTIONAL;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->board_type = devinfo->settings->board_type;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->domain_nr = pci_domain_nr(devinfo->pdev->bus) + 1;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/pcie.c:	fwreq->bus_nr = devinfo->pdev->bus->number;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	code = fwreq->items[BRCMF_SDIO_FW_CODE].binary;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	nvram = fwreq->items[BRCMF_SDIO_FW_NVRAM].nv_data.data;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	nvram_len = fwreq->items[BRCMF_SDIO_FW_NVRAM].nv_data.len;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	fwreq->items[BRCMF_SDIO_FW_CODE].type = BRCMF_FW_TYPE_BINARY;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	fwreq->items[BRCMF_SDIO_FW_NVRAM].type = BRCMF_FW_TYPE_NVRAM;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/sdio.c:	fwreq->board_type = bus->sdiodev->settings->board_type;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	list_add_tail(&req->list, q);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		req->urb = usb_alloc_urb(0, GFP_ATOMIC);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		if (!req->urb)
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		INIT_LIST_HEAD(&req->list);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		list_add_tail(&req->list, q);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:			usb_free_urb(req->urb);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		if (!req->urb) {
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		usb_free_urb(req->urb);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		list_del_init(&req->list);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	list_del_init(&req->list);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	struct brcmf_usbdev_info *devinfo = req->devinfo;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		  req->skb);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	brcmf_proto_bcdc_txcomplete(devinfo->dev, req->skb, urb->status == 0);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->skb = NULL;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	struct brcmf_usbdev_info *devinfo = req->devinfo;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	skb = req->skb;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->skb = NULL;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->skb = skb;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	usb_fill_bulk_urb(req->urb, devinfo->usbdev, devinfo->rx_pipe,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->devinfo = devinfo;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	ret = usb_submit_urb(req->urb, GFP_ATOMIC);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		brcmu_pkt_buf_free_skb(req->skb);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		req->skb = NULL;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->skb = skb;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->devinfo = devinfo;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	usb_fill_bulk_urb(req->urb, devinfo->usbdev, devinfo->tx_pipe,
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	req->urb->transfer_flags |= URB_ZERO_PACKET;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	ret = usb_submit_urb(req->urb, GFP_ATOMIC);
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:		req->skb = NULL;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	fw = fwreq->items[BRCMF_USB_FW_CODE].binary;
drivers/net/wireless/broadcom/brcm80211/brcmfmac/usb.c:	fwreq->items[BRCMF_USB_FW_CODE].type = BRCMF_FW_TYPE_BINARY;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	if (freq->e == 1 &&
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	    freq->m / 100000 >= freq_list[0] &&
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	    freq->m / 100000 <= freq_list[FREQ_COUNT - 1]) {
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:		int fr = freq->m / 100000;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:				freq->e = 0;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:				freq->m = ch + 1;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	if (freq->e != 0 || freq->m < 1 || freq->m > FREQ_COUNT ||
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	    !(local->channel_mask & (1 << (freq->m - 1))))
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	local->channel = freq->m; /* channel is used in prism2_setup_rids() */
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	freq->m = freq_list[val - 1] * 100000;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:	freq->e = 1;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:		ssid = req->essid;
drivers/net/wireless/intersil/hostap/hostap_ioctl.c:		ssid_len = req->essid_len;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->magic = cpu_to_le16(EZUSB_MAGIC);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->req_reply_count = reply_count;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->ans_reply_count = 0;
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->frame_type = cpu_to_le16(frame_type);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->size = cpu_to_le16(length + 4);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->crc = cpu_to_le16(build_crc(req));
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->hermes_len = cpu_to_le16(HERMES_BYTES_TO_RECLEN(length));
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:	req->hermes_rid = cpu_to_le16(rid);
drivers/net/wireless/intersil/orinoco/orinoco_usb.c:		memcpy(req->data, data, length);
drivers/net/wireless/intersil/prism54/isl_ioctl.c:	range->num_channels = freq->nr;
drivers/net/wireless/intersil/prism54/isl_ioctl.c:	range->num_frequency = freq->nr;
drivers/net/wireless/intersil/prism54/isl_ioctl.c:	m = min(IW_MAX_FREQUENCIES, (int) freq->nr);
drivers/net/wireless/intersil/prism54/isl_ioctl.c:		range->freq[i].m = freq->mhz[i];
drivers/net/wireless/intersil/prism54/isl_ioctl.c:		range->freq[i].i = channel_of_freq(freq->mhz[i]);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			freq->nr = le16_to_cpu(freq->nr);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			for (i = 0; i < freq->nr; i++)
drivers/net/wireless/intersil/prism54/oid_mgt.c:				freq->mhz[i] = le16_to_cpu(freq->mhz[i]);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			freq->nr = cpu_to_le16(freq->nr);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			for (i = 0; i < freq->nr; i++)
drivers/net/wireless/intersil/prism54/oid_mgt.c:				freq->mhz[i] = cpu_to_le16(freq->mhz[i]);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			printk("nr : %u\n", freq->nr);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			t = scnprintf(str, PRIV_STR_SIZE, "nr=%u\n", freq->nr);
drivers/net/wireless/intersil/prism54/oid_mgt.c:			for (i = 0; i < freq->nr; i++)
drivers/net/wireless/intersil/prism54/oid_mgt.c:					      "mhz[%u]=%u\n", i, freq->mhz[i]);
drivers/net/wireless/mac80211_hwsim.c:	if (hwsim->scan_chan_idx >= req->n_channels) {
drivers/net/wireless/mac80211_hwsim.c:		  req->channels[hwsim->scan_chan_idx]->center_freq);
drivers/net/wireless/mac80211_hwsim.c:	hwsim->tmp_chan = req->channels[hwsim->scan_chan_idx];
drivers/net/wireless/mac80211_hwsim.c:	    !req->n_ssids) {
drivers/net/wireless/mac80211_hwsim.c:		for (i = 0; i < req->n_ssids; i++) {
drivers/net/wireless/mac80211_hwsim.c:						       req->ssids[i].ssid,
drivers/net/wireless/mac80211_hwsim.c:						       req->ssids[i].ssid_len,
drivers/net/wireless/mac80211_hwsim.c:						       req->ie_len);
drivers/net/wireless/mac80211_hwsim.c:			memcpy(mgmt->da, req->bssid, ETH_ALEN);
drivers/net/wireless/mac80211_hwsim.c:			memcpy(mgmt->bssid, req->bssid, ETH_ALEN);
drivers/net/wireless/mac80211_hwsim.c:			if (req->ie_len)
drivers/net/wireless/mac80211_hwsim.c:				skb_put_data(probe, req->ie, req->ie_len);
drivers/net/wireless/mac80211_hwsim.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/mac80211_hwsim.c:	if (req->flags & NL80211_SCAN_FLAG_RANDOM_ADDR)
drivers/net/wireless/mac80211_hwsim.c:				     hw_req->req.mac_addr,
drivers/net/wireless/mac80211_hwsim.c:				     hw_req->req.mac_addr_mask);
drivers/net/wireless/ath/ath6kl/cfg80211.c:	if (vif->scan_req->n_ssids && vif->scan_req->ssids[0].ssid_len) {
drivers/net/wireless/ath/ath6kl/cfg80211.c:		for (i = 0; i < vif->scan_req->n_ssids; i++) {
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	if (conn_req->svc_id == 0) {
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	if (conn_req->svc_id == HTC_CTRL_RSVD_SVC) {
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		tx_alloc = htc_get_credit_alloc(target, conn_req->svc_id);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		conn_msg->svc_id = cpu_to_le16(conn_req->svc_id);
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		conn_msg->conn_flags = cpu_to_le16(conn_req->conn_flags &
drivers/net/wireless/ath/ath6kl/htc_pipe.c:		if (conn_req->conn_flags &
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	ep->svc_id = conn_req->svc_id; /* this marks ep in use */
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	ep->max_txq_depth = conn_req->max_txq_depth;
drivers/net/wireless/ath/ath6kl/htc_pipe.c:	ep->ep_cb = conn_req->ep_cb;
drivers/net/wireless/ath/ath6kl/hif.c:	buf = req->virt_dma_buf;
drivers/net/wireless/ath/ath6kl/hif.c:	for (i = 0; i < req->scat_entries; i++) {
drivers/net/wireless/ath/ath6kl/hif.c:			memcpy(req->scat_list[i].buf, buf,
drivers/net/wireless/ath/ath6kl/hif.c:			       req->scat_list[i].len);
drivers/net/wireless/ath/ath6kl/hif.c:			memcpy(buf, req->scat_list[i].buf,
drivers/net/wireless/ath/ath6kl/hif.c:			       req->scat_list[i].len);
drivers/net/wireless/ath/ath6kl/hif.c:		buf += req->scat_list[i].len;
drivers/net/wireless/ath/ath6kl/hif.c:		scat_req->req = HIF_RD_SYNC_BLOCK_FIX;
drivers/net/wireless/ath/ath6kl/hif.c:		scat_req->addr = dev->ar->mbox_info.htc_addr;
drivers/net/wireless/ath/ath6kl/hif.c:		scat_req->req = HIF_WR_ASYNC_BLOCK_INC;
drivers/net/wireless/ath/ath6kl/hif.c:		scat_req->addr =
drivers/net/wireless/ath/ath6kl/hif.c:			(scat_req->len > HIF_MBOX_WIDTH) ?
drivers/net/wireless/ath/ath6kl/hif.c:		   scat_req->scat_entries, scat_req->len,
drivers/net/wireless/ath/ath6kl/hif.c:		   scat_req->addr, !read ? "async" : "sync",
drivers/net/wireless/ath/ath6kl/hif.c:	if (!read && scat_req->virt_scat) {
drivers/net/wireless/ath/ath6kl/hif.c:			scat_req->status = status;
drivers/net/wireless/ath/ath6kl/hif.c:			scat_req->complete(dev->ar->htc_target, scat_req);
drivers/net/wireless/ath/ath6kl/hif.c:		scat_req->status = status;
drivers/net/wireless/ath/ath6kl/hif.c:		if (!status && scat_req->virt_scat)
drivers/net/wireless/ath/ath6kl/hif.c:			scat_req->status =
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		   scat_req->len, scat_req->scat_entries);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	if (scat_req->status)
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		ath6kl_err("send scatter req failed: %d\n", scat_req->status);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	packet = scat_req->scat_list[0].packet;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	for (i = 0; i < scat_req->scat_entries; i++) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		packet = scat_req->scat_list[i].packet;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		packet->status = scat_req->status;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].packet = NULL;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].packet = packet;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].buf = packet->buf;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].len = len;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->len += len;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_entries++;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	if (scat_req->scat_entries < HTC_MIN_HTC_MSGS_TO_BUNDLE) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		for (i = scat_req->scat_entries - 1; i >= 0; i--) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:			packet = scat_req->scat_list[i].packet;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:			if (scat_req->scat_q_depth < ATH6KL_SCATTER_REQS)
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->len = 0;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_entries = 0;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->complete = htc_async_tx_scat_complete;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		tot_pkts_bundle += scat_req->scat_entries;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:			   scat_req->len, scat_req->scat_entries);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		for (i = 0; i < scat_req->scat_entries; i++) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:			packet = scat_req->scat_list[i].packet;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].buf = packet->buf;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		scat_req->scat_list[i].len = pad_len;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		WARN_ON(!scat_req->scat_list[i].len);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		len += scat_req->scat_list[i].len;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	scat_req->len = len;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	scat_req->scat_entries = i;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		   target, conn_req->svc_id);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	if (conn_req->svc_id == HTC_CTRL_RSVD_SVC) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		conn_msg->svc_id = cpu_to_le16(conn_req->svc_id);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		conn_msg->conn_flags = cpu_to_le16(conn_req->conn_flags);
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	endpoint->svc_id = conn_req->svc_id;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	endpoint->max_txq_depth = conn_req->max_txq_depth;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	endpoint->ep_cb = conn_req->ep_cb;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	endpoint->cred_dist.svc_id = conn_req->svc_id;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	if (conn_req->max_rxmsg_sz) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		if (conn_req->max_rxmsg_sz > max_msg_sz) {
drivers/net/wireless/ath/ath6kl/htc_mbox.c:		    conn_req->max_rxmsg_sz / target->tgt_cred_sz;
drivers/net/wireless/ath/ath6kl/htc_mbox.c:	endpoint->conn_flags = conn_req->flags;
drivers/net/wireless/ath/ath6kl/init.c:	switch (con_req->svc_id) {
drivers/net/wireless/ath/ath6kl/init.c:		ath6kl_err("service id is not mapped %d\n", con_req->svc_id);
drivers/net/wireless/ath/ath6kl/sdio.c:	list_del(&bus_req->list);
drivers/net/wireless/ath/ath6kl/sdio.c:	list_add_tail(&bus_req->list, &ar_sdio->bus_req_freeq);
drivers/net/wireless/ath/ath6kl/sdio.c:	data->blocks = scat_req->len / HIF_MBOX_BLOCK_SIZE;
drivers/net/wireless/ath/ath6kl/sdio.c:		   (scat_req->req & HIF_WRITE) ? "WR" : "RD", scat_req->addr,
drivers/net/wireless/ath/ath6kl/sdio.c:		   data->blksz, data->blocks, scat_req->len,
drivers/net/wireless/ath/ath6kl/sdio.c:		   scat_req->scat_entries);
drivers/net/wireless/ath/ath6kl/sdio.c:	data->flags = (scat_req->req & HIF_WRITE) ? MMC_DATA_WRITE :
drivers/net/wireless/ath/ath6kl/sdio.c:	sg = scat_req->sgentries;
drivers/net/wireless/ath/ath6kl/sdio.c:	sg_init_table(sg, scat_req->scat_entries);
drivers/net/wireless/ath/ath6kl/sdio.c:	for (i = 0; i < scat_req->scat_entries; i++, sg++) {
drivers/net/wireless/ath/ath6kl/sdio.c:			   i, scat_req->scat_list[i].buf,
drivers/net/wireless/ath/ath6kl/sdio.c:			   scat_req->scat_list[i].len);
drivers/net/wireless/ath/ath6kl/sdio.c:		sg_set_buf(sg, scat_req->scat_list[i].buf,
drivers/net/wireless/ath/ath6kl/sdio.c:			   scat_req->scat_list[i].len);
drivers/net/wireless/ath/ath6kl/sdio.c:	data->sg = scat_req->sgentries;
drivers/net/wireless/ath/ath6kl/sdio.c:	data->sg_len = scat_req->scat_entries;
drivers/net/wireless/ath/ath6kl/sdio.c:	scat_req = req->scat_req;
drivers/net/wireless/ath/ath6kl/sdio.c:	if (scat_req->virt_scat) {
drivers/net/wireless/ath/ath6kl/sdio.c:		len = scat_req->len;
drivers/net/wireless/ath/ath6kl/sdio.c:		if (scat_req->req & HIF_BLOCK_BASIS)
drivers/net/wireless/ath/ath6kl/sdio.c:		status = ath6kl_sdio_io(ar_sdio->func, scat_req->req,
drivers/net/wireless/ath/ath6kl/sdio.c:					scat_req->addr, scat_req->virt_dma_buf,
drivers/net/wireless/ath/ath6kl/sdio.c:	opcode = (scat_req->req & HIF_FIXED_ADDRESS) ?
drivers/net/wireless/ath/ath6kl/sdio.c:	rw = (scat_req->req & HIF_WRITE) ? CMD53_ARG_WRITE : CMD53_ARG_READ;
drivers/net/wireless/ath/ath6kl/sdio.c:	if (scat_req->req & HIF_WRITE) {
drivers/net/wireless/ath/ath6kl/sdio.c:		if (scat_req->addr == HIF_MBOX_BASE_ADDR)
drivers/net/wireless/ath/ath6kl/sdio.c:			scat_req->addr += HIF_MBOX_WIDTH - scat_req->len;
drivers/net/wireless/ath/ath6kl/sdio.c:			scat_req->addr += HIF_MBOX0_EXT_WIDTH - scat_req->len;
drivers/net/wireless/ath/ath6kl/sdio.c:				  CMD53_ARG_BLOCK_BASIS, opcode, scat_req->addr,
drivers/net/wireless/ath/ath6kl/sdio.c:	trace_ath6kl_sdio_scat(scat_req->addr,
drivers/net/wireless/ath/ath6kl/sdio.c:			       scat_req->req,
drivers/net/wireless/ath/ath6kl/sdio.c:			       scat_req->len,
drivers/net/wireless/ath/ath6kl/sdio.c:			       scat_req->scat_entries,
drivers/net/wireless/ath/ath6kl/sdio.c:			       scat_req->scat_list);
drivers/net/wireless/ath/ath6kl/sdio.c:	scat_req->status = status;
drivers/net/wireless/ath/ath6kl/sdio.c:	if (scat_req->status)
drivers/net/wireless/ath/ath6kl/sdio.c:			   scat_req->status);
drivers/net/wireless/ath/ath6kl/sdio.c:	if (scat_req->req & HIF_ASYNCHRONOUS)
drivers/net/wireless/ath/ath6kl/sdio.c:		scat_req->complete(ar_sdio->ar->htc_target, scat_req);
drivers/net/wireless/ath/ath6kl/sdio.c:			s_req->virt_dma_buf =
drivers/net/wireless/ath/ath6kl/sdio.c:			s_req->sgentries = kzalloc(size, GFP_KERNEL);
drivers/net/wireless/ath/ath6kl/sdio.c:			if (!s_req->sgentries) {
drivers/net/wireless/ath/ath6kl/sdio.c:			kfree(s_req->sgentries);
drivers/net/wireless/ath/ath6kl/sdio.c:			kfree(s_req->virt_dma_buf);
drivers/net/wireless/ath/ath6kl/sdio.c:		bus_req->scat_req = s_req;
drivers/net/wireless/ath/ath6kl/sdio.c:		s_req->busrequest = bus_req;
drivers/net/wireless/ath/ath6kl/sdio.c:		s_req->virt_scat = virt_scat;
drivers/net/wireless/ath/ath6kl/sdio.c:	if (req->scat_req) {
drivers/net/wireless/ath/ath6kl/sdio.c:		status = ath6kl_sdio_read_write_sync(ar_sdio->ar, req->address,
drivers/net/wireless/ath/ath6kl/sdio.c:						     req->buffer, req->length,
drivers/net/wireless/ath/ath6kl/sdio.c:						     req->request);
drivers/net/wireless/ath/ath6kl/sdio.c:		context = req->packet;
drivers/net/wireless/ath/ath6kl/sdio.c:		list_del(&req->list);
drivers/net/wireless/ath/ath6kl/sdio.c:	bus_req->address = address;
drivers/net/wireless/ath/ath6kl/sdio.c:	bus_req->buffer = buffer;
drivers/net/wireless/ath/ath6kl/sdio.c:	bus_req->length = length;
drivers/net/wireless/ath/ath6kl/sdio.c:	bus_req->request = request;
drivers/net/wireless/ath/ath6kl/sdio.c:	bus_req->packet = packet;
drivers/net/wireless/ath/ath6kl/sdio.c:	list_add_tail(&bus_req->list, &ar_sdio->wr_asyncq);
drivers/net/wireless/ath/ath6kl/sdio.c:	list_add_tail(&s_req->list, &ar_sdio->scat_req);
drivers/net/wireless/ath/ath6kl/sdio.c:	u32 request = scat_req->req;
drivers/net/wireless/ath/ath6kl/sdio.c:	if (!scat_req->len)
drivers/net/wireless/ath/ath6kl/sdio.c:		   scat_req->len, scat_req->scat_entries);
drivers/net/wireless/ath/ath6kl/sdio.c:		status = ath6kl_sdio_scat_rw(ar_sdio, scat_req->busrequest);
drivers/net/wireless/ath/ath6kl/sdio.c:		list_add_tail(&scat_req->busrequest->list, &ar_sdio->wr_asyncq);
drivers/net/wireless/ath/ath6kl/sdio.c:		list_del(&s_req->list);
drivers/net/wireless/ath/ath6kl/sdio.c:		if (s_req->busrequest) {
drivers/net/wireless/ath/ath6kl/sdio.c:			s_req->busrequest->scat_req = NULL;
drivers/net/wireless/ath/ath6kl/sdio.c:			ath6kl_sdio_free_bus_req(ar_sdio, s_req->busrequest);
drivers/net/wireless/ath/ath6kl/sdio.c:		kfree(s_req->virt_dma_buf);
drivers/net/wireless/ath/ath6kl/sdio.c:		kfree(s_req->sgentries);
drivers/net/wireless/ath/ath6kl/sdio.c:		list_del(&req->list);
drivers/net/wireless/ath/ath6kl/sdio.c:		if (req->scat_req) {
drivers/net/wireless/ath/ath6kl/sdio.c:			req->scat_req->status = -ECANCELED;
drivers/net/wireless/ath/ath6kl/sdio.c:			req->scat_req->complete(ar_sdio->ar->htc_target,
drivers/net/wireless/ath/ath6kl/sdio.c:						req->scat_req);
drivers/net/wireless/ath/ath6kl/sdio.c:			context = req->packet;
drivers/net/wireless/ath/wcn36xx/main.c:	for (i = 0; i < hw_req->req.n_channels; i++) {
drivers/net/wireless/ath/wcn36xx/main.c:		if (hw_req->req.channels[i]->band != NL80211_BAND_2GHZ)
drivers/net/wireless/ath/wcn36xx/main.c:	wcn->scan_req = &hw_req->req;
drivers/net/wireless/ath/wcn36xx/main.c:	return wcn36xx_smd_start_hw_scan(wcn, vif, &hw_req->req);
drivers/net/wireless/ath/wcn36xx/smd.c:	if (req->ie_len > WCN36XX_MAX_SCAN_IE_LEN)
drivers/net/wireless/ath/wcn36xx/smd.c:	msg_body->num_ssid = min_t(u8, req->n_ssids, ARRAY_SIZE(msg_body->ssids));
drivers/net/wireless/ath/wcn36xx/smd.c:		msg_body->ssids[i].length = min_t(u8, req->ssids[i].ssid_len,
drivers/net/wireless/ath/wcn36xx/smd.c:		memcpy(msg_body->ssids[i].ssid, req->ssids[i].ssid,
drivers/net/wireless/ath/wcn36xx/smd.c:	msg_body->num_channel = min_t(u8, req->n_channels,
drivers/net/wireless/ath/wcn36xx/smd.c:			HW_VALUE_CHANNEL(req->channels[i]->hw_value);
drivers/net/wireless/ath/wcn36xx/smd.c:	if (req->ie_len > 0) {
drivers/net/wireless/ath/wcn36xx/smd.c:		msg_body->ie_len = req->ie_len;
drivers/net/wireless/ath/wcn36xx/smd.c:		msg_body->header.len += req->ie_len;
drivers/net/wireless/ath/wcn36xx/smd.c:		memcpy(msg_body->ie, req->ie, req->ie_len);
drivers/net/wireless/ath/ath11k/qmi.c:	req->client_id_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->client_id = QMI_WLANFW_CLIENT_ID;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_ready_enable_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_ready_enable = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->request_mem_enable_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->request_mem_enable = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_mem_ready_enable_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_mem_ready_enable = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->cal_done_enable_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->cal_done_enable = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_init_done_enable_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->fw_init_done_enable = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->pin_connect_result_enable_valid = 0;
drivers/net/wireless/ath/ath11k/qmi.c:	req->pin_connect_result_enable = 0;
drivers/net/wireless/ath/ath11k/qmi.c:		req->mem_seg_len = ab->qmi.mem_seg_count;
drivers/net/wireless/ath/ath11k/qmi.c:		for (i = 0; i < req->mem_seg_len ; i++) {
drivers/net/wireless/ath/ath11k/qmi.c:			req->mem_seg[i].addr = ab->qmi.target_mem[i].paddr;
drivers/net/wireless/ath/ath11k/qmi.c:			req->mem_seg[i].size = ab->qmi.target_mem[i].size;
drivers/net/wireless/ath/ath11k/qmi.c:			req->mem_seg[i].type = ab->qmi.target_mem[i].type;
drivers/net/wireless/ath/ath11k/qmi.c:	req->total_size = fw_size;
drivers/net/wireless/ath/ath11k/qmi.c:		req->valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->file_id_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->file_id = ab->qmi.target.board_id;
drivers/net/wireless/ath/ath11k/qmi.c:		req->total_size_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->seg_id_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->seg_id = type;
drivers/net/wireless/ath/ath11k/qmi.c:		req->data_valid = 0;
drivers/net/wireless/ath/ath11k/qmi.c:		req->data_len = ATH11K_QMI_MAX_BDF_FILE_NAME_SIZE;
drivers/net/wireless/ath/ath11k/qmi.c:		req->bdf_type = 0;
drivers/net/wireless/ath/ath11k/qmi.c:		req->bdf_type_valid = 0;
drivers/net/wireless/ath/ath11k/qmi.c:		req->end_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->end = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->file_id_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->file_id = ab->qmi.target.board_id;
drivers/net/wireless/ath/ath11k/qmi.c:		req->total_size_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->total_size = bd.len;
drivers/net/wireless/ath/ath11k/qmi.c:		req->seg_id_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->data_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->data_len = ATH11K_QMI_MAX_BDF_FILE_NAME_SIZE;
drivers/net/wireless/ath/ath11k/qmi.c:		req->bdf_type = bdf_type;
drivers/net/wireless/ath/ath11k/qmi.c:		req->bdf_type_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->end_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->end = 0;
drivers/net/wireless/ath/ath11k/qmi.c:			req->data_len = QMI_WLANFW_MAX_DATA_SIZE_V01;
drivers/net/wireless/ath/ath11k/qmi.c:			req->data_len = remaining;
drivers/net/wireless/ath/ath11k/qmi.c:			req->end = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		memcpy(req->data, temp, req->data_len);
drivers/net/wireless/ath/ath11k/qmi.c:		remaining -= req->data_len;
drivers/net/wireless/ath/ath11k/qmi.c:		temp += req->data_len;
drivers/net/wireless/ath/ath11k/qmi.c:		req->seg_id++;
drivers/net/wireless/ath/ath11k/qmi.c:	req->host_version_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	strlcpy(req->host_version, ATH11K_HOST_VERSION_STRING,
drivers/net/wireless/ath/ath11k/qmi.c:		sizeof(req->host_version));
drivers/net/wireless/ath/ath11k/qmi.c:	req->tgt_cfg_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->tgt_cfg_len = ab->qmi.ce_cfg.tgt_ce_len;
drivers/net/wireless/ath/ath11k/qmi.c:	for (pipe_num = 0; pipe_num < req->tgt_cfg_len ; pipe_num++) {
drivers/net/wireless/ath/ath11k/qmi.c:		req->tgt_cfg[pipe_num].pipe_num = ce_cfg[pipe_num].pipenum;
drivers/net/wireless/ath/ath11k/qmi.c:		req->tgt_cfg[pipe_num].pipe_dir = ce_cfg[pipe_num].pipedir;
drivers/net/wireless/ath/ath11k/qmi.c:		req->tgt_cfg[pipe_num].nentries = ce_cfg[pipe_num].nentries;
drivers/net/wireless/ath/ath11k/qmi.c:		req->tgt_cfg[pipe_num].nbytes_max = ce_cfg[pipe_num].nbytes_max;
drivers/net/wireless/ath/ath11k/qmi.c:		req->tgt_cfg[pipe_num].flags = ce_cfg[pipe_num].flags;
drivers/net/wireless/ath/ath11k/qmi.c:	req->svc_cfg_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:	req->svc_cfg_len = ab->qmi.ce_cfg.svc_to_ce_map_len;
drivers/net/wireless/ath/ath11k/qmi.c:	for (pipe_num = 0; pipe_num < req->svc_cfg_len; pipe_num++) {
drivers/net/wireless/ath/ath11k/qmi.c:		req->svc_cfg[pipe_num].service_id = svc_cfg[pipe_num].service_id;
drivers/net/wireless/ath/ath11k/qmi.c:		req->svc_cfg[pipe_num].pipe_dir = svc_cfg[pipe_num].pipedir;
drivers/net/wireless/ath/ath11k/qmi.c:		req->svc_cfg[pipe_num].pipe_num = svc_cfg[pipe_num].pipenum;
drivers/net/wireless/ath/ath11k/qmi.c:	req->shadow_reg_valid = 0;
drivers/net/wireless/ath/ath11k/qmi.c:		req->shadow_reg_v2_valid = 1;
drivers/net/wireless/ath/ath11k/qmi.c:		req->shadow_reg_v2_len = min_t(u32,
drivers/net/wireless/ath/ath11k/qmi.c:		memcpy(&req->shadow_reg_v2, ab->qmi.ce_cfg.shadow_reg_v2,
drivers/net/wireless/ath/ath11k/qmi.c:		       sizeof(u32) * req->shadow_reg_v2_len);
drivers/net/wireless/ath/ath11k/qmi.c:		req->shadow_reg_v2_valid = 0;
drivers/net/wireless/ath/ath11k/debugfs_sta.c:	stats_req->type = ATH11K_DBG_HTT_EXT_STATS_PEER_INFO;
drivers/net/wireless/ath/ath11k/debugfs_sta.c:	memcpy(stats_req->peer_addr, sta->addr, ETH_ALEN);
drivers/net/wireless/ath/ath11k/debugfs_sta.c:	buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_sta.c:	length = min_t(u32, stats_req->buf_len, ATH11K_HTT_STATS_BUF_SIZE);
drivers/net/wireless/ath/ath11k/mac.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/ath/ath11k/mac.c:	if (req->ie_len) {
drivers/net/wireless/ath/ath11k/mac.c:		arg.extraie.len = req->ie_len;
drivers/net/wireless/ath/ath11k/mac.c:		arg.extraie.ptr = kzalloc(req->ie_len, GFP_KERNEL);
drivers/net/wireless/ath/ath11k/mac.c:		memcpy(arg.extraie.ptr, req->ie, req->ie_len);
drivers/net/wireless/ath/ath11k/mac.c:	if (req->n_ssids) {
drivers/net/wireless/ath/ath11k/mac.c:		arg.num_ssids = req->n_ssids;
drivers/net/wireless/ath/ath11k/mac.c:			arg.ssid[i].length  = req->ssids[i].ssid_len;
drivers/net/wireless/ath/ath11k/mac.c:			memcpy(&arg.ssid[i].ssid, req->ssids[i].ssid,
drivers/net/wireless/ath/ath11k/mac.c:			       req->ssids[i].ssid_len);
drivers/net/wireless/ath/ath11k/mac.c:	if (req->n_channels) {
drivers/net/wireless/ath/ath11k/mac.c:		arg.num_chan = req->n_channels;
drivers/net/wireless/ath/ath11k/mac.c:			arg.chan_list[i] = req->channels[i]->center_freq;
drivers/net/wireless/ath/ath11k/mac.c:	if (req->ie_len)
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 *buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u32 len = stats_req->buf_len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:		stats_req->buf_len = buf_len - 1;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:		stats_req->buf_len = len;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->done = FIELD_GET(HTT_T2H_EXT_STATS_INFO1_DONE, msg->info1);
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	if (stats_req->done)
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:		complete(&stats_req->cmpln);
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	u8 type = stats_req->type;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	init_completion(&stats_req->cmpln);
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->done = false;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->pdev_id = pdev_id;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	ret = ath11k_prep_htt_stats_cfg_params(ar, type, stats_req->peer_addr,
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	while (!wait_for_completion_timeout(&stats_req->cmpln, 3 * HZ)) {
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:		if (!stats_req->done) {
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:			stats_req->done = true;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	stats_req->type = type;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	buf = stats_req->buf;
drivers/net/wireless/ath/ath11k/debugfs_htt_stats.c:	length = min_t(u32, stats_req->buf_len, ATH11K_HTT_STATS_BUF_SIZE);
drivers/net/wireless/ath/ath11k/htc.c:	if (conn_req->service_id == ATH11K_HTC_SVC_ID_RSVD_CTRL) {
drivers/net/wireless/ath/ath11k/htc.c:						    conn_req->service_id);
drivers/net/wireless/ath/ath11k/htc.c:			   htc_service_name(conn_req->service_id));
drivers/net/wireless/ath/ath11k/htc.c:	if (!(conn_req->service_id == ATH11K_HTC_SVC_ID_WMI_CONTROL ||
drivers/net/wireless/ath/ath11k/htc.c:	      conn_req->service_id == ATH11K_HTC_SVC_ID_WMI_CONTROL_MAC1 ||
drivers/net/wireless/ath/ath11k/htc.c:	      conn_req->service_id == ATH11K_HTC_SVC_ID_WMI_CONTROL_MAC2)) {
drivers/net/wireless/ath/ath11k/htc.c:					  conn_req->service_id);
drivers/net/wireless/ath/ath11k/htc.c:	ep->service_id = conn_req->service_id;
drivers/net/wireless/ath/ath11k/htc.c:	ep->max_tx_queue_depth = conn_req->max_send_queue_depth;
drivers/net/wireless/ath/ath11k/htc.c:	ep->ep_ops = conn_req->ep_ops;
drivers/net/wireless/ath/ath9k/main.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/ath/ath9k/channel.c:	if (!req->n_ssids || (chan->flags & IEEE80211_CHAN_NO_IR))
drivers/net/wireless/ath/ath9k/channel.c:	if (sc->offchannel.scan_idx >= req->n_channels) {
drivers/net/wireless/ath/ath9k/channel.c:			req->n_channels);
drivers/net/wireless/ath/ath9k/channel.c:	chan = req->channels[sc->offchannel.scan_idx++];
drivers/net/wireless/ath/ath9k/channel.c:			ssid->ssid, ssid->ssid_len, req->ie_len);
drivers/net/wireless/ath/ath9k/channel.c:	if (req->no_cck)
drivers/net/wireless/ath/ath9k/channel.c:	if (req->ie_len)
drivers/net/wireless/ath/ath9k/channel.c:		skb_put_data(skb, req->ie, req->ie_len);
drivers/net/wireless/ath/ath9k/channel.c:	    req->n_ssids) {
drivers/net/wireless/ath/ath9k/channel.c:		for (i = 0; i < req->n_ssids; i++)
drivers/net/wireless/ath/ath9k/channel.c:			ath_scan_send_probe(sc, &req->ssids[i]);
drivers/net/wireless/ath/ath9k/htc_hst.c:			service_connreq->service_id);
drivers/net/wireless/ath/ath9k/htc_hst.c:	endpoint->service_id = service_connreq->service_id;
drivers/net/wireless/ath/ath9k/htc_hst.c:	endpoint->max_txqdepth = service_connreq->max_send_qdepth;
drivers/net/wireless/ath/ath9k/htc_hst.c:	endpoint->ul_pipeid = service_to_ulpipe(service_connreq->service_id);
drivers/net/wireless/ath/ath9k/htc_hst.c:	endpoint->dl_pipeid = service_to_dlpipe(service_connreq->service_id);
drivers/net/wireless/ath/ath9k/htc_hst.c:	endpoint->ep_callbacks = service_connreq->ep_callbacks;
drivers/net/wireless/ath/ath9k/htc_hst.c:	conn_msg->service_id = cpu_to_be16(service_connreq->service_id);
drivers/net/wireless/ath/ath9k/htc_hst.c:	conn_msg->con_flags = cpu_to_be16(service_connreq->con_flags);
drivers/net/wireless/ath/ath9k/htc_hst.c:			service_connreq->service_id);
drivers/net/wireless/ath/wil6210/cfg80211.c:	struct wil_sta_info *sta = &wil->sta[req->cid];
drivers/net/wireless/ath/wil6210/cfg80211.c:	cfg80211_probe_status(ndev, sta->addr, req->cookie, alive,
drivers/net/wireless/ath/wil6210/cfg80211.c:		list_del(&req->list);
drivers/net/wireless/ath/wil6210/cfg80211.c:	req->cid = cid;
drivers/net/wireless/ath/wil6210/cfg80211.c:	req->cookie = cid;
drivers/net/wireless/ath/wil6210/cfg80211.c:	list_add_tail(&req->list, &vif->probe_client_pending);
drivers/net/wireless/ath/wil6210/cfg80211.c:	*cookie = req->cookie;
drivers/net/wireless/ath/wil6210/debugfs.c:/*---------freq------------*/
drivers/net/wireless/ath/ath10k/qmi.c:		req->valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->file_id_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->file_id = 0;
drivers/net/wireless/ath/ath10k/qmi.c:		req->total_size_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->total_size = ar->normal_mode_fw.board_len;
drivers/net/wireless/ath/ath10k/qmi.c:		req->seg_id_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->data_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->end_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:			req->data_len = QMI_WLFW_MAX_DATA_SIZE_V01;
drivers/net/wireless/ath/ath10k/qmi.c:			req->data_len = remaining;
drivers/net/wireless/ath/ath10k/qmi.c:			req->end = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		memcpy(req->data, temp, req->data_len);
drivers/net/wireless/ath/ath10k/qmi.c:		    !(req->end == 1 &&
drivers/net/wireless/ath/ath10k/qmi.c:		remaining -= req->data_len;
drivers/net/wireless/ath/ath10k/qmi.c:		temp += req->data_len;
drivers/net/wireless/ath/ath10k/qmi.c:		req->seg_id++;
drivers/net/wireless/ath/ath10k/qmi.c:	req->host_version_valid = 0;
drivers/net/wireless/ath/ath10k/qmi.c:	req->tgt_cfg_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg_len = QMI_WLFW_MAX_NUM_CE_V01;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg_len = config->num_ce_tgt_cfg;
drivers/net/wireless/ath/ath10k/qmi.c:	for (i = 0; i < req->tgt_cfg_len; i++) {
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg[i].pipe_num = config->ce_tgt_cfg[i].pipe_num;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg[i].pipe_dir = config->ce_tgt_cfg[i].pipe_dir;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg[i].nentries = config->ce_tgt_cfg[i].nentries;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg[i].nbytes_max = config->ce_tgt_cfg[i].nbytes_max;
drivers/net/wireless/ath/ath10k/qmi.c:		req->tgt_cfg[i].flags = config->ce_tgt_cfg[i].flags;
drivers/net/wireless/ath/ath10k/qmi.c:	req->svc_cfg_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->svc_cfg_len = QMI_WLFW_MAX_NUM_SVC_V01;
drivers/net/wireless/ath/ath10k/qmi.c:		req->svc_cfg_len = config->num_ce_svc_pipe_cfg;
drivers/net/wireless/ath/ath10k/qmi.c:	for (i = 0; i < req->svc_cfg_len; i++) {
drivers/net/wireless/ath/ath10k/qmi.c:		req->svc_cfg[i].service_id = config->ce_svc_cfg[i].service_id;
drivers/net/wireless/ath/ath10k/qmi.c:		req->svc_cfg[i].pipe_dir = config->ce_svc_cfg[i].pipe_dir;
drivers/net/wireless/ath/ath10k/qmi.c:		req->svc_cfg[i].pipe_num = config->ce_svc_cfg[i].pipe_num;
drivers/net/wireless/ath/ath10k/qmi.c:	req->shadow_reg_valid = 1;
drivers/net/wireless/ath/ath10k/qmi.c:		req->shadow_reg_len = QMI_WLFW_MAX_NUM_SHADOW_REG_V01;
drivers/net/wireless/ath/ath10k/qmi.c:		req->shadow_reg_len = config->num_shadow_reg_cfg;
drivers/net/wireless/ath/ath10k/qmi.c:	memcpy(req->shadow_reg, config->shadow_reg_cfg,
drivers/net/wireless/ath/ath10k/qmi.c:	       sizeof(struct wlfw_shadow_reg_cfg_s_v01) * req->shadow_reg_len);
drivers/net/wireless/ath/ath10k/htt_tx.c:	memcpy(req->upload_types, &mask, 3);
drivers/net/wireless/ath/ath10k/htt_tx.c:	memcpy(req->reset_types, &reset_mask, 3);
drivers/net/wireless/ath/ath10k/htt_tx.c:	req->stat_type = HTT_STATS_REQ_CFG_STAT_TYPE_INVALID;
drivers/net/wireless/ath/ath10k/htt_tx.c:	req->cookie_lsb = cpu_to_le32(cookie & 0xffffffff);
drivers/net/wireless/ath/ath10k/htt_tx.c:	req->cookie_msb = cpu_to_le32((cookie & 0xffffffff00000000ULL) >> 32);
drivers/net/wireless/ath/ath10k/mac.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/ath/ath10k/mac.c:	if (req->ie_len) {
drivers/net/wireless/ath/ath10k/mac.c:		arg.ie_len = req->ie_len;
drivers/net/wireless/ath/ath10k/mac.c:		memcpy(arg.ie, req->ie, arg.ie_len);
drivers/net/wireless/ath/ath10k/mac.c:	if (req->n_ssids) {
drivers/net/wireless/ath/ath10k/mac.c:		arg.n_ssids = req->n_ssids;
drivers/net/wireless/ath/ath10k/mac.c:			arg.ssids[i].len  = req->ssids[i].ssid_len;
drivers/net/wireless/ath/ath10k/mac.c:			arg.ssids[i].ssid = req->ssids[i].ssid;
drivers/net/wireless/ath/ath10k/mac.c:	if (req->flags & NL80211_SCAN_FLAG_RANDOM_ADDR) {
drivers/net/wireless/ath/ath10k/mac.c:		ether_addr_copy(arg.mac_addr.addr, req->mac_addr);
drivers/net/wireless/ath/ath10k/mac.c:		ether_addr_copy(arg.mac_mask.addr, req->mac_addr_mask);
drivers/net/wireless/ath/ath10k/mac.c:	if (req->n_channels) {
drivers/net/wireless/ath/ath10k/mac.c:		arg.n_channels = req->n_channels;
drivers/net/wireless/ath/ath10k/mac.c:			arg.channels[i] = req->channels[i]->center_freq;
drivers/net/wireless/ath/ath10k/mac.c:	if (req->duration) {
drivers/net/wireless/ath/ath10k/mac.c:		arg.dwell_time_active = req->duration;
drivers/net/wireless/ath/ath10k/mac.c:		arg.dwell_time_passive = req->duration;
drivers/net/wireless/ath/ath10k/mac.c:		arg.burst_duration_ms = req->duration;
drivers/net/wireless/ath/ath10k/mac.c:				(arg.n_channels - 1) + (req->duration +
drivers/net/wireless/ath/ath10k/htc.c:	if (conn_req->service_id == ATH10K_HTC_SVC_ID_RSVD_CTRL) {
drivers/net/wireless/ath/ath10k/htc.c:						    conn_req->service_id);
drivers/net/wireless/ath/ath10k/htc.c:			   htc_service_name(conn_req->service_id));
drivers/net/wireless/ath/ath10k/htc.c:	if (conn_req->service_id != ATH10K_HTC_SVC_ID_WMI_CONTROL) {
drivers/net/wireless/ath/ath10k/htc.c:	req_msg->service_id = __cpu_to_le16(conn_req->service_id);
drivers/net/wireless/ath/ath10k/htc.c:	ep->service_id = conn_req->service_id;
drivers/net/wireless/ath/ath10k/htc.c:	ep->max_tx_queue_depth = conn_req->max_send_queue_depth;
drivers/net/wireless/ath/ath10k/htc.c:	if (conn_req->service_id == ATH10K_HTC_SVC_ID_HTT_DATA_MSG &&
drivers/net/wireless/ath/ath10k/htc.c:	ep->ep_ops = conn_req->ep_ops;
drivers/net/wireless/ath/ath10k/sdio.c:	list_del(&bus_req->list);
drivers/net/wireless/ath/ath10k/sdio.c:	list_add_tail(&bus_req->list, &ar_sdio->bus_req_freeq);
drivers/net/wireless/ath/ath10k/sdio.c:	skb = req->skb;
drivers/net/wireless/ath/ath10k/sdio.c:	ret = ath10k_sdio_write(ar, req->address, skb->data, skb->len);
drivers/net/wireless/ath/ath10k/sdio.c:			    req->address, ret);
drivers/net/wireless/ath/ath10k/sdio.c:	if (req->htc_msg) {
drivers/net/wireless/ath/ath10k/sdio.c:		ep = &ar->htc.endpoint[req->eid];
drivers/net/wireless/ath/ath10k/sdio.c:	} else if (req->comp) {
drivers/net/wireless/ath/ath10k/sdio.c:		complete(req->comp);
drivers/net/wireless/ath/ath10k/sdio.c:		list_del(&req->list);
drivers/net/wireless/ath/ath10k/sdio.c:		if (req->address >= mbox_info->htc_addr &&
drivers/net/wireless/ath/ath10k/sdio.c:	bus_req->skb = skb;
drivers/net/wireless/ath/ath10k/sdio.c:	bus_req->eid = eid;
drivers/net/wireless/ath/ath10k/sdio.c:	bus_req->address = addr;
drivers/net/wireless/ath/ath10k/sdio.c:	bus_req->htc_msg = htc_msg;
drivers/net/wireless/ath/ath10k/sdio.c:	bus_req->comp = comp;
drivers/net/wireless/ath/ath10k/sdio.c:	list_add_tail(&bus_req->list, &ar_sdio->wr_asyncq);
drivers/net/wireless/ath/ath10k/sdio.c:		list_del(&req->list);
drivers/net/wireless/ath/ath10k/sdio.c:		if (req->htc_msg) {
drivers/net/wireless/ath/ath10k/sdio.c:			ep = &ar->htc.endpoint[req->eid];
drivers/net/wireless/ath/ath10k/sdio.c:			ath10k_htc_notify_tx_completion(ep, req->skb);
drivers/net/wireless/ath/ath10k/sdio.c:		} else if (req->skb) {
drivers/net/wireless/ath/ath10k/sdio.c:			kfree_skb(req->skb);
drivers/net/wireless/quantenna/qtnfmac/cfg80211.c:	pr_debug("MAC%u: initiator=%d alpha=%c%c\n", mac->macid, req->initiator,
drivers/net/wireless/quantenna/qtnfmac/cfg80211.c:		 req->alpha2[0], req->alpha2[1]);
drivers/net/wireless/quantenna/qtnfmac/cfg80211.c:		       mac->macid, req->alpha2[0], req->alpha2[1], ret);
drivers/net/wireless/quantenna/qtnfmac/commands.c:	struct wireless_dev *wdev = scan_req->wdev;
drivers/net/wireless/quantenna/qtnfmac/commands.c:	if (scan_req->duration) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:		dwell_active = scan_req->duration;
drivers/net/wireless/quantenna/qtnfmac/commands.c:		dwell_passive = scan_req->duration;
drivers/net/wireless/quantenna/qtnfmac/commands.c:	cmd->n_ssids = cpu_to_le16(scan_req->n_ssids);
drivers/net/wireless/quantenna/qtnfmac/commands.c:	for (count = 0; count < scan_req->n_ssids; ++count) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:					 scan_req->ssids[count].ssid,
drivers/net/wireless/quantenna/qtnfmac/commands.c:					 scan_req->ssids[count].ssid_len);
drivers/net/wireless/quantenna/qtnfmac/commands.c:	if (scan_req->ie_len != 0)
drivers/net/wireless/quantenna/qtnfmac/commands.c:					scan_req->ie, scan_req->ie_len);
drivers/net/wireless/quantenna/qtnfmac/commands.c:	for (count = 0; count < scan_req->n_channels; ++count) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:		sc = scan_req->channels[count];
drivers/net/wireless/quantenna/qtnfmac/commands.c:	if (scan_req->flags & NL80211_SCAN_FLAG_FLUSH)
drivers/net/wireless/quantenna/qtnfmac/commands.c:	if (scan_req->duration_mandatory)
drivers/net/wireless/quantenna/qtnfmac/commands.c:		 scan_req->duration_mandatory ? "mandatory" : "max",
drivers/net/wireless/quantenna/qtnfmac/commands.c:	if (scan_req->flags & NL80211_SCAN_FLAG_RANDOM_ADDR) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:			 scan_req->mac_addr, scan_req->mac_addr_mask);
drivers/net/wireless/quantenna/qtnfmac/commands.c:		qtnf_cmd_randmac_tlv_add(cmd_skb, scan_req->mac_addr,
drivers/net/wireless/quantenna/qtnfmac/commands.c:					 scan_req->mac_addr_mask);
drivers/net/wireless/quantenna/qtnfmac/commands.c:	cmd->alpha2[0] = req->alpha2[0];
drivers/net/wireless/quantenna/qtnfmac/commands.c:	cmd->alpha2[1] = req->alpha2[1];
drivers/net/wireless/quantenna/qtnfmac/commands.c:	switch (req->initiator) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:	switch (req->user_reg_hint_type) {
drivers/net/wireless/quantenna/qtnfmac/commands.c:	switch (req->dfs_region) {
drivers/net/wireless/atmel/at76c50x-usb.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/atmel/at76c50x-usb.c:	if (req->n_ssids) {
drivers/net/wireless/atmel/at76c50x-usb.c:		ssid = req->ssids[0].ssid;
drivers/net/wireless/atmel/at76c50x-usb.c:		len = req->ssids[0].ssid_len;
drivers/net/wireless/ti/wlcore/main.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/ti/wlcore/main.c:	if (req->n_ssids) {
drivers/net/wireless/ti/wlcore/main.c:		ssid = req->ssids[0].ssid;
drivers/net/wireless/ti/wlcore/main.c:		len = req->ssids[0].ssid_len;
drivers/net/wireless/ti/wlcore/scan.c:	BUG_ON(req->n_channels > WL1271_MAX_CHANNELS);
drivers/net/wireless/ti/wlcore/scan.c:	struct cfg80211_match_set *sets = req->match_sets;
drivers/net/wireless/ti/wlcore/scan.c:	struct cfg80211_ssid *ssids = req->ssids;
drivers/net/wireless/ti/wlcore/scan.c:	for (i = 0; i < req->n_match_sets; i++)
drivers/net/wireless/ti/wlcore/scan.c:	    (!req->n_ssids ||
drivers/net/wireless/ti/wlcore/scan.c:	     (req->n_ssids == 1 && req->ssids[0].ssid_len == 0))) {
drivers/net/wireless/ti/wlcore/scan.c:		for (i = 0; i < req->n_ssids; i++) {
drivers/net/wireless/ti/wlcore/scan.c:		for (i = 0; i < req->n_match_sets; i++) {
drivers/net/wireless/ti/wlcore/scan.c:		if ((req->n_ssids > 1) ||
drivers/net/wireless/ti/wlcore/scan.c:		    (req->n_ssids == 1 && req->ssids[0].ssid_len > 0)) {
drivers/net/wireless/ti/wlcore/scan.c:			for (i = 0; i < req->n_ssids; i++) {
drivers/net/wireless/ti/wlcore/scan.c:				if (!req->ssids[i].ssid_len)
drivers/net/wireless/ti/wlcore/scan.c:					if ((req->ssids[i].ssid_len ==
drivers/net/wireless/ti/wlcore/scan.c:					    !memcmp(req->ssids[i].ssid,
drivers/net/wireless/ti/wlcore/scan.c:						   req->ssids[i].ssid_len)) {
drivers/net/wireless/ti/wl18xx/scan.c:	WARN_ON(req->n_ssids > 1);
drivers/net/wireless/ti/wl18xx/scan.c:	wlcore_set_scan_chan_params(wl, cmd_channels, req->channels,
drivers/net/wireless/ti/wl18xx/scan.c:				    req->n_channels, req->n_ssids,
drivers/net/wireless/ti/wl18xx/scan.c:	if (req->no_cck)
drivers/net/wireless/ti/wl18xx/scan.c:	if (req->n_ssids) {
drivers/net/wireless/ti/wl18xx/scan.c:		cmd->ssid_len = req->ssids[0].ssid_len;
drivers/net/wireless/ti/wl18xx/scan.c:		memcpy(cmd->ssid, req->ssids[0].ssid, cmd->ssid_len);
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid : NULL,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid_len : 0,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ie,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ie_len,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid : NULL,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid_len : 0,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ie,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ie_len,
drivers/net/wireless/ti/wl18xx/scan.c:	wlcore_set_scan_chan_params(wl, cmd_channels, req->channels,
drivers/net/wireless/ti/wl18xx/scan.c:				    req->n_channels, req->n_ssids,
drivers/net/wireless/ti/wl18xx/scan.c:	    c->long_interval > req->scan_plans[0].interval * MSEC_PER_SEC) {
drivers/net/wireless/ti/wl18xx/scan.c:			cpu_to_le16(req->scan_plans[0].interval * MSEC_PER_SEC);
drivers/net/wireless/ti/wl18xx/scan.c:			cpu_to_le16(req->scan_plans[0].interval * MSEC_PER_SEC);
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid : NULL,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid_len : 0,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid : NULL,
drivers/net/wireless/ti/wl18xx/scan.c:				 req->ssids ? req->ssids[0].ssid_len : 0,
drivers/net/wireless/ti/wl12xx/scan.c:	     i < req->n_channels && j < WL1271_SCAN_MAX_CHANNELS;
drivers/net/wireless/ti/wl12xx/scan.c:		flags = req->channels[i]->flags;
drivers/net/wireless/ti/wl12xx/scan.c:		    (req->channels[i]->band == band) &&
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->band,
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->center_freq);
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->hw_value,
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->flags);
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->max_antenna_gain,
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->max_power);
drivers/net/wireless/ti/wl12xx/scan.c:				     req->channels[i]->beacon_found);
drivers/net/wireless/ti/wl12xx/scan.c:			channels[j].tx_power_att = req->channels[i]->max_power;
drivers/net/wireless/ti/wl12xx/scan.c:			channels[j].channel = req->channels[i]->hw_value;
drivers/net/wireless/ti/wl12xx/scan.c:	if (!passive && wl->scan.req->n_ssids == 0)
drivers/net/wireless/ti/wl12xx/scan.c:					 wl->scan.req->ie,
drivers/net/wireless/ti/wl12xx/scan.c:					 wl->scan.req->ie_len, NULL, 0, false);
drivers/net/wireless/ti/wl12xx/scan.c:		if (wl->scan.req->no_cck) {
drivers/net/wireless/ti/wl12xx/scan.c:		if (wl->scan.req->no_cck) {
drivers/net/wireless/ti/wl12xx/scan.c:	bool force_passive = !req->n_ssids;
drivers/net/wireless/ti/wl12xx/scan.c:		cfg->intervals[i] = cpu_to_le32(req->scan_plans[0].interval *
drivers/net/wireless/ti/wl12xx/scan.c:	if (!wlcore_set_scan_chan_params(wl, cfg_channels, req->channels,
drivers/net/wireless/ti/wl12xx/scan.c:					 req->n_channels, req->n_ssids,
drivers/net/wireless/ti/wl12xx/scan.c:						 req->ssids[0].ssid,
drivers/net/wireless/ti/wl12xx/scan.c:						 req->ssids[0].ssid_len,
drivers/net/wireless/ti/wl12xx/scan.c:						 req->ssids[0].ssid,
drivers/net/wireless/ti/wl12xx/scan.c:						 req->ssids[0].ssid_len,
drivers/net/wireless/ti/wl1251/main.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/ti/wl1251/main.c:	if (req->n_ssids) {
drivers/net/wireless/ti/wl1251/main.c:		ssid = req->ssids[0].ssid;
drivers/net/wireless/ti/wl1251/main.c:		ssid_len = req->ssids[0].ssid_len;
drivers/net/wireless/ti/wl1251/main.c:				     req->ie_len);
drivers/net/wireless/ti/wl1251/main.c:	if (req->ie_len)
drivers/net/wireless/ti/wl1251/main.c:		skb_put_data(skb, req->ie, req->ie_len);
drivers/net/wireless/ti/wl1251/main.c:	ret = wl1251_cmd_scan(wl, ssid, ssid_len, req->channels,
drivers/net/wireless/ti/wl1251/main.c:			      req->n_channels, WL1251_SCAN_NUM_PROBES);
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:	if (req->n_channels == 0)
drivers/net/wireless/intel/iwlwifi/dvm/mac80211.c:					req->channels[0]->band);
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	if (hw_req->req.n_channels == 0 ||
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	    hw_req->req.n_channels > mvm->fw->ucode_capa.n_scan_channels)
drivers/net/wireless/intel/iwlwifi/mvm/mac80211.c:	ret = iwl_mvm_reg_scan_start(mvm, vif, &hw_req->req, &hw_req->ies);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	for (i = 0; i < mvm->ftm_initiator.req->n_peers; i++) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		memcpy(result.addr, mvm->ftm_initiator.req->peers[i].addr,
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	cmd->request_id = req->cookie;
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	cmd->num_of_ap = req->n_peers;
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	if (!req->timeout || req->timeout > 255 * 100)
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		cmd->req_timeout = DIV_ROUND_UP(req->timeout, 100);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	memcpy(cmd->macaddr_template, req->mac_addr, ETH_ALEN);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		cmd->macaddr_mask[i] = ~req->mac_addr_mask[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	cmd->request_id = req->cookie;
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	cmd->num_of_ap = req->n_peers;
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	if (req->timeout)
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		cmd->req_timeout_ms = cpu_to_le32(req->timeout);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	memcpy(cmd->macaddr_template, req->mac_addr, ETH_ALEN);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		cmd->macaddr_mask[i] = ~req->mac_addr_mask[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		for (i = 0; i < req->n_peers; i++) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:			if (req->peers[i].report_ap_tsf) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		.request_id = req->cookie,
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	for (i = 0; i < req->n_peers; i++) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		struct cfg80211_pmsr_request_peer *peer = &req->peers[i];
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	if (request_id != (u8)mvm->ftm_initiator.req->cookie) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:			request_id, (u8)mvm->ftm_initiator.req->cookie);
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:	if (num_of_aps > mvm->ftm_initiator.req->n_peers) {
drivers/net/wireless/intel/iwlwifi/mvm/ftm-initiator.c:		       mvm->ftm_initiator.req->cookie, num_of_aps);
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (WARN_ON(req->n_match_sets > max_profiles))
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	data->num_profiles = req->n_match_sets;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (!req->n_match_sets || !req->match_sets[0].ssid.ssid_len)
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	for (i = 0; i < req->n_match_sets; i++) {
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (req->n_match_sets && req->match_sets[0].ssid.ssid_len) {
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:			       req->n_match_sets);
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	p_req->mac_header = src_p_req->mac_header;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:		p_req->band_data[i] = src_p_req->band_data[i];
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	p_req->common_data = src_p_req->common_data;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	memcpy(p_req->buf, src_p_req->buf, sizeof(p_req->buf));
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (!iwl_mvm_scan_fits(mvm, req->n_ssids, ies, req->n_channels))
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_ssids = req->n_ssids;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.flags = req->flags;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_channels = req->n_channels;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.ssids = req->ssids;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.channels = req->channels;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.mac_addr = req->mac_addr;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.mac_addr_mask = req->mac_addr_mask;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.no_cck = req->no_cck;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_6ghz_params = req->n_6ghz_params;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.scan_6ghz_params = req->scan_6ghz_params;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.scan_6ghz = req->scan_6ghz;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (req->duration)
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_ssids = req->n_ssids;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.flags = req->flags;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_channels = req->n_channels;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.ssids = req->ssids;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.channels = req->channels;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.mac_addr = req->mac_addr;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.mac_addr_mask = req->mac_addr_mask;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_match_sets = req->n_match_sets;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.match_sets = req->match_sets;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (!req->n_scan_plans)
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.n_scan_plans = req->n_scan_plans;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	params.scan_plans = req->scan_plans;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	if (req->delay > U16_MAX) {
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:		params.delay = req->delay;
drivers/net/wireless/intel/iwlwifi/mvm/scan.c:	    !iwl_mvm_scan_fits(mvm, req->n_ssids, ies, params.n_channels)) {
drivers/net/wireless/intel/ipw2x00/ipw2200.c:			int len = min((int)req->essid_len,
drivers/net/wireless/intel/ipw2x00/ipw2200.c:			memcpy(priv->direct_scan_ssid, req->essid, len);
drivers/net/wireless/intel/ipw2x00/ipw2200.c:		} else if (req->scan_type == IW_SCAN_TYPE_PASSIVE) {
drivers/net/wireless/intel/iwlegacy/common.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/intel/iwlegacy/common.c:	if (req->n_channels == 0) {
drivers/net/wireless/intel/iwlegacy/common.c:	il->scan_band = req->channels[0]->band;
drivers/net/wireless/marvell/mwifiex/11h.c:	cr_req->chan_desc.start_freq = cpu_to_le16(MWIFIEX_A_BAND_START_FREQ);
drivers/net/wireless/marvell/mwifiex/11h.c:	cr_req->chan_desc.chan_num = radar_params->chandef->chan->hw_value;
drivers/net/wireless/marvell/mwifiex/11h.c:	cr_req->chan_desc.chan_width = radar_params->chandef->width;
drivers/net/wireless/marvell/mwifiex/11h.c:	cr_req->msec_dwell_time = cpu_to_le32(radar_params->cac_time_ms);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	    memcmp(priv->cfg_bssid, cmd_addba_req->peer_mac_addr, ETH_ALEN)) {
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:						cmd_addba_req->peer_mac_addr);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:				    cmd_addba_req->peer_mac_addr);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	memcpy(add_ba_rsp->peer_mac_addr, cmd_addba_req->peer_mac_addr,
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	add_ba_rsp->dialog_token = cmd_addba_req->dialog_token;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	add_ba_rsp->block_ack_tmo = cmd_addba_req->block_ack_tmo;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	add_ba_rsp->ssn = cmd_addba_req->ssn;
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	block_ack_param_set = le16_to_cpu(cmd_addba_req->block_ack_param_set);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	cmd_addba_req->block_ack_param_set = cpu_to_le16(block_ack_param_set);
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:	mwifiex_11n_create_rx_reorder_tbl(priv, cmd_addba_req->peer_mac_addr,
drivers/net/wireless/marvell/mwifiex/11n_rxreorder.c:					  le16_to_cpu(cmd_addba_req->ssn));
drivers/net/wireless/marvell/libertas/cfg.c:			priv->scan_req->channels[priv->scan_channel]->hw_value;
drivers/net/wireless/marvell/libertas/cfg.c:	if (priv->scan_req->n_ssids && priv->scan_req->ssids[0].ssid_len > 0)
drivers/net/wireless/marvell/libertas/cfg.c:					priv->scan_req->ssids[0].ssid,
drivers/net/wireless/marvell/libertas/cfg.c:					priv->scan_req->ssids[0].ssid_len);
drivers/net/wireless/marvell/libertas/cfg.c:	if (last_channel > priv->scan_req->n_channels)
drivers/net/wireless/marvell/libertas/cfg.c:		last_channel = priv->scan_req->n_channels;
drivers/net/wireless/marvell/libertas/cfg.c:		priv->scan_req->n_ssids);
drivers/net/wireless/marvell/libertas/cfg.c:	if (priv->scan_channel < priv->scan_req->n_channels) {
drivers/net/wireless/marvell/libertas/cfg.c:	if (priv->scan_channel >= priv->scan_req->n_channels) {
drivers/net/wireless/marvell/libertas/cfg.c:	creq->ssids = (void *)&creq->channels[n_channels];
drivers/net/wireless/marvell/libertas/cfg.c:	creq->n_channels = n_channels;
drivers/net/wireless/marvell/libertas/cfg.c:	creq->n_ssids = 1;
drivers/net/wireless/marvell/libertas/cfg.c:			creq->channels[i] = &wiphy->bands[band]->channels[j];
drivers/net/wireless/marvell/libertas/cfg.c:		/* Set real number of channels specified in creq->channels[] */
drivers/net/wireless/marvell/libertas/cfg.c:		creq->n_channels = i;
drivers/net/wireless/marvell/libertas/cfg.c:		memcpy(creq->ssids[0].ssid, sme->ssid, sme->ssid_len);
drivers/net/wireless/marvell/libertas/cfg.c:		creq->ssids[0].ssid_len = sme->ssid_len;
drivers/net/wireless/rsi/rsi_91x_mgmt.c:	bgscan->num_bgscan_channels = scan_req->n_channels;
drivers/net/wireless/rsi/rsi_91x_mgmt.c:			cpu_to_le16(scan_req->channels[i]->hw_value);
drivers/net/wireless/rsi/rsi_91x_mgmt.c:	if (scan_req->n_ssids) {
drivers/net/wireless/rsi/rsi_91x_mgmt.c:		ssid = scan_req->ssids[0].ssid;
drivers/net/wireless/rsi/rsi_91x_mgmt.c:		ssid_len = scan_req->ssids[0].ssid_len;
drivers/net/wireless/rsi/rsi_91x_mgmt.c:					      ssid_len, scan_req->ie_len);
drivers/net/wireless/rsi/rsi_91x_mac80211.c:	struct cfg80211_scan_request *scan_req = &hw_req->req;
drivers/net/wireless/rsi/rsi_91x_mac80211.c:	    scan_req->n_channels == 0)
drivers/net/wireless/mediatek/mt76/mt7915/mcu.c:	u8 num = req->total;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	struct cfg80211_scan_request *sreq = &scan_req->req;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	int ext_channels_num = max_t(int, sreq->n_channels - 32, 0);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	struct ieee80211_channel **scan_list = sreq->channels;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->seq_num = mvif->scan_seq_num | ext_phy << 7;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->bss_idx = mvif->idx;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->scan_type = sreq->n_ssids ? 1 : 0;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->probe_req_num = sreq->n_ssids ? 2 : 0;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->version = 1;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < sreq->n_ssids; i++) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		if (!sreq->ssids[i].ssid_len)
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->ssids[i].ssid_len = cpu_to_le32(sreq->ssids[i].ssid_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		memcpy(req->ssids[i].ssid, sreq->ssids[i].ssid,
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		       sreq->ssids[i].ssid_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->ssid_type = n_ssids ? BIT(2) : BIT(0);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->ssid_type_ext = n_ssids ? BIT(0) : 0;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->ssids_num = n_ssids;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	if (!sreq->n_ssids)
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->timeout_value = cpu_to_le16(sreq->n_channels * duration);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channel_min_dwell_time = cpu_to_le16(duration);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channel_dwell_time = cpu_to_le16(duration);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channels_num = min_t(u8, sreq->n_channels, 32);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->ext_channels_num = min_t(u8, ext_channels_num, 32);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < req->channels_num + req->ext_channels_num; i++) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:			chan = &req->ext_channels[i - 32];
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:			chan = &req->channels[i];
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channel_type = sreq->n_channels ? 4 : 0;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	if (sreq->ie_len > 0) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		memcpy(req->ies, sreq->ie, sreq->ie_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->ies_len = cpu_to_le16(sreq->ie_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	memcpy(req->bssid, sreq->bssid, ETH_ALEN);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	if (sreq->flags & NL80211_SCAN_FLAG_RANDOM_ADDR) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		get_random_mask_addr(req->random_mac, sreq->mac_addr,
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:				     sreq->mac_addr_mask);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->scan_func = 1;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	struct ieee80211_channel **scan_list = sreq->channels;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	skb = mt76_mcu_msg_alloc(mdev, NULL, sizeof(*req) + sreq->ie_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->version = 1;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->seq_num = mvif->scan_seq_num | ext_phy << 7;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	if (sreq->flags & NL80211_SCAN_FLAG_RANDOM_ADDR) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		get_random_mask_addr(req->random_mac, sreq->mac_addr,
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:				     sreq->mac_addr_mask);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->scan_func = 1;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->ssids_num = sreq->n_ssids;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < req->ssids_num; i++) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		ssid = &sreq->ssids[i];
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		memcpy(req->ssids[i].ssid, ssid->ssid, ssid->ssid_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->ssids[i].ssid_len = cpu_to_le32(ssid->ssid_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->match_num = sreq->n_match_sets;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < req->match_num; i++) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		match = &sreq->match_sets[i];
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		memcpy(req->match[i].ssid, match->ssid.ssid,
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->match[i].rssi_th = cpu_to_le32(match->rssi_thold);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->match[i].ssid_len = match->ssid.ssid_len;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channel_type = sreq->n_channels ? 4 : 0;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->channels_num = min_t(u8, sreq->n_channels, 64);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < req->channels_num; i++) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		chan = &req->channels[i];
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	req->intervals_num = sreq->n_scan_plans;
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	for (i = 0; i < req->intervals_num; i++)
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->intervals[i] = cpu_to_le16(sreq->scan_plans[i].interval);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:	if (sreq->ie_len > 0) {
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		req->ie_len = cpu_to_le16(sreq->ie_len);
drivers/net/wireless/mediatek/mt76/mt76_connac_mcu.c:		memcpy(skb_put(skb, sreq->ie_len), sreq->ie, sreq->ie_len);
drivers/net/wireless/mediatek/mt7601u/phy.c:			dev->freq_cal.freq--;
drivers/net/wireless/rndis_wlan.c:		if (buflen < le32_to_cpu(auth_req->length))
drivers/net/wireless/rndis_wlan.c:		flags = le32_to_cpu(auth_req->flags);
drivers/net/wireless/rndis_wlan.c:			    type, le32_to_cpu(auth_req->flags));
drivers/net/wireless/rndis_wlan.c:							auth_req->bssid,
drivers/net/wireless/rndis_wlan.c:							auth_req->bssid,
drivers/net/wireless/rndis_wlan.c:		buflen -= le32_to_cpu(auth_req->length);
drivers/net/wireless/rndis_wlan.c:		buf += le32_to_cpu(auth_req->length);
drivers/net/wireless/st/cw1200/scan.c:	struct cfg80211_scan_request *req = &hw_req->req;
drivers/net/wireless/st/cw1200/scan.c:	if (req->n_ssids == 1 && !req->ssids[0].ssid_len)
drivers/net/wireless/st/cw1200/scan.c:		req->n_ssids = 0;
drivers/net/wireless/st/cw1200/scan.c:		  req->n_ssids);
drivers/net/wireless/st/cw1200/scan.c:	if (req->n_ssids > WSM_SCAN_MAX_NUM_OF_SSIDS)
drivers/net/wireless/st/cw1200/scan.c:		req->ie_len);
drivers/net/wireless/st/cw1200/scan.c:	if (req->ie_len)
drivers/net/wireless/st/cw1200/scan.c:		skb_put_data(frame.skb, req->ie, req->ie_len);
drivers/net/wireless/st/cw1200/scan.c:	priv->scan.begin = &req->channels[0];
drivers/net/wireless/st/cw1200/scan.c:	priv->scan.end = &req->channels[req->n_channels];
drivers/net/wireless/st/cw1200/scan.c:	for (i = 0; i < req->n_ssids; ++i) {
drivers/net/wireless/st/cw1200/scan.c:		memcpy(&dst->ssid[0], req->ssids[i].ssid, sizeof(dst->ssid));
drivers/net/wireless/st/cw1200/scan.c:		dst->length = req->ssids[i].ssid_len;
drivers/net/wireless/st/cw1200/scan.c:		if (priv->scan.req->no_cck)
drivers/net/wireless/zydas/zd1201.c:	if (freq->e == 0)
drivers/net/wireless/zydas/zd1201.c:		channel = freq->m;
drivers/net/wireless/zydas/zd1201.c:		channel = ieee80211_frequency_to_channel(freq->m);
drivers/net/wireless/zydas/zd1201.c:	freq->e = 0;
drivers/net/wireless/zydas/zd1201.c:	freq->m = channel;
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		if (rd->addr != req->addr[i]) {
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:				 le16_to_cpu(req->addr[i]));
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	req->id = cpu_to_le16(USB_REQ_READ_REGS);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		req->addr[i] = cpu_to_le16((u16)addresses[i]);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	req->id = cpu_to_le16(USB_REQ_WRITE_REGS);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		struct reg_data *rw  = &req->reg_writes[i];
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	req->id = cpu_to_le16(USB_REQ_WRITE_RF);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	req->value = cpu_to_le16(2);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:	req->bits = cpu_to_le16(bits);
drivers/net/wireless/zydas/zd1211rw/zd_usb.c:		req->bit_values[i] = cpu_to_le16(bv);
drivers/net/phy/dp83640.c:	sec = clkreq->perout.start.sec;
drivers/net/phy/dp83640.c:	nsec = clkreq->perout.start.nsec;
drivers/net/phy/dp83640.c:	pwidth = clkreq->perout.period.sec * 1000000000UL;
drivers/net/phy/dp83640.c:	pwidth += clkreq->perout.period.nsec;
drivers/net/dsa/sja1105/sja1105_ptp.c:	if (req->type == PTP_CLK_REQ_PEROUT)
drivers/net/dsa/sja1105/sja1105_ptp.c:		rc = sja1105_per_out_enable(priv, &req->perout, on);
drivers/net/dsa/sja1105/sja1105_ptp.c:	else if (req->type == PTP_CLK_REQ_EXTTS)
drivers/net/dsa/sja1105/sja1105_ptp.c:		rc = sja1105_extts_enable(priv, &req->extts, on);
drivers/net/usb/pegasus.c:	req->bRequestType = PEGASUS_REQT_WRITE;
drivers/net/usb/pegasus.c:	req->bRequest = PEGASUS_REQ_SET_REGS;
drivers/net/usb/pegasus.c:	req->wValue = cpu_to_le16(0);
drivers/net/usb/pegasus.c:	req->wIndex = cpu_to_le16(EthCtrl0);
drivers/net/usb/pegasus.c:	req->wLength = cpu_to_le16(3);
drivers/net/usb/hso.c:	ctrl_req->wValue = 0;
drivers/net/usb/hso.c:	ctrl_req->wIndex = cpu_to_le16(hso_port_to_mux(port));
drivers/net/usb/hso.c:	ctrl_req->wLength = cpu_to_le16(size);
drivers/net/usb/hso.c:		ctrl_req->bRequestType = USB_DIR_IN |
drivers/net/usb/hso.c:		ctrl_req->bRequest = USB_CDC_GET_ENCAPSULATED_RESPONSE;
drivers/net/usb/hso.c:		ctrl_req->bRequestType = USB_DIR_OUT |
drivers/net/usb/hso.c:		ctrl_req->bRequest = USB_CDC_SEND_ENCAPSULATED_COMMAND;
drivers/net/usb/hso.c:		ctrl_req->bRequestType, ctrl_req->wLength, port);
drivers/net/usb/hso.c:	if (req->bRequestType ==
drivers/net/usb/cdc-phonet.c:	req->transfer_flags = URB_ZERO_PACKET;
drivers/net/usb/cdc-phonet.c:	struct sk_buff *skb = req->context;
drivers/net/usb/cdc-phonet.c:	int status = req->status;
drivers/net/usb/cdc-phonet.c:	req->transfer_flags = 0;
drivers/net/usb/cdc-phonet.c:	struct net_device *dev = req->context;
drivers/net/usb/cdc-phonet.c:	struct page *page = virt_to_page(req->transfer_buffer);
drivers/net/usb/cdc-phonet.c:	int status = req->status;
drivers/net/usb/cdc-phonet.c:						page, 1, req->actual_length,
drivers/net/usb/cdc-phonet.c:					page, 0, req->actual_length,
drivers/net/usb/cdc-phonet.c:		if (req->actual_length < PAGE_SIZE)
drivers/net/usb/cdc-phonet.c:		req->ifr_phonet_autoconf.device = PN_DEV_PC;
drivers/net/usb/rtl8150.c:	req->rx_creg = cpu_to_le16(reg);
drivers/net/usb/rtl8150.c:	req->dr.bRequestType = RTL8150_REQT_WRITE;
drivers/net/usb/rtl8150.c:	req->dr.bRequest = RTL8150_REQ_SET_REGS;
drivers/net/usb/rtl8150.c:	req->dr.wIndex = 0;
drivers/net/usb/rtl8150.c:	req->dr.wValue = cpu_to_le16(indx);
drivers/net/usb/rtl8150.c:	req->dr.wLength = cpu_to_le16(size);
drivers/net/usb/rtl8150.c:	                     usb_sndctrlpipe(dev->udev, 0), (void *)&req->dr,
drivers/net/usb/rtl8150.c:			     &req->rx_creg, size, async_set_reg_cb, req);
drivers/net/usb/usbnet.c:	req->bRequestType = reqtype;
drivers/net/usb/usbnet.c:	req->bRequest = cmd;
drivers/net/usb/usbnet.c:	req->wValue = cpu_to_le16(value);
drivers/net/usb/usbnet.c:	req->wIndex = cpu_to_le16(index);
drivers/net/usb/usbnet.c:	req->wLength = cpu_to_le16(size);
drivers/net/xen-netfront.c:		req->id = id;
drivers/net/xen-netfront.c:		req->gref = ref;
drivers/net/xen-netback/netback.c:		.id = req->id,
drivers/net/xen-netback/netback.c:		.type = req->type,
drivers/net/xen-netback/netback.c:	switch (req->type) {
drivers/net/xen-netback/netback.c:		status = xenvif_set_hash_alg(vif, req->data[0]);
drivers/net/xen-netback/netback.c:		status = xenvif_set_hash_flags(vif, req->data[0]);
drivers/net/xen-netback/netback.c:		status = xenvif_set_hash_key(vif, req->data[0],
drivers/net/xen-netback/netback.c:					     req->data[1]);
drivers/net/xen-netback/netback.c:						      req->data[0]);
drivers/net/xen-netback/netback.c:		status = xenvif_set_hash_mapping(vif, req->data[0],
drivers/net/xen-netback/netback.c:						 req->data[1],
drivers/net/xen-netback/netback.c:						 req->data[2]);
drivers/net/xen-netback/rx.c:	op->dest.u.ref    = req->gref;
drivers/net/xen-netback/rx.c:	rsp->id = req->id;
drivers/net/ethernet/brocade/bna/bna_enet.c:	switch (admin_req->enable) {
drivers/net/ethernet/brocade/bna/bna_enet.c:	switch (diag_lb_req->enable) {
drivers/net/ethernet/brocade/bna/bna_enet.c:	u32 tx_enet_mask = ntohl(stats_req->tx_enet_mask);
drivers/net/ethernet/brocade/bna/bna_enet.c:	u32 rx_enet_mask = ntohl(stats_req->rx_enet_mask);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(admin_up_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	admin_up_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	admin_up_req->enable = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_enable_req), &admin_up_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(admin_down_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	admin_down_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	admin_down_req->enable = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_enable_req), &admin_down_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(lpbk_up_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	lpbk_up_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	lpbk_up_req->mode = (ethport->bna->enet.type ==
drivers/net/ethernet/brocade/bna/bna_enet.c:	lpbk_up_req->enable = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_diag_lb_req), &lpbk_up_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(lpbk_down_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	lpbk_down_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	lpbk_down_req->enable = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_diag_lb_req), &lpbk_down_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(pause_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	pause_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	pause_req->tx_pause = enet->pause_config.tx_pause;
drivers/net/ethernet/brocade/bna/bna_enet.c:	pause_req->rx_pause = enet->pause_config.rx_pause;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_set_pause_req), &pause_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(attr_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	attr_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_attr_req), &attr_req->mh);
drivers/net/ethernet/brocade/bna/bna_enet.c:	bfi_msgq_mhdr_set(stats_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->stats_mask = htons(BFI_ENET_STATS_ALL);
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->tx_enet_mask = htonl(bna->tx_mod.rid_mask);
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->rx_enet_mask = htonl(bna->rx_mod.rid_mask);
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->host_buffer.a32.addr_hi = bna->stats.hw_stats_dma.msb;
drivers/net/ethernet/brocade/bna/bna_enet.c:	stats_req->host_buffer.a32.addr_lo = bna->stats.hw_stats_dma.lsb;
drivers/net/ethernet/brocade/bna/bna_enet.c:		sizeof(struct bfi_enet_stats_req), &stats_req->mh);
drivers/net/ethernet/brocade/bna/bfa_msgq.c:	cmdq->offset = ntohs(req->offset);
drivers/net/ethernet/brocade/bna/bfa_msgq.c:	cmdq->bytes_to_copy = ntohs(req->len);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET, req_type, 0, rxf->rx->rid);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	ether_addr_copy(req->mac_addr, mac->addr);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_ucast_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET, BFI_ENET_H2I_MAC_MCAST_ADD_REQ,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	ether_addr_copy(req->mac_addr, mac->addr);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_mcast_add_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET, BFI_ENET_H2I_MAC_MCAST_DEL_REQ,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->handle = htons(handle);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_mcast_del_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->enable = status;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_enable_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->enable = status;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_enable_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->block_idx = block_idx;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			req->bit_mask[i] =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			req->bit_mask[i] = 0xFFFFFFFF;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_rx_vlan_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->enable = rxf->vlan_strip_status;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_enable_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->size = htons(rxf->rit_size);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	memcpy(&req->table[0], rxf->rit, rxf->rit_size);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_rit_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->cfg.type = rxf->rss_cfg.hash_type;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->cfg.mask = rxf->rss_cfg.hash_mask;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		req->cfg.key[i] =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_rss_cfg_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->enable = rxf->rss_status;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_enable_req), &req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bna_rxf_mchandle_attach(rxf, (u8 *)&req->mac_addr,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(cfg_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->rx_cfg.frame_size = bna_enet_mtu_get(&rx->bna->enet);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->num_queue_sets = rx->num_paths;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			bfi_enet_datapath_q_init(&cfg_req->q_cfg[i].qs.q,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			cfg_req->q_cfg[i].qs.rx_buffer_size =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			bfi_enet_datapath_q_init(&cfg_req->q_cfg[i].ql.q,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:				cfg_req->rx_cfg.multi_buffer =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:			cfg_req->q_cfg[i].ql.rx_buffer_size =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		bfi_enet_datapath_q_init(&cfg_req->q_cfg[i].cq.q,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.intr.msix_index =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_pkt_dma = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_enabled = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_pkt_enabled = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.continuous_coalescing = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.msix = (rxp->cq.ib.intr_type == BNA_INTR_T_MSIX)
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.coalescing_timeout =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.inter_pkt_timeout =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.inter_pkt_count = (u8)rxp->cq.ib.interpkt_count;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.rxq_type = BFI_ENET_RXQ_LARGE_SMALL;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.rxq_type = BFI_ENET_RXQ_HDS;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.hds.type = rx->hds_cfg.hdr_type;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.hds.force_offset = rx->hds_cfg.forced_offset;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.hds.max_header_size = rx->hds_cfg.forced_offset;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->rx_cfg.rxq_type = BFI_ENET_RXQ_SINGLE;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->rx_cfg.strip_vlan = rx->rxf.vlan_strip_status;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_rx_cfg_req), &cfg_req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		&req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(cfg_req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->num_queues = tx->num_txq;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		bfi_enet_datapath_q_init(&cfg_req->q_cfg[i].q.q, &txq->qpt);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].q.priority = txq->priority;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.index_addr.a32.addr_lo =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.index_addr.a32.addr_hi =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		cfg_req->q_cfg[i].ib.intr.msix_index =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_pkt_dma = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_enabled = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.int_pkt_enabled = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.continuous_coalescing = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.msix = (txq->ib.intr_type == BNA_INTR_T_MSIX)
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.coalescing_timeout =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.inter_pkt_timeout =
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->ib_cfg.inter_pkt_count = (u8)txq->ib.interpkt_count;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->tx_cfg.vlan_mode = BFI_ENET_TX_VLAN_WI;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->tx_cfg.vlan_id = htons((u16)tx->txf_vlan_id);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->tx_cfg.admit_tagged_frame = BNA_STATUS_T_ENABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	cfg_req->tx_cfg.apply_vlan_filter = BNA_STATUS_T_DISABLED;
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		sizeof(struct bfi_enet_tx_cfg_req), &cfg_req->mh);
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	bfi_msgq_mhdr_set(req->mh, BFI_MC_ENET,
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:	req->mh.num_entries = htons(
drivers/net/ethernet/brocade/bna/bna_tx_rx.c:		&req->mh);
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	strcpy(iwreq->name, "IEEE 802.11bg");
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	struct iw_point *point = &iwreq->data;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:		essid = req->essid;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:		essid_len = req->essid_len;
drivers/net/ethernet/toshiba/ps3_gelic_wireless.c:	struct iw_param *param = &iwreq->param;
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:	s64 fns_in_sec_phy = phyfreq * (ptp_adj_freq->fns_phy +
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:					AQ_FRAC_PER_NS * ptp_adj_freq->ns_phy);
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:	s64 fns_in_sec_mac = macfreq * (ptp_adj_freq->fns_mac +
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:					AQ_FRAC_PER_NS * ptp_adj_freq->ns_mac);
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:	adj_fns_val = (ptp_adj_freq->fns_mac + AQ_FRAC_PER_NS *
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:		       ptp_adj_freq->ns_mac) + diff_in_mcp_overflow;
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:	ptp_adj_freq->mac_ns_adj = div64_s64(adj_fns_val, AQ_FRAC_PER_NS);
drivers/net/ethernet/aquantia/atlantic/hw_atl/hw_atl_b0.c:	ptp_adj_freq->mac_fns_adj = adj_fns_val - ptp_adj_freq->mac_ns_adj *
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		if (req->pf_state)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hdev->num_tqps = le16_to_cpu(req->tqp_num) +
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			 le16_to_cpu(req->ext_tqp_num);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hdev->pkt_buf_size = le16_to_cpu(req->buf_size) << HCLGE_BUF_UNIT_S;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	if (req->tx_buf_size)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			le16_to_cpu(req->tx_buf_size) << HCLGE_BUF_UNIT_S;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	if (req->dv_buf_size)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			le16_to_cpu(req->dv_buf_size) << HCLGE_BUF_UNIT_S;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hdev->num_nic_msi = le16_to_cpu(req->msixcap_localid_number_nic);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			le16_to_cpu(req->pf_intr_vector_number_roce);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->vmdq_vport_num = hnae3_get_field(__le32_to_cpu(req->param[0]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->tc_num = hnae3_get_field(__le32_to_cpu(req->param[0]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->tqp_desc_num = hnae3_get_field(__le32_to_cpu(req->param[0]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->phy_addr = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->media_type = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->rx_buf_len = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	mac_addr_tmp = __le32_to_cpu(req->param[2]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	mac_addr_tmp_high = hnae3_get_field(__le32_to_cpu(req->param[3]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->default_speed = hnae3_get_field(__le32_to_cpu(req->param[3]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->vf_rss_size_max = hnae3_get_field(__le32_to_cpu(req->param[3]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->numa_node_map = __le32_to_cpu(req->param[0]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->speed_ability = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	speed_ability_ext = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->umv_space = hnae3_get_field(__le32_to_cpu(req->param[1]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	cfg->pf_rss_size_max = hnae3_get_field(__le32_to_cpu(req->param[2]),
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->offset = cpu_to_le32(offset);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tso_mss_min = cpu_to_le16(tso_mss_min);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tso_mss_max = cpu_to_le16(tso_mss_max);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->gro_en = en ? 1 : 0;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_id = cpu_to_le16(tqp_pid);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_vf = func_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_flag = 1U << HCLGE_TQP_MAP_EN_B;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->tqp_flag |= 1U << HCLGE_TQP_MAP_TYPE_B;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_vid = cpu_to_le16(tqp_vid);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->tx_pkt_buff[i] =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->buf_num[i] =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->buf_num[i] |=
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->shared_buf =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->tc_wl[j].high =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->tc_wl[j].high |=
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->tc_wl[j].low =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->tc_wl[j].low |=
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->com_thrd[j].high =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->com_thrd[j].high |=
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->com_thrd[j].low =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->com_thrd[j].low |=
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->com_wl.high = cpu_to_le16(buf->self.high >> HCLGE_BUF_UNIT_S);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->com_wl.high |=  cpu_to_le16(BIT(HCLGE_RX_PRIV_EN_B));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->com_wl.low = cpu_to_le16(buf->self.low >> HCLGE_BUF_UNIT_S);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->com_wl.low |=  cpu_to_le16(BIT(HCLGE_RX_PRIV_EN_B));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_bit(req->speed_dup, HCLGE_CFG_DUPLEX_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->speed_dup, HCLGE_CFG_SPEED_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->mac_change_fec_en, HCLGE_CFG_MAC_SPEED_CHANGE_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->cfg_an_cmd_flag = cpu_to_le32(flag);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_bit(req->fec_mode, HCLGE_MAC_CFG_FEC_AUTO_EN_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->fec_mode, HCLGE_MAC_CFG_FEC_MODE_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_field(req->fec_mode, HCLGE_MAC_CFG_FEC_MODE_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*link_status = (req->status & HCLGE_LINK_STATUS_UP_M) > 0 ?
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->dest_vfid = func_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->vf_rst = 0x1;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		} else if (req->all_vf_ready) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->mac_func_reset, HCLGE_CFG_RESET_FUNC_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->fun_reset_vfid = func_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->pf_rst_done |= HCLGE_PF_RESET_DONE_BIT;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->hash_config |= (hfunc & HCLGE_RSS_HASH_ALGO_MASK);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->hash_config |= (key_offset << HCLGE_RSS_HASH_KEY_OFFSET_B);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		memcpy(req->hash_key,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->start_table_index =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->rss_set_bitmap = cpu_to_le16(HCLGE_RSS_SET_BITMAP_MSK);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->rss_qid_l[j] = qid & 0xff;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->rss_qid_h[rss_msb_oft] |= rss_msb_val;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->rss_tc_mode[i] = cpu_to_le16(mode);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_tcp_en = hdev->vport[0].rss_tuple_sets.ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_udp_en = hdev->vport[0].rss_tuple_sets.ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_sctp_en = hdev->vport[0].rss_tuple_sets.ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_fragment_en = hdev->vport[0].rss_tuple_sets.ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_tcp_en = hdev->vport[0].rss_tuple_sets.ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_udp_en = hdev->vport[0].rss_tuple_sets.ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_sctp_en = hdev->vport[0].rss_tuple_sets.ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_fragment_en = hdev->vport[0].rss_tuple_sets.ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_tcp_en = vport->rss_tuple_sets.ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_udp_en = vport->rss_tuple_sets.ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_sctp_en = vport->rss_tuple_sets.ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv4_fragment_en = vport->rss_tuple_sets.ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_tcp_en = vport->rss_tuple_sets.ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_udp_en = vport->rss_tuple_sets.ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_sctp_en = vport->rss_tuple_sets.ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ipv6_fragment_en = vport->rss_tuple_sets.ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv4_tcp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv6_tcp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv4_udp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv6_udp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv4_sctp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv6_sctp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv4_fragment_en = HCLGE_RSS_INPUT_TUPLE_OTHER;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->ipv6_fragment_en = HCLGE_RSS_INPUT_TUPLE_OTHER;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv4_tcp_en = req->ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv4_udp_en = req->ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv4_sctp_en = req->ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv4_fragment_en = req->ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv6_tcp_en = req->ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv6_udp_en = req->ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv6_sctp_en = req->ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	vport->rss_tuple_sets.ipv6_fragment_en = req->ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->int_vector_id_l = hnae3_get_field(vector_id,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->int_vector_id_h = hnae3_get_field(vector_id,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		tqp_type_and_id = le16_to_cpu(req->tqp_type_and_id[i]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->tqp_type_and_id[i] = cpu_to_le16(tqp_type_and_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->int_cause_num = HCLGE_VECTOR_ELEMENTS_PER_CMD;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->vfid = vport->vport_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->int_vector_id_l =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->int_vector_id_h =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->int_cause_num = i;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->vfid = vport->vport_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_id = vf_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->extend_promisc = promisc_cfg;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->promisc = promisc_cfg;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*fd_mode = req->mode;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*stage1_entry_num = le32_to_cpu(req->stage1_entry_num);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*stage2_entry_num = le32_to_cpu(req->stage2_entry_num);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*stage1_counter_num = le16_to_cpu(req->stage1_counter_num);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	*stage2_counter_num = le16_to_cpu(req->stage2_counter_num);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->stage = stage_num;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->key_select = stage->key_sel;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->inner_sipv6_word_en = stage->inner_sipv6_word_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->inner_dipv6_word_en = stage->inner_dipv6_word_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->outer_sipv6_word_en = stage->outer_sipv6_word_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->outer_dipv6_word_en = stage->outer_dipv6_word_en;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tuple_mask = cpu_to_le32(~stage->tuple_active);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->meta_data_mask = cpu_to_le32(~stage->meta_data_active);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->index = cpu_to_le32(loc);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->stage = stage;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->ad_data = cpu_to_le64(ad_data);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->txrx_pad_fcs_loop_en = cpu_to_le32(loop_en);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->roce_sel = HCLGE_MAC_VLAN_NIC_SEL;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->func_id = cpu_to_le32(func_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->switch_param = (req->switch_param & param_mask) | switch_param;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->param_mask = param_mask;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	loop_en = le32_to_cpu(req->txrx_pad_fcs_loop_en);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->txrx_pad_fcs_loop_en = cpu_to_le32(loop_en);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->enable = loop_mode_b;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->mask = loop_mode_b;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->mask = loop_mode_b;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		 !(req->result & HCLGE_CMD_SERDES_DONE_B));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	if (!(req->result & HCLGE_CMD_SERDES_DONE_B)) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	} else if (!(req->result & HCLGE_CMD_SERDES_SUCCESS_B)) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_id = cpu_to_le16(tqp_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->stream_id = cpu_to_le16(stream_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		req->enable |= 1U << HCLGE_TQP_ENABLE_B;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(new_req->flags, HCLGE_MAC_VLAN_BIT0_EN_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_bit(new_req->entry_type, HCLGE_MAC_VLAN_BIT1_EN_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_bit(new_req->mc_mac_en, HCLGE_MAC_VLAN_BIT0_EN_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	new_req->mac_addr_hi32 = cpu_to_le32(high_val);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	new_req->mac_addr_lo16 = cpu_to_le16(low_val & 0xffff);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->space_size = cpu_to_le32(space_size);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vlan_type = vlan_type;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_id = vf_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vlan_fe = filter_en ?
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			(req->vlan_fe | fe_type) : (req->vlan_fe & ~fe_type);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		if (!req->resp_code || req->resp_code == 1)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		if (req->resp_code == HCLGE_VF_VLAN_NO_ENTRY) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->resp_code);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		if (!req->resp_code)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		if (req->resp_code == HCLGE_VF_VLAN_DEL_NO_FOUND)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:			req->resp_code);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vlan_offset = vlan_offset_160;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vlan_cfg = is_kill;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vlan_offset_bitmap[vlan_offset_byte] = vlan_offset_byte_val;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->def_vlan_tag1 = cpu_to_le16(vcfg->default_tag1);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->def_vlan_tag2 = cpu_to_le16(vcfg->default_tag2);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_ACCEPT_TAG1_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_ACCEPT_UNTAG1_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_ACCEPT_TAG2_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_ACCEPT_UNTAG2_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_PORT_INS_TAG1_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_PORT_INS_TAG2_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_TAG_SHIFT_MODE_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_CFG_NIC_ROCE_SEL_B, 0);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_offset = vport->vport_id / HCLGE_VF_NUM_PER_CMD;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_bitmap[bmap_index] =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_REM_TAG1_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_REM_TAG2_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_SHOW_TAG1_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_SHOW_TAG2_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_DISCARD_TAG1_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_bit(req->vport_vlan_cfg, HCLGE_DISCARD_TAG2_EN_B,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_offset = vport->vport_id / HCLGE_VF_NUM_PER_CMD;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->vf_bitmap[bmap_index] =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	rx_req->ot_fst_vlan_type =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	rx_req->ot_sec_vlan_type =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	rx_req->in_fst_vlan_type =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	rx_req->in_sec_vlan_type =
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	tx_req->ot_vlan_type = cpu_to_le16(hdev->vlan_type_cfg.tx_ot_vlan_type);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	tx_req->in_vlan_type = cpu_to_le16(hdev->vlan_type_cfg.tx_in_vlan_type);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->max_frm_size = cpu_to_le16(new_mps);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->min_frm_size = HCLGE_MAC_MIN_FRAME;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_id = cpu_to_le16(queue_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:		hnae3_set_bit(req->reset_req, HCLGE_TQP_RESET_B, 1U);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	req->tqp_id = cpu_to_le16(queue_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	return hnae3_get_bit(req->ready_to_reset, HCLGE_TQP_RESET_B);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_main.c:	hnae3_set_field(req->locate_led_config, HCLGE_LED_LOCATE_STATE_M,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_err.c:	*vf_id = le16_to_cpu(req->over_8bd_no_fe_vf_id);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_err.c:	*q_id = le16_to_cpu(req->over_8bd_no_fe_qid);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_cmd.c:	req->compat = cpu_to_le32(compat);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	resp_pf_to_vf->dest_vfid = vf_to_pf_req->mbx_src_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	resp_pf_to_vf->msg_len = vf_to_pf_req->msg_len;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	resp_pf_to_vf->msg.vf_mbx_msg_code = vf_to_pf_req->msg.code;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	resp_pf_to_vf->msg.vf_mbx_msg_subcode = vf_to_pf_req->msg.subcode;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			status, vf_to_pf_req->mbx_src_vfid,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			vf_to_pf_req->msg.code, vf_to_pf_req->msg.subcode);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	ring_num = req->msg.ring_num;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		if (req->msg.param[i].tqp_index >= vport->nic.kinfo.rss_size) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:				req->msg.param[i].tqp_index,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		      req->msg.param[0].ring_type);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:				   [req->msg.param[0].tqp_index]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			HNAE3_RING_GL_IDX_S, req->msg.param[0].int_gl_index);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			      req->msg.param[i].ring_type);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			[req->msg.param[i].tqp_index]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:				req->msg.param[i].int_gl_index);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	int vector_id = req->msg.vector_id;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	bool en_bc = req->msg.en_bc ? true : false;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	bool en_uc = req->msg.en_uc ? true : false;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	bool en_mc = req->msg.en_mc ? true : false;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	if (req->msg.en_limit_promisc)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	const u8 *mac_addr = (const u8 *)(mbx_req->msg.data);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	if (mbx_req->msg.subcode == HCLGE_MBX_MAC_VLAN_UC_MODIFY) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		(&mbx_req->msg.data[HCLGE_MBX_VF_OLD_MAC_ADDR_OFFSET]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	} else if (mbx_req->msg.subcode == HCLGE_MBX_MAC_VLAN_UC_ADD) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	} else if (mbx_req->msg.subcode == HCLGE_MBX_MAC_VLAN_UC_REMOVE) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			mbx_req->msg.subcode);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	const u8 *mac_addr = (const u8 *)(mbx_req->msg.data);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	if (mbx_req->msg.subcode == HCLGE_MBX_MAC_VLAN_MC_ADD) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	} else if (mbx_req->msg.subcode == HCLGE_MBX_MAC_VLAN_MC_REMOVE) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			mbx_req->msg.subcode);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	msg_cmd = (struct hclge_vf_vlan_cfg *)&mbx_req->msg;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		state = (u16 *)&mbx_req->msg.data[HCLGE_MBX_VLAN_STATE_OFFSET];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			&mbx_req->msg.data[HCLGE_MBX_VLAN_INFO_OFFSET];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	bool alive = !!mbx_req->msg.data[0];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	dest_vfid = mbx_req->mbx_src_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	dest_vfid = mbx_req->mbx_src_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	msg_data[0] = mbx_req->msg.data[0];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	memcpy(&queue_id, mbx_req->msg.data, sizeof(queue_id));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	memcpy(&mtu, mbx_req->msg.data, sizeof(mtu));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	memcpy(&queue_id, mbx_req->msg.data, sizeof(queue_id));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	index = mbx_req->msg.data[0];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	if (!req->msg.subcode)
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		hclge_link_fail_parse(hdev, req->msg.data[0]);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:	msg_cmd = (struct hclge_vf_vlan_cfg *)&mbx_req->msg;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:				 req->msg.code);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		vport = &hdev->vport[req->mbx_src_vfid];
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		switch (req->msg.code) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:			is_del = req->msg.code == HCLGE_MBX_VF_UNINIT;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:				req->msg.code);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		if (hnae3_get_bit(req->mbx_need_resp, HCLGE_MBX_NEED_RESP_B) &&
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_mbx.c:		    req->msg.code < HCLGE_MBX_GET_VF_FLR_STATUS) {
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_trace.h:		__entry->vfid = req->mbx_src_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_trace.h:		__entry->code = req->msg.code;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_trace.h:		__entry->subcode = req->msg.subcode;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_trace.h:		__entry->vfid = req->dest_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_trace.h:		__entry->code = req->msg.code;
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:	loop_en = le32_to_cpu(req->txrx_pad_fcs_loop_en);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:		 le16_to_cpu(req->max_frm_size));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:	dev_info(&hdev->pdev->dev, "min_frame_size: %u\n", req->min_frm_size);
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:		 hnae3_get_field(req->speed_dup, HCLGE_MAC_SPEED_MASK,
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:		 hnae3_get_bit(req->speed_dup, HCLGE_MAC_DUPLEX_SHIFT));
drivers/net/ethernet/hisilicon/hns3/hns3pf/hclge_debugfs.c:	bd_num = le32_to_cpu(req->bd_num);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->hash_config |= (hfunc & HCLGEVF_RSS_HASH_ALGO_MASK);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->hash_config |=
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		memcpy(req->hash_key,
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->start_table_index =
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->rss_set_bitmap = cpu_to_le16(HCLGEVF_RSS_SET_BITMAP_MSK);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:			req->rss_result[j] =
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->rss_tc_mode[i] = cpu_to_le16(mode);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_tcp_en = rss_cfg->rss_tuple_sets.ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_udp_en = rss_cfg->rss_tuple_sets.ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_sctp_en = rss_cfg->rss_tuple_sets.ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_fragment_en = rss_cfg->rss_tuple_sets.ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_tcp_en = rss_cfg->rss_tuple_sets.ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_udp_en = rss_cfg->rss_tuple_sets.ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_sctp_en = rss_cfg->rss_tuple_sets.ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_fragment_en = rss_cfg->rss_tuple_sets.ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv4_tcp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv6_tcp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv4_udp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv6_udp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv4_sctp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv6_sctp_en = tuple_sets;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv4_fragment_en = HCLGEVF_RSS_INPUT_TUPLE_OTHER;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->ipv6_fragment_en = HCLGEVF_RSS_INPUT_TUPLE_OTHER;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv4_tcp_en = req->ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv4_udp_en = req->ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv4_sctp_en = req->ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv4_fragment_en = req->ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv6_tcp_en = req->ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv6_udp_en = req->ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv6_sctp_en = req->ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	rss_cfg->rss_tuple_sets.ipv6_fragment_en = req->ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_tcp_en = rss_cfg->rss_tuple_sets.ipv4_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_udp_en = rss_cfg->rss_tuple_sets.ipv4_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_sctp_en = rss_cfg->rss_tuple_sets.ipv4_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv4_fragment_en = rss_cfg->rss_tuple_sets.ipv4_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_tcp_en = rss_cfg->rss_tuple_sets.ipv6_tcp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_udp_en = rss_cfg->rss_tuple_sets.ipv6_udp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_sctp_en = rss_cfg->rss_tuple_sets.ipv6_sctp_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->ipv6_fragment_en = rss_cfg->rss_tuple_sets.ipv6_fragment_en;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->tqp_id = cpu_to_le16(tqp_id & HCLGEVF_RING_ID_MASK);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->stream_id = cpu_to_le16(stream_id);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		req->enable |= 1U << HCLGEVF_TQP_ENABLE_B;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:	req->gro_en = en ? 1 : 0;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		hnae3_get_field(le16_to_cpu(req->msixcap_localid_ba_rocee),
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		hnae3_get_field(le16_to_cpu(req->vf_intr_vector_number),
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_main.c:		hnae3_get_field(le16_to_cpu(req->vf_intr_vector_number),
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_trace.h:		__entry->vfid = req->dest_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_trace.h:		__entry->code = req->msg.code;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_trace.h:		__entry->vfid = req->mbx_src_vfid;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_trace.h:		__entry->code = req->msg.code;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_trace.h:		__entry->subcode = req->msg.subcode;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:		hnae3_set_bit(req->mbx_need_resp, HCLGE_MBX_NEED_RESP_B, 1);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:	memcpy(&req->msg, send_msg, sizeof(struct hclge_vf_to_pf_msg));
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:				 req->msg.code);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:		switch (req->msg.code) {
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:					 req->msg.vf_mbx_msg_code);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:					(req->msg.vf_mbx_msg_code << 16);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:			resp->origin_mbx_msg |= req->msg.vf_mbx_msg_subcode;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:				hclgevf_resp_to_errno(req->msg.resp_status);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:			temp = (u8 *)req->msg.resp_data;
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:					 req->msg.code);
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:			memcpy(&msg_q[0], &req->msg,
drivers/net/ethernet/hisilicon/hns3/hns3vf/hclgevf_mbx.c:				req->msg.code);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->addr_high = high_swapped;
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->addr_low = htonl(low);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->pseudo_hdr_offset = htons(pseudo_hdr_offset);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->pad = 0;	/* complete solid 16-byte block; does this matter? */
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->rdma_count = 1;
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->length = htons(seglen);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->cksum_offset = cksum_offset;
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->flags = flags | ((cum_len & 1) * odd_flag);
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req--;
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:			req->flags |= MXGEFW_FLAGS_TSO_LAST;
drivers/net/ethernet/myricom/myri10ge/myri10ge.c:		} while (!(req->flags & (MXGEFW_FLAGS_TSO_CHOP |
drivers/net/ethernet/renesas/ravb_ptp.c:	if (req->flags & ~(PTP_ENABLE_FEATURE |
drivers/net/ethernet/renesas/ravb_ptp.c:	if (req->index)
drivers/net/ethernet/renesas/ravb_ptp.c:	if (priv->ptp.extts[req->index] == on)
drivers/net/ethernet/renesas/ravb_ptp.c:	priv->ptp.extts[req->index] = on;
drivers/net/ethernet/renesas/ravb_ptp.c:	if (req->flags)
drivers/net/ethernet/renesas/ravb_ptp.c:	if (req->index)
drivers/net/ethernet/renesas/ravb_ptp.c:		start_ns = req->start.sec * NSEC_PER_SEC + req->start.nsec;
drivers/net/ethernet/renesas/ravb_ptp.c:		period_ns = req->period.sec * NSEC_PER_SEC + req->period.nsec;
drivers/net/ethernet/renesas/ravb_ptp.c:		perout = &priv->ptp.perout[req->index];
drivers/net/ethernet/renesas/ravb_ptp.c:		perout = &priv->ptp.perout[req->index];
drivers/net/ethernet/renesas/ravb_ptp.c:	switch (req->type) {
drivers/net/ethernet/renesas/ravb_ptp.c:		return ravb_ptp_extts(ptp, &req->extts, on);
drivers/net/ethernet/renesas/ravb_ptp.c:		return ravb_ptp_perout(ptp, &req->perout, on);
drivers/net/ethernet/renesas/ravb_main.c:	return copy_to_user(req->ifr_data, &config, sizeof(config)) ?
drivers/net/ethernet/renesas/ravb_main.c:	if (copy_from_user(&config, req->ifr_data, sizeof(config)))
drivers/net/ethernet/renesas/ravb_main.c:	return copy_to_user(req->ifr_data, &config, sizeof(config)) ?
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:	req->dest_data_addr = cpu_to_le64(data_dma_addr);
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:	req->data_len = cpu_to_le16(nvm_param.nvm_num_bits);
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:	req->option_num = cpu_to_le16(nvm_param.offset);
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:	req->index_0 = cpu_to_le16(idx);
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:		req->dimensions = cpu_to_le16(1);
drivers/net/ethernet/broadcom/bnxt/bnxt_devlink.c:	if (req->req_type == cpu_to_le16(HWRM_NVM_SET_VARIABLE)) {
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	req->force_link_speed = cpu_to_le16(fw_speed);
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	req->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_FORCE |
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	req->flags = 0;
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	req->force_link_speed = cpu_to_le16(0);
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	cmn_req->host_dest_addr = cpu_to_le64(dma_handle);
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:	cmn_req->host_buf_len = cpu_to_le32(info->dma_len);
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:		    cmn_req->req_type == cpu_to_le16(HWRM_DBG_COREDUMP_LIST)) {
drivers/net/ethernet/broadcom/bnxt/bnxt_ethtool.c:		if (cmn_req->req_type ==
drivers/net/ethernet/broadcom/bnxt/bnxt_ulp.c:	req->resp_addr = cpu_to_le64(bp->hwrm_cmd_resp_dma_addr);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->req_type = cpu_to_le16(req_type);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->cmpl_ring = cpu_to_le16(cmpl_ring);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->target_id = cpu_to_le16(target_id);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->resp_addr = cpu_to_le64(bp->hwrm_cmd_kong_resp_dma_addr);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->resp_addr = cpu_to_le64(bp->hwrm_cmd_resp_dma_addr);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	    le16_to_cpu(req->req_type) != HWRM_FUNC_RESET)
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	cp_ring_id = le16_to_cpu(req->cmpl_ring);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->seq_id = cpu_to_le16(bnxt_get_hwrm_seq_id(bp, dst));
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		bp->hwrm_intr_seq_id = le16_to_cpu(req->seq_id);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		short_input.req_type = req->req_type;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:					   le16_to_cpu(req->req_type));
drivers/net/ethernet/broadcom/bnxt/bnxt.c:					   le16_to_cpu(req->req_type),
drivers/net/ethernet/broadcom/bnxt/bnxt.c:					   le16_to_cpu(req->seq_id), len);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:					   le16_to_cpu(req->req_type),
drivers/net/ethernet/broadcom/bnxt/bnxt.c:					   le16_to_cpu(req->seq_id), len,
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->fid = cpu_to_le16(0xffff);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_tx_rings = cpu_to_le16(tx_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_rx_rings = cpu_to_le16(rx_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_cmpl_rings = cpu_to_le16(tx_rings + ring_grps);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_msix = cpu_to_le16(cp_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_rsscos_ctxs =
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_cmpl_rings = cpu_to_le16(cp_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_hw_ring_grps = cpu_to_le16(ring_grps);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->num_rsscos_ctxs = cpu_to_le16(1);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:				req->num_rsscos_ctxs =
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_stat_ctxs = cpu_to_le16(stats);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_vnics = cpu_to_le16(vnics);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->enables = cpu_to_le32(enables);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_l2_ctxs = cpu_to_le16(BNXT_VF_MAX_L2_CTX);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_tx_rings = cpu_to_le16(tx_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_rx_rings = cpu_to_le16(rx_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_cmpl_rings = cpu_to_le16(tx_rings + ring_grps);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_rsscos_ctxs = cpu_to_le16(DIV_ROUND_UP(ring_grps, 64));
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_cmpl_rings = cpu_to_le16(cp_rings);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_hw_ring_grps = cpu_to_le16(ring_grps);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->num_rsscos_ctxs = cpu_to_le16(BNXT_VF_MAX_RSS_CTX);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_stat_ctxs = cpu_to_le16(stats);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_vnics = cpu_to_le16(vnics);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->enables = cpu_to_le32(enables);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_cmpl_aggr_int = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_cmpl_dma_aggr = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->num_cmpl_dma_aggr_during_int = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->int_lat_tmr_max = cpu_to_le16(tmr);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->int_lat_tmr_min = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->enables |= cpu_to_le16(BNXT_COAL_CMPL_MIN_TMR_ENABLE);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->cmpl_aggr_dma_tmr = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->cmpl_aggr_dma_tmr_during_int = cpu_to_le16(val);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->enables |=
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->flags = cpu_to_le16(flags);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->enables |= cpu_to_le16(BNXT_COAL_CMPL_ENABLES);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->ring_id = cpu_to_le16(ring_id);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->ring_id = cpu_to_le16(ring_id);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_pause =
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_pause |= PORT_PHY_CFG_REQ_AUTO_PAUSE_RX;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_pause |= PORT_PHY_CFG_REQ_AUTO_PAUSE_TX;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->enables |=
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->force_pause |= PORT_PHY_CFG_REQ_FORCE_PAUSE_RX;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->force_pause |= PORT_PHY_CFG_REQ_FORCE_PAUSE_TX;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->enables |=
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_pause = req->force_pause;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->enables |= cpu_to_le32(
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->auto_mode |= PORT_PHY_CFG_REQ_AUTO_MODE_SPEED_MASK;
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_LINK_SPEED_MASK);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_link_speed_mask = cpu_to_le16(bp->link_info.advertising);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->enables |=
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->auto_link_pam4_speed_mask =
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_AUTO_MODE);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_RESTART_AUTONEG);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_FORCE);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->force_pam4_link_speed = cpu_to_le16(bp->link_info.req_link_speed);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->enables |= cpu_to_le32(PORT_PHY_CFG_REQ_ENABLES_FORCE_PAM4_LINK_SPEED);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:			req->force_link_speed = cpu_to_le16(bp->link_info.req_link_speed);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:	req->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_RESET_PHY);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->flags |= cpu_to_le32(flags);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->eee_link_speed_mask = cpu_to_le16(eee_speeds);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->tx_lpi_timer = cpu_to_le32(eee->tx_lpi_timer);
drivers/net/ethernet/broadcom/bnxt/bnxt.c:		req->flags |= cpu_to_le32(PORT_PHY_CFG_REQ_FLAGS_EEE_DISABLE);
drivers/net/ethernet/broadcom/bnxt/bnxt.h:		bnxt_cfa_hwrm_message(le16_to_cpu(req->req_type)));
drivers/net/ethernet/broadcom/bnxt/bnxt.h:		req->resp_addr == cpu_to_le64(bp->hwrm_cmd_kong_resp_dma_addr));
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:	if (req->enables & cpu_to_le32(FUNC_VF_CFG_REQ_ENABLES_DFLT_MAC_ADDR)) {
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:		if (is_valid_ether_addr(req->dflt_mac_addr) &&
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:		     ether_addr_equal(req->dflt_mac_addr, vf->mac_addr))) {
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:			ether_addr_copy(vf->vf_mac_addr, req->dflt_mac_addr);
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:	if (!is_valid_ether_addr((const u8 *)req->l2_addr))
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:		if (ether_addr_equal((const u8 *)req->l2_addr, vf->mac_addr))
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:		if (ether_addr_equal((const u8 *)req->l2_addr, vf->vf_mac_addr))
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:		phy_qcfg_resp.seq_id = phy_qcfg_req->seq_id;
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:					phy_qcfg_req->resp_addr,
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:					phy_qcfg_req->cmpl_ring,
drivers/net/ethernet/broadcom/bnxt/bnxt_sriov.c:	u32 req_type = le16_to_cpu(encap_req->req_type);
drivers/net/ethernet/broadcom/cnic.c:	u32 l5_cid, cid = BNX2X_SW_CID(req->context_id);
drivers/net/ethernet/broadcom/cnic.c:			req->context_id, ISCSI_CONNECTION_TYPE, &l5_data);
drivers/net/ethernet/broadcom/cnic.c:	u32 l5_cid = req->reserved0;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.iscsi_conn_context_id = req->context_id;
drivers/net/ethernet/broadcom/cnic.c:			req->cid, ISCSI_CONNECTION_TYPE, &l5_data);
drivers/net/ethernet/broadcom/cnic.c:			req->cid, ISCSI_CONNECTION_TYPE, &l5_data);
drivers/net/ethernet/broadcom/cnic.c:	kcqe.pg_host_opaque = req->host_opaque;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.pg_cid = req->host_opaque;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.pg_host_opaque = req->pg_host_opaque;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.pg_cid = req->pg_cid;
drivers/net/ethernet/broadcom/cnic.c:	cid = req->context_id;
drivers/net/ethernet/broadcom/cnic.c:	l5_cid = req->conn_id + BNX2X_FCOE_L5_CID_BASE;
drivers/net/ethernet/broadcom/cnic.c:	cid = req->context_id;
drivers/net/ethernet/broadcom/cnic.c:	l5_cid = req->conn_id;
drivers/net/ethernet/broadcom/cnic.c:	cid = req->context_id;
drivers/net/ethernet/broadcom/cnic.c:	l5_cid = req->conn_id;
drivers/net/ethernet/broadcom/cnic.c:	kcqe.fcoe_conn_id = req->conn_id;
drivers/net/ethernet/broadcom/cnic.c:			cid = req->context_id;
drivers/net/ethernet/broadcom/cnic.c:			l5_cid = req->conn_id;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sriov.c:	cur_query_entry = &bp->fw_stats_req->
drivers/net/ethernet/broadcom/bnx2x/bnx2x_sriov.c:	bp->fw_stats_req->hdr.cmd_num = bp->fw_stats_num + stats_count;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_ACQUIRE, sizeof(*req));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vfdev_info.vf_id = vf_id;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vfdev_info.vf_os = 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vfdev_info.fp_hsi_ver = ETH_FP_HSI_VERSION;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_rxqs = rx_count;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_txqs = tx_count;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_sbs = bp->igu_sb_cnt;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_mac_filters = VF_ACQUIRE_MAC_FILTERS;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_mc_filters = VF_ACQUIRE_MC_FILTERS;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->resc_request.num_vlan_filters = VF_ACQUIRE_VLAN_FILTERS;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->bulletin_addr = bp->pf2vf_bulletin_mapping;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vfdev_info.caps |= VF_CAP_SUPPORT_EXT_BULLETIN;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vfdev_info.caps |= VF_CAP_SUPPORT_VLAN_FILTER;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		      req->first_tlv.tl.length + sizeof(struct channel_tlv),
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_txqs =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_txqs,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_rxqs =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_rxqs,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_sbs =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_sbs,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_mac_filters =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_mac_filters,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_vlan_filters =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_vlan_filters,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->resc_request.num_mc_filters =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:				min(req->resc_request.num_mc_filters,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_RELEASE, sizeof(*req));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_id = vf_id;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_INIT, sizeof(*req));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->sb_addr[i] = (dma_addr_t)bnx2x_fp(bp, i,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->stats_addr = bp->fw_stats_data_mapping +
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->stats_stride = sizeof(struct per_queue_stats);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_CLOSE, sizeof(*req));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_id = vf_id;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_SETUP_Q, sizeof(*req));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = fp_idx;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->param_valid = VFPF_RXQ_VALID | VFPF_TXQ_VALID;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.rcq_addr = fp->rx_comp_mapping;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.rcq_np_addr = fp->rx_comp_mapping + BCM_PAGE_SIZE;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.rxq_addr = fp->rx_desc_mapping;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.sge_addr = fp->rx_sge_mapping;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.vf_sb = fp_idx;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.sb_index = HC_INDEX_ETH_RX_CQ_CONS;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.hc_rate = bp->rx_ticks ? 1000000/bp->rx_ticks : 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.mtu = bp->dev->mtu;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.buf_sz = fp->rx_buf_size;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.sge_buf_sz = BCM_PAGE_SIZE * PAGES_PER_SGE;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.tpa_agg_sz = tpa_agg_size;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.max_sge_pkt = SGE_PAGE_ALIGN(bp->dev->mtu) >> SGE_PAGE_SHIFT;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.max_sge_pkt = ((req->rxq.max_sge_pkt + PAGES_PER_SGE - 1) &
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.flags = flags;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.drop_flags = 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.cache_line_log = BNX2X_RX_ALIGN_SHIFT;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rxq.stat_id = -1; /* No stats at the moment */
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.txq_addr = fp->txdata_ptr[FIRST_TX_COS_INDEX]->tx_desc_mapping;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.vf_sb = fp_idx;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.sb_index = HC_INDEX_ETH_TX_CQ_CONS_COS0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.hc_rate = bp->tx_ticks ? 1000000/bp->tx_ticks : 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.flags = flags;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->txq.traffic_type = LLFC_TRAFFIC_TYPE_NW;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_TEARDOWN_Q,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = qidx;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_SET_Q_FILTERS,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->flags = VFPF_SET_Q_FILTERS_MAC_VLAN_CHANGED;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = vf_qid;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->n_mac_vlan_filters = 1;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->filters[0].flags = VFPF_Q_FILTER_DEST_MAC_VALID;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->filters[0].flags |= VFPF_Q_FILTER_SET;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	memcpy(req->filters[0].mac, addr, ETH_ALEN);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			memcpy(req->filters[0].mac, bp->dev->dev_addr,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_UPDATE_RSS,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	memcpy(req->ind_table, params->ind_table, T_ETH_INDIRECTION_TABLE_SIZE);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	memcpy(req->rss_key, params->rss_key, sizeof(params->rss_key));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->ind_table_size = T_ETH_INDIRECTION_TABLE_SIZE;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rss_key_size = T_ETH_RSS_KEY;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->rss_result_mask = params->rss_result_mask;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_MODE_DISABLED;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_MODE_REGULAR;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_SET_SRCH;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV4;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV4_TCP;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV4_UDP;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV6;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV6_TCP;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rss_flags |= VFPF_RSS_IPV6_UDP;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	DP(BNX2X_MSG_IOV, "rss flags %x\n", req->rss_flags);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_SET_Q_FILTERS,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		memcpy(req->multicast[i], bnx2x_mc_addr(ha), ETH_ALEN);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->n_multicast = i;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->flags |= VFPF_SET_Q_FILTERS_MULTICAST_CHANGED;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_SET_Q_FILTERS,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->flags = VFPF_SET_Q_FILTERS_MAC_VLAN_CHANGED;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = vf_qid;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->n_mac_vlan_filters = 1;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->filters[0].flags = VFPF_Q_FILTER_VLAN_TAG_VALID;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->filters[0].flags |= VFPF_Q_FILTER_SET;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->filters[0].vlan_tag = vid;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_prep(bp, &req->first_tlv, CHANNEL_TLV_SET_Q_FILTERS,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rx_mask = VFPF_RX_MASK_ACCEPT_NONE;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rx_mask = VFPF_RX_MASK_ACCEPT_MATCHED_MULTICAST;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rx_mask |= VFPF_RX_MASK_ACCEPT_MATCHED_UNICAST;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rx_mask |= VFPF_RX_MASK_ACCEPT_BROADCAST;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:			req->rx_mask |= VFPF_RX_MASK_ACCEPT_ANY_VLAN;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:		req->rx_mask |= VFPF_RX_MASK_ACCEPT_ANY_VLAN;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->flags |= VFPF_SET_Q_FILTERS_RX_MASK_CHANGED;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	req->vf_qid = 0;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_add_tlv(bp, req, req->first_tlv.tl.length, CHANNEL_TLV_LIST_END,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_vfpf.c:	bnx2x_vfpf_finalize(bp, &req->first_tlv);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.cmd_num,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.reserved0,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.drv_stats_counter,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.reserved1,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.stats_counters_addrs.hi,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   bp->fw_stats_req->hdr.stats_counters_addrs.lo);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	for (i = 0; i < bp->fw_stats_req->hdr.cmd_num; i++) {
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   i, bp->fw_stats_req->query[i].kind,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   bp->fw_stats_req->query[i].index,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   bp->fw_stats_req->query[i].funcID,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   bp->fw_stats_req->query[i].reserved,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   bp->fw_stats_req->query[i].address.hi,
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:		   bp->fw_stats_req->query[i].address.lo);
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c: * bp->fw_stats_req->hdr.drv_stats_counter and ramrods must be
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	bp->fw_stats_req->hdr.drv_stats_counter =
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	   le16_to_cpu(bp->fw_stats_req->hdr.drv_stats_counter));
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	struct stats_query_header *stats_hdr = &bp->fw_stats_req->hdr;
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	cur_query_entry = &bp->fw_stats_req->query[BNX2X_PORT_QUERY_IDX];
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:	cur_query_entry = &bp->fw_stats_req->query[BNX2X_PF_QUERY_IDX];
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:			&bp->fw_stats_req->query[BNX2X_FCOE_QUERY_IDX];
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:			&bp->fw_stats_req->
drivers/net/ethernet/broadcom/bnx2x/bnx2x_stats.c:			&bp->fw_stats_req->
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_hw.c:	req->wr.wr_mid |= htonl(FW_WR_FLOWID_V(csk->tid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_hw.c:	req->reply_ctrl = htons(NO_REPLY_V(no_reply) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_hw.c:	req->word_cookie = htons(TCB_WORD_V(word) | TCB_COOKIE_V(cookie));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_hw.c:	req->mask = cpu_to_be64(mask);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_hw.c:	req->val = cpu_to_be64(val);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->cmd = CPL_ABORT_NO_RST;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->rsvd0 = htonl(tp->snd_nxt);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->rsvd1 = !csk_flag_nochk(csk, CSK_TX_DATA_SENT);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->cmd = mode;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->wr.wr_hi = htonl(FW_WR_OP_V(FW_TP_WR) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:					      sizeof(req->wr)));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	req->wr.wr_mid = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*req), 16)) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		if (req->rsk_ops == &chtls_rsk_ops ||
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		    req->rsk_ops == &chtls_rsk_opsv6) {
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:			struct sock *child = req->sk;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:			*pprev = req->dl_next;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:			pprev = &req->dl_next;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	data = lookup_stid(cdev->tids, oreq->ts_recent);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	mss = ntohs(req->tcpopt.mss);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	if (req->tcpopt.tstamp)
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	if (req->tcpopt.tstamp)
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	if (req->tcpopt.sack)
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	hlen = ntohl(req->hdr_len);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		newsk->sk_v6_daddr = treq->ir_v6_rmt_addr;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		newsk->sk_v6_rcv_saddr = treq->ir_v6_loc_addr;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		inet6_sk(newsk)->saddr = treq->ir_v6_loc_addr;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		newsk->sk_bound_dev_if = treq->ir_iif;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->ts_recent = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	csk->tos = PASS_OPEN_TOS_G(ntohl(req->tos_stid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	eth_hdr_len = T6_ETH_HDR_LEN_G(ntohl(req->hdr_len));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->rsk_rcv_wnd = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->rsk_window_clamp = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->syncookie = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->mss = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	oreq->ts_recent = 0;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	if (req->tcpopt.wsf <= 14 &&
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		inet_rsk(oreq)->snd_wscale = req->tcpopt.wsf;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		refcount_set(&oreq->rsk_refcnt, 1);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		make_established(sk, ntohl(req->snd_isn), ntohs(req->tcp_opt));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:			 (req->status & CPL_ABORT_NO_RST));
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	set_wr_txq(reply_skb, CPL_PRIORITY_DATA, req->status >> 1);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:		req->status = (queue << 1) | status;
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	ctx = lookup_stid(cdev->tids, oreq->ts_recent);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.c:	if (is_neg_adv(req->status)) {
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:	req->op_to_immdlen = htonl(WR_OP_V(opcode) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:	req->flowid_len16 = htonl(FW_WR_FLOWID_V(csk->tid) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:	req->tunnel_to_proxy = htonl(wr_ulp_mode_force |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:	req->plen = htonl(len);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:				req->wr.wr_hi |= htonl(FW_WR_COMPL_F);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_io.c:	req->credit_dack = cpu_to_be32(RX_CREDITS_V(credits) |
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.h:	if (req->rsk_listener)
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.h:		sock_put(req->rsk_listener);
drivers/net/ethernet/chelsio/inline_crypto/chtls/chtls_cm.h:	kmem_cache_free(req->rsk_ops->slab, req);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	req->reply_ctrl = htons(QUEUENO_V(tx_info->rx_qid) |
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	req->word_cookie = htons(TCB_WORD_V(word));
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	req->mask = cpu_to_be64(mask);
drivers/net/ethernet/chelsio/inline_crypto/ch_ktls/chcr_ktls.c:	req->val = cpu_to_be64(val);
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.c:		      ETH_HDR_LEN_G(be32_to_cpu(req->hdr_len)) :
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.c:		      T6_ETH_HDR_LEN_G(be32_to_cpu(req->hdr_len));
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.c:		     IP_HDR_LEN_G(be32_to_cpu(req->hdr_len)) :
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.c:		     T6_IP_HDR_LEN_G(be32_to_cpu(req->hdr_len));
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.h:	req->cmd = CPL_ABORT_SEND_RST;
drivers/net/ethernet/chelsio/libcxgb/libcxgb_cm.h:	req->credit_dack = cpu_to_be32(credit_dack);
drivers/net/ethernet/chelsio/cxgb3/l2t.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/l2t.c:	req->params = htonl(V_L2T_W_IDX(e->idx) | V_L2T_W_IFF(e->smt_idx) |
drivers/net/ethernet/chelsio/cxgb3/l2t.c:	memcpy(req->dst_mac, e->dmac, sizeof(req->dst_mac));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	unsigned int stid = G_PASS_OPEN_TID(ntohl(req->tos_tid));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:		u8 cmd = req->status;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:		if (req->status == CPL_ERR_RTX_NEG_ADVICE ||
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:		    req->status == CPL_ERR_PERSIST_NEG_ADVICE)
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	unsigned int atid = G_PASS_OPEN_TID(ntohl(req->tos_tid));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->reply = 0;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->cpu_idx = 0;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->word = htons(W_TCB_L2T_IX);
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->mask = cpu_to_be64(V_TCB_L2T_IX(M_TCB_L2T_IX));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_offload.c:	req->val = cpu_to_be64(V_TCB_L2T_IX(e->idx));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->mtu_idx = NMTUS - 1;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->iff = i;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->params = htonl(V_L2T_W_IDX(i));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		req->l2t_idx = htonl(V_L2T_W_IDX(i));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	greq->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	greq->mask = cpu_to_be64(1);
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->mtu_idx = NMTUS - 1;	/* should be 0 but there's a T3 bug */
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->iff = idx;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	memcpy(req->src_mac0, adapter->port[idx]->dev_addr, ETH_ALEN);
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	memcpy(req->src_mac1, pi->iscsic.mac_addr, ETH_ALEN);
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->wr_hi = htonl(V_WR_OP(FW_WROPCODE_MNGT));
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->mngt_opcode = FW_MNGTOPCODE_PKTSCHED_SET;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->sched = sched;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->idx = qidx;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->min = lo;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->max = hi;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:	req->binding = port;
drivers/net/ethernet/chelsio/cxgb3/cxgb3_main.c:		return cxgb_extension_ioctl(dev, req->ifr_data);
drivers/net/ethernet/chelsio/cxgb4/l2t.c:	req->params = htons(L2T_W_PORT_V(e->lport) | L2T_W_NOREPLY_V(!sync));
drivers/net/ethernet/chelsio/cxgb4/l2t.c:	req->l2t_idx = htons(l2t_idx);
drivers/net/ethernet/chelsio/cxgb4/l2t.c:	req->vlan = htons(e->vlan);
drivers/net/ethernet/chelsio/cxgb4/l2t.c:	memcpy(req->dst_mac, e->dmac, sizeof(req->dst_mac));
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->reply_ctrl = htons(REPLY_CHAN_V(0) |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->word_cookie = htons(TCB_WORD_V(word) | TCB_COOKIE_V(ftid));
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->mask = cpu_to_be64(mask);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->val = cpu_to_be64(val);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	abort_req->rsvd0 = htonl(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	abort_req->rsvd1 = 0;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	abort_req->cmd = CPL_ABORT_NO_RST;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->reply_ctrl = htons(NO_REPLY_V(no_reply) | REPLY_CHAN_V(0) |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->word_cookie = htons(TCB_WORD_V(word) | TCB_COOKIE_V(cookie));
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->mask = cpu_to_be64(mask);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->val = cpu_to_be64(val);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->local_port = cpu_to_be16(f->fs.val.lport);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->peer_port = cpu_to_be16(f->fs.val.fport);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->local_ip_hi = *(__be64 *)(&f->fs.val.lip);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->local_ip_lo = *(((__be64 *)&f->fs.val.lip) + 1);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->peer_ip_hi = *(__be64 *)(&f->fs.val.fip);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->peer_ip_lo = *(((__be64 *)&f->fs.val.fip) + 1);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->opt0 = cpu_to_be64(NAGLE_V(f->fs.newvlan == VLAN_REMOVE ||
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	t6req->params = cpu_to_be64(FILTER_TUPLE_V(hash_filter_ntuple(&f->fs,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	t6req->opt2 = htonl(RSS_QUEUE_VALID_F |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->local_port = cpu_to_be16(f->fs.val.lport);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->peer_port = cpu_to_be16(f->fs.val.fport);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	memcpy(&req->local_ip, f->fs.val.lip, 4);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	memcpy(&req->peer_ip, f->fs.val.fip, 4);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	req->opt0 = cpu_to_be64(NAGLE_V(f->fs.newvlan == VLAN_REMOVE ||
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	t6req->params = cpu_to_be64(FILTER_TUPLE_V(hash_filter_ntuple(&f->fs,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_filter.c:	t6req->opt2 = htonl(RSS_QUEUE_VALID_F |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->local_port = sport;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->peer_port = htons(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->local_ip = sip;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->peer_ip = htonl(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->opt0 = cpu_to_be64(TX_CHAN_V(chan));
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->opt1 = cpu_to_be64(CONN_POLICY_V(CPL_CONN_POLICY_ASK) |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->local_port = sport;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->peer_port = htons(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->local_ip_hi = *(__be64 *)(sip->s6_addr);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->local_ip_lo = *(__be64 *)(sip->s6_addr + 8);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->peer_ip_hi = cpu_to_be64(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->peer_ip_lo = cpu_to_be64(0);
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->opt0 = cpu_to_be64(TX_CHAN_V(chan));
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->opt1 = cpu_to_be64(CONN_POLICY_V(CPL_CONN_POLICY_ASK) |
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	req->reply_ctrl = htons(NO_REPLY_V(0) | (ipv6 ? LISTSVR_IPV6_V(1) :
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:	struct mii_ioctl_data *data = (struct mii_ioctl_data *)&req->ifr_data;
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:		return copy_to_user(req->ifr_data, &pi->tstamp_config,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:		if (copy_from_user(&pi->tstamp_config, req->ifr_data,
drivers/net/ethernet/chelsio/cxgb4/cxgb4_main.c:		return copy_to_user(req->ifr_data, &pi->tstamp_config,
drivers/net/ethernet/chelsio/cxgb4/sge.c:	unsigned long opcode = FW_WR_OP_G(ntohl(req->wr_hi));
drivers/net/ethernet/chelsio/cxgb4/smt.c:			req->pfvf1 = 0x0;
drivers/net/ethernet/chelsio/cxgb4/smt.c:			memcpy(req->src_mac1, e->src_mac, ETH_ALEN);
drivers/net/ethernet/chelsio/cxgb4/smt.c:			req->pfvf0 = 0x0;
drivers/net/ethernet/chelsio/cxgb4/smt.c:			memcpy(req->src_mac0, s->smtab[e->idx - 1].src_mac,
drivers/net/ethernet/chelsio/cxgb4/smt.c:			req->pfvf0 = 0x0;
drivers/net/ethernet/chelsio/cxgb4/smt.c:			memcpy(req->src_mac0, e->src_mac, ETH_ALEN);
drivers/net/ethernet/chelsio/cxgb4/smt.c:			req->pfvf1 = 0x0;
drivers/net/ethernet/chelsio/cxgb4/smt.c:			memcpy(req->src_mac1, s->smtab[e->idx + 1].src_mac,
drivers/net/ethernet/chelsio/cxgb4/smt.c:		req->pfvf0 = 0x0;
drivers/net/ethernet/chelsio/cxgb4/smt.c:		memcpy(req->src_mac0, s->smtab[e->idx].src_mac, ETH_ALEN);
drivers/net/ethernet/chelsio/cxgb4/smt.c:	req->params = htonl(SMTW_NORPL_V(0) |
drivers/net/ethernet/chelsio/cxgb4/srq.c:	req->idx = srq_idx;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->ep_id = 0;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	memcpy(req->handle, fw_handle, sizeof(req->handle));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->front.key_len += sizeof(__be32) * 2;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		nfp_net_tls_assign_conn_id(nn, &req->front);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		req->src_ip = inet->inet_daddr;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		req->dst_ip = inet->inet_saddr;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	return &req->back;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->front.key_len += sizeof(struct in6_addr) * 2;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		nfp_net_tls_assign_conn_id(nn, &req->front);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		memcpy(req->src_ip, &sk->sk_v6_daddr, sizeof(req->src_ip));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:		memcpy(req->dst_ip, &np->saddr, sizeof(req->dst_ip));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	return &req->back;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->ep_id = 0;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->opcode = nfp_tls_1_2_dir_to_opcode(direction);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	memset(req->resv, 0, sizeof(req->resv));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	memcpy(req->handle, ntls->fw_handle, sizeof(ntls->fw_handle));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->tcp_seq = cpu_to_be32(seq);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	memcpy(req->rec_no, rcd_sn, sizeof(req->rec_no));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	iph = pkt + req->l3_offset;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	ipv6h = pkt + req->l3_offset;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	th = pkt + req->l4_offset;
drivers/net/ethernet/netronome/nfp/crypto/tls.c:				 req->l3_offset, req->l4_offset, pkt_len);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:				 req->l3_offset, req->l4_offset, iph->version);
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	if (memchr_inv(&req->fw_handle, 0, sizeof(req->fw_handle)) &&
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	    memcmp(&req->fw_handle, &ntls->fw_handle, sizeof(ntls->fw_handle)))
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	memcpy(&tcp_seq, &req->tcp_seq, sizeof(tcp_seq));
drivers/net/ethernet/netronome/nfp/crypto/tls.c:	req->ep_id = 0;
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->key_size = cpu_to_be32(map->key_size);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->value_size = cpu_to_be32(map->value_size);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->max_entries = cpu_to_be32(map->max_entries);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->map_type = cpu_to_be32(map->map_type);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->map_flags = 0;
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->tid = cpu_to_be32(nfp_map->tid);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	return &req->data[bpf->cmsg_key_sz * n + bpf->cmsg_val_sz * n];
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	return &req->data[bpf->cmsg_key_sz * (n + 1) + bpf->cmsg_val_sz * n];
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->tid = cpu_to_be32(nfp_map->tid);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->count = cpu_to_be32(n_entries);
drivers/net/ethernet/netronome/nfp/bpf/cmsg.c:	req->flags = cpu_to_be32(flags);
drivers/net/ethernet/ti/am65-cpts.c:		ts.tv_sec = req->period.sec;
drivers/net/ethernet/ti/am65-cpts.c:		ts.tv_nsec = req->period.nsec;
drivers/net/ethernet/ti/am65-cpts.c:		ts.tv_sec = req->start.sec;
drivers/net/ethernet/ti/am65-cpts.c:		ts.tv_nsec = req->start.nsec;
drivers/net/ethernet/ti/am65-cpts.c:		am65_cpts_write32(cpts, val, genf[req->index].comp_hi);
drivers/net/ethernet/ti/am65-cpts.c:		am65_cpts_write32(cpts, val, genf[req->index].comp_lo);
drivers/net/ethernet/ti/am65-cpts.c:		am65_cpts_write32(cpts, val, genf[req->index].length);
drivers/net/ethernet/ti/am65-cpts.c:		cpts->genf_enable |= BIT(req->index);
drivers/net/ethernet/ti/am65-cpts.c:		am65_cpts_write32(cpts, 0, genf[req->index].length);
drivers/net/ethernet/ti/am65-cpts.c:		cpts->genf_enable &= ~BIT(req->index);
drivers/net/ethernet/ti/am65-cpts.c:	if (!!(cpts->genf_enable & BIT(req->index)) == !!on)
drivers/net/ethernet/ti/am65-cpts.c:		__func__, req->index, on ? "enabled" : "disabled");
drivers/net/ethernet/intel/e1000e/ich8lan.c:		if (freq--) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->priority == NPC_MCAM_HIGHER_PRIO)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	*start = req->ref_entry + 1;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->ref_entry >= mcam->hprio_end)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (fcnt > req->count)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	*end = req->ref_entry;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->ref_entry <= mcam->lprio_start)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (fcnt < req->count)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->priority) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (fcnt > req->count) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	} else if ((fcnt + (hp_fcnt / 2) + (lp_fcnt / 2)) > req->count) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->contig) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:						req->count, &max_contig);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		for (entry = 0; entry < req->count; entry++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->priority && (rsp->count < req->count) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->priority && rsp->count < req->count) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		if (req->priority == NPC_MCAM_LOWER_PRIO &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		    (start != (req->ref_entry + 1))) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:			start = req->ref_entry + 1;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		} else if ((req->priority == NPC_MCAM_HIGHER_PRIO) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:			   ((end - start) != req->ref_entry)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:			end = req->ref_entry;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->contig && rsp->count) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		index = req->contig ?
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->priority && req->ref_entry >= mcam->bmap_entries)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if ((!req->ref_entry && req->priority == NPC_MCAM_HIGHER_PRIO) ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	    ((req->ref_entry == (mcam->bmap_entries - 1)) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	     req->priority == NPC_MCAM_LOWER_PRIO))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->contig && req->count > NPC_MAX_NONCONTIG_ENTRIES)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->all)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_entry(mcam, pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	mcam->entry2pfvf_map[req->entry] = 0;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	mcam->entry2target_pffunc[req->entry] = 0x0;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	npc_mcam_clear_bit(mcam, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	npc_enable_mcam_entry(rvu, mcam, blkaddr, req->entry, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	cntr = mcam->entry2cntr_map[req->entry];
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:					      req->entry, cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_entry(mcam, pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		npc_read_mcam_entry(rvu, mcam, blkaddr, req->entry,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	struct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	chan_mask = req->entry_data.kw_mask[0] & NPC_KEX_CHAN_MASK;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	channel = req->entry_data.kw[0] & NPC_KEX_CHAN_MASK;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_entry(mcam, pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->set_cntr &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	    npc_mcam_verify_counter(mcam, pcifunc, req->cntr)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!is_npc_interface_valid(rvu, req->intf)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (npc_mcam_verify_channel(rvu, pcifunc, req->intf, channel)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (npc_mcam_verify_pf_func(rvu, &req->entry_data, req->intf,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	npc_config_mcam_entry(rvu, mcam, blkaddr, req->entry, nix_intf,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:			      &req->entry_data, req->enable_entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->set_cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:					    req->entry, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_entry(mcam, pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	npc_enable_mcam_entry(rvu, mcam, blkaddr, req->entry, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_entry(mcam, pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	npc_enable_mcam_entry(rvu, mcam, blkaddr, req->entry, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->shift_count > NPC_MCAM_MAX_SHIFTS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	for (index = 0; index < req->shift_count; index++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		old_entry = req->curr_entry[index];
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		new_entry = req->new_entry[index];
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (index != req->shift_count) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->contig && req->count > NPC_MAX_NONCONTIG_COUNTERS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->contig) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:						req->count, &max_contig);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		for (cntr = 0; cntr < req->count; cntr++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	err = npc_mcam_verify_counter(mcam, req->hdr.pcifunc, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	mcam->cntr2pfvf_map[req->cntr] = NPC_MCAM_INVALID_MAP;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rvu_free_rsrc(&mcam->counters, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		if (!mcam->cntr_refcnt[req->cntr])
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		if (mcam->entry2cntr_map[index] != req->cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:					      index, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rc = npc_mcam_verify_counter(mcam, req->hdr.pcifunc, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->all) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		rc = npc_mcam_verify_entry(mcam, req->hdr.pcifunc, req->entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:					      req->entry, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		if (!mcam->cntr_refcnt[req->cntr])
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:		if (mcam->entry2cntr_map[index] != req->cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:					      index, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	err = npc_mcam_verify_counter(mcam, req->hdr.pcifunc, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rvu_write64(rvu, blkaddr, NPC_AF_MATCH_STATX(req->cntr), 0x00);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	err = npc_mcam_verify_counter(mcam, req->hdr.pcifunc, req->cntr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	rsp->stat = rvu_read64(rvu, blkaddr, NPC_AF_MATCH_STATX(req->cntr));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	struct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!is_npc_interface_valid(rvu, req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	chan_mask = req->entry_data.kw_mask[0] & NPC_KEX_CHAN_MASK;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	channel = req->entry_data.kw[0] & NPC_KEX_CHAN_MASK;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (npc_mcam_verify_channel(rvu, req->hdr.pcifunc, req->intf, channel))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (npc_mcam_verify_pf_func(rvu, &req->entry_data, req->intf,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:				    req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	entry_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	entry_req.priority = req->priority;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	entry_req.ref_entry = req->ref_entry;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (!req->alloc_cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	cntr_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:			      &req->entry_data, req->enable_entry);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	if (req->alloc_cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/mbox.c:		if (preq->id != prsp->id) {
drivers/net/ethernet/marvell/octeontx2/af/mbox.c:			trace_otx2_msg_check(mbox->pdev, preq->id,
drivers/net/ethernet/marvell/octeontx2/af/mbox.c:			trace_otx2_msg_check(mbox->pdev, preq->id,
drivers/net/ethernet/marvell/octeontx2/af/mbox.c:		ireq = mbox->tx_start + preq->next_msgoff;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	blkaddr = req->blkaddr ? req->blkaddr : BLKADDR_CPT0;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	if (req->eng_grpmsk == 0x0)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	if (req->nix_pf_func) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		if (req->nix_pf_func == RVU_DEFAULT_PF_FUNC)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:			req->nix_pf_func = pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		if (!is_pffunc_map_valid(rvu, req->nix_pf_func, BLKTYPE_NIX))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	if (req->sso_pf_func) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		if (req->sso_pf_func == RVU_DEFAULT_PF_FUNC)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:			req->sso_pf_func = pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		if (!is_pffunc_map_valid(rvu, req->sso_pf_func, BLKTYPE_SSO))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		val = (u64)req->eng_grpmsk << 48 | 1;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		val = (u64)req->nix_pf_func << 48 |
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		      (u64)req->sso_pf_func << 32;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	u64 offset = req->reg_offset;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:				req->hdr.pcifunc, lf);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	} else if (!(req->hdr.pcifunc & RVU_PFVF_FUNC_MASK)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	blkaddr = req->blkaddr ? req->blkaddr : BLKADDR_CPT0;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	if (!is_cpt_pf(rvu, req->hdr.pcifunc) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	    !is_cpt_vf(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	rsp->reg_offset = req->reg_offset;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	rsp->ret_val = req->ret_val;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	rsp->is_write = req->is_write;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:	if (req->is_write)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		rvu_write64(rvu, blkaddr, req->reg_offset, req->val);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cpt.c:		rsp->val = rvu_read64(rvu, blkaddr, req->reg_offset);
drivers/net/ethernet/marvell/octeontx2/af/ptp.c:	switch (req->op) {
drivers/net/ethernet/marvell/octeontx2/af/ptp.c:		err = ptp_adjfine(rvu->ptp, req->scaled_ppm);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	npc_update_entry(rvu, NPC_CHAN, entry, req->channel, 0,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.op = req->op;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.index = req->index;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.match_id = req->match_id;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.flow_key_alg = req->flow_key_alg;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->op == NIX_RX_ACTION_DEFAULT && pfvf->def_ucast_rule)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	entry->vtag_action = FIELD_PREP(RX_VTAG0_VALID_BIT, req->vtag0_valid) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(RX_VTAG0_TYPE_MASK, req->vtag0_type) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(RX_VTAG1_VALID_BIT, req->vtag1_valid) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(RX_VTAG1_TYPE_MASK, req->vtag1_type) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.op = req->op;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.index = req->index;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	action.match_id = req->match_id;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	entry->vtag_action = FIELD_PREP(TX_VTAG0_DEF_MASK, req->vtag0_def) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(TX_VTAG0_OP_MASK, req->vtag0_op) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(TX_VTAG1_DEF_MASK, req->vtag1_def) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			     FIELD_PREP(TX_VTAG1_OP_MASK, req->vtag1_op) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	u16 owner = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	installed_features = req->features;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	features = req->features;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	entry_index = req->entry;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	npc_update_flow(rvu, entry, features, &req->packet, &req->mask, &dummy,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			req->intf);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (is_npc_intf_rx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->default_rule && req->append) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:					&dummy, req->intf);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		installed_features = req->features | missing_features;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	} else if (req->default_rule && !req->append) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:				&dummy, req->intf);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		installed_features = req->features | missing_features;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->default_rule)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->set_cntr && !rule->has_cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (!req->set_cntr && rule->has_cntr)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	write_req.entry = req->entry;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	write_req.intf = req->intf;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->set_cntr && rule->has_cntr) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	rule->default_rule = req->default_rule;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->default_rule)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		ether_addr_copy(pfvf->default_mac, req->packet.dmac);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		ether_addr_copy(pfvf->mac_addr, req->packet.dmac);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (pfvf->pf_set_vf_cfg && req->vtag0_type == NIX_AF_LFX_RX_VTAG_TYPE7)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	bool from_vf = !!(req->hdr.pcifunc & RVU_PFVF_FUNC_MASK);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (!is_npc_interface_valid(rvu, req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (from_vf && req->default_rule)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (!req->hdr.pcifunc)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		target = req->vf;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	else if (!from_vf && req->vf) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		target = (req->hdr.pcifunc & ~RVU_PFVF_FUNC_MASK) | req->vf;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		pf_set_vfs_mac = req->default_rule &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:				(req->features & BIT_ULL(NPC_DMAC));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		target = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (npc_check_unsupported_flows(rvu, req->features, req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (npc_mcam_verify_channel(rvu, target, req->intf, req->channel))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (req->hdr.pcifunc && !from_vf && req->vf)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if ((req->features & BIT_ULL(NPC_DMAC)) && is_npc_intf_rx(req->intf) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	    is_zero_ether_addr(req->packet.dmac)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		ether_addr_copy(req->packet.dmac, pfvf->mac_addr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:		eth_broadcast_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (err || (!req->default_rule && !pfvf->def_ucast_rule))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (is_npc_intf_tx(req->intf))
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	if (from_vf && pfvf->def_ucast_rule && is_npc_intf_rx(req->intf) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	    pfvf->def_ucast_rule->features & req->features)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			if (req->all) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			} else if (req->end && iter->entry >= req->start &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:				   iter->entry <= req->end) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npc_fs.c:			} else if (req->entry == iter->entry) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_trace.h:	    TP_printk("[%s] req->id:0x%x rsp->id:0x%x resp_code:%d\n",
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->npalf && !is_blktype_attached(pfvf, BLKTYPE_NPA)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	} else if (req->npalf) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->nixlf && !is_blktype_attached(pfvf, BLKTYPE_NIX)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	} else if (req->nixlf) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->sso) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->sso > block->lf.max) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:				 pcifunc, req->sso, block->lf.max);
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->sso > mappedlfs &&
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		    ((req->sso - mappedlfs) > free_lfs))
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->ssow) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->ssow > block->lf.max) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:				 pcifunc, req->sso, block->lf.max);
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->ssow > mappedlfs &&
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		    ((req->ssow - mappedlfs) > free_lfs))
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->timlfs) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->timlfs > block->lf.max) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:				 pcifunc, req->timlfs, block->lf.max);
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->timlfs > mappedlfs &&
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		    ((req->timlfs - mappedlfs) > free_lfs))
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->cptlfs) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->cptlfs > block->lf.max) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:				 pcifunc, req->cptlfs, block->lf.max);
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		if (req->cptlfs > mappedlfs &&
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		    ((req->cptlfs - mappedlfs) > free_lfs))
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	if (req->sig != OTX2_MBOX_REQ_SIG)
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:	switch (req->id) {
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:			rsp->hdr.pcifunc = req->pcifunc;		\
drivers/net/ethernet/marvell/octeontx2/af/rvu.c:		otx2_reply_invalid_msg(mbox, devid, req->pcifunc, req->id);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (!pfvf->aura_ctx || req->aura_id >= pfvf->aura_ctx->qsize)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	inst.cindex = req->aura_id;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	inst.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	inst.op = req->op;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	switch (req->op) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->ctype == NPA_AQ_CTYPE_AURA) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(mask, &req->aura_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(ctx, &req->aura, sizeof(struct npa_aura_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(mask, &req->pool_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(ctx, &req->pool, sizeof(struct npa_pool_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->ctype == NPA_AQ_CTYPE_AURA) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			if (req->aura.pool_addr >= pfvf->pool_ctx->qsize) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			req->aura.pool_addr = pfvf->pool_ctx->iova +
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			(req->aura.pool_addr * pfvf->pool_ctx->entry_sz);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(ctx, &req->aura, sizeof(struct npa_aura_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			memcpy(ctx, &req->pool, sizeof(struct npa_pool_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->ctype == NPA_AQ_CTYPE_AURA) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->op == NPA_AQ_INSTOP_INIT && req->aura.ena)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			__set_bit(req->aura_id, pfvf->aura_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->op == NPA_AQ_INSTOP_WRITE) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			ena = (req->aura.ena & req->aura_mask.ena) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				(test_bit(req->aura_id, pfvf->aura_bmap) &
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				~req->aura_mask.ena);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				__set_bit(req->aura_id, pfvf->aura_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				__clear_bit(req->aura_id, pfvf->aura_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->ctype == NPA_AQ_CTYPE_POOL) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->op == NPA_AQ_INSTOP_INIT && req->pool.ena)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			__set_bit(req->aura_id, pfvf->pool_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->op == NPA_AQ_INSTOP_WRITE) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			ena = (req->pool.ena & req->pool_mask.ena) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				(test_bit(req->aura_id, pfvf->pool_bmap) &
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				~req->pool_mask.ena);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				__set_bit(req->aura_id, pfvf->pool_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				__clear_bit(req->aura_id, pfvf->pool_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		if (req->op == NPA_AQ_INSTOP_READ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			if (req->ctype == NPA_AQ_CTYPE_AURA)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	struct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	aq_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->ctype == NPA_AQ_CTYPE_POOL) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	} else if (req->ctype == NPA_AQ_CTYPE_AURA) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	aq_req.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:				(req->ctype == NPA_AQ_CTYPE_AURA) ?
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->op != NPA_AQ_INSTOP_INIT)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	lock_ctx_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	lock_ctx_req.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	lock_ctx_req.aura_id = req->aura_id;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			req->hdr.pcifunc,
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			(req->ctype == NPA_AQ_CTYPE_AURA) ?
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			"Aura" : "Pool", req->aura_id);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->aura_sz > NPA_AURA_SZ_MAX ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	    req->aura_sz == NPA_AURA_SZ_0 || !req->nr_pools)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	if (req->way_mask)
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		req->way_mask &= 0xFFFF;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:			 NPA_AURA_COUNT(req->aura_sz), hwctx_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	pfvf->aura_bmap = kcalloc(NPA_AURA_COUNT(req->aura_sz), sizeof(long),
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	err = qmem_alloc(rvu->dev, &pfvf->pool_ctx, req->nr_pools, hwctx_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	pfvf->pool_bmap = kcalloc(NPA_AURA_COUNT(req->aura_sz), sizeof(long),
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	cfg |= (req->aura_sz << 16) | BIT_ULL(34) | req->way_mask;
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:		    BIT_ULL(36) | req->way_mask << 20);
drivers/net/ethernet/marvell/octeontx2/af/rvu_npa.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	req->hdr.sig = OTX2_MBOX_REQ_SIG;				\
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	req->hdr.id = _id;						\
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_rxtx(rvu, req->hdr.pcifunc, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_rxtx(rvu, req->hdr.pcifunc, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	cgx_lmac_addr_set(cgx_id, lmac_id, req->mac_addr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	/* copy 48 bit mac address to req->mac_addr */
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	return rvu_cgx_ptp_rx_cfg(rvu, req->hdr.pcifunc, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	return rvu_cgx_ptp_rx_cfg(rvu, req->hdr.pcifunc, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_linkevents(rvu, req->hdr.pcifunc, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_linkevents(rvu, req->hdr.pcifunc, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_intlbk(rvu, req->hdr.pcifunc, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rvu_cgx_config_intlbk(rvu, req->hdr.pcifunc, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (req->set)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:					      req->tx_pause, req->rx_pause);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (req->fec == OTX2_FEC_OFF)
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:		req->fec = OTX2_FEC_NONE;
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rsp->fec = cgx_set_fec(req->fec, cgx_id, lmac_id);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	int pf = rvu_get_pf(req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	if (!is_cgx_config_permitted(rvu, req->hdr.pcifunc))
drivers/net/ethernet/marvell/octeontx2/af/rvu_cgx.c:	rsp->status = cgx_set_link_mode(cgxd, req->args, cgx_idx, lmac);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	chan_base = pfvf->rx_chan_base + req->chan_base;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	for (chan = chan_base; chan < (chan_base + req->chan_cnt); chan++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if ((req->chan_base + req->chan_cnt) > 15)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			(lmac_id * lmac_chan_cnt) + req->chan_base;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->bpid_per_chan)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if ((req->chan_base + req->chan_cnt) > 63)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		bpid = cgx_bpid_cnt + req->chan_base;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->bpid_per_chan)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	chan_base = pfvf->rx_chan_base + req->chan_base;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	for (chan = chan_base; chan < (chan_base + req->chan_cnt); chan++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	for (chan = 0; chan < req->chan_cnt; chan++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		rsp->chan_bpid[chan] = ((req->chan_base + chan) & 0x7F) << 10 |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->bpid_per_chan)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	rsp->chan_cnt = req->chan_cnt;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!(!rsp && req->ctype == NIX_AQ_CTYPE_MCE)) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	switch (req->ctype) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!pfvf->rq_ctx || req->qidx >= pfvf->rq_ctx->qsize)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!pfvf->sq_ctx || req->qidx >= pfvf->sq_ctx->qsize)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!pfvf->cq_ctx || req->qidx >= pfvf->cq_ctx->qsize)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    (req->qidx >= (256UL << (cfg & 0xF))))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    (req->qidx >= (256UL << (cfg & 0xF))))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->ctype == NIX_AQ_CTYPE_SQ &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    ((req->op == NIX_AQ_INSTOP_INIT && req->sq.ena) ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	     (req->op == NIX_AQ_INSTOP_WRITE &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	      req->sq_mask.ena && req->sq_mask.smq && req->sq.ena))) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				     pcifunc, req->sq.smq))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	inst.cindex = req->qidx;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	inst.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	inst.op = req->op;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	switch (req->op) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_RQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(mask, &req->rq_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_SQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(mask, &req->sq_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_CQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(mask, &req->cq_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_RSS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(mask, &req->rss_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_MCE)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(mask, &req->mce_mask,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_RQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(ctx, &req->rq, sizeof(struct nix_rq_ctx_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_SQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(ctx, &req->sq, sizeof(struct nix_sq_ctx_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_CQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(ctx, &req->cq, sizeof(struct nix_cq_ctx_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_RSS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(ctx, &req->rss, sizeof(struct nix_rsse_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		else if (req->ctype == NIX_AQ_CTYPE_MCE)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			memcpy(ctx, &req->mce, sizeof(struct nix_rx_mce_s));
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->op == NIX_AQ_INSTOP_INIT) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_RQ && req->rq.ena)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			__set_bit(req->qidx, pfvf->rq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_SQ && req->sq.ena)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			__set_bit(req->qidx, pfvf->sq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_CQ && req->cq.ena)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			__set_bit(req->qidx, pfvf->cq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->op == NIX_AQ_INSTOP_WRITE) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_RQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			ena = (req->rq.ena & req->rq_mask.ena) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				(test_bit(req->qidx, pfvf->rq_bmap) &
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				~req->rq_mask.ena);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__set_bit(req->qidx, pfvf->rq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__clear_bit(req->qidx, pfvf->rq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_SQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			ena = (req->rq.ena & req->sq_mask.ena) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				(test_bit(req->qidx, pfvf->sq_bmap) &
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				~req->sq_mask.ena);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__set_bit(req->qidx, pfvf->sq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__clear_bit(req->qidx, pfvf->sq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->ctype == NIX_AQ_CTYPE_CQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			ena = (req->rq.ena & req->cq_mask.ena) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				(test_bit(req->qidx, pfvf->cq_bmap) &
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				~req->cq_mask.ena);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__set_bit(req->qidx, pfvf->cq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				__clear_bit(req->qidx, pfvf->cq_bmap);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->op == NIX_AQ_INSTOP_READ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			if (req->ctype == NIX_AQ_CTYPE_RQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			else if (req->ctype == NIX_AQ_CTYPE_SQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			else if (req->ctype == NIX_AQ_CTYPE_CQ)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			else if (req->ctype == NIX_AQ_CTYPE_RSS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			else if (req->ctype == NIX_AQ_CTYPE_MCE)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	blkaddr = rvu_get_blkaddr(rvu, BLKTYPE_NIX, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	struct rvu_pfvf *pfvf = rvu_get_pfvf(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	aq_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->ctype == NIX_AQ_CTYPE_CQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->ctype == NIX_AQ_CTYPE_SQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->ctype == NIX_AQ_CTYPE_RQ) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	aq_req.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				nix_get_ctx_name(req->ctype), qidx);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->op != NIX_AQ_INSTOP_INIT)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->ctype == NIX_AQ_CTYPE_MCE ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    req->ctype == NIX_AQ_CTYPE_DYNO)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	lock_ctx_req.hdr.pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	lock_ctx_req.ctype = req->ctype;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	lock_ctx_req.qidx = req->qidx;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			req->hdr.pcifunc,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			nix_get_ctx_name(req->ctype), req->qidx);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!req->rq_cnt || !req->sq_cnt || !req->cq_cnt)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->way_mask)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		req->way_mask &= 0xFFFF;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->npa_func) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->npa_func == RVU_DEFAULT_PF_FUNC)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			req->npa_func = pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!is_pffunc_map_valid(rvu, req->npa_func, BLKTYPE_NPA))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->sso_func) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->sso_func == RVU_DEFAULT_PF_FUNC)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			req->sso_func = pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!is_pffunc_map_valid(rvu, req->sso_func, BLKTYPE_SSO))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rss_sz && (req->rss_sz > MAX_RSS_INDIR_TBL_SIZE ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			    !is_power_of_2(req->rss_sz)))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rss_sz &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    (!req->rss_grps || req->rss_grps > MAX_RSS_GROUPS))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	err = qmem_alloc(rvu->dev, &pfvf->rq_ctx, req->rq_cnt, hwctx_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	pfvf->rq_bmap = kcalloc(req->rq_cnt, sizeof(long), GFP_KERNEL);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg = BIT_ULL(36) | (req->rq_cnt - 1) | req->way_mask << 20;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	err = qmem_alloc(rvu->dev, &pfvf->sq_ctx, req->sq_cnt, hwctx_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	pfvf->sq_bmap = kcalloc(req->sq_cnt, sizeof(long), GFP_KERNEL);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg = BIT_ULL(36) | (req->sq_cnt - 1) | req->way_mask << 20;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	err = qmem_alloc(rvu->dev, &pfvf->cq_ctx, req->cq_cnt, hwctx_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	pfvf->cq_bmap = kcalloc(req->cq_cnt, sizeof(long), GFP_KERNEL);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg = BIT_ULL(36) | (req->cq_cnt - 1) | req->way_mask << 20;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	err = nixlf_rss_ctx_init(rvu, blkaddr, pfvf, nixlf, req->rss_sz,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				 req->rss_grps, hwctx_size, req->way_mask);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    BIT_ULL(36) | req->way_mask << 20);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    BIT_ULL(36) | req->way_mask << 20);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->npa_func)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		cfg = req->npa_func;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->sso_func)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		cfg |= (u64)req->sso_func << 16;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg |= (u64)req->xqe_sz << 33;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	rvu_write64(rvu, blkaddr, NIX_AF_LFX_RX_CFG(nixlf), req->rx_cfg);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->flags & NIX_LF_DISABLE_FLOWS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!(req->flags & NIX_LF_DONT_FREE_TX_VTAG))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg = (((u32)req->offset & 0x7) << 16) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	      (((u32)req->y_mask & 0xF) << 12) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	      (((u32)req->y_val & 0xF) << 8) |
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	      (((u32)req->r_mask & 0xF) << 4) | ((u32)req->r_val & 0xF);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	req_schq = req->schq_contig[lvl] + req->schq[lvl];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!hw->cap.nix_fixed_txschq_mapping && req->schq_contig[lvl] &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    !rvu_rsrc_check_contig(&txsch->schq, req->schq_contig[lvl]))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!req->schq[lvl] && !req->schq_contig[lvl])
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		rsp->schq[lvl] = req->schq[lvl];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		rsp->schq_contig[lvl] = req->schq_contig[lvl];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		for (idx = 0; idx < req->schq_contig[lvl]; idx++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		for (idx = 0; idx < req->schq[lvl]; idx++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	lvl = req->schq_lvl;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	schq = req->schq;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->flags & TXSCHQ_FREE_ALL)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		return nix_txschq_free(rvu, req->hdr.pcifunc);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->lvl >= NIX_TXSCH_LVL_CNT ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    req->num_regs > MAX_REGS_PER_MBOX_MSG)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	txsch = &nix_hw->txsch[req->lvl];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->lvl >= hw->cap.nix_tx_aggr_lvl &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->lvl == NIX_TXSCH_LVL_TL1)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	for (idx = 0; idx < req->num_regs; idx++) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		reg = req->reg[idx];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		regval = req->regval[idx];
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (!is_txschq_shaping_valid(hw, req->lvl, reg))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u64 regval = req->vtag_size;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rx.vtag_type > NIX_AF_LFX_RX_VTAG_TYPE7 ||
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	    req->vtag_size > VTAGSIZE_T8)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rx.vtag_type == NIX_AF_LFX_RX_VTAG_TYPE7)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rx.capture_vtag)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->rx.strip_vtag)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    NIX_AF_LFX_RX_VTAG_TYPEX(nixlf, req->rx.vtag_type), regval);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	int idx0 = req->tx.vtag0_idx;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	int idx1 = req->tx.vtag1_idx;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.free_vtag0 && req->tx.free_vtag1)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.free_vtag0) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.free_vtag1)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.cfg_vtag0) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:					  req->tx.vtag0, req->vtag_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.cfg_vtag1) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:					  req->tx.vtag1, req->vtag_size);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->tx.cfg_vtag0)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->cfg_type) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if ((req->tx.cfg_vtag0 || req->tx.cfg_vtag1) &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		    (req->tx.free_vtag0 || req->tx.free_vtag1))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->tx.cfg_vtag0 || req->tx.cfg_vtag1)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->tx.free_vtag0 || req->tx.free_vtag1)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	alg_idx = get_flowkey_alg_idx(nix_hw, req->flowkey_cfg);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:						  req->flowkey_cfg);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	rvu_npc_update_flowkey_alg_idx(rvu, pcifunc, nixlf, req->group,
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				       alg_idx, req->mcam_index);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	bool from_vf = req->hdr.pcifunc & RVU_PFVF_FUNC_MASK;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	ether_addr_copy(pfvf->mac_addr, req->mac_addr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:				    pfvf->rx_chan_base, req->mac_addr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->mode & NIX_RX_MODE_PROMISC)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	else if (req->mode & NIX_RX_MODE_ALLMULTI)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	pfvf->maxlen = req->maxlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->update_minlen)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		pfvf->minlen = req->minlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	maxlen = req->maxlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	minlen = req->update_minlen ? req->minlen : 0;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->update_minlen &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->update_minlen &&
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	req->maxlen = maxlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->update_minlen)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		req->minlen = minlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!req->sdp_link && req->maxlen > max_mtu)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->update_minlen && req->minlen < NIC_HW_MIN_FRS)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (!req->update_smq)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		cfg = (cfg & ~(0xFFFFULL << 8)) | ((u64)req->maxlen << 8);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		if (req->update_minlen)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			cfg = (cfg & ~0x7FULL) | ((u64)req->minlen & 0x7F);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->sdp_link) {
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg = (cfg & ~(0xFFFFULL << 16)) | ((u64)req->maxlen << 16);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->update_minlen)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:		cfg = (cfg & ~0xFFFFULL) | req->minlen;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->sdp_link || pf == 0)
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	cfg |=  ((lmac_fifo_len - req->maxlen) / 16) << 12;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	err = nix_get_nixlf(rvu, req->hdr.pcifunc, &nixlf, &blkaddr);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->len_verify & BIT(0))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->len_verify & BIT(1))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	if (req->csum_verify & BIT(0))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	return rvu_nix_lf_ptp_tx_cfg(rvu, req->hdr.pcifunc, true);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	return rvu_nix_lf_ptp_tx_cfg(rvu, req->hdr.pcifunc, false);
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:	u16 pcifunc = req->hdr.pcifunc;
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			if (req->fields[f] != (reg & req->field_mask))
drivers/net/ethernet/marvell/octeontx2/af/rvu_nix.c:			    req->fields[f]);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_vf.c:	if (req->sig != OTX2_MBOX_REQ_SIG) {
drivers/net/ethernet/marvell/octeontx2/nic/otx2_vf.c:		otx2_reply_invalid_msg(&vf->mbox.mbox_up, 0, 0, req->id);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_vf.c:	switch (req->id) {
drivers/net/ethernet/marvell/octeontx2/nic/otx2_vf.c:		otx2_reply_invalid_msg(&vf->mbox.mbox_up, 0, 0, req->id);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ptp.c:	req->op = PTP_OP_ADJFINE;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ptp.c:	req->scaled_ppm = scaled_ppm;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ptp.c:	req->op = PTP_OP_GET_CLOCK;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ptp.c:						  &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ptp.c:	req->op = PTP_OP_GET_CLOCK;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h:	req->hdr.sig = OTX2_MBOX_REQ_SIG;				\
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.h:	req->hdr.id = _id;						\
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:		       otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:			otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:	req->fec = fec;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:						   0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:	req->args.speed = cmd->base.speed;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:	req->args.duplex = cmd->base.duplex ^ 0x1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:	req->args.an = cmd->base.autoneg;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_ethtool.c:	otx2_get_advertised_mode(cmd, &req->args.mode);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	ether_addr_copy(req->mac_addr, mac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	msghdr = otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->maxlen = pfvf->max_frs;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->rx_pause = !!(pfvf->flags & OTX2_FLAG_RX_PAUSE_ENABLED);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->tx_pause = !!(pfvf->flags & OTX2_FLAG_TX_PAUSE_ENABLED);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->set = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->mcam_index = -1; /* Default or reserved index */
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->flowkey_cfg = rss->flowkey_cfg;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->group = DEFAULT_RSS_CONTEXT_GROUP;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->lvl = lvl;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->num_regs = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[0] = NIX_AF_SMQX_CFG(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] = ((pfvf->netdev->max_mtu + OTX2_ETH_HLEN) << 8)
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] |= (0x20ULL << 51) | (0x80ULL << 39) |
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[1] = NIX_AF_MDQX_PARENT(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[1] = parent << 16;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[2] = NIX_AF_MDQX_SCHEDULE(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[2] =  DFLT_RR_QTM;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[0] = NIX_AF_TL4X_PARENT(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] = parent << 16;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[1] = NIX_AF_TL4X_SCHEDULE(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[1] = DFLT_RR_QTM;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[0] = NIX_AF_TL3X_PARENT(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] = parent << 16;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[1] = NIX_AF_TL3X_SCHEDULE(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[1] = DFLT_RR_QTM;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[0] = NIX_AF_TL2X_PARENT(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] = parent << 16;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[1] = NIX_AF_TL2X_SCHEDULE(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[1] = TXSCH_TL1_DFLT_RR_PRIO << 24 | DFLT_RR_QTM;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[2] = NIX_AF_TL3_TL2X_LINKX_CFG(schq,
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[2] = BIT_ULL(13) | BIT_ULL(12);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[0] = NIX_AF_TL1X_SCHEDULE(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[0] = TXSCH_TL1_DFLT_RR_QTM;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[1] = NIX_AF_TL1X_TOPOLOGY(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[1] = (TXSCH_TL1_DFLT_RR_PRIO << 1);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->num_regs++;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->reg[2] = NIX_AF_TL1X_CIR(schq);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->regval[2] = 0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		req->schq[lvl] = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	free_req->flags = TXSCHQ_FREE_ALL;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->ctype = type;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->chan_base = 0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->chan_cnt = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:	req->bpid_per_chan = 0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_common.c:		       otx2_mbox_get_rsp(&pfvf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->hdr.pcifunc &= RVU_PFVF_FUNC_MASK;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->hdr.pcifunc |= (vf + 1) & RVU_PFVF_FUNC_MASK;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	if (req->sig != OTX2_MBOX_REQ_SIG) {
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		otx2_reply_invalid_msg(&pf->mbox.mbox_up, 0, 0, req->id);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	switch (req->id) {
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		otx2_reply_invalid_msg(&pf->mbox.mbox_up, 0, 0, req->id);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		free_req->flags = NIX_LF_DISABLE_FLOWS;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		free_req->flags = NIX_LF_DISABLE_FLOWS;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:			free_req->flags |= NIX_LF_DONT_FREE_TX_VTAG;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->mode = NIX_RX_MODE_UCAST;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		req->mode |= NIX_RX_MODE_PROMISC;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		req->mode |= NIX_RX_MODE_ALLMULTI;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		return copy_to_user(req->ifr_data, cfg,
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	ether_addr_copy(req->packet.dmac, mac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	eth_broadcast_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->features = BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->channel = pf->hw.rx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->intf = NIX_INTF_RX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->default_rule = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->append = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vf = vf + 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->op = NIX_RX_ACTION_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		vtag_req->cfg_type = 0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		vtag_req->tx.free_vtag0 = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		vtag_req->tx.vtag0_idx = config->tx_vtag_idx;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		del_req->entry =
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:		del_req->entry =
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->entry = flow_cfg->entry[flow_cfg->vf_vlan_offset + idx];
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->packet.vlan_tci = htons(vlan);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->mask.vlan_tci = htons(VLAN_VID_MASK);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	eth_broadcast_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->features = BIT_ULL(NPC_OUTER_VID) | BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->channel = pf->hw.rx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->intf = NIX_INTF_RX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vf = vf + 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->op = NIX_RX_ACTION_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vtag0_valid = true;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vtag0_type = NIX_AF_LFX_RX_VTAG_TYPE7;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->set_cntr = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	vtag_req->vtag_size = VTAGSIZE_T4;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	vtag_req->cfg_type = 0; /* tx vlan cfg */
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	vtag_req->tx.cfg_vtag0 = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	vtag_req->tx.vtag0 = ((u64)ntohs(proto) << 16) | vlan;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:			(&pf->mbox.mbox, 0, &vtag_req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	eth_zero_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->entry = flow_cfg->entry[flow_cfg->vf_vlan_offset + idx];
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->features = BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->channel = pf->hw.tx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->intf = NIX_INTF_TX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vf = vf + 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->op = NIX_TX_ACTIONOP_UCAST_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vtag0_def = vtag_rsp->vtag0_idx;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->vtag0_op = VTAG_INSERT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->set_cntr = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->hdr.id = MBOX_MSG_CGX_LINK_EVENT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	req->hdr.sig = OTX2_MBOX_REQ_SIG;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_pf.c:	memcpy(&req->link_info, &pf->linfo, sizeof(req->link_info));
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->contig = false;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->count = OTX2_MCAM_COUNT + vf_vlan_max_flows;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	       (&pfvf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	if (rsp->count != req->count) {
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			    req->count, rsp->count);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->entry =  pf->mac_table[i].mcam_entry;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	ether_addr_copy(req->packet.dmac, mac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	eth_broadcast_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->features = BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->channel = pf->hw.rx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->intf = NIX_INTF_RX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->op = NIX_RX_ACTION_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->set_cntr = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->entry = mcam_entry;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pmask = &req->mask;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pkt = &req->packet;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV4);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_AH);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_ESP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pmask = &req->mask;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pkt = &req->packet;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_SPORT_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:				req->features |= BIT_ULL(NPC_DPORT_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_UDP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_TCP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_SCTP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DIP_IPV6);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_AH);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_IPPROTO_ESP);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pmask = &req->mask;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	struct flow_msg *pkt = &req->packet;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_SMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_ETYPE);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->features |= BIT_ULL(NPC_OUTER_VID);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->op = NIX_RX_ACTION_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->features |= BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	if (!req->features)
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->entry = flow->entry;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->intf = NIX_INTF_RX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->set_cntr = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->channel = pfvf->hw.rx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->op = NIX_RX_ACTIONOP_DROP;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->op = NIX_RX_ACTIONOP_RSS;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->index = flow->rss_ctx_id;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->op = NIX_RX_ACTIONOP_UCAST;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:			req->index = ethtool_get_flow_spec_ring(ring_cookie);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->vf = vf;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->entry = entry;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:		req->all = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->start = flow_cfg->entry[flow_cfg->ntuple_offset];
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->end   = flow_cfg->entry[flow_cfg->ntuple_offset +
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->all = 1;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->entry = flow_cfg->entry[flow_cfg->rx_vlan_offset];
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->intf = NIX_INTF_RX;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	ether_addr_copy(req->packet.dmac, pfvf->netdev->dev_addr);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	eth_broadcast_addr((u8 *)&req->mask.dmac);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->channel = pfvf->hw.rx_chan_base;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->op = NIX_RX_ACTION_DEFAULT;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->features = BIT_ULL(NPC_OUTER_VID) | BIT_ULL(NPC_DMAC);
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->vtag0_valid = true;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->vtag0_type = NIX_AF_LFX_RX_VTAG_TYPE0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->entry = flow_cfg->entry[flow_cfg->rx_vlan_offset];
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->vtag_size = VTAGSIZE_T4;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->cfg_type = 1; /* rx vlan cfg */
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->rx.vtag_type = NIX_AF_LFX_RX_VTAG_TYPE0;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->rx.strip_vtag = enable;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	req->rx.capture_vtag = enable;
drivers/net/ethernet/marvell/octeontx2/nic/otx2_flows.c:	rsp_hdr = otx2_mbox_get_rsp(&pf->mbox.mbox, 0, &req->hdr);
drivers/net/ethernet/mellanox/mlx4/resource_tracker.c:	if (req->com.from_state != RES_EQ_HW) {
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	struct mlx5_core_dev *dev = req->dev;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	if (req->release_all)
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:		release_all_pages(dev, req->func_id, req->ec_function);
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	else if (req->npages < 0)
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:		err = reclaim_pages(dev, req->func_id, -1 * req->npages, NULL,
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:				    req->ec_function);
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	else if (req->npages > 0)
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:		err = give_pages(dev, req->func_id, req->npages, 1, req->ec_function);
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:			       req->npages < 0 ? "reclaim" : "give", err);
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	req->dev = dev;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	req->func_id = func_id;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	req->npages = npages;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	req->ec_function = ec_function;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	req->release_all = release_all;
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	INIT_WORK(&req->work, pages_work_handler);
drivers/net/ethernet/mellanox/mlx5/core/pagealloc.c:	queue_work(dev->priv.pg_wq, &req->work);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:	MLX5_SET(hca_vport_context, ctx, field_select, req->field_select);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:	if (req->field_select & MLX5_HCA_VPORT_SEL_STATE_POLICY)
drivers/net/ethernet/mellanox/mlx5/core/vport.c:			 req->policy);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:	if (req->field_select & MLX5_HCA_VPORT_SEL_PORT_GUID)
drivers/net/ethernet/mellanox/mlx5/core/vport.c:		MLX5_SET64(hca_vport_context, ctx, port_guid, req->port_guid);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:	if (req->field_select & MLX5_HCA_VPORT_SEL_NODE_GUID)
drivers/net/ethernet/mellanox/mlx5/core/vport.c:		MLX5_SET64(hca_vport_context, ctx, node_guid, req->node_guid);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:	MLX5_SET(hca_vport_context, ctx, cap_mask1, req->cap_mask1);
drivers/net/ethernet/mellanox/mlx5/core/vport.c:		 req->cap_mask1_perm);
drivers/net/ethernet/amd/xgbe/xgbe-drv.c:	if (copy_to_user(ifreq->ifr_data, &pdata->tstamp_config,
drivers/net/ethernet/amd/xgbe/xgbe-drv.c:	if (copy_from_user(&config, ifreq->ifr_data, sizeof(config)))
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.version = ver;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages =  cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/net/ethernet/emulex/benet/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, valid, req->context, 1);
drivers/net/ethernet/emulex/benet/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, size, req->context, 0);
drivers/net/ethernet/emulex/benet/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, count, req->context,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(req->context, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->type = MAC_ADDRESS_TYPE_NETWORK;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->permanent = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->if_id = cpu_to_le16((u16)if_handle);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->pmac_id = cpu_to_le32(pmac_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->permanent = 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_id = cpu_to_le32(if_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->mac_address, mac_addr, ETH_ALEN);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = dom;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_id = cpu_to_le32(if_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->pmac_id = cpu_to_le32(pmac_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages =  cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 2;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->page_size = 1; /* 1 for 4K */
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->cq_id = cpu_to_le16(cq->id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->async_event_bitmap[0] =
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:			req->hdr.version = 2;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 2;
drivers/net/ethernet/emulex/benet/be_cmds.c:	if (req->hdr.version > 0)
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->if_id = cpu_to_le16(adapter->if_handle);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->ulp_num = BE_ULP1_NUM;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->type = BE_ETH_TX_RING_TYPE_STANDARD;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cq_id = cpu_to_le16(cq->id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->queue_size = be_encoded_q_len(txq->len);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	ver = req->hdr.version;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cq_id = cpu_to_le16(cq_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->frag_size = fls(frag_size) - 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pages = 2;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->interface_id = cpu_to_le32(if_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->max_frame_size = cpu_to_le16(BE_MAX_JUMBO_FRAME_SIZE);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->rss_queue = cpu_to_le32(rss);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, subsys, opcode, sizeof(*req), wrb,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->id = cpu_to_le16(q->id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->id = cpu_to_le16(q->id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->capability_flags = cpu_to_le32(cap_flags);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->enable_flags = cpu_to_le32(en_flags);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->pmac_invalid = true;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->interface_id = cpu_to_le32(interface_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cmd_params.params.pport_num = cpu_to_le16(adapter->hba_port_num);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cmd_params.params.reset_stats = 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = dom;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->fat_operation = cpu_to_le32(QUERY_FAT);
drivers/net/ethernet/emulex/benet/be_cmds.c:		be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->fat_operation = cpu_to_le32(RETRIEVE_FAT);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->read_log_offset = cpu_to_le32(log_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->read_log_length = cpu_to_le32(buf_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->data_buffer_size = cpu_to_le32(buf_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_eq = cpu_to_le32(num);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->set_eqd[i].eq_id = cpu_to_le32(set_eqd[i].eq_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->set_eqd[i].phase = 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->set_eqd[i].delay_multiplier =
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->interface_id = if_id;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->untagged = BE_IF_FLAGS_UNTAGGED & be_if_cap_flags(adapter) ? 1 : 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_vlan = num;
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->normal_vlan, vtag_array,
drivers/net/ethernet/emulex/benet/be_cmds.c:	       req->num_vlan * sizeof(vtag_array[0]));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_id = cpu_to_le32(adapter->if_handle);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_flags_mask = cpu_to_le32(flags);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_flags = (value == ON) ? req->if_flags_mask : 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->if_flags_mask |=
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->mcast_num = cpu_to_le32(adapter->mc_count);
drivers/net/ethernet/emulex/benet/be_cmds.c:			ether_addr_copy(req->mcast_mac[i].byte,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->tx_flow_control = cpu_to_le16((u16)tx_fc);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->rx_flow_control = cpu_to_le16((u16)rx_fc);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->if_id = cpu_to_le32(adapter->if_handle);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->enable_rss = cpu_to_le16(rss_hash_opts);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cpu_table_size_log2 = cpu_to_le16(fls(table_size) - 1);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->cpu_table, rsstable, table_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->hash, rss_hkey, RSS_HASH_KEY_LEN);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(req->hash, sizeof(req->hash));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->port_num = port_num;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->beacon_state = state;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->beacon_duration = bcn;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->status_duration = sts;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->port_num = port_num;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->port = cpu_to_le32(adapter->hba_port_num);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->page_num = cpu_to_le32(page_num);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->write_offset = cpu_to_le32(data_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:	strlcpy(req->object_name, obj_name, sizeof(req->object_name));
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->descriptor_count = cpu_to_le32(1);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->buf_len = cpu_to_le32(data_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->addr_low = cpu_to_le32((cmd->dma +
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->addr_high = cpu_to_le32(upper_32_bits(cmd->dma +
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	strlcpy(req->object_name, obj_name, sizeof(req->object_name));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->desired_read_len = cpu_to_le32(data_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->read_offset = cpu_to_le32(data_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:	strcpy(req->object_name, obj_name);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->descriptor_count = cpu_to_le32(1);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->buf_len = cpu_to_le32(data_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->addr_low = cpu_to_le32((cmd->dma & 0xFFFFFFFF));
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->addr_high = cpu_to_le32(upper_32_bits(cmd->dma));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.op_type = cpu_to_le32(flash_type);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->params.offset = cpu_to_le32(img_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.op_code = cpu_to_le32(flash_opcode);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.data_buf_size = cpu_to_le32(buf_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.op_type = cpu_to_le32(img_optype);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->params.offset = cpu_to_le32(img_offset + crc_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->params.offset = cpu_to_le32(crc_offset);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.op_code = cpu_to_le32(FLASHROM_OPER_REPORT);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->params.data_buf_size = cpu_to_le32(0x4);
drivers/net/ethernet/emulex/benet/be_cmds.c:		memcpy(flashed_crc, req->crc, 4);
drivers/net/ethernet/emulex/benet/be_cmds.c:		memcpy(req->data_buf, img, num_bytes);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->magic_mac, mac, ETH_ALEN);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->src_port = port_num;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->dest_port = port_num;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->loopback_type = loopback_type;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->loopback_state = enable;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.timeout = cpu_to_le32(15);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->pattern = cpu_to_le64(pattern);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->src_port = cpu_to_le32(port_num);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->dest_port = cpu_to_le32(port_num);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->pkt_size = cpu_to_le32(pkt_size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->num_pkts = cpu_to_le32(num_pkts);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->loopback_type = cpu_to_le32(loopback_type);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_LOWLEVEL,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->pattern = cpu_to_le64(pattern);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->byte_count = cpu_to_le32(byte_cnt);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->snd_buff[i] = (u8)(pattern >> (j*8));
drivers/net/ethernet/emulex/benet/be_cmds.c:		if ((memcmp(resp->rcv_buff, req->snd_buff, byte_cnt) != 0) ||
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->valid_bits = cpu_to_le32(BE_QOS_BITS_NIC);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->max_bps_nic = cpu_to_le32(bps);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->valid_cap_flags = cpu_to_le32(CAPABILITY_SW_TIMESTAMPS |
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->cap_flags = cpu_to_le32(CAPABILITY_BE3_NATIVE_ERX_API);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->privileges_lancer = cpu_to_le32(privileges);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->privileges = cpu_to_le32(privileges);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->mac_type = MAC_ADDRESS_TYPE_NETWORK;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->mac_id = cpu_to_le32(*pmac_id);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->iface_id = cpu_to_le16(if_handle);
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->perm_override = 0;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->perm_override = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->mac_count = mac_count;
drivers/net/ethernet/emulex/benet/be_cmds.c:		memcpy(req->mac, mac_array, ETH_ALEN*mac_count);
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(req->context, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	ctxt = &req->context;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_dws_cpu_to_le(req->context, sizeof(req->context));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ETH,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->query_options = BE_GET_WOL_CAP;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->parameter_type = cpu_to_le32(1);
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(&req->set_params, configs, sizeof(struct be_fat_conf_params));
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->hdr.version = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->type = profile_type;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:		req->type |= QUERY_MODIFIABLE_FIELDS_TYPE;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.version = version;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->desc_count = cpu_to_le32(count);
drivers/net/ethernet/emulex/benet/be_cmds.c:	memcpy(req->desc, desc, size);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->op = op;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->target_iface_id = cpu_to_le32(iface);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = vf_num + 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->enable = 1;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->intr_enabled = intr_enable;
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.version = version;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->hdr.domain = domain;
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->link_config = cpu_to_le32(link_config);
drivers/net/ethernet/emulex/benet/be_cmds.c:	be_wrb_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->features = cpu_to_le32(BE_FEATURE_UE_RECOVERY);
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->parameter_len = cpu_to_le32(sizeof(struct be_req_ue_recovery));
drivers/net/ethernet/emulex/benet/be_cmds.c:	req->parameter.req.uer = cpu_to_le32(BE_UE_RECOVERY_UER_MASK);
drivers/net/ethernet/sfc/rx_common.c:	struct efx_nic *efx = netdev_priv(req->net_dev);
drivers/net/ethernet/sfc/rx_common.c:	struct efx_channel *channel = efx_get_channel(efx, req->rxq_index);
drivers/net/ethernet/sfc/rx_common.c:	rc = efx->type->filter_insert(efx, &req->spec, true);
drivers/net/ethernet/sfc/rx_common.c:		rule = efx_rps_hash_find(efx, &req->spec);
drivers/net/ethernet/sfc/rx_common.c:		channel->rps_flow_id[rc] = req->flow_id;
drivers/net/ethernet/sfc/rx_common.c:		if (req->spec.ether_type == htons(ETH_P_IP))
drivers/net/ethernet/sfc/rx_common.c:				   (req->spec.ip_proto == IPPROTO_TCP) ? "TCP" : "UDP",
drivers/net/ethernet/sfc/rx_common.c:				   req->spec.rem_host, ntohs(req->spec.rem_port),
drivers/net/ethernet/sfc/rx_common.c:				   req->spec.loc_host, ntohs(req->spec.loc_port),
drivers/net/ethernet/sfc/rx_common.c:				   req->rxq_index, req->flow_id, rc, arfs_id);
drivers/net/ethernet/sfc/rx_common.c:				   (req->spec.ip_proto == IPPROTO_TCP) ? "TCP" : "UDP",
drivers/net/ethernet/sfc/rx_common.c:				   req->spec.rem_host, ntohs(req->spec.rem_port),
drivers/net/ethernet/sfc/rx_common.c:				   req->spec.loc_host, ntohs(req->spec.loc_port),
drivers/net/ethernet/sfc/rx_common.c:				   req->rxq_index, req->flow_id, rc, arfs_id);
drivers/net/ethernet/sfc/rx_common.c:		if (req->spec.ether_type == htons(ETH_P_IP))
drivers/net/ethernet/sfc/rx_common.c:				  (req->spec.ip_proto == IPPROTO_TCP) ? "TCP" : "UDP",
drivers/net/ethernet/sfc/rx_common.c:				  req->spec.rem_host, ntohs(req->spec.rem_port),
drivers/net/ethernet/sfc/rx_common.c:				  req->spec.loc_host, ntohs(req->spec.loc_port),
drivers/net/ethernet/sfc/rx_common.c:				  req->rxq_index, req->flow_id, rc, arfs_id);
drivers/net/ethernet/sfc/rx_common.c:				  (req->spec.ip_proto == IPPROTO_TCP) ? "TCP" : "UDP",
drivers/net/ethernet/sfc/rx_common.c:				  req->spec.rem_host, ntohs(req->spec.rem_port),
drivers/net/ethernet/sfc/rx_common.c:				  req->spec.loc_host, ntohs(req->spec.loc_port),
drivers/net/ethernet/sfc/rx_common.c:				  req->rxq_index, req->flow_id, rc, arfs_id);
drivers/net/ethernet/sfc/rx_common.c:	dev_put(req->net_dev);
drivers/net/ethernet/sfc/rx_common.c:	efx_filter_init_rx(&req->spec, EFX_FILTER_PRI_HINT,
drivers/net/ethernet/sfc/rx_common.c:	req->spec.match_flags =
drivers/net/ethernet/sfc/rx_common.c:	req->spec.ether_type = fk.basic.n_proto;
drivers/net/ethernet/sfc/rx_common.c:	req->spec.ip_proto = fk.basic.ip_proto;
drivers/net/ethernet/sfc/rx_common.c:		req->spec.rem_host[0] = fk.addrs.v4addrs.src;
drivers/net/ethernet/sfc/rx_common.c:		req->spec.loc_host[0] = fk.addrs.v4addrs.dst;
drivers/net/ethernet/sfc/rx_common.c:		memcpy(req->spec.rem_host, &fk.addrs.v6addrs.src,
drivers/net/ethernet/sfc/rx_common.c:		memcpy(req->spec.loc_host, &fk.addrs.v6addrs.dst,
drivers/net/ethernet/sfc/rx_common.c:	req->spec.rem_port = fk.ports.src;
drivers/net/ethernet/sfc/rx_common.c:	req->spec.loc_port = fk.ports.dst;
drivers/net/ethernet/sfc/rx_common.c:		rule = efx_rps_hash_add(efx, &req->spec, &new);
drivers/net/ethernet/sfc/rx_common.c:	dev_hold(req->net_dev = net_dev);
drivers/net/ethernet/sfc/rx_common.c:	INIT_WORK(&req->work, efx_filter_rfs_work);
drivers/net/ethernet/sfc/rx_common.c:	req->rxq_index = rxq_index;
drivers/net/ethernet/sfc/rx_common.c:	req->flow_id = flow_id;
drivers/net/ethernet/sfc/rx_common.c:	schedule_work(&req->work);
drivers/net/ethernet/sfc/siena_sriov.c:			       req->to_rid);
drivers/net/ethernet/sfc/siena_sriov.c:			       req->to_addr);
drivers/net/ethernet/sfc/siena_sriov.c:		if (req->from_buf == NULL) {
drivers/net/ethernet/sfc/siena_sriov.c:			from_rid = req->from_rid;
drivers/net/ethernet/sfc/siena_sriov.c:			from_addr = req->from_addr;
drivers/net/ethernet/sfc/siena_sriov.c:			if (WARN_ON(used + req->length >
drivers/net/ethernet/sfc/siena_sriov.c:			memcpy(_MCDI_PTR(inbuf, used), req->from_buf,
drivers/net/ethernet/sfc/siena_sriov.c:			       req->length);
drivers/net/ethernet/sfc/siena_sriov.c:			used += req->length;
drivers/net/ethernet/sfc/siena_sriov.c:			       req->length);
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_evq = req->u.init_evq.index;
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned buf_count = req->u.init_evq.buf_count;
drivers/net/ethernet/sfc/siena_sriov.c:	efx_siena_sriov_bufs(efx, buftbl, req->u.init_evq.addr, buf_count);
drivers/net/ethernet/sfc/siena_sriov.c:		memcpy(vf->evq0_addrs, req->u.init_evq.addr,
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_rxq = req->u.init_rxq.index;
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_evq = req->u.init_rxq.evq;
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned buf_count = req->u.init_rxq.buf_count;
drivers/net/ethernet/sfc/siena_sriov.c:	if (__test_and_set_bit(req->u.init_rxq.index, vf->rxq_mask))
drivers/net/ethernet/sfc/siena_sriov.c:	efx_siena_sriov_bufs(efx, buftbl, req->u.init_rxq.addr, buf_count);
drivers/net/ethernet/sfc/siena_sriov.c:	label = req->u.init_rxq.label & EFX_FIELD_MASK(FRF_AZ_RX_DESCQ_LABEL);
drivers/net/ethernet/sfc/siena_sriov.c:			     !!(req->u.init_rxq.flags &
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_txq = req->u.init_txq.index;
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_evq = req->u.init_txq.evq;
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned buf_count = req->u.init_txq.buf_count;
drivers/net/ethernet/sfc/siena_sriov.c:	if (__test_and_set_bit(req->u.init_txq.index, vf->txq_mask))
drivers/net/ethernet/sfc/siena_sriov.c:	efx_siena_sriov_bufs(efx, buftbl, req->u.init_txq.addr, buf_count);
drivers/net/ethernet/sfc/siena_sriov.c:	label = req->u.init_txq.label & EFX_FIELD_MASK(FRF_AZ_TX_DESCQ_LABEL);
drivers/net/ethernet/sfc/siena_sriov.c:	unsigned vf_rxq = req->u.mac_filter.rxq;
drivers/net/ethernet/sfc/siena_sriov.c:				  req->u.mac_filter.flags);
drivers/net/ethernet/sfc/siena_sriov.c:	if (req->u.mac_filter.flags & VFDI_MAC_FILTER_FLAG_RSS)
drivers/net/ethernet/sfc/siena_sriov.c:	if (req->u.mac_filter.flags & VFDI_MAC_FILTER_FLAG_SCATTER)
drivers/net/ethernet/sfc/siena_sriov.c:	u64 page_count = req->u.set_status_page.peer_page_count;
drivers/net/ethernet/sfc/siena_sriov.c:		/ sizeof(req->u.set_status_page.peer_page_addr[0]);
drivers/net/ethernet/sfc/siena_sriov.c:	if (!req->u.set_status_page.dma_addr || page_count > max_page_count) {
drivers/net/ethernet/sfc/siena_sriov.c:	vf->status_addr = req->u.set_status_page.dma_addr;
drivers/net/ethernet/sfc/siena_sriov.c:			       req->u.set_status_page.peer_page_addr,
drivers/net/ethernet/sfc/siena_sriov.c:	if (req->op < VFDI_OP_LIMIT && vfdi_ops[req->op] != NULL) {
drivers/net/ethernet/sfc/siena_sriov.c:		rc = vfdi_ops[req->op](vf);
drivers/net/ethernet/sfc/siena_sriov.c:				  req->op, vf->pci_name);
drivers/net/ethernet/sfc/siena_sriov.c:			  "%llx\n", req->op, vf->pci_name,
drivers/net/ethernet/sfc/siena_sriov.c:	req->rc = rc;
drivers/net/ethernet/sfc/siena_sriov.c:	req->op = VFDI_OP_RESPONSE;
drivers/net/ethernet/sfc/siena_sriov.c:	copy[0].from_buf = &req->rc;
drivers/net/ethernet/sfc/siena_sriov.c:	copy[0].length = sizeof(req->rc);
drivers/net/ethernet/sfc/siena_sriov.c:	copy[1].from_buf = &req->op;
drivers/net/ethernet/sfc/siena_sriov.c:	copy[1].length = sizeof(req->op);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	p_resp->num_cids = min_t(u8, p_req->num_cids, num_vf_cons);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:					p_req->num_mac_filters);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:					 p_req->num_vlan_filters);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (p_resp->num_rxqs < p_req->num_rxqs ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_txqs < p_req->num_txqs ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_sbs < p_req->num_sbs ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_mac_filters < p_req->num_mac_filters ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_vlan_filters < p_req->num_vlan_filters ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_mc_filters < p_req->num_mc_filters ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_resp->num_cids < p_req->num_cids) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_rxqs,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_rxqs,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_sbs,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_mac_filters,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_vlan_filters,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_mc_filters,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			   p_req->num_cids, p_resp->num_cids);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (req->vfdev_info.eth_fp_hsi_major != ETH_HSI_VER_MAJOR) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:		if (req->vfdev_info.capabilities &
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			struct vf_pf_vfdev_info *p_vfdev = &req->vfdev_info;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				req->vfdev_info.eth_fp_hsi_major,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				req->vfdev_info.eth_fp_hsi_minor,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    !(req->vfdev_info.capabilities & VFPF_ACQUIRE_CAP_100G)) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	vf->opaque_fid = req->vfdev_info.opaque_fid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	vf->vf_bulletin = req->bulletin_addr;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	vf->bulletin.size = (vf->bulletin.size < req->bulletin_size) ?
drivers/net/ethernet/qlogic/qed/qed_sriov.c:			    vf->bulletin.size : req->bulletin_size;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (req->vfdev_info.capabilities & VFPF_ACQUIRE_CAP_QUEUE_QIDS)
drivers/net/ethernet/qlogic/qed/qed_sriov.c:					 req->vfdev_info.eth_fp_hsi_minor);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:						  &req->resc_request, resc);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				sizeof(struct eth_rx_prod_data) * req->rx_qid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (!qed_iov_validate_rxq(p_hwfn, vf, req->rx_qid,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	p_queue = &vf->vf_queues[req->rx_qid];
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	sb_dummy.igu_sb_id = req->hw_sb;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	params.sb_idx = req->sb_index;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	vf_params.vf_qid = (u8)req->rx_qid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:		       MSTORM_ETH_VF_PRODS_OFFSET(vf->abs_vf_id, req->rx_qid),
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      req->bd_max_bytes,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      req->rxq_addr,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      req->cqe_pbl_addr, req->cqe_pbl_size);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (p_req->tun_mode_update_mask & BIT(mask)) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:		if (p_req->tunn_mode & BIT(mask))
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (p_req->tun_mode_update_mask || p_req->update_tun_cls ||
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    p_req->update_geneve_port || p_req->update_vxlan_port)
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	tunn.b_update_rx_cls = p_req->update_tun_cls;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	tunn.b_update_tx_cls = p_req->update_tun_cls;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    QED_MODE_VXLAN_TUNN, p_req->vxlan_clss,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    p_req->update_vxlan_port,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    p_req->vxlan_port);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    p_req->l2geneve_clss,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    p_req->update_geneve_port,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				    p_req->geneve_port);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      p_req->ipgeneve_clss);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      QED_MODE_L2GRE_TUNN, p_req->l2gre_clss);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      QED_MODE_IPGRE_TUNN, p_req->ipgre_clss);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (!qed_iov_validate_txq(p_hwfn, vf, req->tx_qid,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	    !qed_iov_validate_sb(p_hwfn, vf, req->hw_sb))
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	p_queue = &vf->vf_queues[req->tx_qid];
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	sb_dummy.igu_sb_id = req->hw_sb;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	params.sb_idx = req->sb_index;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	vf_params.vf_qid = (u8)req->tx_qid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				      req->pbl_addr, req->pbl_size, pq);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (req->num_rxqs != 1) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	rc = qed_iov_vf_stop_rxqs(p_hwfn, vf, req->rx_qid,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				  qid_usage_idx, req->cqe_completion);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	if (req->num_txqs != 1) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	rc = qed_iov_vf_stop_txqs(p_hwfn, vf, req->tx_qid, qid_usage_idx);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	complete_cqe_flg = !!(req->flags & VFPF_RXQ_UPD_COMPLETE_CQE_FLAG);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	complete_event_flg = !!(req->flags & VFPF_RXQ_UPD_COMPLETE_EVENT_FLAG);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	     VFPF_ACQUIRE_CAP_QUEUE_QIDS) && req->num_rxqs != 1) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	for (i = req->rx_qid; i < req->rx_qid + req->num_rxqs; i++) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				   vf->relative_vf_id, req->rx_qid,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:				   req->num_rxqs);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	for (i = 0; i < req->num_rxqs; i++) {
drivers/net/ethernet/qlogic/qed/qed_sriov.c:		u16 qid = req->rx_qid + i;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:					 req->num_rxqs,
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	params.opcode = (enum qed_filter_opcode)req->opcode;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	params.type = (enum qed_filter_ucast_type)req->type;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	memcpy(params.mac, req->mac, ETH_ALEN);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	params.vlan = req->vlan;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	qid = req->qid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	b_is_rx = req->is_rx ? true : false;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	rx_coal = req->rx_coal;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	tx_coal = req->tx_coal;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	qid = req->qid;
drivers/net/ethernet/qlogic/qed/qed_sriov.c:	ether_addr_copy(p_bulletin->mac, p_req->mac);
drivers/net/ethernet/qlogic/qed/qed_sriov.c:		   p_vf->abs_vf_id, p_req->mac);
drivers/net/ethernet/qlogic/qed/qed_vf.c:			  p_req->first_tlv.tl.type);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				  *done, p_req->first_tlv.tl.type);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				   *done, p_req->first_tlv.tl.type);
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_rxqs,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_rxqs,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_sbs,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_mac_filters,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_vlan_filters,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_req->num_mc_filters,
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   p_resp->num_mc_filters, p_req->num_cids, p_resp->num_cids);
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_txqs = p_resp->num_txqs;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_rxqs = p_resp->num_rxqs;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_sbs = p_resp->num_sbs;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_mac_filters = p_resp->num_mac_filters;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_vlan_filters = p_resp->num_vlan_filters;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_mc_filters = p_resp->num_mc_filters;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_req->num_cids = p_resp->num_cids;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	p_resc = &req->resc_request;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.opaque_fid = p_hwfn->hw_info.opaque_fid;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.os_type = VFPF_ACQUIRE_OS_LINUX;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.fw_major = FW_MAJOR_VERSION;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.fw_minor = FW_MINOR_VERSION;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.fw_revision = FW_REVISION_VERSION;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.fw_engineering = FW_ENGINEERING_VERSION;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.eth_fp_hsi_major = ETH_HSI_VER_MAJOR;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.eth_fp_hsi_minor = ETH_HSI_VER_MINOR;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vfdev_info.capabilities |= VFPF_ACQUIRE_CAP_100G;
drivers/net/ethernet/qlogic/qed/qed_vf.c:		req->vfdev_info.capabilities |= VFPF_ACQUIRE_CAP_PHYSICAL_BAR |
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->bulletin_addr = p_iov->bulletin.phys;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->bulletin_size = p_iov->bulletin.size;
drivers/net/ethernet/qlogic/qed/qed_vf.c:				req->vfdev_info.capabilities |=
drivers/net/ethernet/qlogic/qed/qed_vf.c:				if (req->vfdev_info.capabilities &
drivers/net/ethernet/qlogic/qed/qed_vf.c:					req->vfdev_info.capabilities |=
drivers/net/ethernet/qlogic/qed/qed_vf.c:	if (req->vfdev_info.capabilities & VFPF_ACQUIRE_CAP_PRE_FP_HSI)
drivers/net/ethernet/qlogic/qed/qed_vf.c:		p_req->tun_mode_update_mask |= BIT(mask);
drivers/net/ethernet/qlogic/qed/qed_vf.c:			p_req->tunn_mode |= BIT(mask);
drivers/net/ethernet/qlogic/qed/qed_vf.c:		p_req->update_tun_cls = 1;
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->vxlan_clss, &p_src->vxlan_port,
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->update_vxlan_port,
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->vxlan_port);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->l2geneve_clss, &p_src->geneve_port,
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->update_geneve_port,
drivers/net/ethernet/qlogic/qed/qed_vf.c:				 &p_req->geneve_port);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				   &p_req->ipgeneve_clss);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				   QED_MODE_L2GRE_TUNN, &p_req->l2gre_clss);
drivers/net/ethernet/qlogic/qed/qed_vf.c:				   QED_MODE_IPGRE_TUNN, &p_req->ipgre_clss);
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->rx_qid = rx_qid;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->cqe_pbl_addr = cqe_pbl_addr;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->cqe_pbl_size = cqe_pbl_size;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->rxq_addr = bd_chain_phys_addr;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->hw_sb = p_cid->sb_igu_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->sb_index = p_cid->sb_idx;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->bd_max_bytes = bd_max_bytes;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->stat_id = -1;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->rx_qid = p_cid->rel.queue_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->num_rxqs = 1;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->cqe_completion = cqe_completion;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->tx_qid = qid;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->pbl_addr = pbl_addr;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->pbl_size = pbl_size;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->hw_sb = p_cid->sb_igu_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->sb_index = p_cid->sb_idx;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->tx_qid = p_cid->rel.queue_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->num_txqs = 1;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->mtu = mtu;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vport_id = vport_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->inner_vlan_removal = inner_vlan_removal;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->tpa_mode = tpa_mode;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->max_buffers_per_cqe = max_buffers_per_cqe;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->only_untagged = only_untagged;
drivers/net/ethernet/qlogic/qed/qed_vf.c:			req->sb_addr[i] = p_sb->sb_phys;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->opcode = (u8) p_ucast->opcode;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->type = (u8) p_ucast->type;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	memcpy(req->mac, p_ucast->mac, ETH_ALEN);
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->vlan = p_ucast->vlan;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->qid = p_cid->rel.queue_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->is_rx = p_cid->b_is_rx ? 1 : 0;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	ether_addr_copy(p_req->mac, p_mac);
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->rx_coal = rx_coal;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->tx_coal = tx_coal;
drivers/net/ethernet/qlogic/qed/qed_vf.c:	req->qid = p_cid->rel.queue_id;
drivers/net/ethernet/qlogic/qed/qed_vf.c:		   rx_coal, tx_coal, req->qid);
drivers/net/ethernet/qlogic/qed/qed_dev.c:	p_load_req->drv_role = p_drv_load->is_crash_kernel ?
drivers/net/ethernet/qlogic/qed/qed_dev.c:	p_load_req->timeout_val = p_drv_load->mfw_timeout_val;
drivers/net/ethernet/qlogic/qed/qed_dev.c:	p_load_req->avoid_eng_reset = p_drv_load->avoid_eng_reset;
drivers/net/ethernet/qlogic/qed/qed_dev.c:	p_load_req->override_force_load = p_drv_load->override_force_load;
drivers/net/ethernet/qlogic/netxen/netxen_nic_hw.c:	mac_req->op = op;
drivers/net/ethernet/qlogic/netxen/netxen_nic_hw.c:	memcpy(mac_req->mac_addr, addr, ETH_ALEN);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	req->qhdr = cpu_to_le64(QLCNIC_REQUEST << 23);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	req->req_hdr = cpu_to_le64(word);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	mac_req = (struct qlcnic_mac_req *)&(req->words[0]);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	mac_req->op = vlan_id ? QLCNIC_MAC_VLAN_ADD : QLCNIC_MAC_ADD;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	memcpy(mac_req->mac_addr, uaddr, ETH_ALEN);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	vlan_req = (struct qlcnic_vlan_req *)&req->words[1];
drivers/net/ethernet/qlogic/qlcnic/qlcnic_io.c:	vlan_req->vlan_id = cpu_to_le16(vlan_id);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_hw.c:	mac_req->op = op;
drivers/net/ethernet/qlogic/qlcnic/qlcnic_hw.c:	memcpy(mac_req->mac_addr, addr, ETH_ALEN);
drivers/net/ethernet/qlogic/qlcnic/qlcnic_hw.c:	vlan_req->vlan_id = cpu_to_le16(vlan_id);
drivers/net/hyperv/rndis_filter.c:	list_del(&req->list_ent);
drivers/net/hyperv/rndis_filter.c:	packet = &req->pkt;
drivers/net/hyperv/rndis_filter.c:	packet->total_data_buflen = req->request_msg.msg_len;
drivers/net/hyperv/rndis_filter.c:	pb[0].pfn = virt_to_phys(&req->request_msg) >>
drivers/net/hyperv/rndis_filter.c:	pb[0].len = req->request_msg.msg_len;
drivers/net/hyperv/rndis_filter.c:	pb[0].offset = offset_in_hvpage(&req->request_msg);
drivers/net/hyperv/rndis_filter.c:		pb[1].pfn = virt_to_phys((void *)&req->request_msg
drivers/net/hyperv/rndis_filter.c:		pb[1].len = req->request_msg.msg_len -
drivers/net/hyperv/rndis_filter.c:	trace_rndis_send(dev->ndev, 0, &req->request_msg);
drivers/mtd/ubi/cdev.c:	if (req->bytes < 0 || req->alignment < 0 || req->vol_type < 0 ||
drivers/mtd/ubi/cdev.c:	    req->name_len < 0)
drivers/mtd/ubi/cdev.c:	if ((req->vol_id < 0 || req->vol_id >= ubi->vtbl_slots) &&
drivers/mtd/ubi/cdev.c:	    req->vol_id != UBI_VOL_NUM_AUTO)
drivers/mtd/ubi/cdev.c:	if (req->alignment == 0)
drivers/mtd/ubi/cdev.c:	if (req->bytes == 0)
drivers/mtd/ubi/cdev.c:	if (req->vol_type != UBI_DYNAMIC_VOLUME &&
drivers/mtd/ubi/cdev.c:	    req->vol_type != UBI_STATIC_VOLUME)
drivers/mtd/ubi/cdev.c:	if (req->flags & ~UBI_VOL_VALID_FLGS)
drivers/mtd/ubi/cdev.c:	if (req->flags & UBI_VOL_SKIP_CRC_CHECK_FLG &&
drivers/mtd/ubi/cdev.c:	    req->vol_type != UBI_STATIC_VOLUME)
drivers/mtd/ubi/cdev.c:	if (req->alignment > ubi->leb_size)
drivers/mtd/ubi/cdev.c:	n = req->alignment & (ubi->min_io_size - 1);
drivers/mtd/ubi/cdev.c:	if (req->alignment != 1 && n)
drivers/mtd/ubi/cdev.c:	if (!req->name[0] || !req->name_len)
drivers/mtd/ubi/cdev.c:	if (req->name_len > UBI_VOL_NAME_MAX) {
drivers/mtd/ubi/cdev.c:	n = strnlen(req->name, req->name_len + 1);
drivers/mtd/ubi/cdev.c:	if (n != req->name_len)
drivers/mtd/ubi/cdev.c:	if (req->bytes <= 0)
drivers/mtd/ubi/cdev.c:	if (req->vol_id < 0 || req->vol_id >= ubi->vtbl_slots)
drivers/mtd/ubi/cdev.c:	if (req->count < 0 || req->count > UBI_MAX_RNVOL)
drivers/mtd/ubi/cdev.c:	if (req->count == 0)
drivers/mtd/ubi/cdev.c:	for (i = 0; i < req->count; i++) {
drivers/mtd/ubi/cdev.c:		if (req->ents[i].vol_id < 0 ||
drivers/mtd/ubi/cdev.c:		    req->ents[i].vol_id >= ubi->vtbl_slots)
drivers/mtd/ubi/cdev.c:		if (req->ents[i].name_len < 0)
drivers/mtd/ubi/cdev.c:		if (req->ents[i].name_len > UBI_VOL_NAME_MAX)
drivers/mtd/ubi/cdev.c:		req->ents[i].name[req->ents[i].name_len] = '\0';
drivers/mtd/ubi/cdev.c:		n = strlen(req->ents[i].name);
drivers/mtd/ubi/cdev.c:		if (n != req->ents[i].name_len)
drivers/mtd/ubi/cdev.c:	for (i = 0; i < req->count - 1; i++) {
drivers/mtd/ubi/cdev.c:		for (n = i + 1; n < req->count; n++) {
drivers/mtd/ubi/cdev.c:			if (req->ents[i].vol_id == req->ents[n].vol_id) {
drivers/mtd/ubi/cdev.c:					req->ents[i].vol_id);
drivers/mtd/ubi/cdev.c:			if (!strcmp(req->ents[i].name, req->ents[n].name)) {
drivers/mtd/ubi/cdev.c:					req->ents[i].name);
drivers/mtd/ubi/cdev.c:	for (i = 0; i < req->count; i++) {
drivers/mtd/ubi/cdev.c:		int vol_id = req->ents[i].vol_id;
drivers/mtd/ubi/cdev.c:		int name_len = req->ents[i].name_len;
drivers/mtd/ubi/cdev.c:		const char *name = req->ents[i].name;
drivers/mtd/ubi/upd.c:		vol->vol_id, req->lnum, req->bytes);
drivers/mtd/ubi/upd.c:	if (req->bytes == 0)
drivers/mtd/ubi/upd.c:		return ubi_eba_atomic_leb_change(ubi, vol, req->lnum, NULL, 0);
drivers/mtd/ubi/upd.c:	vol->upd_bytes = req->bytes;
drivers/mtd/ubi/upd.c:	vol->ch_lnum = req->lnum;
drivers/mtd/ubi/upd.c:	vol->upd_buf = vmalloc(ALIGN((int)req->bytes, ubi->min_io_size));
drivers/mtd/ubi/debug.c:	pr_err("\tvol_id    %d\n",   req->vol_id);
drivers/mtd/ubi/debug.c:	pr_err("\talignment %d\n",   req->alignment);
drivers/mtd/ubi/debug.c:	pr_err("\tbytes     %lld\n", (long long)req->bytes);
drivers/mtd/ubi/debug.c:	pr_err("\tvol_type  %d\n",   req->vol_type);
drivers/mtd/ubi/debug.c:	pr_err("\tname_len  %d\n",   req->name_len);
drivers/mtd/ubi/debug.c:	memcpy(nm, req->name, 16);
drivers/mtd/ubi/block.c:	struct ubiblock *dev = req->q->queuedata;
drivers/mtd/ubi/block.c:	blk_rq_map_sg(req->q, req, pdu->usgl.sg);
drivers/mtd/ubi/vmt.c: * This function creates volume described by @req. If @req->vol_id id
drivers/mtd/ubi/vmt.c: * and saves it in @req->vol_id. Returns zero in case of success and a negative
drivers/mtd/ubi/vmt.c:	int i, err, vol_id = req->vol_id;
drivers/mtd/ubi/vmt.c:	if (req->flags & UBI_VOL_SKIP_CRC_CHECK_FLG)
drivers/mtd/ubi/vmt.c:		req->vol_id = vol_id;
drivers/mtd/ubi/vmt.c:		ubi->ubi_num, vol_id, (unsigned long long)req->bytes,
drivers/mtd/ubi/vmt.c:		(int)req->vol_type, req->name);
drivers/mtd/ubi/vmt.c:		    ubi->volumes[i]->name_len == req->name_len &&
drivers/mtd/ubi/vmt.c:		    !strcmp(ubi->volumes[i]->name, req->name)) {
drivers/mtd/ubi/vmt.c:				req->name, i);
drivers/mtd/ubi/vmt.c:	vol->usable_leb_size = ubi->leb_size - ubi->leb_size % req->alignment;
drivers/mtd/ubi/vmt.c:	vol->reserved_pebs = div_u64(req->bytes + vol->usable_leb_size - 1,
drivers/mtd/ubi/vmt.c:	vol->alignment = req->alignment;
drivers/mtd/ubi/vmt.c:	vol->vol_type  = req->vol_type;
drivers/mtd/ubi/vmt.c:	vol->name_len  = req->name_len;
drivers/mtd/ubi/vmt.c:	memcpy(vol->name, req->name, vol->name_len);
drivers/mtd/nand/spi/core.c:	bool enable = (req->mode != MTD_OPS_RAW);
drivers/mtd/nand/spi/core.c:	if (req->mode == MTD_OPS_RAW)
drivers/mtd/nand/spi/core.c:	if (req->type == NAND_PAGE_WRITE)
drivers/mtd/nand/spi/core.c:	unsigned int row = nanddev_pos_to_row(nand, &req->pos);
drivers/mtd/nand/spi/core.c:	if (req->datalen) {
drivers/mtd/nand/spi/core.c:	if (req->ooblen) {
drivers/mtd/nand/spi/core.c:	rdesc = spinand->dirmaps[req->pos.plane].rdesc;
drivers/mtd/nand/spi/core.c:	if (req->datalen)
drivers/mtd/nand/spi/core.c:		memcpy(req->databuf.in, spinand->databuf + req->dataoffs,
drivers/mtd/nand/spi/core.c:		       req->datalen);
drivers/mtd/nand/spi/core.c:	if (req->ooblen) {
drivers/mtd/nand/spi/core.c:		if (req->mode == MTD_OPS_AUTO_OOB)
drivers/mtd/nand/spi/core.c:			mtd_ooblayout_get_databytes(mtd, req->oobbuf.in,
drivers/mtd/nand/spi/core.c:						    req->ooboffs,
drivers/mtd/nand/spi/core.c:						    req->ooblen);
drivers/mtd/nand/spi/core.c:			memcpy(req->oobbuf.in, spinand->oobbuf + req->ooboffs,
drivers/mtd/nand/spi/core.c:			       req->ooblen);
drivers/mtd/nand/spi/core.c:	if (req->datalen)
drivers/mtd/nand/spi/core.c:		memcpy(spinand->databuf + req->dataoffs, req->databuf.out,
drivers/mtd/nand/spi/core.c:		       req->datalen);
drivers/mtd/nand/spi/core.c:	if (req->ooblen) {
drivers/mtd/nand/spi/core.c:		if (req->mode == MTD_OPS_AUTO_OOB)
drivers/mtd/nand/spi/core.c:			mtd_ooblayout_set_databytes(mtd, req->oobbuf.out,
drivers/mtd/nand/spi/core.c:						    req->ooboffs,
drivers/mtd/nand/spi/core.c:						    req->ooblen);
drivers/mtd/nand/spi/core.c:			memcpy(spinand->oobbuf + req->ooboffs, req->oobbuf.out,
drivers/mtd/nand/spi/core.c:			       req->ooblen);
drivers/mtd/nand/spi/core.c:	wdesc = spinand->dirmaps[req->pos.plane].wdesc;
drivers/mtd/nand/spi/core.c:	unsigned int row = nanddev_pos_to_row(nand, &req->pos);
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.sectorsize == 512) {
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.sectorsize == 512)
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->pagesize <= 0 || req->oobsize <= 0 || req->ecc.bytes <= 0)
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.ooboffset >= 0 &&
drivers/mtd/nand/raw/atmel/pmecc.c:	    req->ecc.ooboffset + req->ecc.bytes > req->oobsize)
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.sectorsize == ATMEL_PMECC_SECTOR_SIZE_AUTO) {
drivers/mtd/nand/raw/atmel/pmecc.c:		if (req->ecc.strength != ATMEL_PMECC_MAXIMIZE_ECC_STRENGTH)
drivers/mtd/nand/raw/atmel/pmecc.c:		if (req->pagesize > 512)
drivers/mtd/nand/raw/atmel/pmecc.c:			req->ecc.sectorsize = 1024;
drivers/mtd/nand/raw/atmel/pmecc.c:			req->ecc.sectorsize = 512;
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.sectorsize != 512 && req->ecc.sectorsize != 1024)
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->pagesize % req->ecc.sectorsize)
drivers/mtd/nand/raw/atmel/pmecc.c:	req->ecc.nsectors = req->pagesize / req->ecc.sectorsize;
drivers/mtd/nand/raw/atmel/pmecc.c:	max_eccbytes = req->ecc.bytes;
drivers/mtd/nand/raw/atmel/pmecc.c:		if (req->ecc.strength != ATMEL_PMECC_MAXIMIZE_ECC_STRENGTH &&
drivers/mtd/nand/raw/atmel/pmecc.c:		    strength < req->ecc.strength)
drivers/mtd/nand/raw/atmel/pmecc.c:		nbytes = DIV_ROUND_UP(strength * fls(8 * req->ecc.sectorsize),
drivers/mtd/nand/raw/atmel/pmecc.c:		nbytes *= req->ecc.nsectors;
drivers/mtd/nand/raw/atmel/pmecc.c:		if (req->ecc.strength != ATMEL_PMECC_MAXIMIZE_ECC_STRENGTH)
drivers/mtd/nand/raw/atmel/pmecc.c:	req->ecc.bytes = eccbytes;
drivers/mtd/nand/raw/atmel/pmecc.c:	req->ecc.strength = eccstrength;
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.ooboffset < 0)
drivers/mtd/nand/raw/atmel/pmecc.c:		req->ecc.ooboffset = req->oobsize - eccbytes;
drivers/mtd/nand/raw/atmel/pmecc.c:	size += ((2 * req->ecc.strength) + 1) * sizeof(u16) *
drivers/mtd/nand/raw/atmel/pmecc.c:		(2 + req->ecc.strength + 2);
drivers/mtd/nand/raw/atmel/pmecc.c:	size += (req->ecc.strength + 1) * sizeof(u16);
drivers/mtd/nand/raw/atmel/pmecc.c:	size += (req->ecc.strength + 1) * sizeof(s32) * 3;
drivers/mtd/nand/raw/atmel/pmecc.c:	user->si = user->partial_syn + ((2 * req->ecc.strength) + 1);
drivers/mtd/nand/raw/atmel/pmecc.c:	user->lmu = user->si + ((2 * req->ecc.strength) + 1);
drivers/mtd/nand/raw/atmel/pmecc.c:	user->smu = user->lmu + (req->ecc.strength + 1);
drivers/mtd/nand/raw/atmel/pmecc.c:				    (((2 * req->ecc.strength) + 1) *
drivers/mtd/nand/raw/atmel/pmecc.c:				     (req->ecc.strength + 2)),
drivers/mtd/nand/raw/atmel/pmecc.c:	user->dmu = user->mu + req->ecc.strength + 1;
drivers/mtd/nand/raw/atmel/pmecc.c:	user->delta = user->dmu + req->ecc.strength + 1;
drivers/mtd/nand/raw/atmel/pmecc.c:	user->eccbytes = req->ecc.bytes / req->ecc.nsectors;
drivers/mtd/nand/raw/atmel/pmecc.c:		if (pmecc->caps->strengths[strength] == req->ecc.strength)
drivers/mtd/nand/raw/atmel/pmecc.c:			  PMECC_CFG_NSECTORS(req->ecc.nsectors);
drivers/mtd/nand/raw/atmel/pmecc.c:	if (req->ecc.sectorsize == 1024)
drivers/mtd/nand/raw/atmel/pmecc.c:	user->cache.sarea = req->oobsize - 1;
drivers/mtd/nand/raw/atmel/pmecc.c:	user->cache.saddr = req->ecc.ooboffset;
drivers/mtd/nand/raw/atmel/pmecc.c:	user->cache.eaddr = req->ecc.ooboffset + req->ecc.bytes - 1;
drivers/mtd/nand/ecc-sw-bch.c:	if (req->mode == MTD_OPS_RAW)
drivers/mtd/nand/ecc-sw-bch.c:	if (!req->datalen)
drivers/mtd/nand/ecc-sw-bch.c:	if (req->type == NAND_PAGE_READ)
drivers/mtd/nand/ecc-sw-bch.c:	for (i = 0, data = req->databuf.out;
drivers/mtd/nand/ecc-sw-bch.c:	return mtd_ooblayout_set_eccbytes(mtd, ecccalc, (void *)req->oobbuf.out,
drivers/mtd/nand/ecc-sw-bch.c:	u8 *data = req->databuf.in;
drivers/mtd/nand/ecc-sw-bch.c:	if (req->mode == MTD_OPS_RAW)
drivers/mtd/nand/ecc-sw-bch.c:	if (!req->datalen)
drivers/mtd/nand/ecc-sw-bch.c:	if (req->type == NAND_PAGE_WRITE) {
drivers/mtd/nand/ecc-sw-bch.c:	ret = mtd_ooblayout_get_eccbytes(mtd, ecccode, req->oobbuf.in, 0,
drivers/mtd/nand/ecc-sw-bch.c:	for (eccsteps = engine_conf->nsteps, i = 0, data = req->databuf.in;
drivers/mtd/nand/ecc-sw-hamming.c:	if (req->mode == MTD_OPS_RAW)
drivers/mtd/nand/ecc-sw-hamming.c:	if (!req->datalen)
drivers/mtd/nand/ecc-sw-hamming.c:	if (req->type == NAND_PAGE_READ)
drivers/mtd/nand/ecc-sw-hamming.c:	for (i = 0, data = req->databuf.out;
drivers/mtd/nand/ecc-sw-hamming.c:	return mtd_ooblayout_set_eccbytes(mtd, ecccalc, (void *)req->oobbuf.out,
drivers/mtd/nand/ecc-sw-hamming.c:	u8 *data = req->databuf.in;
drivers/mtd/nand/ecc-sw-hamming.c:	if (req->mode == MTD_OPS_RAW)
drivers/mtd/nand/ecc-sw-hamming.c:	if (!req->datalen)
drivers/mtd/nand/ecc-sw-hamming.c:	if (req->type == NAND_PAGE_WRITE) {
drivers/mtd/nand/ecc-sw-hamming.c:	ret = mtd_ooblayout_get_eccbytes(mtd, ecccode, req->oobbuf.in, 0,
drivers/mtd/nand/ecc-sw-hamming.c:	for (eccsteps = engine_conf->nsteps, i = 0, data = req->databuf.in;
drivers/mtd/mtd_blkdevs.c:	    get_capacity(req->rq_disk))
drivers/mtd/mtd_blkdevs.c:		buf = kmap(bio_page(req->bio)) + bio_offset(req->bio);
drivers/mtd/mtd_blkdevs.c:				kunmap(bio_page(req->bio));
drivers/mtd/mtd_blkdevs.c:		kunmap(bio_page(req->bio));
drivers/mtd/mtd_blkdevs.c:		buf = kmap(bio_page(req->bio)) + bio_offset(req->bio);
drivers/mtd/mtd_blkdevs.c:				kunmap(bio_page(req->bio));
drivers/mtd/mtd_blkdevs.c:		kunmap(bio_page(req->bio));
drivers/rapidio/devices/rio_mport_cdev.c:	struct mport_cdev_priv *priv = req->priv;
drivers/rapidio/devices/rio_mport_cdev.c:	dma_unmap_sg(req->dmach->device->dev,
drivers/rapidio/devices/rio_mport_cdev.c:		     req->sgt.sgl, req->sgt.nents, req->dir);
drivers/rapidio/devices/rio_mport_cdev.c:	sg_free_table(&req->sgt);
drivers/rapidio/devices/rio_mport_cdev.c:	if (req->page_list) {
drivers/rapidio/devices/rio_mport_cdev.c:		unpin_user_pages(req->page_list, req->nr_pages);
drivers/rapidio/devices/rio_mport_cdev.c:		kfree(req->page_list);
drivers/rapidio/devices/rio_mport_cdev.c:	if (req->map) {
drivers/rapidio/devices/rio_mport_cdev.c:		mutex_lock(&req->map->md->buf_mutex);
drivers/rapidio/devices/rio_mport_cdev.c:		kref_put(&req->map->ref, mport_release_mapping);
drivers/rapidio/devices/rio_mport_cdev.c:		mutex_unlock(&req->map->md->buf_mutex);
drivers/rapidio/devices/rio_mport_cdev.c:	struct mport_cdev_priv *priv = req->priv;
drivers/rapidio/devices/rio_mport_cdev.c:	req->status = dma_async_is_tx_complete(priv->dmach, req->cookie,
drivers/rapidio/devices/rio_mport_cdev.c:	complete(&req->req_comp);
drivers/rapidio/devices/rio_mport_cdev.c:	kref_put(&req->refcount, dma_req_free);
drivers/rapidio/devices/rio_mport_cdev.c:	priv = req->priv;
drivers/rapidio/devices/rio_mport_cdev.c:	sgt = &req->sgt;
drivers/rapidio/devices/rio_mport_cdev.c:	dir = (req->dir == DMA_FROM_DEVICE) ? DMA_DEV_TO_MEM : DMA_MEM_TO_DEV;
drivers/rapidio/devices/rio_mport_cdev.c:	req->status = DMA_IN_PROGRESS;
drivers/rapidio/devices/rio_mport_cdev.c:	kref_get(&req->refcount);
drivers/rapidio/devices/rio_mport_cdev.c:	req->cookie = cookie;
drivers/rapidio/devices/rio_mport_cdev.c:		kref_put(&req->refcount, dma_req_free);
drivers/rapidio/devices/rio_mport_cdev.c:		list_add_tail(&req->node, &priv->async_list);
drivers/rapidio/devices/rio_mport_cdev.c:	wret = wait_for_completion_interruptible_timeout(&req->req_comp, tmo);
drivers/rapidio/devices/rio_mport_cdev.c:	if (req->status != DMA_COMPLETE) {
drivers/rapidio/devices/rio_mport_cdev.c:			cookie, req->status, ret);
drivers/rapidio/devices/rio_mport_cdev.c:	kref_init(&req->refcount);
drivers/rapidio/devices/rio_mport_cdev.c:	init_completion(&req->req_comp);
drivers/rapidio/devices/rio_mport_cdev.c:	req->dir = dir;
drivers/rapidio/devices/rio_mport_cdev.c:	req->filp = filp;
drivers/rapidio/devices/rio_mport_cdev.c:	req->priv = priv;
drivers/rapidio/devices/rio_mport_cdev.c:	req->dmach = chan;
drivers/rapidio/devices/rio_mport_cdev.c:	req->sync = sync;
drivers/rapidio/devices/rio_mport_cdev.c:		ret = sg_alloc_table_from_pages(&req->sgt, page_list, nr_pages,
drivers/rapidio/devices/rio_mport_cdev.c:		req->page_list = page_list;
drivers/rapidio/devices/rio_mport_cdev.c:		req->nr_pages = nr_pages;
drivers/rapidio/devices/rio_mport_cdev.c:				req->map = map;
drivers/rapidio/devices/rio_mport_cdev.c:		if (req->map == NULL) {
drivers/rapidio/devices/rio_mport_cdev.c:		ret = sg_alloc_table(&req->sgt, 1, GFP_KERNEL);
drivers/rapidio/devices/rio_mport_cdev.c:		sg_set_buf(req->sgt.sgl,
drivers/rapidio/devices/rio_mport_cdev.c:			   req->sgt.sgl, req->sgt.nents, dir);
drivers/rapidio/devices/rio_mport_cdev.c:	if (!req->page_list) {
drivers/rapidio/devices/rio_mport_cdev.c:	kref_put(&req->refcount, dma_req_free);
drivers/rapidio/devices/rio_mport_cdev.c:		if (req->cookie == cookie) {
drivers/rapidio/devices/rio_mport_cdev.c:			list_del(&req->node);
drivers/rapidio/devices/rio_mport_cdev.c:	wret = wait_for_completion_interruptible_timeout(&req->req_comp, tmo);
drivers/rapidio/devices/rio_mport_cdev.c:		       (req->dir == DMA_FROM_DEVICE)?"READ":"WRITE");
drivers/rapidio/devices/rio_mport_cdev.c:			(req->dir == DMA_FROM_DEVICE)?"READ":"WRITE");
drivers/rapidio/devices/rio_mport_cdev.c:	if (req->status != DMA_COMPLETE) {
drivers/rapidio/devices/rio_mport_cdev.c:			(req->dir == DMA_FROM_DEVICE)?"READ":"WRITE",
drivers/rapidio/devices/rio_mport_cdev.c:			req->status);
drivers/rapidio/devices/rio_mport_cdev.c:	if (req->status != DMA_IN_PROGRESS && req->status != DMA_PAUSED)
drivers/rapidio/devices/rio_mport_cdev.c:		kref_put(&req->refcount, dma_req_free);
drivers/rapidio/devices/rio_mport_cdev.c:	list_add_tail(&req->node, &priv->async_list);
drivers/rapidio/devices/rio_mport_cdev.c:			rmcd_debug(EXIT, "free req->filp=%p cookie=%d compl=%s",
drivers/rapidio/devices/rio_mport_cdev.c:				   req->filp, req->cookie,
drivers/rapidio/devices/rio_mport_cdev.c:				   completion_done(&req->req_comp)?"yes":"no");
drivers/rapidio/devices/rio_mport_cdev.c:			list_del(&req->node);
drivers/rapidio/devices/rio_mport_cdev.c:			kref_put(&req->refcount, dma_req_free);
drivers/rapidio/rio_cm.c:	req->destid = ntohl(hh->bhdr.src_id);
drivers/rapidio/rio_cm.c:	req->chan = ntohs(hh->src_ch);
drivers/rapidio/rio_cm.c:	req->cmdev = cm;
drivers/rapidio/rio_cm.c:	list_add_tail(&req->node, &ch->accept_queue);
drivers/rapidio/rio_cm.c:			list_del(&req->node);
drivers/rapidio/rio_cm.c:			cm->tx_buf[cm->tx_slot] = req->buffer;
drivers/rapidio/rio_cm.c:			rc = rio_add_outb_message(cm->mport, req->rdev, cmbox,
drivers/rapidio/rio_cm.c:						  req->buffer, req->len);
drivers/rapidio/rio_cm.c:			kfree(req->buffer);
drivers/rapidio/rio_cm.c:	treq->rdev = rdev;
drivers/rapidio/rio_cm.c:	treq->buffer = buffer;
drivers/rapidio/rio_cm.c:	treq->len = len;
drivers/rapidio/rio_cm.c:	list_add_tail(&treq->node, &cm->tx_reqs);
drivers/rapidio/rio_cm.c:	list_del(&req->node);
drivers/rapidio/rio_cm.c:	new_ch->rem_destid = req->destid;
drivers/rapidio/rio_cm.c:	new_ch->rem_channel = req->chan;
drivers/xen/pvcalls-back.c:	if (req->u.socket.domain != AF_INET ||
drivers/xen/pvcalls-back.c:	    req->u.socket.type != SOCK_STREAM ||
drivers/xen/pvcalls-back.c:	    (req->u.socket.protocol != IPPROTO_IP &&
drivers/xen/pvcalls-back.c:	     req->u.socket.protocol != AF_INET))
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.socket.id = req->u.socket.id;
drivers/xen/pvcalls-back.c:	struct sockaddr *sa = (struct sockaddr *)&req->u.connect.addr;
drivers/xen/pvcalls-back.c:	if (req->u.connect.len < sizeof(sa->sa_family) ||
drivers/xen/pvcalls-back.c:	    req->u.connect.len > sizeof(req->u.connect.addr) ||
drivers/xen/pvcalls-back.c:	ret = inet_stream_connect(sock, sa, req->u.connect.len, 0);
drivers/xen/pvcalls-back.c:					req->u.connect.id,
drivers/xen/pvcalls-back.c:					req->u.connect.ref,
drivers/xen/pvcalls-back.c:					req->u.connect.evtchn,
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.connect.id = req->u.connect.id;
drivers/xen/pvcalls-back.c:		if (map->id == req->u.release.id) {
drivers/xen/pvcalls-back.c:				    req->u.release.id);
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->u.release.id = req->u.release.id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	if (req->cmd != PVCALLS_ACCEPT) {
drivers/xen/pvcalls-back.c:					req->u.accept.id_new,
drivers/xen/pvcalls-back.c:					req->u.accept.ref,
drivers/xen/pvcalls-back.c:					req->u.accept.evtchn,
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.accept.id = req->u.accept.id;
drivers/xen/pvcalls-back.c:	ret = inet_bind(map->sock, (struct sockaddr *)&req->u.bind.addr,
drivers/xen/pvcalls-back.c:			req->u.bind.len);
drivers/xen/pvcalls-back.c:	map->id = req->u.bind.id;
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.bind.id = req->u.bind.id;
drivers/xen/pvcalls-back.c:	map = radix_tree_lookup(&fedata->socketpass_mappings, req->u.listen.id);
drivers/xen/pvcalls-back.c:	ret = inet_listen(map->sock, req->u.listen.backlog);
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.listen.id = req->u.listen.id;
drivers/xen/pvcalls-back.c:		req->u.accept.id);
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.accept.id = req->u.accept.id;
drivers/xen/pvcalls-back.c:				    req->u.poll.id);
drivers/xen/pvcalls-back.c:	rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:	rsp->cmd = req->cmd;
drivers/xen/pvcalls-back.c:	rsp->u.poll.id = req->u.poll.id;
drivers/xen/pvcalls-back.c:	switch (req->cmd) {
drivers/xen/pvcalls-back.c:		rsp->req_id = req->req_id;
drivers/xen/pvcalls-back.c:		rsp->cmd = req->cmd;
drivers/xen/xen-scsiback.c:	return vaddr_page(req->pages[seg]);
drivers/xen/xen-scsiback.c:	struct scsiback_tpg *tpg = pending_req->v2p->tpg;
drivers/xen/xen-scsiback.c:	       tpg->tport->tport_name, pending_req->v2p->lun,
drivers/xen/xen-scsiback.c:	       pending_req->cmnd[0], status_byte(errors), msg_byte(errors),
drivers/xen/xen-scsiback.c:	kfree(req->sgl);
drivers/xen/xen-scsiback.c:	req->sgl = NULL;
drivers/xen/xen-scsiback.c:	req->n_sg = 0;
drivers/xen/xen-scsiback.c:	if (!req->n_grants)
drivers/xen/xen-scsiback.c:	for (i = 0; i < req->n_grants; i++) {
drivers/xen/xen-scsiback.c:		handle = req->grant_handles[i];
drivers/xen/xen-scsiback.c:		req->grant_handles[i] = SCSIBACK_INVALID_HANDLE;
drivers/xen/xen-scsiback.c:		pages[invcount] = req->pages[i];
drivers/xen/xen-scsiback.c:	gnttab_page_cache_put(&req->info->free_pages, req->pages,
drivers/xen/xen-scsiback.c:			      req->n_grants);
drivers/xen/xen-scsiback.c:	req->n_grants = 0;
drivers/xen/xen-scsiback.c:	scsiback_send_response(pending_req->info, sense_buffer, result,
drivers/xen/xen-scsiback.c:			       resid, pending_req->rqid);
drivers/xen/xen-scsiback.c:	if (pending_req->v2p)
drivers/xen/xen-scsiback.c:		kref_put(&pending_req->v2p->kref,
drivers/xen/xen-scsiback.c:	struct vscsibk_info *info = pending_req->info;
drivers/xen/xen-scsiback.c:	sense_buffer = pending_req->sense_buffer;
drivers/xen/xen-scsiback.c:	resid        = pending_req->se_cmd.residual_count;
drivers/xen/xen-scsiback.c:	errors       = pending_req->result;
drivers/xen/xen-scsiback.c:	target_put_sess_cmd(&pending_req->se_cmd);
drivers/xen/xen-scsiback.c:	struct se_cmd *se_cmd = &pending_req->se_cmd;
drivers/xen/xen-scsiback.c:	struct se_session *sess = pending_req->v2p->tpg->tpg_nexus->tvn_se_sess;
drivers/xen/xen-scsiback.c:	scsiback_get(pending_req->info);
drivers/xen/xen-scsiback.c:	se_cmd->tag = pending_req->rqid;
drivers/xen/xen-scsiback.c:	rc = target_submit_cmd_map_sgls(se_cmd, sess, pending_req->cmnd,
drivers/xen/xen-scsiback.c:			pending_req->sense_buffer, pending_req->v2p->lun,
drivers/xen/xen-scsiback.c:			pending_req->data_len, 0,
drivers/xen/xen-scsiback.c:			pending_req->sc_data_direction, TARGET_SCF_ACK_KREF,
drivers/xen/xen-scsiback.c:			pending_req->sgl, pending_req->n_sg,
drivers/xen/xen-scsiback.c:	struct vscsibk_info *info = pending_req->info;
drivers/xen/xen-scsiback.c:		pending_req->n_grants += mapcount;
drivers/xen/xen-scsiback.c:	pending_req->n_grants += mapcount;
drivers/xen/xen-scsiback.c:	unsigned int nr_segments = (unsigned int)ring_req->nr_segments;
drivers/xen/xen-scsiback.c:	pending_req->n_sg = 0;
drivers/xen/xen-scsiback.c:	pending_req->n_grants = 0;
drivers/xen/xen-scsiback.c:	pending_req->data_len = 0;
drivers/xen/xen-scsiback.c:			ring_req->nr_segments);
drivers/xen/xen-scsiback.c:	if (ring_req->nr_segments & VSCSIIF_SG_GRANT) {
drivers/xen/xen-scsiback.c:		err = scsiback_gnttab_data_map_list(pending_req, ring_req->seg,
drivers/xen/xen-scsiback.c:			pending_req->pages, pending_req->grant_handles,
drivers/xen/xen-scsiback.c:			n_segs = ring_req->seg[i].length /
drivers/xen/xen-scsiback.c:			if ((unsigned)ring_req->seg[i].offset +
drivers/xen/xen-scsiback.c:			    (unsigned)ring_req->seg[i].length > PAGE_SIZE ||
drivers/xen/xen-scsiback.c:			    ring_req->seg[i].length)
drivers/xen/xen-scsiback.c:	pending_req->sgl = kmalloc_array(nr_segments,
drivers/xen/xen-scsiback.c:	if (!pending_req->sgl)
drivers/xen/xen-scsiback.c:	sg_init_table(pending_req->sgl, nr_segments);
drivers/xen/xen-scsiback.c:	pending_req->n_sg = nr_segments;
drivers/xen/xen-scsiback.c:	if (pending_req->sc_data_direction == DMA_TO_DEVICE)
drivers/xen/xen-scsiback.c:	pg = pending_req->pages + nr_sgl;
drivers/xen/xen-scsiback.c:	grant = pending_req->grant_handles + nr_sgl;
drivers/xen/xen-scsiback.c:		seg = ring_req->seg;
drivers/xen/xen-scsiback.c:			      vaddr(pending_req, i) + ring_req->seg[i].offset);
drivers/xen/xen-scsiback.c:			n_segs = ring_req->seg[i].length /
drivers/xen/xen-scsiback.c:		end_seg = vaddr(pending_req, 0) + ring_req->seg[0].offset;
drivers/xen/xen-scsiback.c:		end_seg += ring_req->seg[0].length;
drivers/xen/xen-scsiback.c:		pg = pending_req->pages + nr_sgl;
drivers/xen/xen-scsiback.c:	for_each_sg(pending_req->sgl, sg, nr_segments, i) {
drivers/xen/xen-scsiback.c:		pending_req->data_len += seg->length;
drivers/xen/xen-scsiback.c:				  ring_req->seg[i_seg].offset;
drivers/xen/xen-scsiback.c:			end_seg += ring_req->seg[i_seg].length;
drivers/xen/xen-scsiback.c:	struct scsiback_tpg *tpg = pending_req->v2p->tpg;
drivers/xen/xen-scsiback.c:	struct se_cmd *se_cmd = &pending_req->se_cmd;
drivers/xen/xen-scsiback.c:	u64 unpacked_lun = pending_req->v2p->lun;
drivers/xen/xen-scsiback.c:	init_completion(&pending_req->tmr_done);
drivers/xen/xen-scsiback.c:	rc = target_submit_tmr(&pending_req->se_cmd, nexus->tvn_se_sess,
drivers/xen/xen-scsiback.c:			       &pending_req->sense_buffer[0],
drivers/xen/xen-scsiback.c:	wait_for_completion(&pending_req->tmr_done);
drivers/xen/xen-scsiback.c:	err = (se_cmd->se_tmr_req->response == TMR_FUNCTION_COMPLETE) ?
drivers/xen/xen-scsiback.c:	transport_generic_free_cmd(&pending_req->se_cmd, 0);
drivers/xen/xen-scsiback.c:	req->se_cmd.map_tag = tag;
drivers/xen/xen-scsiback.c:	req->se_cmd.map_cpu = cpu;
drivers/xen/xen-scsiback.c:		req->grant_handles[i] = SCSIBACK_INVALID_HANDLE;
drivers/xen/xen-scsiback.c:	if ((ring_req->sc_data_direction != DMA_BIDIRECTIONAL) &&
drivers/xen/xen-scsiback.c:		(ring_req->sc_data_direction != DMA_TO_DEVICE) &&
drivers/xen/xen-scsiback.c:		(ring_req->sc_data_direction != DMA_FROM_DEVICE) &&
drivers/xen/xen-scsiback.c:		(ring_req->sc_data_direction != DMA_NONE)) {
drivers/xen/xen-scsiback.c:			ring_req->sc_data_direction);
drivers/xen/xen-scsiback.c:	if (ring_req->cmd_len > VSCSIIF_MAX_COMMAND_SIZE) {
drivers/xen/xen-scsiback.c:			ring_req->cmd_len);
drivers/xen/xen-scsiback.c:	vir.chn = ring_req->channel;
drivers/xen/xen-scsiback.c:	vir.tgt = ring_req->id;
drivers/xen/xen-scsiback.c:	vir.lun = ring_req->lun;
drivers/xen/xen-scsiback.c:	pending_req->rqid = ring_req->rqid;
drivers/xen/xen-scsiback.c:	pending_req->info = info;
drivers/xen/xen-scsiback.c:	pending_req->v2p = v2p;
drivers/xen/xen-scsiback.c:	pending_req->sc_data_direction = ring_req->sc_data_direction;
drivers/xen/xen-scsiback.c:	pending_req->cmd_len = ring_req->cmd_len;
drivers/xen/xen-scsiback.c:	memcpy(pending_req->cmnd, ring_req->cmnd, pending_req->cmd_len);
drivers/xen/xen-scsiback.c:				transport_generic_free_cmd(&pending_req->se_cmd, 0);
drivers/xen/xen-scsiback.c:			transport_generic_free_cmd(&pending_req->se_cmd, 0);
drivers/xen/xen-scsiback.c:	pending_req->result = SAM_STAT_GOOD;
drivers/xen/xen-scsiback.c:		pending_req->result = (DRIVER_SENSE << 24) |
drivers/xen/xen-scsiback.c:		pending_req->result = se_cmd->scsi_status;
drivers/xen/xen-scsiback.c:	complete(&pending_req->tmr_done);
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_SOCKET;
drivers/xen/pvcalls-front.c:	req->u.socket.id = (uintptr_t) map;
drivers/xen/pvcalls-front.c:	req->u.socket.domain = AF_INET;
drivers/xen/pvcalls-front.c:	req->u.socket.type = SOCK_STREAM;
drivers/xen/pvcalls-front.c:	req->u.socket.protocol = IPPROTO_IP;
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_CONNECT;
drivers/xen/pvcalls-front.c:	req->u.connect.id = (uintptr_t)map;
drivers/xen/pvcalls-front.c:	req->u.connect.len = addr_len;
drivers/xen/pvcalls-front.c:	req->u.connect.flags = flags;
drivers/xen/pvcalls-front.c:	req->u.connect.ref = map->active.ref;
drivers/xen/pvcalls-front.c:	req->u.connect.evtchn = evtchn;
drivers/xen/pvcalls-front.c:	memcpy(req->u.connect.addr, addr, sizeof(*addr));
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_BIND;
drivers/xen/pvcalls-front.c:	req->u.bind.id = (uintptr_t)map;
drivers/xen/pvcalls-front.c:	memcpy(req->u.bind.addr, addr, sizeof(*addr));
drivers/xen/pvcalls-front.c:	req->u.bind.len = addr_len;
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_LISTEN;
drivers/xen/pvcalls-front.c:	req->u.listen.id = (uintptr_t) map;
drivers/xen/pvcalls-front.c:	req->u.listen.backlog = backlog;
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_ACCEPT;
drivers/xen/pvcalls-front.c:	req->u.accept.id = (uintptr_t) map;
drivers/xen/pvcalls-front.c:	req->u.accept.ref = map2->active.ref;
drivers/xen/pvcalls-front.c:	req->u.accept.id_new = (uintptr_t) map2;
drivers/xen/pvcalls-front.c:	req->u.accept.evtchn = evtchn;
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_POLL;
drivers/xen/pvcalls-front.c:	req->u.poll.id = (uintptr_t) map;
drivers/xen/pvcalls-front.c:	req->req_id = req_id;
drivers/xen/pvcalls-front.c:	req->cmd = PVCALLS_RELEASE;
drivers/xen/pvcalls-front.c:	req->u.release.id = (uintptr_t)map;
drivers/xen/xenbus/xenbus_xs.c:	req->type = req->msg.type;
drivers/xen/xenbus/xenbus_xs.c:	if (req->type == XS_TRANSACTION_START && !req->user_req)
drivers/xen/xenbus/xenbus_xs.c:	if ((req->type == XS_TRANSACTION_START && req->msg.type == XS_ERROR) ||
drivers/xen/xenbus/xenbus_xs.c:	    (req->type == XS_TRANSACTION_END && !req->user_req &&
drivers/xen/xenbus/xenbus_xs.c:	     !WARN_ON_ONCE(req->msg.type == XS_ERROR &&
drivers/xen/xenbus/xenbus_xs.c:			   !strcmp(req->body, "ENOENT"))))
drivers/xen/xenbus/xenbus_xs.c:	if (req->state == xb_req_state_got_reply || !xenbus_ok()) {
drivers/xen/xenbus/xenbus_xs.c:		/* read req->state before all other fields */
drivers/xen/xenbus/xenbus_xs.c:	/* Make sure to reread req->state each time. */
drivers/xen/xenbus/xenbus_xs.c:		wait_event(req->wq, test_reply(req));
drivers/xen/xenbus/xenbus_xs.c:		if (req->err)
drivers/xen/xenbus/xenbus_xs.c:			return ERR_PTR(req->err);
drivers/xen/xenbus/xenbus_xs.c:	} while (req->state != xb_req_state_got_reply);
drivers/xen/xenbus/xenbus_xs.c:	return req->body;
drivers/xen/xenbus/xenbus_xs.c:	req->msg = *msg;
drivers/xen/xenbus/xenbus_xs.c:	req->err = 0;
drivers/xen/xenbus/xenbus_xs.c:	req->state = xb_req_state_queued;
drivers/xen/xenbus/xenbus_xs.c:	init_waitqueue_head(&req->wq);
drivers/xen/xenbus/xenbus_xs.c:	req->caller_req_id = req->msg.req_id;
drivers/xen/xenbus/xenbus_xs.c:	req->msg.req_id = xs_request_enter(req);
drivers/xen/xenbus/xenbus_xs.c:	list_add_tail(&req->list, &xb_write_list);
drivers/xen/xenbus/xenbus_xs.c:	msg->type = req->msg.type;
drivers/xen/xenbus/xenbus_xs.c:	msg->len = req->msg.len;
drivers/xen/xenbus/xenbus_xs.c:	if (req->state == xb_req_state_queued ||
drivers/xen/xenbus/xenbus_xs.c:	    req->state == xb_req_state_wait_reply)
drivers/xen/xenbus/xenbus_xs.c:		req->state = xb_req_state_aborted;
drivers/xen/xenbus/xenbus_xs.c:	wake_up(&req->wq);
drivers/xen/xenbus/xenbus_xs.c:	req->vec = vec;
drivers/xen/xenbus/xenbus_xs.c:	req->num_vecs = 1;
drivers/xen/xenbus/xenbus_xs.c:	req->cb = xenbus_dev_queue_reply;
drivers/xen/xenbus/xenbus_xs.c:	req->par = par;
drivers/xen/xenbus/xenbus_xs.c:	req->user_req = true;
drivers/xen/xenbus/xenbus_xs.c:	req->vec = iovec;
drivers/xen/xenbus/xenbus_xs.c:	req->num_vecs = num_vecs;
drivers/xen/xenbus/xenbus_xs.c:	req->cb = xs_wake_up;
drivers/xen/xenbus/xenbus_xs.c:	req->user_req = false;
drivers/xen/xenbus/xenbus_xs.c:		wake_up(&req->wq);
drivers/xen/xenbus/xenbus_xs.c:		wake_up(&req->wq);
drivers/xen/xenbus/xenbus_comms.c:			if (req->msg.req_id == state.msg.req_id) {
drivers/xen/xenbus/xenbus_comms.c:				list_del(&req->list);
drivers/xen/xenbus/xenbus_comms.c:		if (req->state == xb_req_state_wait_reply) {
drivers/xen/xenbus/xenbus_comms.c:			req->msg.req_id = req->caller_req_id;
drivers/xen/xenbus/xenbus_comms.c:			req->msg.type = state.msg.type;
drivers/xen/xenbus/xenbus_comms.c:			req->msg.len = state.msg.len;
drivers/xen/xenbus/xenbus_comms.c:			req->body = state.body;
drivers/xen/xenbus/xenbus_comms.c:			req->state = xb_req_state_got_reply;
drivers/xen/xenbus/xenbus_comms.c:			req->cb(req);
drivers/xen/xenbus/xenbus_comms.c:	if (state.req->state == xb_req_state_aborted)
drivers/xen/xenbus/xenbus_comms.c:	while (state.idx < state.req->num_vecs) {
drivers/xen/xenbus/xenbus_comms.c:			base = &state.req->msg;
drivers/xen/xenbus/xenbus_comms.c:			len = sizeof(state.req->msg);
drivers/xen/xenbus/xenbus_comms.c:			base = state.req->vec[state.idx].iov_base;
drivers/xen/xenbus/xenbus_comms.c:			len = state.req->vec[state.idx].iov_len;
drivers/xen/xenbus/xenbus_comms.c:	list_del(&state.req->list);
drivers/xen/xenbus/xenbus_comms.c:	state.req->state = xb_req_state_wait_reply;
drivers/xen/xenbus/xenbus_comms.c:	list_add_tail(&state.req->list, &xs_reply_list);
drivers/xen/xenbus/xenbus_comms.c:	state.req->msg.type = XS_ERROR;
drivers/xen/xenbus/xenbus_comms.c:	state.req->err = err;
drivers/xen/xenbus/xenbus_comms.c:	list_del(&state.req->list);
drivers/xen/xenbus/xenbus_comms.c:	if (state.req->state == xb_req_state_aborted)
drivers/xen/xenbus/xenbus_comms.c:		state.req->state = xb_req_state_got_reply;
drivers/xen/xenbus/xenbus_comms.c:		wake_up(&state.req->wq);
drivers/xen/xenbus/xenbus_dev_frontend.c:	struct xenbus_file_priv *u = req->par;
drivers/xen/xenbus/xenbus_dev_frontend.c:	if (req->type == XS_TRANSACTION_START) {
drivers/xen/xenbus/xenbus_dev_frontend.c:		if (req->msg.type == XS_ERROR) {
drivers/xen/xenbus/xenbus_dev_frontend.c:			rc = kstrtou32(req->body, 10, &trans->handle.id);
drivers/xen/xenbus/xenbus_dev_frontend.c:	} else if (req->type == XS_TRANSACTION_END) {
drivers/xen/xenbus/xenbus_dev_frontend.c:		trans = xenbus_get_transaction(u, req->msg.tx_id);
drivers/xen/xenbus/xenbus_dev_frontend.c:	rc = queue_reply(&staging_q, &req->msg, sizeof(req->msg));
drivers/xen/xenbus/xenbus_dev_frontend.c:		rc = queue_reply(&staging_q, req->body, req->msg.len);
drivers/xen/xenbus/xenbus_dev_frontend.c:	kfree(req->body);
drivers/vhost/scsi.c:	tmf->scsi_resp = se_cmd->se_tmr_req->response;
drivers/hv/hv_balloon.c:	union dm_mem_page_range *range_array = req->range_array;
drivers/hv/hv_balloon.c:	int range_count = req->range_count;
drivers/hv/hv_balloon.c:	if (req->more_pages == 1)
drivers/scsi/scsi_error.c:	req->rq_flags |= RQF_QUIET;
drivers/scsi/scsi_error.c:	req->timeout = 10 * HZ;
drivers/scsi/libfc/fc_lport.c:		fmt = req->rnid_fmt;
drivers/scsi/pm8001/pm80xx_hwi.c: * pm80xx_hw_event_ack_req- For PM8001,some events need to acknowage to FW.
drivers/scsi/pm8001/pm80xx_hwi.c:	length = sg_req->length;
drivers/scsi/pm8001/pm80xx_hwi.c:	pm8001_dbg(pm8001_ha, IO, "SMP Frame Length %d\n", sg_req->length);
drivers/scsi/pm8001/pm8001_hwi.c: * pm8001_hw_event_ack_req- For PM8001,some events need to acknowage to FW.
drivers/scsi/isci/host.c:	if (test_bit(IREQ_ACTIVE, &ireq->flags) &&
drivers/scsi/isci/host.c:	    ireq->io_tag != SCI_CONTROLLER_INVALID_IO_TAG &&
drivers/scsi/isci/host.c:	    ISCI_TAG_SEQ(ireq->io_tag) == ihost->io_request_sequence[index])
drivers/scsi/isci/host.c:	if (!test_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags) &&
drivers/scsi/isci/host.c:		if (test_bit(IREQ_COMPLETE_IN_TARGET, &ireq->flags)) {
drivers/scsi/isci/host.c:	if (test_and_clear_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags))
drivers/scsi/isci/host.c:	if (!test_bit(IREQ_NO_AUTO_FREE_TAG, &ireq->flags))
drivers/scsi/isci/host.c:		isci_free_tag(ihost, ireq->io_tag);
drivers/scsi/isci/host.c:		ireq->tc = &ihost->task_context_table[i];
drivers/scsi/isci/host.c:		ireq->owning_controller = ihost;
drivers/scsi/isci/host.c:		ireq->request_daddr = dma;
drivers/scsi/isci/host.c:		ireq->isci_host = ihost;
drivers/scsi/isci/host.c:		if (test_bit(IREQ_ACTIVE, &ireq->flags)) {
drivers/scsi/isci/host.c:	set_bit(IREQ_ACTIVE, &ireq->flags);
drivers/scsi/isci/host.c:	sci_controller_post_request(ihost, ireq->post_context);
drivers/scsi/isci/host.c:		__func__, status, ireq, ireq->flags);
drivers/scsi/isci/host.c:	    !test_bit(IREQ_PENDING_ABORT, &ireq->flags) &&
drivers/scsi/isci/host.c:	    !test_and_set_bit(IREQ_TC_ABORT_POSTED, &ireq->flags)) {
drivers/scsi/isci/host.c:			ihost, ireq->post_context |
drivers/scsi/isci/host.c:		clear_bit(IREQ_ACTIVE, &ireq->flags);
drivers/scsi/isci/host.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/host.c:	set_bit(IREQ_ACTIVE, &ireq->flags);
drivers/scsi/isci/host.c:	sci_controller_post_request(ihost, ireq->post_context);
drivers/scsi/isci/host.c:		set_bit(IREQ_ACTIVE, &ireq->flags);
drivers/scsi/isci/host.c:		set_bit(IREQ_ACTIVE, &ireq->flags);
drivers/scsi/isci/host.c:		sci_controller_post_request(ihost, ireq->post_context);
drivers/scsi/isci/request.h:	return ireq->request_daddr + (requested_addr - base_addr);
drivers/scsi/isci/request.c:		return &ireq->tc->sgl_pair_ab;
drivers/scsi/isci/request.c:		return &ireq->tc->sgl_pair_cd;
drivers/scsi/isci/request.c:		return &ireq->sg_table[idx - 2];
drivers/scsi/isci/request.c:		offset = (void *) &ireq->tc->sgl_pair_ab -
drivers/scsi/isci/request.c:		offset = (void *) &ireq->tc->sgl_pair_cd -
drivers/scsi/isci/request.c:	return sci_io_request_get_dma_addr(ireq, &ireq->sg_table[idx - 2]);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->isci_host;
drivers/scsi/isci/request.c:		ireq->zero_scatter_daddr = dma_addr;
drivers/scsi/isci/request.c:	cmd_iu = &ireq->ssp.cmd;
drivers/scsi/isci/request.c:	task_iu = &ireq->ssp.tmf;
drivers/scsi/isci/request.c:		(test_bit(IREQ_TMF, &ireq->flags)) ?
drivers/scsi/isci/request.c:	idev = ireq->target_device;
drivers/scsi/isci/request.c:	/* task_context->type.ssp.tag = ireq->io_tag; */
drivers/scsi/isci/request.c:	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
drivers/scsi/isci/request.c:			      ISCI_TAG_TCI(ireq->io_tag));
drivers/scsi/isci/request.c:	dma_addr = sci_io_request_get_dma_addr(ireq, &ireq->ssp.cmd);
drivers/scsi/isci/request.c:	dma_addr = sci_io_request_get_dma_addr(ireq, &ireq->ssp.rsp);
drivers/scsi/isci/request.c:	struct scu_task_context *tc = ireq->tc;
drivers/scsi/isci/request.c:	struct scsi_cmnd *scmd = ireq->ttype_ptr.io_task_ptr->uldd_task;
drivers/scsi/isci/request.c:	struct scu_task_context *tc = ireq->tc;
drivers/scsi/isci/request.c:	struct scsi_cmnd *scmd = ireq->ttype_ptr.io_task_ptr->uldd_task;
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	struct sas_task *sas_task = ireq->ttype_ptr.io_task_ptr;
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	idev = ireq->target_device;
drivers/scsi/isci/request.c:	task_context->type.words[0] = *(u32 *)&ireq->stp.cmd;
drivers/scsi/isci/request.c:	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
drivers/scsi/isci/request.c:			      ISCI_TAG_TCI(ireq->io_tag));
drivers/scsi/isci/request.c:						((char *) &ireq->stp.cmd) +
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	struct isci_stp_request *stp_req = &ireq->stp.req;
drivers/scsi/isci/request.c:	stp_req->status = 0;
drivers/scsi/isci/request.c:	stp_req->sgl.offset = 0;
drivers/scsi/isci/request.c:	stp_req->sgl.set = SCU_SGL_ELEMENT_PAIR_A;
drivers/scsi/isci/request.c:		stp_req->sgl.index = 0;
drivers/scsi/isci/request.c:		stp_req->sgl.index = -1;
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	struct host_to_dev_fis *h2d_fis = &ireq->stp.cmd;
drivers/scsi/isci/request.c:	ireq->stp.rsp.fis_type = 0;
drivers/scsi/isci/request.c:	struct domain_device *dev = ireq->target_device->domain_dev;
drivers/scsi/isci/request.c:	if (test_bit(IREQ_TMF, &ireq->flags)) {
drivers/scsi/isci/request.c:		dev_err(&ireq->owning_controller->pdev->dev,
drivers/scsi/isci/request.c:		dev_err(&ireq->owning_controller->pdev->dev,
drivers/scsi/isci/request.c:	ireq->protocol = SAS_PROTOCOL_SSP;
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
drivers/scsi/isci/request.c:	ireq->protocol = SAS_PROTOCOL_STP;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:				((sizeof(struct scu_task_context)) * ISCI_TAG_TCI(ireq->io_tag)));
drivers/scsi/isci/request.c:	struct scu_task_context *tc = ireq->tc;
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:	tc->task_index = ISCI_TAG_TCI(ireq->io_tag);
drivers/scsi/isci/request.c:		tc->type.ssp.tag = ireq->io_tag;
drivers/scsi/isci/request.c:		 * tc->type.stp.ncq_tag = ireq->ncq_tag;
drivers/scsi/isci/request.c:	ireq->post_context |= ISCI_TAG_TCI(ireq->io_tag);
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_STARTED);
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:		set_bit(IREQ_TC_ABORT_POSTED, &ireq->flags);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_TASK_ABORT;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_IO_TERMINATED;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_ABORTING);
drivers/scsi/isci/request.c:		if (!isci_remote_device_is_safe_to_abort(ireq->target_device))
drivers/scsi/isci/request.c:			set_bit(IREQ_PENDING_ABORT, &ireq->flags);
drivers/scsi/isci/request.c:			clear_bit(IREQ_PENDING_ABORT, &ireq->flags);
drivers/scsi/isci/request.c:		dev_warn(&ireq->owning_controller->pdev->dev,
drivers/scsi/isci/request.c:			 "state %d\n", __func__, ireq->sm.current_state_id);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:	if (ireq->saved_rx_frame_index != SCU_INVALID_FRAME_INDEX)
drivers/scsi/isci/request.c:						  ireq->saved_rx_frame_index);
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_FINAL);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
drivers/scsi/isci/request.c:	ssp_response = &ireq->ssp.rsp;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		struct ssp_response_iu *resp = &ireq->ssp.rsp;
drivers/scsi/isci/request.c:		sci_swab32_cpy(&ireq->ssp.rsp,
drivers/scsi/isci/request.c:			       &ireq->ssp.rsp,
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_SUCCESS_IO_DONE_EARLY;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:		sci_swab32_cpy(&ireq->ssp.rsp,
drivers/scsi/isci/request.c:			       &ireq->ssp.rsp,
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:		resp_iu = &ireq->ssp.rsp;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		if (ireq->protocol == SAS_PROTOCOL_STP) {
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_GET_COMPLETION_TL_STATUS(completion_code) >>
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_TASK_ABORT;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_IO_TERMINATED;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
drivers/scsi/isci/request.c:		dev_warn(&ireq->owning_controller->pdev->dev,
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_TASK_WAIT_TC_RESP);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_SMP_RESP_TO_ERR;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_RETRY_REQUIRED;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct isci_stp_pio_sgl *pio_sgl = &stp_req->sgl;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_STP_NON_DATA_WAIT_D2H);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct isci_stp_request *stp_req = &ireq->stp.req;
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	sgl_pair = to_sgl_element_pair(ireq, stp_req->sgl.index);
drivers/scsi/isci/request.c:	if (stp_req->sgl.set == SCU_SGL_ELEMENT_PAIR_A)
drivers/scsi/isci/request.c:	struct isci_stp_request *stp_req = &ireq->stp.req;
drivers/scsi/isci/request.c:	offset = stp_req->sgl.offset;
drivers/scsi/isci/request.c:	sgl_pair = to_sgl_element_pair(ireq, stp_req->sgl.index);
drivers/scsi/isci/request.c:	if (stp_req->sgl.set == SCU_SGL_ELEMENT_PAIR_A) {
drivers/scsi/isci/request.c:	if (stp_req->pio_len == 0)
drivers/scsi/isci/request.c:	if (stp_req->pio_len >= len) {
drivers/scsi/isci/request.c:		stp_req->pio_len -= len;
drivers/scsi/isci/request.c:	} else if (stp_req->pio_len < len) {
drivers/scsi/isci/request.c:		sci_stp_request_pio_data_out_trasmit_data_frame(ireq, stp_req->pio_len);
drivers/scsi/isci/request.c:		offset += stp_req->pio_len;
drivers/scsi/isci/request.c:		sgl->address_lower += stp_req->pio_len;
drivers/scsi/isci/request.c:		stp_req->pio_len = 0;
drivers/scsi/isci/request.c:	stp_req->sgl.offset = offset;
drivers/scsi/isci/request.c:	if (stp_req->pio_len < SCU_MAX_FRAME_BUFFER_SIZE) {
drivers/scsi/isci/request.c:			stp_req, data_buffer, stp_req->pio_len);
drivers/scsi/isci/request.c:			stp_req->pio_len = 0;
drivers/scsi/isci/request.c:			stp_req->pio_len -= SCU_MAX_FRAME_BUFFER_SIZE;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct isci_stp_request *stp_req = &ireq->stp.req;
drivers/scsi/isci/request.c:		if (stp_req->pio_len != 0) {
drivers/scsi/isci/request.c:				if (stp_req->pio_len == 0)
drivers/scsi/isci/request.c:		} else if (stp_req->pio_len == 0) {
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:		sci_controller_copy_sata_response(&ireq->stp.rsp,
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:		dev_err(&ireq->isci_host->pdev->dev,
drivers/scsi/isci/request.c:	sci_controller_copy_sata_response(&ireq->stp.rsp,
drivers/scsi/isci/request.c:		if (ireq->stp.rsp.status & ATA_ERR)
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:		ireq->sci_status = status;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct ata_device *dev = sas_to_ata_dev(ireq->target_device->domain_dev);
drivers/scsi/isci/request.c:	void *atapi_cdb = ireq->ttype_ptr.io_task_ptr->ata_task.atapi_packet;
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	memset(&ireq->stp.cmd, 0, sizeof(struct host_to_dev_fis));
drivers/scsi/isci/request.c:	memcpy(((u8 *)&ireq->stp.cmd + sizeof(u32)), atapi_cdb, ATAPI_CDB_LEN);
drivers/scsi/isci/request.c:	struct ata_device *dev = sas_to_ata_dev(ireq->target_device->domain_dev);
drivers/scsi/isci/request.c:	struct scu_task_context *task_context = ireq->tc;
drivers/scsi/isci/request.c:	memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
drivers/scsi/isci/request.c:	memcpy(&ireq->stp.cmd.lbal, task->ata_task.atapi_packet, cdb_len);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	struct isci_stp_request *stp_req = &ireq->stp.req;
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:			sci_swab32_cpy(&ireq->ssp.rsp, resp_iu, word_cnt);
drivers/scsi/isci/request.c:			resp_iu = &ireq->ssp.rsp;
drivers/scsi/isci/request.c:				ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:				ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:				ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:				ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_SMP_WAIT_TC_COMP);
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_SMP_FRM_TYPE_ERR;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			sci_controller_copy_sata_response(&ireq->stp.rsp,
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_UNEXP_FIS;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_PROTOCOL_VIOLATION;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			stp_req->pio_len = frame_buffer[3] & 0xffff;
drivers/scsi/isci/request.c:			stp_req->status = (frame_buffer[2] >> 24) & 0xff;
drivers/scsi/isci/request.c:			sci_controller_copy_sata_response(&ireq->stp.rsp,
drivers/scsi/isci/request.c:			ireq->stp.rsp.status = stp_req->status;
drivers/scsi/isci/request.c:				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_IN);
drivers/scsi/isci/request.c:				sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_DATA_OUT);
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
drivers/scsi/isci/request.c:			sci_controller_copy_sata_response(&ireq->stp.rsp,
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_REQUIRES_SCSI_ABORT;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		if (stp_req->sgl.index < 0) {
drivers/scsi/isci/request.c:			ireq->saved_rx_frame_index = frame_index;
drivers/scsi/isci/request.c:			stp_req->pio_len = 0;
drivers/scsi/isci/request.c:		if (status != SCI_SUCCESS || stp_req->pio_len != 0)
drivers/scsi/isci/request.c:		if ((stp_req->status & ATA_BUSY) == 0) {
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_STP_PIO_WAIT_FRAME);
drivers/scsi/isci/request.c:		ireq->target_device->working_request = ireq;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_TC_COMP);
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_D2H);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		if (ireq->stp.rsp.fis_type == FIS_REGD2H) {
drivers/scsi/isci/request.c:			sci_remote_device_suspend(ireq->target_device,
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_STP_UDMA_WAIT_D2H);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, next);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_NORMALIZE_COMPLETION_STATUS(completion_code);
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_FAILURE_CONTROLLER_SPECIFIC_IO_ERR;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:	struct isci_remote_device *idev = ireq->target_device;
drivers/scsi/isci/request.c:	struct dev_to_host_fis *d2h = &ireq->stp.rsp;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS_IO_DONE_EARLY;
drivers/scsi/isci/request.c:		status = ireq->sci_status;
drivers/scsi/isci/request.c:		ireq->scu_status = SCU_TASK_DONE_GOOD;
drivers/scsi/isci/request.c:		ireq->sci_status = SCI_SUCCESS;
drivers/scsi/isci/request.c:		sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/request.c:			status = ireq->sci_status;
drivers/scsi/isci/request.c:			ireq->scu_status = SCU_TASK_DONE_CHECK_RESPONSE;
drivers/scsi/isci/request.c:			ireq->sci_status = SCI_FAILURE_IO_RESPONSE_VALID;
drivers/scsi/isci/request.c:			sci_change_state(&ireq->sm, SCI_REQ_ATAPI_WAIT_D2H);
drivers/scsi/isci/request.c:	switch (ireq->protocol) {
drivers/scsi/isci/request.c:		dev_warn(&ireq->isci_host->pdev->dev,
drivers/scsi/isci/request.c:			&ireq->target_device->rnc,
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	state = ireq->sm.current_state_id;
drivers/scsi/isci/request.c:	struct domain_device *dev = ireq->target_device->domain_dev;
drivers/scsi/isci/request.c:	task = (test_bit(IREQ_TMF, &ireq->flags)) ? NULL : isci_request_access_task(ireq);
drivers/scsi/isci/request.c:	struct isci_host *ihost = ireq->owning_controller;
drivers/scsi/isci/request.c:	if (!test_bit(IREQ_TMF, &ireq->flags))
drivers/scsi/isci/request.c:						 ireq->sci_status);
drivers/scsi/isci/request.c:		isci_task_request_complete(ihost, ireq, ireq->sci_status);
drivers/scsi/isci/request.c:	ireq->tc->abort = 1;
drivers/scsi/isci/request.c:	ireq->target_device->working_request = ireq;
drivers/scsi/isci/request.c:	ireq->target_device->working_request = ireq;
drivers/scsi/isci/request.c:	sci_init_sm(&ireq->sm, sci_request_state_table, SCI_REQ_INIT);
drivers/scsi/isci/request.c:	ireq->target_device = idev;
drivers/scsi/isci/request.c:	ireq->protocol = SAS_PROTOCOL_NONE;
drivers/scsi/isci/request.c:	ireq->saved_rx_frame_index = SCU_INVALID_FRAME_INDEX;
drivers/scsi/isci/request.c:	ireq->sci_status   = SCI_SUCCESS;
drivers/scsi/isci/request.c:	ireq->scu_status   = 0;
drivers/scsi/isci/request.c:	ireq->post_context = 0xFFFFFFFF;
drivers/scsi/isci/request.c:		memset(&ireq->stp.cmd, 0, sizeof(ireq->stp.cmd));
drivers/scsi/isci/request.c:	memset(ireq->tc, 0, offsetof(struct scu_task_context, sgl_pair_ab));
drivers/scsi/isci/request.c:		set_bit(IREQ_TMF, &ireq->flags);
drivers/scsi/isci/request.c:		memset(ireq->tc, 0, sizeof(struct scu_task_context));
drivers/scsi/isci/request.c:			ireq->protocol = SAS_PROTOCOL_STP;
drivers/scsi/isci/request.c:			ireq->protocol = SAS_PROTOCOL_SSP;
drivers/scsi/isci/request.c:	struct host_to_dev_fis *fis = &ireq->stp.cmd;
drivers/scsi/isci/request.c:	dev_dbg(&ireq->isci_host->pdev->dev,
drivers/scsi/isci/request.c:		ireq->tc->type.stp.ncq_tag = qc->tag;
drivers/scsi/isci/request.c:	if (smp_req->req_len == 0) {
drivers/scsi/isci/request.c:		switch (smp_req->func) {
drivers/scsi/isci/request.c:			smp_req->req_len = 2;
drivers/scsi/isci/request.c:			smp_req->req_len = 9;
drivers/scsi/isci/request.c:	req_len = smp_req->req_len;
drivers/scsi/isci/request.c:	ireq->protocol = SAS_PROTOCOL_SMP;
drivers/scsi/isci/request.c:	task_context = ireq->tc;
drivers/scsi/isci/request.c:	idev = ireq->target_device;
drivers/scsi/isci/request.c:	ireq->post_context = (SCU_CONTEXT_COMMAND_REQUEST_TYPE_POST_TC |
drivers/scsi/isci/request.c:			      ISCI_TAG_TCI(ireq->io_tag));
drivers/scsi/isci/request.c:	sci_change_state(&ireq->sm, SCI_REQ_CONSTRUCTED);
drivers/scsi/isci/request.c:	struct device *dev = &ireq->isci_host->pdev->dev;
drivers/scsi/isci/request.c:		dev_dbg(&ireq->isci_host->pdev->dev,
drivers/scsi/isci/request.c:	ireq->io_tag = tag;
drivers/scsi/isci/request.c:	ireq->io_request_completion = NULL;
drivers/scsi/isci/request.c:	ireq->flags = 0;
drivers/scsi/isci/request.c:	ireq->num_sg_entries = 0;
drivers/scsi/isci/request.c:	ireq->ttype_ptr.io_task_ptr = task;
drivers/scsi/isci/request.c:	clear_bit(IREQ_TMF, &ireq->flags);
drivers/scsi/isci/request.c:	ireq->ttype_ptr.tmf_task_ptr = isci_tmf;
drivers/scsi/isci/request.c:	set_bit(IREQ_TMF, &ireq->flags);
drivers/scsi/isci/request.c:			 * ireq->is_task_management_request is false).
drivers/scsi/isci/request.c:		set_bit(IREQ_TERMINATED, &ireq->flags);
drivers/scsi/isci/remote_device.c:	if (!test_bit(IREQ_ACTIVE, &ireq->flags) ||
drivers/scsi/isci/remote_device.c:	    (ireq->target_device != idev) ||
drivers/scsi/isci/remote_device.c:	    (check_abort && !test_bit(IREQ_PENDING_ABORT, &ireq->flags)))
drivers/scsi/isci/remote_device.c:		__func__, idev, idev->flags, ireq, ireq->target_device);
drivers/scsi/isci/remote_device.c:	set_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags);
drivers/scsi/isci/remote_device.c:		&& !test_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags);
drivers/scsi/isci/remote_device.c:			set_bit(IREQ_NO_AUTO_FREE_TAG, &ireq->flags);
drivers/scsi/isci/remote_device.c:					 "ireq=%p, ireq->flags = %lx\n",
drivers/scsi/isci/remote_device.c:					 ireq, ireq->flags);
drivers/scsi/isci/remote_device.c:			clear_bit(IREQ_NO_AUTO_FREE_TAG, &ireq->flags);
drivers/scsi/isci/remote_device.c:			if (!test_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags))
drivers/scsi/isci/remote_device.c:				isci_free_tag(ihost, ireq->io_tag);
drivers/scsi/isci/remote_device.c:		if (ireq && ireq->target_device == idev) {
drivers/scsi/isci/remote_device.c:	sci_change_state(&ireq->sm, SCI_REQ_COMPLETED);
drivers/scsi/isci/remote_device.c:		if (ireq->sci_status == SCI_FAILURE_REMOTE_DEVICE_RESET_REQUIRED) {
drivers/scsi/isci/task.c:	set_bit(IREQ_COMPLETE_IN_TARGET, &ireq->flags);
drivers/scsi/isci/task.c:			       &ireq->ssp.rsp,
drivers/scsi/isci/task.c:			       &ireq->stp.rsp,
drivers/scsi/isci/task.c:	sci_controller_complete_io(ihost, ireq->target_device, ireq);
drivers/scsi/isci/task.c:	set_bit(IREQ_TERMINATED, &ireq->flags);
drivers/scsi/isci/task.c:	if (test_and_clear_bit(IREQ_ABORT_PATH_ACTIVE, &ireq->flags))
drivers/scsi/isci/task.c:	if (!test_bit(IREQ_NO_AUTO_FREE_TAG, &ireq->flags))
drivers/scsi/isci/task.c:		isci_free_tag(ihost, ireq->io_tag);
drivers/scsi/aacraid/src.c:				if (tm_req->iu_type ==
drivers/scsi/megaraid/megaraid_sas_fusion.c:		status = scsi_io_req->RaidContext.raid_context.status;
drivers/scsi/megaraid/megaraid_sas_fusion.c:		extStatus = scsi_io_req->RaidContext.raid_context.ex_status;
drivers/scsi/megaraid/megaraid_sas_fusion.c:		data_length = scsi_io_req->DataLength;
drivers/scsi/megaraid/megaraid_sas_fusion.c:		switch (scsi_io_req->Function) {
drivers/scsi/megaraid/megaraid_sas_fusion.c:						&mr_tm_req->TmRequest;
drivers/scsi/megaraid/megaraid_sas_fusion.c:				mpi_tm_req->TaskType, mpi_tm_req->TaskMID);
drivers/scsi/megaraid/megaraid_sas_fusion.c:			(struct MPI25_IEEE_SGE_CHAIN64 *)&io_req->SGL;
drivers/scsi/megaraid/megaraid_sas_fusion.c:	  (struct MPI25_IEEE_SGE_CHAIN64 *)&io_req->SGL.IeeeChain;
drivers/scsi/megaraid/megaraid_sas_fusion.c:	io_req->Function    = MEGASAS_MPI2_FUNCTION_PASSTHRU_IO_REQUEST;
drivers/scsi/megaraid/megaraid_sas_fusion.c:	io_req->SGLOffset0  = offsetof(struct MPI2_RAID_SCSI_IO_REQUEST,
drivers/scsi/megaraid/megaraid_sas_fusion.c:	io_req->ChainOffset = fusion->chain_offset_mfi_pthru;
drivers/scsi/megaraid/megaraid_sas_fusion.c:		if (scsi_io_req->Function == MPI2_FUNCTION_SCSI_TASK_MGMT)
drivers/scsi/esas2r/esas2r_int.c:		esas2r_hdebug("aereq->length (0x%x) too long", length);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->local_port = csk->saddr.sin_port;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->peer_port = csk->daddr.sin_port;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->local_ip = csk->saddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->peer_ip = csk->daddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->opt0h = htonl(V_KEEP_ALIVE(1) | F_TCAM_BYPASS |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->opt0l = htonl(V_ULP_MODE(ULP2_MODE_ISCSI) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		&req->local_ip, ntohs(req->local_port),
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		&req->peer_ip, ntohs(req->peer_port),
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_CLOSE_CON));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_lo = htonl(V_WR_TID(tid));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->rsvd = htonl(csk->write_seq);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->cmd = CPL_ABORT_NO_RST;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_HOST_ABORT_CON_REQ));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_lo = htonl(V_WR_TID(csk->tid));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->rsvd0 = htonl(csk->snd_nxt);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->rsvd1 = !cxgbi_sock_flag(csk, CTPF_TX_DATA_SENT);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->cmd = CPL_ABORT_SEND_RST;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		req->rsvd1);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->credit_dack = htonl(F_RX_DACK_CHANGE | V_RX_DACK_MODE(1) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr_hi = htonl(V_WR_OP(FW_WROPCODE_OFLD_TX_DATA) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr_lo = htonl(V_WR_TID(csk->tid));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->len = htonl(len);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->flags = htonl(V_TX_ULP_SUBMODE(cxgbi_skcb_tx_ulp_mode(skb)) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->sndseq = htonl(csk->snd_nxt);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->param = htonl(V_TX_PORT(l2t->smt_idx));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		req->flags |= htonl(V_TX_ACK_PAGES(2) | F_TX_INIT |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		req->param |= htonl(V_TX_SNDBUF(csk->snd_win >> 15));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	unsigned int atid = G_PASS_OPEN_TID(ntohl(req->tos_tid));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	u32 rcv_isn = ntohl(req->rcv_isn);	/* real RCV_ISN + 1 */
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	cxgbi_sock_established(csk, ntohl(req->snd_isn), ntohs(req->tcp_opt));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	if (req->status == CPL_ERR_RTX_NEG_ADVICE ||
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	    req->status == CPL_ERR_PERSIST_NEG_ADVICE) {
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:		csk->err = abort_status_to_errno(csk, req->status, &rst_status);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_BYPASS));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->cmd_lock_addr = htonl(V_ULP_MEMIO_ADDR(addr >> 5) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->len = htonl(V_ULP_MEMIO_DATA_LEN(IPPOD_SIZE >> 5) |
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->reply = V_NO_REPLY(1);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->cpu_idx = 0;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->word = htons(31);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->mask = cpu_to_be64(0xF0000000);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->val = cpu_to_be64(val << 28);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->wr.wr_hi = htonl(V_WR_OP(FW_WROPCODE_FORWARD));
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->reply = V_NO_REPLY(1);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->cpu_idx = 0;
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->word = htons(31);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->mask = cpu_to_be64(0x0F000000);
drivers/scsi/cxgbi/cxgb3i/cxgb3i.c:	req->val = cpu_to_be64(val << 24);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip = csk->saddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip = csk->daddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be32(cxgb4_select_ntuple(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			csk, &req->local_ip, ntohs(req->local_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			&req->peer_ip, ntohs(req->peer_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip = csk->saddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip = csk->daddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be64(FILTER_TUPLE_V(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->rsvd = cpu_to_be32(isn);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			csk, &req->local_ip, ntohs(req->local_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			&req->peer_ip, ntohs(req->peer_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr.sin_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip = csk->saddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip = csk->daddr.sin_addr.s_addr;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be64(FILTER_TUPLE_V(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->rsvd = cpu_to_be32(isn);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->rsvd2 = cpu_to_be32(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt3 = cpu_to_be32(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			  csk, &req->local_ip, ntohs(req->local_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			  &req->peer_ip, ntohs(req->peer_port),
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_hi = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_lo = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_hi = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_lo = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be32(cxgb4_select_ntuple(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_hi = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_lo = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_hi = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_lo = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be64(FILTER_TUPLE_V(cxgb4_select_ntuple(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_port = csk->saddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_port = csk->daddr6.sin6_port;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_hi = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->local_ip_lo = *(__be64 *)(csk->saddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_hi = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->peer_ip_lo = *(__be64 *)(csk->daddr6.sin6_addr.s6_addr +
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt0 = cpu_to_be64(opt0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt2 = cpu_to_be32(opt2);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->params = cpu_to_be64(FILTER_TUPLE_V(cxgb4_select_ntuple(
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->rsvd2 = cpu_to_be32(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->opt3 = cpu_to_be32(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->rsvd = 0;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->cmd = CPL_ABORT_NO_RST;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->cmd = CPL_ABORT_SEND_RST;
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->rsvd0 = htonl(csk->snd_nxt);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->rsvd1 = !cxgbi_sock_flag(csk, CTPF_TX_DATA_SENT);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		req->rsvd1);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->credit_dack = cpu_to_be32(RX_CREDITS_V(credits)
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->op_to_immdlen = cpu_to_be32(FW_WR_OP_V(opcode) |
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->flowid_len16 = cpu_to_be32(FW_WR_FLOWID_V(csk->tid) |
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->plen = cpu_to_be32(len);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->tunnel_to_proxy = cpu_to_be32(wr_ulp_mode | force |
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:			req->wr.wr_hi |= cpu_to_be32(FW_WR_COMPL_F);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	unsigned short tcp_opt = ntohs(req->tcp_opt);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	unsigned int atid = TID_TID_G(ntohl(req->tos_atid));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	u32 rcv_isn = be32_to_cpu(req->rcv_isn);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	cxgbi_sock_established(csk, ntohl(req->snd_isn), ntohs(req->tcp_opt));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		       csk, csk->state, csk->flags, csk->tid, req->status);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	if (is_neg_adv(req->status))
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:		csk->err = abort_status_to_errno(csk, req->status, &rst_status);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->wr.wr_hi = htonl(FW_WR_OP_V(FW_ULPTX_WR) |
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->cmd = htonl(ULPTX_CMD_V(ULP_TX_MEM_WRITE) |
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->dlen = htonl(ULP_MEMIO_DATA_LEN_V(dlen >> 5));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->lock_addr = htonl(ULP_MEMIO_ADDR_V(pm_addr >> 5));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->len16 = htonl(DIV_ROUND_UP(wr_len - sizeof(req->wr), 16));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->reply_ctrl = htons(NO_REPLY_V(0) | QUEUENO_V(csk->rss_qid));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->word_cookie = htons(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->mask = cpu_to_be64(0x3 << 8);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->val = cpu_to_be64(pg_idx << 8);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->reply_ctrl = htons(NO_REPLY_V(0) | QUEUENO_V(csk->rss_qid));
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->word_cookie = htons(0);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->mask = cpu_to_be64(0x3 << 4);
drivers/scsi/cxgbi/cxgb4i/cxgb4i.c:	req->val = cpu_to_be64(((hcrc ? ULP_CRC_HEADER : 0) |
drivers/scsi/ufs/ufshcd.c:	tag = req->tag;
drivers/scsi/ufs/ufshcd.c:	if (test_bit(req->tag, &ci->pending))
drivers/scsi/ufs/ufshcd.c:	c = req->end_io_data;
drivers/scsi/ufs/ufshcd.c:	req->end_io_data = &wait;
drivers/scsi/ufs/ufshcd.c:	task_tag = req->tag;
drivers/scsi/ufs/ufshcd.c:	treq->req_header.dword_0 |= cpu_to_be32(task_tag);
drivers/scsi/ufs/ufshcd.c:		req->end_io_data = NULL;
drivers/scsi/ufs/ufshcd.c:	tag = req->tag;
drivers/scsi/ufs/ufs-exynos.c:	int gear = max_t(u32, pwr_req->gear_rx, pwr_req->gear_tx);
drivers/scsi/ufs/ufs-exynos.c:	int lanes = max_t(u32, pwr_req->lane_rx, pwr_req->lane_tx);
drivers/scsi/ufs/ufs-exynos.c:		switch (pwr_req->hs_rate) {
drivers/scsi/ufs/ufs-exynos.c:			"FAST",	pwr_req->hs_rate == PA_HS_MODE_A ? "A" : "B",
drivers/scsi/ufs/ufshcd-pltfrm.c:	if (!of_get_property(np, "freq-table-hz", &len)) {
drivers/scsi/ufs/ufshcd-pltfrm.c:		dev_info(dev, "freq-table-hz property not specified\n");
drivers/scsi/ufs/ufshcd-pltfrm.c:		dev_err(dev, "%s len mismatch\n", "freq-table-hz");
drivers/scsi/ufs/ufshcd-pltfrm.c:	ret = of_property_read_u32_array(np, "freq-table-hz",
drivers/scsi/ufs/ufshcd-pltfrm.c:				"freq-table-hz", ret);
drivers/scsi/ufs/ufshcd-pltfrm.c:		dev_dbg(dev, "%s: min %u max %u name %s\n", "freq-table-hz",
drivers/scsi/snic/snic_scsi.c:	if (req->u.icmnd.sense_addr)
drivers/scsi/snic/snic_scsi.c:				 le64_to_cpu(req->u.icmnd.sense_addr),
drivers/scsi/snic/snic_scsi.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &hdr_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/snic/snic_scsi.c:	icmnd_cmpl = &fwreq->u.icmnd_cmpl;
drivers/scsi/snic/snic_scsi.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &hdr_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/snic/snic_scsi.c:	itmf_cmpl = &fwreq->u.itmf_cmpl;
drivers/scsi/snic/snic_scsi.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &hdr_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/snic/snic_scsi.c:	struct snic_async_evnotify *aen = &fwreq->u.async_ev;
drivers/scsi/snic/snic_scsi.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &hdr_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/snic/snic_scsi.c:	if ((fwreq->hdr.type >= SNIC_RSP_REPORT_TGTS_CMPL) &&
drivers/scsi/snic/snic_scsi.c:		(fwreq->hdr.type <= SNIC_RSP_BOOT_LUNS_CMPL))
drivers/scsi/snic/snic_scsi.c:	SNIC_BUG_ON((fwreq->hdr.type > SNIC_RSP_BOOT_LUNS_CMPL) &&
drivers/scsi/snic/snic_scsi.c:		    (fwreq->hdr.type < SNIC_MSG_ASYNC_EVNOTIFY));
drivers/scsi/snic/snic_scsi.c:	switch (fwreq->hdr.status) {
drivers/scsi/snic/snic_scsi.c:	switch (fwreq->hdr.type) {
drivers/scsi/snic/snic_scsi.c:			      fwreq->hdr.type);
drivers/scsi/snic/snic_scsi.c:	snic_io_hdr_enc(&req->hdr, SNIC_REQ_HBA_RESET, 0, snic_cmd_tag(sc),
drivers/scsi/snic/snic_scsi.c:	req->u.reset.flags = 0;
drivers/scsi/snic/snic_res.h:	snic_io_hdr_enc(&req->hdr, SNIC_REQ_ICMND, 0, cmnd_id, host_id, sg_cnt,
drivers/scsi/snic/snic_res.h:	req->u.icmnd.flags = cpu_to_le16(flags);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.tgt_id = cpu_to_le64(tgt_id);
drivers/scsi/snic/snic_res.h:	memcpy(&req->u.icmnd.lun_id, lun, LUN_ADDR_LEN);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.cdb_len = cdb_len;
drivers/scsi/snic/snic_res.h:	memset(req->u.icmnd.cdb, 0, SNIC_CDB_LEN);
drivers/scsi/snic/snic_res.h:	memcpy(req->u.icmnd.cdb, scsi_cdb, cdb_len);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.data_len = cpu_to_le32(data_len);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.sg_addr = cpu_to_le64(sgl_addr);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.sense_len = cpu_to_le32(sense_len);
drivers/scsi/snic/snic_res.h:	req->u.icmnd.sense_addr = cpu_to_le64(sns_addr_pa);
drivers/scsi/snic/snic_res.h:	snic_io_hdr_enc(&req->hdr, SNIC_REQ_ITMF, 0, cmnd_id, host_id, 0, ctx);
drivers/scsi/snic/snic_res.h:	req->u.itmf.tm_type = tm_type;
drivers/scsi/snic/snic_res.h:	req->u.itmf.flags = cpu_to_le16(flags);
drivers/scsi/snic/snic_res.h:	req->u.itmf.req_id = cpu_to_le32(req_id);
drivers/scsi/snic/snic_res.h:	req->u.itmf.tgt_id = cpu_to_le64(tgt_id);
drivers/scsi/snic/snic_res.h:	memcpy(&req->u.itmf.lun_id, lun, LUN_ADDR_LEN);
drivers/scsi/snic/snic_io.c:	req->req_pa = (ulong)pa;
drivers/scsi/snic/snic_io.c:	desc_avail = snic_wqdesc_avail(snic, q_num, req->hdr.type);
drivers/scsi/snic/snic_io.c:		req->req_pa = 0;
drivers/scsi/snic/snic_io.c:	rqi->req->hdr.init_ctx = (ulong) rqi;
drivers/scsi/snic/snic_io.c:	req->hdr.init_ctx = (ulong) rqi;
drivers/scsi/snic/snic_io.c:	req->hdr.init_ctx = (ulong) rqi;
drivers/scsi/snic/snic_io.c:		if (rqi->abort_req->req_pa)
drivers/scsi/snic/snic_io.c:					 rqi->abort_req->req_pa,
drivers/scsi/snic/snic_io.c:		if (rqi->dr_req->req_pa)
drivers/scsi/snic/snic_io.c:					 rqi->dr_req->req_pa,
drivers/scsi/snic/snic_io.c:	if (rqi->req->req_pa)
drivers/scsi/snic/snic_io.c:				 rqi->req->req_pa,
drivers/scsi/snic/snic_io.c:	if (req->hdr.type >= SNIC_RSP_REPORT_TGTS_CMPL)
drivers/scsi/snic/snic_io.c:		rqi = (struct snic_req_info *) fwreq->hdr.init_ctx;
drivers/scsi/snic/snic_io.c:		rqi = (struct snic_req_info *) req->hdr.init_ctx;
drivers/scsi/snic/snic_io.c:	switch (req->hdr.type) {
drivers/scsi/snic/snic_io.c:			 req->u.icmnd.cdb[0]);
drivers/scsi/snic/snic_io.c:			 rqi->req->u.icmnd.cdb[0]);
drivers/scsi/snic/snic_io.c:		  fn, line, req->hdr.cmnd_id, req->hdr.sg_cnt, req->hdr.status,
drivers/scsi/snic/snic_io.c:		  req->hdr.init_ctx);
drivers/scsi/snic/snic_disc.c:	snic_io_hdr_enc(&req->hdr, SNIC_REQ_REPORT_TGTS, 0, SCSI_NO_TAG, hid,
drivers/scsi/snic/snic_disc.c:	req->u.rpt_tgts.sg_cnt = cpu_to_le16(1);
drivers/scsi/snic/snic_disc.c:	req->u.rpt_tgts.sg_addr = cpu_to_le64((ulong)sgd);
drivers/scsi/snic/snic_disc.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &cmpl_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/snic/snic_disc.c:	tgt_cnt = le32_to_cpu(fwreq->u.rpt_tgts_cmpl.tgt_cnt);
drivers/scsi/snic/snic_ctl.c:	snic_io_hdr_enc(&req->hdr, SNIC_REQ_EXCH_VER, 0, SCSI_NO_TAG,
drivers/scsi/snic/snic_ctl.c:	req->u.exch_ver.drvr_ver = cpu_to_le32(ver);
drivers/scsi/snic/snic_ctl.c:	req->u.exch_ver.os_type = cpu_to_le32(SNIC_OS_LINUX);
drivers/scsi/snic/snic_ctl.c:	struct snic_exch_ver_rsp *exv_cmpl = &fwreq->u.exch_ver_cmpl;
drivers/scsi/snic/snic_ctl.c:	snic_io_hdr_dec(&fwreq->hdr, &typ, &hdr_stat, &cmnd_id, &hid, &ctx);
drivers/scsi/csiostor/csio_isr.c:				    ioreq, ioreq->wr_status);
drivers/scsi/csiostor/csio_isr.c:				list_del_init(&ioreq->sm.sm_list);
drivers/scsi/csiostor/csio_isr.c:		ioreq->io_cbfn(hw, ioreq);
drivers/scsi/csiostor/csio_isr.c:		if (unlikely(ioreq->dcopy))
drivers/scsi/csiostor/csio_isr.c:			csio_put_scsi_ddp_list_lock(hw, scm, &ioreq->gen_list,
drivers/scsi/csiostor/csio_isr.c:						    ioreq->nsge);
drivers/scsi/csiostor/csio_isr.c:		/* Return the ioreqs back to ioreq->freelist */
drivers/scsi/csiostor/csio_hw.c:		io_req->tmo -= min_t(uint32_t, io_req->tmo, ECM_MIN_TMO);
drivers/scsi/csiostor/csio_hw.c:		if (!io_req->tmo) {
drivers/scsi/csiostor/csio_hw.c:			list_del_init(&io_req->sm.sm_list);
drivers/scsi/csiostor/csio_hw.c:			if (io_req->io_cbfn) {
drivers/scsi/csiostor/csio_hw.c:				io_req->wr_status = -ETIMEDOUT;
drivers/scsi/csiostor/csio_hw.c:				io_req->io_cbfn(mgmtm->hw, io_req);
drivers/scsi/csiostor/csio_hw.c:		list_del_init(&io_req->sm.sm_list);
drivers/scsi/csiostor/csio_hw.c:		if (io_req->io_cbfn) {
drivers/scsi/csiostor/csio_hw.c:			io_req->wr_status = -ETIMEDOUT;
drivers/scsi/csiostor/csio_hw.c:			io_req->io_cbfn(mgmtm->hw, io_req);
drivers/scsi/csiostor/csio_scsi.c:		return ((ioreq->lnode == sld->lnode) &&
drivers/scsi/csiostor/csio_scsi.c:			(ioreq->rnode == sld->rnode) &&
drivers/scsi/csiostor/csio_scsi.c:		return ((ioreq->lnode == sld->lnode) &&
drivers/scsi/csiostor/csio_scsi.c:				(ioreq->rnode == sld->rnode));
drivers/scsi/csiostor/csio_scsi.c:		return (ioreq->lnode == sld->lnode);
drivers/scsi/csiostor/csio_scsi.c:		if (req->nsge)
drivers/scsi/csiostor/csio_scsi.c:			if (req->datadir == DMA_TO_DEVICE)
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_rnode *rn = req->rnode;
drivers/scsi/csiostor/csio_scsi.c:	wr->iqid = cpu_to_be16(csio_q_physiqid(hw, req->iq_idx));
drivers/scsi/csiostor/csio_scsi.c:	wr->tmo_val = (uint8_t) req->tmo;
drivers/scsi/csiostor/csio_scsi.c:	dma_buf = &req->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	req->drv_status = csio_wr_get(hw, req->eq_idx, size, &wrp);
drivers/scsi/csiostor/csio_scsi.c:	if (unlikely(req->drv_status != 0))
drivers/scsi/csiostor/csio_scsi.c:		uint8_t *tmpwr = csio_q_eq_wrap(hw, req->eq_idx);
drivers/scsi/csiostor/csio_scsi.c:				     ULPTX_NSGE_V(req->nsge));
drivers/scsi/csiostor/csio_scsi.c:	if (likely(!req->dcopy)) {
drivers/scsi/csiostor/csio_scsi.c:		scsi_for_each_sg(scmnd, sgel, req->nsge, i) {
drivers/scsi/csiostor/csio_scsi.c:		list_for_each(tmp, &req->gen_list) {
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_rnode *rn = req->rnode;
drivers/scsi/csiostor/csio_scsi.c:	wr->iqid = cpu_to_be16(csio_q_physiqid(hw, req->iq_idx));
drivers/scsi/csiostor/csio_scsi.c:	wr->tmo_val = (uint8_t)(req->tmo);
drivers/scsi/csiostor/csio_scsi.c:	dma_buf = &req->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_rnode *rn = req->rnode;
drivers/scsi/csiostor/csio_scsi.c:	wr->iqid = cpu_to_be16(csio_q_physiqid(hw, req->iq_idx));
drivers/scsi/csiostor/csio_scsi.c:	wr->tmo_val = (uint8_t)(req->tmo);
drivers/scsi/csiostor/csio_scsi.c:	dma_buf = &req->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	req->drv_status = csio_wr_get(hw, req->eq_idx, size, &wrp);
drivers/scsi/csiostor/csio_scsi.c:	if (likely(req->drv_status == 0)) {
drivers/scsi/csiostor/csio_scsi.c:			uint8_t *tmpwr = csio_q_eq_wrap(hw, req->eq_idx);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	req->drv_status = csio_wr_get(hw, req->eq_idx, size, &wrp);
drivers/scsi/csiostor/csio_scsi.c:	if (likely(req->drv_status == 0)) {
drivers/scsi/csiostor/csio_scsi.c:			uint8_t *tmpwr = csio_q_eq_wrap(hw, req->eq_idx);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	scsi_for_each_sg(scmnd, sgel, req->nsge, i) {
drivers/scsi/csiostor/csio_scsi.c:		if ((i != (req->nsge - 1)) &&
drivers/scsi/csiostor/csio_scsi.c:	req->dcopy = 0;
drivers/scsi/csiostor/csio_scsi.c:	req->dcopy = 1;
drivers/scsi/csiostor/csio_scsi.c:	INIT_LIST_HEAD(&req->gen_list);
drivers/scsi/csiostor/csio_scsi.c:			req->drv_status = -EBUSY;
drivers/scsi/csiostor/csio_scsi.c:		list_add_tail(&dma_buf->list, &req->gen_list);
drivers/scsi/csiostor/csio_scsi.c:	if (!req->drv_status) {
drivers/scsi/csiostor/csio_scsi.c:		req->nsge = i;
drivers/scsi/csiostor/csio_scsi.c:		csio_put_scsi_ddp_list(scsim, &req->gen_list, i);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_rnode *rn = req->rnode;
drivers/scsi/csiostor/csio_scsi.c:	wr->iqid = cpu_to_be16(csio_q_physiqid(hw, req->iq_idx));
drivers/scsi/csiostor/csio_scsi.c:	wr->tmo_val = (uint8_t) req->tmo;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:	req->drv_status = csio_wr_get(hw, req->eq_idx, size, &wrp);
drivers/scsi/csiostor/csio_scsi.c:	if (req->drv_status != 0)
drivers/scsi/csiostor/csio_scsi.c:		uint8_t *tmpwr = csio_q_eq_wrap(hw, req->eq_idx);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:		if (req->nsge) {
drivers/scsi/csiostor/csio_scsi.c:			if (req->datadir == DMA_TO_DEVICE) {
drivers/scsi/csiostor/csio_scsi.c:				req->dcopy = 0;
drivers/scsi/csiostor/csio_scsi.c:		if (likely(req->drv_status == 0)) {
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_io_active);
drivers/scsi/csiostor/csio_scsi.c:			list_add_tail(&req->sm.sm_list, &scsim->active_q);
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status == 0) {
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_tm_active);
drivers/scsi/csiostor/csio_scsi.c:			list_add_tail(&req->sm.sm_list, &scsim->active_q);
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:		req->drv_status = -EINVAL;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&req->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		if (unlikely(req->wr_status != FW_SUCCESS)) {
drivers/scsi/csiostor/csio_scsi.c:			rn = req->rnode;
drivers/scsi/csiostor/csio_scsi.c:			if (csio_scsi_itnexus_loss_error(req->wr_status) &&
drivers/scsi/csiostor/csio_scsi.c:				csio_set_state(&req->sm,
drivers/scsi/csiostor/csio_scsi.c:				list_add_tail(&req->sm.sm_list,
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status == 0) {
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_aborting);
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status == 0) {
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_closing);
drivers/scsi/csiostor/csio_scsi.c:		req->wr_status = FW_HOSTERROR;
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&req->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status == 0) {
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_aborting);
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status == 0) {
drivers/scsi/csiostor/csio_scsi.c:			csio_wr_issue(hw, req->eq_idx, false);
drivers/scsi/csiostor/csio_scsi.c:			csio_set_state(&req->sm, csio_scsis_closing);
drivers/scsi/csiostor/csio_scsi.c:		req->wr_status = FW_HOSTERROR;
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:			 "in aborting st\n", req, req->wr_status);
drivers/scsi/csiostor/csio_scsi.c:		req->drv_status = -ECANCELED;
drivers/scsi/csiostor/csio_scsi.c:			 req, req->wr_status, req->drv_status);
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status != -ECANCELED) {
drivers/scsi/csiostor/csio_scsi.c:		if ((req->wr_status == FW_SUCCESS) ||
drivers/scsi/csiostor/csio_scsi.c:		    (req->wr_status == FW_EINVAL) ||
drivers/scsi/csiostor/csio_scsi.c:		    csio_scsi_itnexus_loss_error(req->wr_status))
drivers/scsi/csiostor/csio_scsi.c:			req->wr_status = FW_SCSI_ABORT_REQUESTED;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&req->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		req->wr_status = FW_HOSTERROR;
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_hw *hw = req->lnode->hwp;
drivers/scsi/csiostor/csio_scsi.c:			 "in closing st\n", req, req->wr_status);
drivers/scsi/csiostor/csio_scsi.c:		req->drv_status = -ECANCELED;
drivers/scsi/csiostor/csio_scsi.c:		if (req->drv_status != -ECANCELED) {
drivers/scsi/csiostor/csio_scsi.c:		CSIO_DB_ASSERT((req->wr_status == FW_SUCCESS) ||
drivers/scsi/csiostor/csio_scsi.c:					(req->wr_status == FW_EINVAL));
drivers/scsi/csiostor/csio_scsi.c:		req->wr_status = FW_SCSI_CLOSE_REQUESTED;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&req->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		req->wr_status = FW_HOSTERROR;
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		req->drv_status = 0;
drivers/scsi/csiostor/csio_scsi.c:		csio_set_state(&req->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		csio_dbg(req->lnode->hwp, "Unhandled event:%d sent to req:%p\n",
drivers/scsi/csiostor/csio_scsi.c: * WR copied into the WR cache (ioreq->fw_wr).
drivers/scsi/csiostor/csio_scsi.c:		ioreq->wr_status = status;
drivers/scsi/csiostor/csio_scsi.c:		ioreq->wr_status = status;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&ioreq->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:			ioreq->io_cbfn(hw, ioreq);
drivers/scsi/csiostor/csio_scsi.c:	struct csio_lnode *ln = ioreq->lnode;
drivers/scsi/csiostor/csio_scsi.c:	dma_buf = (struct csio_dma_buf *)csio_list_next(&req->gen_list);
drivers/scsi/csiostor/csio_scsi.c:	switch (req->wr_status) {
drivers/scsi/csiostor/csio_scsi.c:		dma_buf = &req->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:			    (req->wr_status == FW_SCSI_CLOSE_REQUESTED) ?
drivers/scsi/csiostor/csio_scsi.c:		if (req->wr_status == FW_SCSI_CLOSE_REQUESTED)
drivers/scsi/csiostor/csio_scsi.c:			 req, cmnd, req->wr_status);
drivers/scsi/csiostor/csio_scsi.c:			    req->wr_status, req, cmnd);
drivers/scsi/csiostor/csio_scsi.c:	if (req->nsge > 0) {
drivers/scsi/csiostor/csio_scsi.c:		if (req->dcopy && (host_status == DID_OK))
drivers/scsi/csiostor/csio_scsi.c:	complete(&req->cmplobj);
drivers/scsi/csiostor/csio_scsi.c:	if (likely(req->wr_status == FW_SUCCESS)) {
drivers/scsi/csiostor/csio_scsi.c:		if (req->nsge > 0) {
drivers/scsi/csiostor/csio_scsi.c:			if (req->dcopy)
drivers/scsi/csiostor/csio_scsi.c:	/* Get req->nsge, if there are SG elements to be mapped  */
drivers/scsi/csiostor/csio_scsi.c:	ioreq->nsge		= nsge;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->lnode		= ln;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->rnode		= rn;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->iq_idx		= sqset->iq_idx;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->eq_idx		= sqset->eq_idx;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->wr_status	= 0;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->drv_status	= 0;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->tmo		= 0;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->datadir		= cmnd->sc_data_direction;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->io_cbfn = csio_scsi_cbfn;
drivers/scsi/csiostor/csio_scsi.c:	struct csio_lnode *ln = ioreq->lnode;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->tmo = CSIO_SCSI_ABRT_TMO_MS;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->eq_idx = sqset->eq_idx;
drivers/scsi/csiostor/csio_scsi.c:		cmnd->device->lun, csio_q_physiqid(hw, ioreq->iq_idx));
drivers/scsi/csiostor/csio_scsi.c:	reinit_completion(&ioreq->cmplobj);
drivers/scsi/csiostor/csio_scsi.c:	wait_for_completion_timeout(&ioreq->cmplobj, msecs_to_jiffies(tmo));
drivers/scsi/csiostor/csio_scsi.c:		if (ioreq->nsge > 0)
drivers/scsi/csiostor/csio_scsi.c:		      req, req->wr_status);
drivers/scsi/csiostor/csio_scsi.c:	cmnd->SCp.Status = req->wr_status;
drivers/scsi/csiostor/csio_scsi.c:	if (req->wr_status == FW_SCSI_RSP_ERR) {
drivers/scsi/csiostor/csio_scsi.c:		dma_buf = &req->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->nsge		= 0;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->lnode		= ln;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->rnode		= rn;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->iq_idx		= sqset->iq_idx;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->eq_idx		= sqset->eq_idx;
drivers/scsi/csiostor/csio_scsi.c:	ioreq->tmo		= CSIO_SCSI_LUNRST_TMO_MS / 1000;
drivers/scsi/csiostor/csio_scsi.c:	 * FW times the LUN reset for ioreq->tmo, so we got to wait a little
drivers/scsi/csiostor/csio_scsi.c:	count = DIV_ROUND_UP((ioreq->tmo + 10) * 1000, CSIO_SCSI_TM_POLL_MS);
drivers/scsi/csiostor/csio_scsi.c:	ioreq->io_cbfn = csio_tm_cbfn;
drivers/scsi/csiostor/csio_scsi.c:	sld.lnode = ioreq->lnode;
drivers/scsi/csiostor/csio_scsi.c:	sld.rnode = ioreq->rnode;
drivers/scsi/csiostor/csio_scsi.c:		list_del_init(&ioreq->sm.sm_list);
drivers/scsi/csiostor/csio_scsi.c:		dma_buf = &ioreq->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:		csio_init_state(&ioreq->sm, csio_scsis_uninit);
drivers/scsi/csiostor/csio_scsi.c:		INIT_LIST_HEAD(&ioreq->gen_list);
drivers/scsi/csiostor/csio_scsi.c:		init_completion(&ioreq->cmplobj);
drivers/scsi/csiostor/csio_scsi.c:		list_add_tail(&ioreq->sm.sm_list, &scm->ioreq_freelist);
drivers/scsi/csiostor/csio_scsi.c:		dma_buf = &ioreq->dma_buf;
drivers/scsi/csiostor/csio_scsi.c:		dma_buf = &ioreq->dma_buf;
drivers/scsi/csiostor/csio_lnode.c:	struct csio_lnode *ln = fdmi_req->lnode;
drivers/scsi/csiostor/csio_lnode.c:	if (fdmi_req->wr_status != FW_SUCCESS) {
drivers/scsi/csiostor/csio_lnode.c:			    fdmi_req->wr_status);
drivers/scsi/csiostor/csio_lnode.c:	cmd = fdmi_req->dma_buf.vaddr;
drivers/scsi/csiostor/csio_lnode.c:	struct csio_lnode *ln = fdmi_req->lnode;
drivers/scsi/csiostor/csio_lnode.c:	if (fdmi_req->wr_status != FW_SUCCESS) {
drivers/scsi/csiostor/csio_lnode.c:			    fdmi_req->wr_status);
drivers/scsi/csiostor/csio_lnode.c:	cmd = fdmi_req->dma_buf.vaddr;
drivers/scsi/csiostor/csio_lnode.c:	if (!csio_is_rnode_ready(fdmi_req->rnode)) {
drivers/scsi/csiostor/csio_lnode.c:				FCOE_CT, &fdmi_req->dma_buf, len)) {
drivers/scsi/csiostor/csio_lnode.c:	struct csio_lnode *ln = fdmi_req->lnode;
drivers/scsi/csiostor/csio_lnode.c:	if (fdmi_req->wr_status != FW_SUCCESS) {
drivers/scsi/csiostor/csio_lnode.c:			    fdmi_req->wr_status);
drivers/scsi/csiostor/csio_lnode.c:	if (!csio_is_rnode_ready(fdmi_req->rnode)) {
drivers/scsi/csiostor/csio_lnode.c:	cmd = fdmi_req->dma_buf.vaddr;
drivers/scsi/csiostor/csio_lnode.c:				FCOE_CT, &fdmi_req->dma_buf, len)) {
drivers/scsi/csiostor/csio_lnode.c:	struct csio_lnode *ln = fdmi_req->lnode;
drivers/scsi/csiostor/csio_lnode.c:	if (fdmi_req->wr_status != FW_SUCCESS) {
drivers/scsi/csiostor/csio_lnode.c:			    fdmi_req->wr_status);
drivers/scsi/csiostor/csio_lnode.c:	if (!csio_is_rnode_ready(fdmi_req->rnode)) {
drivers/scsi/csiostor/csio_lnode.c:	cmd = fdmi_req->dma_buf.vaddr;
drivers/scsi/csiostor/csio_lnode.c:				FCOE_CT, &fdmi_req->dma_buf, len)) {
drivers/scsi/csiostor/csio_lnode.c:	fdmi_req->lnode = ln;
drivers/scsi/csiostor/csio_lnode.c:	fdmi_req->rnode = fdmi_rn;
drivers/scsi/csiostor/csio_lnode.c:	cmd = fdmi_req->dma_buf.vaddr;
drivers/scsi/csiostor/csio_lnode.c:					FCOE_CT, &fdmi_req->dma_buf, len)) {
drivers/scsi/csiostor/csio_lnode.c:	io_req->wr_status = csio_wr_status(wr_cmd);
drivers/scsi/csiostor/csio_lnode.c:	list_del_init(&io_req->sm.sm_list);
drivers/scsi/csiostor/csio_lnode.c:	if (io_req->io_cbfn)
drivers/scsi/csiostor/csio_lnode.c:		io_req->io_cbfn(hw, io_req);
drivers/scsi/csiostor/csio_lnode.c:	wr->cookie = io_req->fw_handle;
drivers/scsi/csiostor/csio_lnode.c:					io_req->lnode->hwp, io_req->iq_idx));
drivers/scsi/csiostor/csio_lnode.c:	wr->tmo_val = (uint8_t) io_req->tmo;
drivers/scsi/csiostor/csio_lnode.c:	wr->rsp_dmalen = cpu_to_be32(io_req->dma_buf.len);
drivers/scsi/csiostor/csio_lnode.c:	wr->rsp_dmaaddr = cpu_to_be64(io_req->dma_buf.paddr);
drivers/scsi/csiostor/csio_lnode.c:	struct csio_lnode *ln = io_req->lnode;
drivers/scsi/csiostor/csio_lnode.c:	struct csio_rnode *rn = io_req->rnode;
drivers/scsi/csiostor/csio_lnode.c:	struct csio_hw *hw = csio_lnode_to_hw(io_req->lnode);
drivers/scsi/csiostor/csio_lnode.c:	io_req->io_cbfn = io_cbfn;	/* Upper layer callback handler */
drivers/scsi/csiostor/csio_lnode.c:	io_req->fw_handle = (uintptr_t) (io_req);
drivers/scsi/csiostor/csio_lnode.c:	io_req->eq_idx = mgmtm->eq_idx;
drivers/scsi/csiostor/csio_lnode.c:	io_req->iq_idx = mgmtm->iq_idx;
drivers/scsi/csiostor/csio_lnode.c:		list_add_tail(&io_req->sm.sm_list, &mgmtm->active_q);
drivers/scsi/csiostor/csio_lnode.c:	dma_buf = &ln->mgmt_req->dma_buf;
drivers/scsi/csiostor/csio_lnode.c:	dma_buf = &ln->mgmt_req->dma_buf;
drivers/scsi/csiostor/csio_scsi.h:		list_del_init(&req->sm_list);
drivers/scsi/csiostor/csio_scsi.h:	list_add_tail(&ioreq->sm.sm_list, &scm->ioreq_freelist);
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_COMPLETED);
drivers/scsi/csiostor/csio_scsi.h:	if (csio_list_deleted(&ioreq->sm.sm_list))
drivers/scsi/csiostor/csio_scsi.h:		list_add_tail(&ioreq->sm.sm_list, cbfn_q);
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_ABORTED);
drivers/scsi/csiostor/csio_scsi.h:	list_add_tail(&ioreq->sm.sm_list, cbfn_q);
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_CLOSED);
drivers/scsi/csiostor/csio_scsi.h:	list_add_tail(&ioreq->sm.sm_list, cbfn_q);
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_DRVCLEANUP);
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_START_IO);
drivers/scsi/csiostor/csio_scsi.h:	return ioreq->drv_status;
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_START_TM);
drivers/scsi/csiostor/csio_scsi.h:	return ioreq->drv_status;
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_ABORT);
drivers/scsi/csiostor/csio_scsi.h:	return ioreq->drv_status;
drivers/scsi/csiostor/csio_scsi.h:	csio_post_event(&ioreq->sm, CSIO_SCSIE_CLOSE);
drivers/scsi/csiostor/csio_scsi.h:	return ioreq->drv_status;
drivers/scsi/st.c:		streq->stp = stp;
drivers/scsi/st.c:	struct st_request *SRpnt = req->end_io_data;
drivers/scsi/st.c:	req->rq_flags |= RQF_QUIET;
drivers/scsi/st.c:		err = blk_rq_map_user(req->q, req, mdata, NULL, bufflen,
drivers/scsi/st.c:	SRpnt->bio = req->bio;
drivers/scsi/st.c:	req->timeout = timeout;
drivers/scsi/st.c:	req->end_io_data = SRpnt;
drivers/scsi/sd.c:					req->rq_flags |= RQF_QUIET;
drivers/scsi/mpt3sas/mpt3sas_base.c:		sgel = (Mpi2SGESimple32_t *) &config_req->PageBufferSGE;
drivers/scsi/mpt3sas/mpt3sas_base.c:	chain = chain_req->chain_buffer;
drivers/scsi/mpt3sas/mpt3sas_base.c:	chain_dma = chain_req->chain_buffer_dma;
drivers/scsi/mpt3sas/mpt3sas_base.c:		chain = chain_req->chain_buffer;
drivers/scsi/mpt3sas/mpt3sas_base.c:		chain_dma = chain_req->chain_buffer_dma;
drivers/scsi/mpt3sas/mpt3sas_base.c:	chain = chain_req->chain_buffer;
drivers/scsi/mpt3sas/mpt3sas_base.c:	chain_dma = chain_req->chain_buffer_dma;
drivers/scsi/mpt3sas/mpt3sas_base.c:		chain = chain_req->chain_buffer;
drivers/scsi/mpt3sas/mpt3sas_base.c:		chain_dma = chain_req->chain_buffer_dma;
drivers/scsi/xen-scsifront.c:	ring_req->rqid        = id;
drivers/scsi/xen-scsifront.c:	ring_req->act         = shadow->act;
drivers/scsi/xen-scsifront.c:	ring_req->ref_rqid    = shadow->ref_rqid;
drivers/scsi/xen-scsifront.c:	ring_req->nr_segments = shadow->nr_segments;
drivers/scsi/xen-scsifront.c:	ring_req->id      = sc->device->id;
drivers/scsi/xen-scsifront.c:	ring_req->lun     = sc->device->lun;
drivers/scsi/xen-scsifront.c:	ring_req->channel = sc->device->channel;
drivers/scsi/xen-scsifront.c:	ring_req->cmd_len = sc->cmd_len;
drivers/scsi/xen-scsifront.c:	memcpy(ring_req->cmnd, sc->cmnd, sc->cmd_len);
drivers/scsi/xen-scsifront.c:	ring_req->sc_data_direction   = (uint8_t)sc->sc_data_direction;
drivers/scsi/xen-scsifront.c:	ring_req->timeout_per_command = sc->request->timeout / HZ;
drivers/scsi/xen-scsifront.c:		ring_req->seg[i] = shadow->seg[i];
drivers/scsi/qedf/qedf_main.c:	rval = kref_get_unless_zero(&io_req->refcount);	/* ID: 005 */
drivers/scsi/qedf/qedf_main.c:	if (!rval || io_req->sc_cmd != sc_cmd) {
drivers/scsi/qedf/qedf_main.c:			 "Freed/Incorrect io_req, io_req->sc_cmd=%p, sc_cmd=%p, port_id=%06x, bailing out.\n",
drivers/scsi/qedf/qedf_main.c:			 io_req->sc_cmd, sc_cmd, rdata->ids.port_id);
drivers/scsi/qedf/qedf_main.c:		refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_main.c:			 io_req, io_req->xid, sc_cmd, sc_cmd->cmnd[0],
drivers/scsi/qedf/qedf_main.c:			 io_req->xid, rdata->ids.port_id);
drivers/scsi/qedf/qedf_main.c:		while (io_req->sc_cmd && (wait_count != 0)) {
drivers/scsi/qedf/qedf_main.c:		 io_req, sc_cmd, io_req->xid, io_req->fp_idx,
drivers/scsi/qedf/qedf_main.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_main.c:	wait_for_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_main.c:	if (io_req->event == QEDF_IOREQ_EV_ABORT_SUCCESS ||
drivers/scsi/qedf/qedf_main.c:	    io_req->event == QEDF_IOREQ_EV_ABORT_FAILED ||
drivers/scsi/qedf/qedf_main.c:	    io_req->event == QEDF_IOREQ_EV_CLEANUP_SUCCESS) {
drivers/scsi/qedf/qedf_main.c:			  io_req->xid);
drivers/scsi/qedf/qedf_main.c:			  io_req->xid);
drivers/scsi/qedf/qedf_main.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_main.c:			cpu = io_req->cpu;
drivers/scsi/qedf/qedf_main.c:			io_req->int_cpu = smp_processor_id();
drivers/scsi/qedf/qedf_main.c:	fcport = io_req->fcport;
drivers/scsi/qedf/qedf_main.c:		switch (io_req->cmd_type) {
drivers/scsi/qedf/qedf_els.c:		   els_req->xid);
drivers/scsi/qedf/qedf_els.c:	els_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_els.c:	els_req->cmd_type = QEDF_ELS;
drivers/scsi/qedf/qedf_els.c:	els_req->fcport = fcport;
drivers/scsi/qedf/qedf_els.c:	els_req->cb_func = cb_func;
drivers/scsi/qedf/qedf_els.c:	els_req->cb_arg = cb_arg;
drivers/scsi/qedf/qedf_els.c:	els_req->data_xfer_len = data_len;
drivers/scsi/qedf/qedf_els.c:	els_req->cpu = smp_processor_id();
drivers/scsi/qedf/qedf_els.c:	mp_req = (struct qedf_mp_req *)&(els_req->mp_req);
drivers/scsi/qedf/qedf_els.c:		kref_put(&els_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:		memcpy(mp_req->req_buf, data, data_len);
drivers/scsi/qedf/qedf_els.c:		els_req->cb_func = NULL;
drivers/scsi/qedf/qedf_els.c:		els_req->cb_arg = NULL;
drivers/scsi/qedf/qedf_els.c:		kref_put(&els_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	fc_hdr = &(mp_req->req_fc_hdr);
drivers/scsi/qedf/qedf_els.c:	xid = els_req->xid;
drivers/scsi/qedf/qedf_els.c:	set_bit(QEDF_CMD_OUTSTANDING, &els_req->flags);
drivers/scsi/qedf/qedf_els.c:		   " cmd_type = %d.\n", els_req->xid, els_req->cmd_type);
drivers/scsi/qedf/qedf_els.c:	if ((els_req->event == QEDF_IOREQ_EV_ELS_FLUSH)
drivers/scsi/qedf/qedf_els.c:		|| (els_req->event == QEDF_IOREQ_EV_CLEANUP_SUCCESS)
drivers/scsi/qedf/qedf_els.c:		|| (els_req->event == QEDF_IOREQ_EV_CLEANUP_FAILED)) {
drivers/scsi/qedf/qedf_els.c:			els_req->xid, els_req->event);
drivers/scsi/qedf/qedf_els.c:	fcport = els_req->fcport;
drivers/scsi/qedf/qedf_els.c:			els_req->xid);
drivers/scsi/qedf/qedf_els.c:	clear_bit(QEDF_CMD_OUTSTANDING, &els_req->flags);
drivers/scsi/qedf/qedf_els.c:	cancel_delayed_work(&els_req->timeout_work);
drivers/scsi/qedf/qedf_els.c:	els_req->mp_req.resp_len = mp_info->data_placement_size;
drivers/scsi/qedf/qedf_els.c:	if ((els_req->cb_func) && (els_req->cb_arg)) {
drivers/scsi/qedf/qedf_els.c:		els_req->cb_func(els_req->cb_arg);
drivers/scsi/qedf/qedf_els.c:		els_req->cb_arg = NULL;
drivers/scsi/qedf/qedf_els.c:	kref_put(&els_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	qedf = rrq_req->fcport->qedf;
drivers/scsi/qedf/qedf_els.c:	refcount = kref_read(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:		   orig_io_req, orig_io_req->xid, rrq_req->xid, refcount);
drivers/scsi/qedf/qedf_els.c:		kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	if (rrq_req->event == QEDF_IOREQ_EV_ELS_TMO)
drivers/scsi/qedf/qedf_els.c:		kref_put(&rrq_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	fcport = aborted_io_req->fcport;
drivers/scsi/qedf/qedf_els.c:		refcount = kref_read(&aborted_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:			 aborted_io_req->xid, refcount);
drivers/scsi/qedf/qedf_els.c:		kref_put(&aborted_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	refcount = kref_read(&aborted_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:			  aborted_io_req->xid, aborted_io_req, refcount);
drivers/scsi/qedf/qedf_els.c:		   aborted_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	rrq.rrq_ox_id = htons(aborted_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	    htons(aborted_io_req->task->tstorm_st_context.read_write.rx_id);
drivers/scsi/qedf/qedf_els.c:			  "req 0x%x\n", aborted_io_req->xid);
drivers/scsi/qedf/qedf_els.c:		kref_put(&aborted_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	if (els_req->event == QEDF_IOREQ_EV_ELS_FLUSH) {
drivers/scsi/qedf/qedf_els.c:			 els_req->xid);
drivers/scsi/qedf/qedf_els.c:	fcport = els_req->fcport;
drivers/scsi/qedf/qedf_els.c:	mp_req = &(els_req->mp_req);
drivers/scsi/qedf/qedf_els.c:	mp_fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/qedf/qedf_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/qedf/qedf_els.c:	resp_buf = mp_req->resp_buf;
drivers/scsi/qedf/qedf_els.c:	if (els_req->event == QEDF_IOREQ_EV_ELS_TMO) {
drivers/scsi/qedf/qedf_els.c:	qedf = srr_req->fcport->qedf;
drivers/scsi/qedf/qedf_els.c:	clear_bit(QEDF_CMD_SRR_SENT, &orig_io_req->flags);
drivers/scsi/qedf/qedf_els.c:	if (srr_req->event != QEDF_IOREQ_EV_ELS_TMO &&
drivers/scsi/qedf/qedf_els.c:	    srr_req->event != QEDF_IOREQ_EV_ELS_ERR_DETECT)
drivers/scsi/qedf/qedf_els.c:		cancel_delayed_work_sync(&orig_io_req->timeout_work);
drivers/scsi/qedf/qedf_els.c:	refcount = kref_read(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:		   orig_io_req, orig_io_req->xid, srr_req->xid, refcount);
drivers/scsi/qedf/qedf_els.c:	if (srr_req->event == QEDF_IOREQ_EV_ELS_TMO) {
drivers/scsi/qedf/qedf_els.c:			 "ELS timeout rec_xid=0x%x.\n", srr_req->xid);
drivers/scsi/qedf/qedf_els.c:	mp_req = &(srr_req->mp_req);
drivers/scsi/qedf/qedf_els.c:	mp_fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/qedf/qedf_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/qedf/qedf_els.c:	resp_buf = mp_req->resp_buf;
drivers/scsi/qedf/qedf_els.c:	kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	fcport = orig_io_req->fcport;
drivers/scsi/qedf/qedf_els.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:		   "orig_xid=0x%x\n", orig_io_req, orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	srr.srr_ox_id = htons(orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	srr.srr_rx_id = htons(orig_io_req->rx_id);
drivers/scsi/qedf/qedf_els.c:			  "=0x%x\n", orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:		kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:		set_bit(QEDF_CMD_SRR_SENT, &orig_io_req->flags);
drivers/scsi/qedf/qedf_els.c:	fcport = orig_io_req->fcport;
drivers/scsi/qedf/qedf_els.c:	    orig_io_req->xid, offset);
drivers/scsi/qedf/qedf_els.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:	orig_io_req->cmd_type = QEDF_SEQ_CLEANUP;
drivers/scsi/qedf/qedf_els.c:	orig_io_req->cb_arg = cb_arg;
drivers/scsi/qedf/qedf_els.c:	orig_io_req->task_params->sqe = sqe;
drivers/scsi/qedf/qedf_els.c:	init_initiator_sequence_recovery_fcoe_task(orig_io_req->task_params,
drivers/scsi/qedf/qedf_els.c:	cb_arg = io_req->cb_arg;
drivers/scsi/qedf/qedf_els.c:	if (io_req->event == QEDF_IOREQ_EV_ELS_TMO || !cqe) {
drivers/scsi/qedf/qedf_els.c:			 "cqe is NULL or timeout event (0x%x)", io_req->event);
drivers/scsi/qedf/qedf_els.c:	cancel_delayed_work_sync(&io_req->timeout_work);
drivers/scsi/qedf/qedf_els.c:		    "abort, xid=0x%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_els.c:	kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	fcport = orig_io_req->fcport;
drivers/scsi/qedf/qedf_els.c:	if (!orig_io_req->sc_cmd) {
drivers/scsi/qedf/qedf_els.c:		    "xid=0x%x.\n", orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	new_io_req->sc_cmd = orig_io_req->sc_cmd;
drivers/scsi/qedf/qedf_els.c:	orig_io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_els.c:	kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:		    "new_xid=0x%x.\n", orig_io_req->xid, new_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	qedf = rec_req->fcport->qedf;
drivers/scsi/qedf/qedf_els.c:	if (rec_req->event != QEDF_IOREQ_EV_ELS_TMO &&
drivers/scsi/qedf/qedf_els.c:	    rec_req->event != QEDF_IOREQ_EV_ELS_ERR_DETECT)
drivers/scsi/qedf/qedf_els.c:		cancel_delayed_work_sync(&orig_io_req->timeout_work);
drivers/scsi/qedf/qedf_els.c:	refcount = kref_read(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:		   orig_io_req, orig_io_req->xid, rec_req->xid, refcount);
drivers/scsi/qedf/qedf_els.c:	if (rec_req->event == QEDF_IOREQ_EV_ELS_TMO) {
drivers/scsi/qedf/qedf_els.c:			 orig_io_req, orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	mp_req = &(rec_req->mp_req);
drivers/scsi/qedf/qedf_els.c:	mp_fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/qedf/qedf_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/qedf/qedf_els.c:	acc = resp_buf = mp_req->resp_buf;
drivers/scsi/qedf/qedf_els.c:		sc_cmd = orig_io_req->sc_cmd;
drivers/scsi/qedf/qedf_els.c:			    orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:			if (offset == orig_io_req->data_xfer_len) {
drivers/scsi/qedf/qedf_els.c:				offset = orig_io_req->tx_buf_off;
drivers/scsi/qedf/qedf_els.c:			if (orig_io_req->rx_buf_off ==
drivers/scsi/qedf/qedf_els.c:			    orig_io_req->data_xfer_len) {
drivers/scsi/qedf/qedf_els.c:	kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_els.c:	fcport = orig_io_req->fcport;
drivers/scsi/qedf/qedf_els.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/qedf/qedf_els.c:	rec.rec_ox_id = htons(orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:	    htons(orig_io_req->task->tstorm_st_context.read_write.rx_id);
drivers/scsi/qedf/qedf_els.c:	   orig_io_req->xid, rec.rec_rx_id);
drivers/scsi/qedf/qedf_els.c:			  "=0x%x\n", orig_io_req->xid);
drivers/scsi/qedf/qedf_els.c:		kref_put(&orig_io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	queue_delayed_work(qedf->timer_work_queue, &io_req->timeout_work,
drivers/scsi/qedf/qedf_io.c:	fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:	if (io_req->fcport == NULL) {
drivers/scsi/qedf/qedf_io.c:	switch (io_req->cmd_type) {
drivers/scsi/qedf/qedf_io.c:				  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		    io_req->xid);
drivers/scsi/qedf/qedf_io.c:		complete(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_IN_ABORT, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:				  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:		kref_get(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:			  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_ELS_TMO;
drivers/scsi/qedf/qedf_io.c:		if (io_req->cb_func && io_req->cb_arg) {
drivers/scsi/qedf/qedf_io.c:			io_req->cb_func(io_req->cb_arg);
drivers/scsi/qedf/qedf_io.c:			io_req->cb_arg = NULL;
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		    "xid=0x%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_ELS_TMO;
drivers/scsi/qedf/qedf_io.c:			  "Hit default case, xid=0x%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:		kfree(io_req->sgl_task_params);
drivers/scsi/qedf/qedf_io.c:		kfree(io_req->task_params);
drivers/scsi/qedf/qedf_io.c:		if (io_req->sense_buffer)
drivers/scsi/qedf/qedf_io.c:			    QEDF_SCSI_SENSE_BUFFERSIZE, io_req->sense_buffer,
drivers/scsi/qedf/qedf_io.c:			    io_req->sense_buffer_dma);
drivers/scsi/qedf/qedf_io.c:		cancel_delayed_work_sync(&io_req->rrq_work);
drivers/scsi/qedf/qedf_io.c:	atomic_set(&io_req->state, QEDFC_CMD_ST_RRQ_ACTIVE);
drivers/scsi/qedf/qedf_io.c:		INIT_DELAYED_WORK(&io_req->timeout_work, qedf_cmd_timeout);
drivers/scsi/qedf/qedf_io.c:		io_req->xid = xid++;
drivers/scsi/qedf/qedf_io.c:		INIT_DELAYED_WORK(&io_req->rrq_work, qedf_handle_rrq);
drivers/scsi/qedf/qedf_io.c:		io_req->sense_buffer = dma_alloc_coherent(&qedf->pdev->dev,
drivers/scsi/qedf/qedf_io.c:		    QEDF_SCSI_SENSE_BUFFERSIZE, &io_req->sense_buffer_dma,
drivers/scsi/qedf/qedf_io.c:		if (!io_req->sense_buffer) {
drivers/scsi/qedf/qedf_io.c:		io_req->task_params = kzalloc(sizeof(*io_req->task_params),
drivers/scsi/qedf/qedf_io.c:		if (!io_req->task_params) {
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params = kzalloc(
drivers/scsi/qedf/qedf_io.c:		if (!io_req->sgl_task_params) {
drivers/scsi/qedf/qedf_io.c:		if (!io_req->alloc)
drivers/scsi/qedf/qedf_io.c:	if (test_bit(QEDF_CMD_DIRTY, &io_req->flags))
drivers/scsi/qedf/qedf_io.c:			 io_req->xid);
drivers/scsi/qedf/qedf_io.c:	io_req->flags = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->alloc = 1;
drivers/scsi/qedf/qedf_io.c:	xid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	io_req->cmd_mgr = cmd_mgr;
drivers/scsi/qedf/qedf_io.c:	io_req->fcport = fcport;
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:	io_req->lun = -1;
drivers/scsi/qedf/qedf_io.c:	kref_init(&io_req->refcount);	/* ID: 001 */
drivers/scsi/qedf/qedf_io.c:	atomic_set(&io_req->state, QEDFC_CMD_ST_IO_ACTIVE);
drivers/scsi/qedf/qedf_io.c:	bd_tbl = io_req->bd_tbl = cmd_mgr->io_bdt_pool[xid];
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	io_req->cmd_type = cmd_type;
drivers/scsi/qedf/qedf_io.c:	io_req->tm_flags = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->rx_buf_off = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->tx_buf_off = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->rx_id = 0xffff; /* No OX_ID */
drivers/scsi/qedf/qedf_io.c:	struct qedf_mp_req *mp_req = &(io_req->mp_req);
drivers/scsi/qedf/qedf_io.c:	struct qedf_ctx *qedf = io_req->fcport->qedf;
drivers/scsi/qedf/qedf_io.c:	if (mp_req->mp_req_bd) {
drivers/scsi/qedf/qedf_io.c:		    mp_req->mp_req_bd, mp_req->mp_req_bd_dma);
drivers/scsi/qedf/qedf_io.c:		mp_req->mp_req_bd = NULL;
drivers/scsi/qedf/qedf_io.c:	if (mp_req->mp_resp_bd) {
drivers/scsi/qedf/qedf_io.c:		    mp_req->mp_resp_bd, mp_req->mp_resp_bd_dma);
drivers/scsi/qedf/qedf_io.c:		mp_req->mp_resp_bd = NULL;
drivers/scsi/qedf/qedf_io.c:	if (mp_req->req_buf) {
drivers/scsi/qedf/qedf_io.c:		    mp_req->req_buf, mp_req->req_buf_dma);
drivers/scsi/qedf/qedf_io.c:		mp_req->req_buf = NULL;
drivers/scsi/qedf/qedf_io.c:	if (mp_req->resp_buf) {
drivers/scsi/qedf/qedf_io.c:		    mp_req->resp_buf, mp_req->resp_buf_dma);
drivers/scsi/qedf/qedf_io.c:		mp_req->resp_buf = NULL;
drivers/scsi/qedf/qedf_io.c:	struct qedf_cmd_mgr *cmd_mgr = io_req->cmd_mgr;
drivers/scsi/qedf/qedf_io.c:	struct qedf_rport *fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_SCSI_CMD) {
drivers/scsi/qedf/qedf_io.c:			  io_req, io_req->xid);
drivers/scsi/qedf/qedf_io.c:		WARN_ON(io_req->sc_cmd);
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_ELS ||
drivers/scsi/qedf/qedf_io.c:	    io_req->cmd_type == QEDF_TASK_MGMT_CMD)
drivers/scsi/qedf/qedf_io.c:	atomic_set(&io_req->state, QEDF_CMD_ST_INACTIVE);
drivers/scsi/qedf/qedf_io.c:	io_req->task_retry_identifier++;
drivers/scsi/qedf/qedf_io.c:	io_req->fcport = NULL;
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_DIRTY, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	io_req->cpu = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->fcport = NULL;
drivers/scsi/qedf/qedf_io.c:	io_req->alloc = 0;
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	struct scsi_sge *bd = io_req->bd_tbl->bd_tbl;
drivers/scsi/qedf/qedf_io.c:	io_req->sge_type = QEDF_IOREQ_UNKNOWN_SGE;
drivers/scsi/qedf/qedf_io.c:	if (sg_count <= 8 || io_req->io_req_flags == QEDF_READ)
drivers/scsi/qedf/qedf_io.c:		io_req->sge_type = QEDF_IOREQ_FAST_SGE;
drivers/scsi/qedf/qedf_io.c:		if (io_req->sge_type == QEDF_IOREQ_UNKNOWN_SGE && (i) &&
drivers/scsi/qedf/qedf_io.c:			io_req->sge_type = QEDF_IOREQ_SLOW_SGE;
drivers/scsi/qedf/qedf_io.c:	if (io_req->sge_type == QEDF_IOREQ_UNKNOWN_SGE)
drivers/scsi/qedf/qedf_io.c:		io_req->sge_type = QEDF_IOREQ_FAST_SGE;
drivers/scsi/qedf/qedf_io.c:			   scsi_bufflen(sc), io_req->xid);
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	struct scsi_sge *bd = io_req->bd_tbl->bd_tbl;
drivers/scsi/qedf/qedf_io.c:	io_req->bd_tbl->bd_valid = bd_count;
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	fcp_cmnd->fc_tm_flags = io_req->tm_flags;
drivers/scsi/qedf/qedf_io.c:	fcp_cmnd->fc_flags = io_req->io_req_flags;
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_TASK_MGMT_CMD) {
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type != QEDF_TASK_MGMT_CMD)
drivers/scsi/qedf/qedf_io.c:	fcp_cmnd->fc_dl = htonl(io_req->data_xfer_len);
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	struct io_bdt *bd_tbl = io_req->bd_tbl;
drivers/scsi/qedf/qedf_io.c:	io_req->task = task_ctx;
drivers/scsi/qedf/qedf_io.c:	memset(io_req->task_params, 0, sizeof(struct fcoe_task_params));
drivers/scsi/qedf/qedf_io.c:	memset(io_req->sgl_task_params, 0, sizeof(struct scsi_sgl_task_params));
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_TASK_MGMT_CMD) {
drivers/scsi/qedf/qedf_io.c:			tx_io_size = io_req->data_xfer_len;
drivers/scsi/qedf/qedf_io.c:			rx_io_size = io_req->data_xfer_len;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->context = task_ctx;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->sqe = sqe;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->task_type = task_type;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->tx_io_size = tx_io_size;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->rx_io_size = rx_io_size;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->conn_cid = fcport->fw_cid;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->itid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->cq_rss_number = cq_idx;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->is_tape_device = fcport->dev_type;
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type != QEDF_TASK_MGMT_CMD) {
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params->sgl = bd_tbl->bd_tbl;
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params->sgl_phys_addr.lo =
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params->sgl_phys_addr.hi =
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params->num_sges = bd_count;
drivers/scsi/qedf/qedf_io.c:		io_req->sgl_task_params->total_buffer_size =
drivers/scsi/qedf/qedf_io.c:		    scsi_bufflen(io_req->sc_cmd);
drivers/scsi/qedf/qedf_io.c:		if (io_req->sge_type == QEDF_IOREQ_SLOW_SGE)
drivers/scsi/qedf/qedf_io.c:			io_req->sgl_task_params->small_mid_sge = 1;
drivers/scsi/qedf/qedf_io.c:			io_req->sgl_task_params->small_mid_sge = 0;
drivers/scsi/qedf/qedf_io.c:	sense_data_buffer_phys_addr.lo = U64_LO(io_req->sense_buffer_dma);
drivers/scsi/qedf/qedf_io.c:	sense_data_buffer_phys_addr.hi = U64_HI(io_req->sense_buffer_dma);
drivers/scsi/qedf/qedf_io.c:	init_initiator_rw_fcoe_task(io_req->task_params,
drivers/scsi/qedf/qedf_io.c:				    io_req->sgl_task_params,
drivers/scsi/qedf/qedf_io.c:				    io_req->task_retry_identifier, fcp_cmnd);
drivers/scsi/qedf/qedf_io.c:	if (io_req->sge_type == QEDF_IOREQ_SLOW_SGE)
drivers/scsi/qedf/qedf_io.c:	struct qedf_mp_req *mp_req = &(io_req->mp_req);
drivers/scsi/qedf/qedf_io.c:	struct qedf_rport *fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:	struct qedf_ctx *qedf = io_req->fcport->qedf;
drivers/scsi/qedf/qedf_io.c:		  io_req->cmd_type);
drivers/scsi/qedf/qedf_io.c:	io_req->task = task_ctx;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->context = task_ctx;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->sqe = sqe;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->task_type = FCOE_TASK_TYPE_MIDPATH;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->tx_io_size = io_req->data_xfer_len;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->rx_io_size = PAGE_SIZE;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->conn_cid = fcport->fw_cid;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->itid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->cq_rss_number = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->is_tape_device = fcport->dev_type;
drivers/scsi/qedf/qedf_io.c:	fc_hdr = &(mp_req->req_fc_hdr);
drivers/scsi/qedf/qedf_io.c:	fc_hdr->fh_ox_id = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	tx_sgl_task_params.sgl = mp_req->mp_req_bd;
drivers/scsi/qedf/qedf_io.c:	tx_sgl_task_params.sgl_phys_addr.lo = U64_LO(mp_req->mp_req_bd_dma);
drivers/scsi/qedf/qedf_io.c:	tx_sgl_task_params.sgl_phys_addr.hi = U64_HI(mp_req->mp_req_bd_dma);
drivers/scsi/qedf/qedf_io.c:	tx_sgl_task_params.total_buffer_size = io_req->data_xfer_len;
drivers/scsi/qedf/qedf_io.c:	rx_sgl_task_params.sgl = mp_req->mp_resp_bd;
drivers/scsi/qedf/qedf_io.c:	rx_sgl_task_params.sgl_phys_addr.lo = U64_LO(mp_req->mp_resp_bd_dma);
drivers/scsi/qedf/qedf_io.c:	rx_sgl_task_params.sgl_phys_addr.hi = U64_HI(mp_req->mp_resp_bd_dma);
drivers/scsi/qedf/qedf_io.c:	init_initiator_midpath_unsolicited_fcoe_task(io_req->task_params,
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	io_log->task_id = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	io_log->refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:		io_log->req_cpu = io_req->cpu;
drivers/scsi/qedf/qedf_io.c:		io_log->req_cpu = io_req->cpu;
drivers/scsi/qedf/qedf_io.c:		io_log->int_cpu = io_req->int_cpu;
drivers/scsi/qedf/qedf_io.c:	io_log->sge_type = io_req->sge_type;
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	io_req->data_xfer_len = scsi_bufflen(sc_cmd);
drivers/scsi/qedf/qedf_io.c:	io_req->sge_type = QEDF_IOREQ_FAST_SGE; /* Assume fast SGL by default */
drivers/scsi/qedf/qedf_io.c:	io_req->cpu = smp_processor_id();
drivers/scsi/qedf/qedf_io.c:		io_req->io_req_flags = QEDF_READ;
drivers/scsi/qedf/qedf_io.c:		io_req->io_req_flags = QEDF_WRITE;
drivers/scsi/qedf/qedf_io.c:		io_req->io_req_flags = 0;
drivers/scsi/qedf/qedf_io.c:	xid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:		io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	io_req->lun = (int)sc_cmd->device->lun;
drivers/scsi/qedf/qedf_io.c:		io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	set_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	if (qedf_io_tracing && io_req->sc_cmd)
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = sc_cmd;
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	struct qedf_ctx *qedf = io_req->fcport->qedf;
drivers/scsi/qedf/qedf_io.c:	io_req->fcp_status = FC_GOOD;
drivers/scsi/qedf/qedf_io.c:	io_req->fcp_resid = 0;
drivers/scsi/qedf/qedf_io.c:		io_req->fcp_resid = fcp_rsp->fcp_resid;
drivers/scsi/qedf/qedf_io.c:	io_req->scsi_comp_flags = rsp_flags;
drivers/scsi/qedf/qedf_io.c:	CMD_SCSI_STATUS(sc_cmd) = io_req->cdb_status =
drivers/scsi/qedf/qedf_io.c:	io_req->fcp_rsp_len = fcp_rsp_len;
drivers/scsi/qedf/qedf_io.c:	io_req->fcp_sns_len = fcp_sns_len;
drivers/scsi/qedf/qedf_io.c:	rsp_info = sense_data = io_req->sense_buffer;
drivers/scsi/qedf/qedf_io.c:		io_req->fcp_rsp_code = rsp_info[3];
drivers/scsi/qedf/qedf_io.c:		    "fcp_rsp_code = %d\n", io_req->fcp_rsp_code);
drivers/scsi/qedf/qedf_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	if (io_req->bd_tbl->bd_valid && sc && scsi_sg_count(sc)) {
drivers/scsi/qedf/qedf_io.c:		io_req->bd_tbl->bd_valid = 0;
drivers/scsi/qedf/qedf_io.c:	if (!test_bit(QEDF_CMD_OUTSTANDING, &io_req->flags) ||
drivers/scsi/qedf/qedf_io.c:	    test_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags) ||
drivers/scsi/qedf/qedf_io.c:	    test_bit(QEDF_CMD_IN_ABORT, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:			 io_req->xid);
drivers/scsi/qedf/qedf_io.c:	sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:			  io_req->xid);
drivers/scsi/qedf/qedf_io.c:	if (io_req->fcp_rsp_len > 3 && io_req->fcp_rsp_code) {
drivers/scsi/qedf/qedf_io.c:		    "fcp_rsp_code=%d.\n", io_req->xid, io_req->fcp_rsp_len,
drivers/scsi/qedf/qedf_io.c:		    io_req->fcp_rsp_code);
drivers/scsi/qedf/qedf_io.c:			 io_req->xid, fcp_rsp->rsp_flags.flags,
drivers/scsi/qedf/qedf_io.c:			 io_req->fcp_resid,
drivers/scsi/qedf/qedf_io.c:		if (io_req->cdb_status == 0)
drivers/scsi/qedf/qedf_io.c:			sc_cmd->result = (DID_ERROR << 16) | io_req->cdb_status;
drivers/scsi/qedf/qedf_io.c:			sc_cmd->result = (DID_OK << 16) | io_req->cdb_status;
drivers/scsi/qedf/qedf_io.c:	switch (io_req->fcp_status) {
drivers/scsi/qedf/qedf_io.c:		if (io_req->cdb_status == 0) {
drivers/scsi/qedf/qedf_io.c:			refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:			    sc_cmd->device->lun, io_req->xid,
drivers/scsi/qedf/qedf_io.c:			    io_req->cdb_status, io_req->fcp_resid,
drivers/scsi/qedf/qedf_io.c:			sc_cmd->result = (DID_OK << 16) | io_req->cdb_status;
drivers/scsi/qedf/qedf_io.c:			if (io_req->cdb_status == SAM_STAT_TASK_SET_FULL ||
drivers/scsi/qedf/qedf_io.c:			    io_req->cdb_status == SAM_STAT_BUSY) {
drivers/scsi/qedf/qedf_io.c:				if (io_req->cdb_status ==
drivers/scsi/qedf/qedf_io.c:		if (io_req->fcp_resid)
drivers/scsi/qedf/qedf_io.c:			scsi_set_resid(sc_cmd, io_req->fcp_resid);
drivers/scsi/qedf/qedf_io.c:			   io_req->fcp_status);
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:	kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	if (test_and_set_bit(QEDF_CMD_ERR_SCSI_DONE, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	sc_cmd = io_req->sc_cmd;
drivers/scsi/qedf/qedf_io.c:	refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:		qedf_trace_io(io_req->fcport, io_req, QEDF_IO_TRACE_RSP);
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:	kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	 * Clear the io_req->sc_cmd backpointer so we don't try to process
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:	kref_put(&io_req->refcount, qedf_release_cmd);  /* ID: 001 */
drivers/scsi/qedf/qedf_io.c:	struct qedf_rport *fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:			  io_req, io_req->xid);
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx), "Warning CQE, "
drivers/scsi/qedf/qedf_io.c:		  "xid=0x%x\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx),
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx), "tx_buff_off=%08x, "
drivers/scsi/qedf/qedf_io.c:			if (!test_bit(QEDF_CMD_SRR_SENT, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:				io_req->rx_buf_off =
drivers/scsi/qedf/qedf_io.c:				io_req->tx_buf_off =
drivers/scsi/qedf/qedf_io.c:				io_req->rx_id = cqe->cqe_info.err_info.rx_id;
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx), "Error detection CQE, "
drivers/scsi/qedf/qedf_io.c:		  "xid=0x%x\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx),
drivers/scsi/qedf/qedf_io.c:	QEDF_ERR(&(io_req->fcport->qedf->dbg_ctx), "tx_buff_off=%08x, "
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:	    "Flushing ELS request xid=0x%x refcount=%d.\n", els_req->xid,
drivers/scsi/qedf/qedf_io.c:	    kref_read(&els_req->refcount));
drivers/scsi/qedf/qedf_io.c:	 * els_req->cb_func.
drivers/scsi/qedf/qedf_io.c:	els_req->event = QEDF_IOREQ_EV_ELS_FLUSH;
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_OUTSTANDING, &els_req->flags);
drivers/scsi/qedf/qedf_io.c:	cancel_delayed_work_sync(&els_req->timeout_work);
drivers/scsi/qedf/qedf_io.c:	if (els_req->cb_func && els_req->cb_arg) {
drivers/scsi/qedf/qedf_io.c:		els_req->cb_func(els_req->cb_arg);
drivers/scsi/qedf/qedf_io.c:		els_req->cb_arg = NULL;
drivers/scsi/qedf/qedf_io.c:	kref_put(&els_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		if (!io_req->fcport)
drivers/scsi/qedf/qedf_io.c:		if (io_req->alloc) {
drivers/scsi/qedf/qedf_io.c:			if (!test_bit(QEDF_CMD_OUTSTANDING, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:				if (io_req->cmd_type == QEDF_SCSI_CMD)
drivers/scsi/qedf/qedf_io.c:						 io_req->xid);
drivers/scsi/qedf/qedf_io.c:		if (io_req->fcport != fcport)
drivers/scsi/qedf/qedf_io.c:		if (!test_bit(QEDF_CMD_OUTSTANDING, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:			refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:				  io_req->xid, io_req->cmd_type, refcount);
drivers/scsi/qedf/qedf_io.c:			if (atomic_read(&io_req->state) ==
drivers/scsi/qedf/qedf_io.c:				    (&io_req->rrq_work)) {
drivers/scsi/qedf/qedf_io.c:						  io_req->xid);
drivers/scsi/qedf/qedf_io.c:					kref_put(&io_req->refcount,
drivers/scsi/qedf/qedf_io.c:		if (io_req->cmd_type == QEDF_ELS &&
drivers/scsi/qedf/qedf_io.c:			rc = kref_get_unless_zero(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:				    io_req, io_req->xid);
drivers/scsi/qedf/qedf_io.c:		if (io_req->cmd_type == QEDF_ABTS) {
drivers/scsi/qedf/qedf_io.c:			rc = kref_get_unless_zero(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:				    io_req, io_req->xid);
drivers/scsi/qedf/qedf_io.c:			if (lun != -1 && io_req->lun != lun)
drivers/scsi/qedf/qedf_io.c:			    "Flushing abort xid=0x%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:			if (cancel_delayed_work_sync(&io_req->rrq_work)) {
drivers/scsi/qedf/qedf_io.c:					  io_req->xid);
drivers/scsi/qedf/qedf_io.c:				kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:			if (cancel_delayed_work_sync(&io_req->timeout_work)) {
drivers/scsi/qedf/qedf_io.c:					  io_req->xid);
drivers/scsi/qedf/qedf_io.c:				complete(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:				clear_bit(QEDF_CMD_IN_ABORT, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:				kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		if (!io_req->sc_cmd)
drivers/scsi/qedf/qedf_io.c:		if (!io_req->sc_cmd->device) {
drivers/scsi/qedf/qedf_io.c:				  io_req->sc_cmd);
drivers/scsi/qedf/qedf_io.c:			io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:			kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:			if (io_req->lun != lun)
drivers/scsi/qedf/qedf_io.c:		rc = kref_get_unless_zero(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:			    "io_req=0x%p xid=0x%x\n", io_req, io_req->xid);
drivers/scsi/qedf/qedf_io.c:		    "Cleanup xid=0x%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:		kref_put(&io_req->refcount, qedf_release_cmd);	/* ID: 004 */
drivers/scsi/qedf/qedf_io.c:					if (io_req->fcport &&
drivers/scsi/qedf/qedf_io.c:					    io_req->fcport == fcport) {
drivers/scsi/qedf/qedf_io.c:						kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:							&io_req->flags);
drivers/scsi/qedf/qedf_io.c:							 io_req, io_req->xid,
drivers/scsi/qedf/qedf_io.c:							 io_req->flags,
drivers/scsi/qedf/qedf_io.c:							 io_req->sc_cmd,
drivers/scsi/qedf/qedf_io.c:							 io_req->cmd_type);
drivers/scsi/qedf/qedf_io.c:	struct qedf_rport *fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:	if (!test_bit(QEDF_CMD_OUTSTANDING, &io_req->flags) ||
drivers/scsi/qedf/qedf_io.c:	    test_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags) ||
drivers/scsi/qedf/qedf_io.c:	    test_bit(QEDF_CMD_IN_ABORT, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:			 io_req->xid, io_req->sc_cmd);
drivers/scsi/qedf/qedf_io.c:	kref_get(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:	xid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	io_req->cmd_type = QEDF_ABTS;
drivers/scsi/qedf/qedf_io.c:	io_req->return_scsi_cmd_on_abts = return_scsi_cmd_on_abts;
drivers/scsi/qedf/qedf_io.c:	set_bit(QEDF_CMD_IN_ABORT, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->sqe = sqe;
drivers/scsi/qedf/qedf_io.c:	init_initiator_abort_fcoe_task(io_req->task_params);
drivers/scsi/qedf/qedf_io.c:	struct qedf_rport *fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:		   "0x%x cmd_type = %d\n", io_req->xid, io_req->cmd_type);
drivers/scsi/qedf/qedf_io.c:			  io_req->xid);
drivers/scsi/qedf/qedf_io.c:			  io_req->xid);
drivers/scsi/qedf/qedf_io.c:	if (!cancel_delayed_work(&io_req->timeout_work)) {
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_ABORT_SUCCESS;
drivers/scsi/qedf/qedf_io.c:		rc = kref_get_unless_zero(&io_req->refcount);	/* ID: 003 */
drivers/scsi/qedf/qedf_io.c:				  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		queue_delayed_work(qedf->dpc_wq, &io_req->rrq_work,
drivers/scsi/qedf/qedf_io.c:		atomic_set(&io_req->state, QEDFC_CMD_ST_RRQ_WAIT);
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_ABORT_FAILED;
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_IN_ABORT, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	if (io_req->sc_cmd) {
drivers/scsi/qedf/qedf_io.c:		if (!io_req->return_scsi_cmd_on_abts)
drivers/scsi/qedf/qedf_io.c:				  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		if (io_req->return_scsi_cmd_on_abts)
drivers/scsi/qedf/qedf_io.c:	complete(&io_req->abts_done);
drivers/scsi/qedf/qedf_io.c:	kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:	struct qedf_ctx *qedf = io_req->fcport->qedf;
drivers/scsi/qedf/qedf_io.c:	mp_req = (struct qedf_mp_req *)&(io_req->mp_req);
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type != QEDF_ELS) {
drivers/scsi/qedf/qedf_io.c:		mp_req->req_len = sizeof(struct fcp_cmnd);
drivers/scsi/qedf/qedf_io.c:		io_req->data_xfer_len = mp_req->req_len;
drivers/scsi/qedf/qedf_io.c:		mp_req->req_len = io_req->data_xfer_len;
drivers/scsi/qedf/qedf_io.c:	mp_req->req_buf = dma_alloc_coherent(&qedf->pdev->dev, QEDF_PAGE_SIZE,
drivers/scsi/qedf/qedf_io.c:	    &mp_req->req_buf_dma, GFP_KERNEL);
drivers/scsi/qedf/qedf_io.c:	if (!mp_req->req_buf) {
drivers/scsi/qedf/qedf_io.c:	mp_req->resp_buf = dma_alloc_coherent(&qedf->pdev->dev,
drivers/scsi/qedf/qedf_io.c:	    QEDF_PAGE_SIZE, &mp_req->resp_buf_dma, GFP_KERNEL);
drivers/scsi/qedf/qedf_io.c:	if (!mp_req->resp_buf) {
drivers/scsi/qedf/qedf_io.c:	mp_req->mp_req_bd = dma_alloc_coherent(&qedf->pdev->dev, sz,
drivers/scsi/qedf/qedf_io.c:	    &mp_req->mp_req_bd_dma, GFP_KERNEL);
drivers/scsi/qedf/qedf_io.c:	if (!mp_req->mp_req_bd) {
drivers/scsi/qedf/qedf_io.c:	mp_req->mp_resp_bd = dma_alloc_coherent(&qedf->pdev->dev, sz,
drivers/scsi/qedf/qedf_io.c:	    &mp_req->mp_resp_bd_dma, GFP_KERNEL);
drivers/scsi/qedf/qedf_io.c:	if (!mp_req->mp_resp_bd) {
drivers/scsi/qedf/qedf_io.c:	addr = mp_req->req_buf_dma;
drivers/scsi/qedf/qedf_io.c:	mp_req_bd = mp_req->mp_req_bd;
drivers/scsi/qedf/qedf_io.c:	mp_resp_bd = mp_req->mp_resp_bd;
drivers/scsi/qedf/qedf_io.c:	addr = mp_req->resp_buf_dma;
drivers/scsi/qedf/qedf_io.c:	fcport = io_req->fcport;
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_ELS) {
drivers/scsi/qedf/qedf_io.c:	if (!test_bit(QEDF_CMD_OUTSTANDING, &io_req->flags) ||
drivers/scsi/qedf/qedf_io.c:	    test_and_set_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags)) {
drivers/scsi/qedf/qedf_io.c:			  io_req->xid);
drivers/scsi/qedf/qedf_io.c:	set_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	if (io_req->cmd_type == QEDF_CLEANUP) {
drivers/scsi/qedf/qedf_io.c:			 io_req->xid, io_req->cmd_type);
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	refcount = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:		  io_req->xid, io_req->sc_cmd, io_req->cmd_type, io_req->flags,
drivers/scsi/qedf/qedf_io.c:	io_req->cmd_type = QEDF_CLEANUP;
drivers/scsi/qedf/qedf_io.c:	io_req->return_scsi_cmd_on_abts = return_scsi_cmd_on_abts;
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/qedf/qedf_io.c:	io_req->task_params->sqe = sqe;
drivers/scsi/qedf/qedf_io.c:	init_initiator_cleanup_fcoe_task(io_req->task_params);
drivers/scsi/qedf/qedf_io.c:	tmo = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/qedf/qedf_io.c:			  "xid=%x.\n", io_req->xid);
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	if (io_req->tm_flags  == FCP_TMF_LUN_RESET ||
drivers/scsi/qedf/qedf_io.c:	    io_req->tm_flags == FCP_TMF_TGT_RESET) {
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:		io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:		complete(&io_req->tm_done);
drivers/scsi/qedf/qedf_io.c:	if (io_req->sc_cmd) {
drivers/scsi/qedf/qedf_io.c:		if (!io_req->return_scsi_cmd_on_abts)
drivers/scsi/qedf/qedf_io.c:				  io_req->xid);
drivers/scsi/qedf/qedf_io.c:		if (io_req->return_scsi_cmd_on_abts)
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_CLEANUP_SUCCESS;
drivers/scsi/qedf/qedf_io.c:		io_req->event = QEDF_IOREQ_EV_CLEANUP_FAILED;
drivers/scsi/qedf/qedf_io.c:		   io_req->xid);
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_IN_CLEANUP, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	complete(&io_req->cleanup_done);
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = sc_cmd;
drivers/scsi/qedf/qedf_io.c:	io_req->fcport = fcport;
drivers/scsi/qedf/qedf_io.c:	io_req->cmd_type = QEDF_TASK_MGMT_CMD;
drivers/scsi/qedf/qedf_io.c:	io_req->cpu = smp_processor_id();
drivers/scsi/qedf/qedf_io.c:	io_req->io_req_flags = QEDF_READ;
drivers/scsi/qedf/qedf_io.c:	io_req->data_xfer_len = 0;
drivers/scsi/qedf/qedf_io.c:	io_req->tm_flags = tm_flags;
drivers/scsi/qedf/qedf_io.c:	io_req->return_scsi_cmd_on_abts = false;
drivers/scsi/qedf/qedf_io.c:	xid = io_req->xid;
drivers/scsi/qedf/qedf_io.c:	init_completion(&io_req->tm_done);
drivers/scsi/qedf/qedf_io.c:	set_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	tmo = wait_for_completion_timeout(&io_req->tm_done,
drivers/scsi/qedf/qedf_io.c:		clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:		io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:		if (io_req->fcp_rsp_code == 0)
drivers/scsi/qedf/qedf_io.c:	kref_put(&io_req->refcount, qedf_release_cmd);
drivers/scsi/qedf/qedf_io.c:		ref_cnt = kref_read(&io_req->refcount);
drivers/scsi/qedf/qedf_io.c:			 io_req, io_req->xid, ref_cnt);
drivers/scsi/qedf/qedf_io.c:	clear_bit(QEDF_CMD_OUTSTANDING, &io_req->flags);
drivers/scsi/qedf/qedf_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/qedf/qedf_io.c:	complete(&io_req->tm_done);
drivers/scsi/qla4xxx/ql4_bsg.c:	offset = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	offset = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	options = bsg_req->rqst_data.h_vendor.vendor_cmd[2];
drivers/scsi/qla4xxx/ql4_bsg.c:	acb_idx = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	ip_idx = bsg_req->rqst_data.h_vendor.vendor_cmd[2];
drivers/scsi/qla4xxx/ql4_bsg.c:	offset = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	offset = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	region = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	field0 = bsg_req->rqst_data.h_vendor.vendor_cmd[2];
drivers/scsi/qla4xxx/ql4_bsg.c:	field1 = bsg_req->rqst_data.h_vendor.vendor_cmd[3];
drivers/scsi/qla4xxx/ql4_bsg.c:	acb_type = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:	memcpy(mbox_cmd, &bsg_req->rqst_data.h_vendor.vendor_cmd[1],
drivers/scsi/qla4xxx/ql4_bsg.c:	memcpy(mbox_cmd, &bsg_req->rqst_data.h_vendor.vendor_cmd[1],
drivers/scsi/qla4xxx/ql4_bsg.c:	diag_cmd = bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/qla4xxx/ql4_bsg.c:		switch (bsg_req->rqst_data.h_vendor.vendor_cmd[2]) {
drivers/scsi/qla4xxx/ql4_bsg.c:				   bsg_req->rqst_data.h_vendor.vendor_cmd[2]);
drivers/scsi/qla4xxx/ql4_bsg.c:	switch (bsg_req->rqst_data.h_vendor.vendor_cmd[0]) {
drivers/scsi/qla4xxx/ql4_bsg.c:			   "0x%x\n", __func__, bsg_req->msgcode);
drivers/scsi/qla4xxx/ql4_bsg.c:	switch (bsg_req->msgcode) {
drivers/scsi/qla4xxx/ql4_bsg.c:			   __func__, bsg_req->msgcode);
drivers/scsi/fnic/fnic_scsi.c:	if (io_req->sgl_list_pa)
drivers/scsi/fnic/fnic_scsi.c:		dma_unmap_single(&fnic->pdev->dev, io_req->sgl_list_pa,
drivers/scsi/fnic/fnic_scsi.c:				 sizeof(io_req->sgl_list[0]) * io_req->sgl_cnt,
drivers/scsi/fnic/fnic_scsi.c:	if (io_req->sgl_cnt)
drivers/scsi/fnic/fnic_scsi.c:		mempool_free(io_req->sgl_list_alloc,
drivers/scsi/fnic/fnic_scsi.c:			     fnic->io_sgl_pool[io_req->sgl_type]);
drivers/scsi/fnic/fnic_scsi.c:	if (io_req->sense_buf_pa)
drivers/scsi/fnic/fnic_scsi.c:		dma_unmap_single(&fnic->pdev->dev, io_req->sense_buf_pa,
drivers/scsi/fnic/fnic_scsi.c:		desc = io_req->sgl_list;
drivers/scsi/fnic/fnic_scsi.c:		io_req->sgl_list_pa = dma_map_single(&fnic->pdev->dev,
drivers/scsi/fnic/fnic_scsi.c:				io_req->sgl_list,
drivers/scsi/fnic/fnic_scsi.c:				sizeof(io_req->sgl_list[0]) * sg_count,
drivers/scsi/fnic/fnic_scsi.c:		if (dma_mapping_error(&fnic->pdev->dev, io_req->sgl_list_pa)) {
drivers/scsi/fnic/fnic_scsi.c:	io_req->sense_buf_pa = dma_map_single(&fnic->pdev->dev,
drivers/scsi/fnic/fnic_scsi.c:	if (dma_mapping_error(&fnic->pdev->dev, io_req->sense_buf_pa)) {
drivers/scsi/fnic/fnic_scsi.c:		dma_unmap_single(&fnic->pdev->dev, io_req->sgl_list_pa,
drivers/scsi/fnic/fnic_scsi.c:				sizeof(io_req->sgl_list[0]) * sg_count,
drivers/scsi/fnic/fnic_scsi.c:					 0, exch_flags, io_req->sgl_cnt,
drivers/scsi/fnic/fnic_scsi.c:					 io_req->sgl_list_pa,
drivers/scsi/fnic/fnic_scsi.c:					 io_req->sense_buf_pa,
drivers/scsi/fnic/fnic_scsi.c:					 fc_lun.scsi_lun, io_req->port_id,
drivers/scsi/fnic/fnic_scsi.c:	io_req->sgl_cnt = sg_count;
drivers/scsi/fnic/fnic_scsi.c:	io_req->sgl_type = FNIC_SGL_CACHE_DFLT;
drivers/scsi/fnic/fnic_scsi.c:		io_req->sgl_type = FNIC_SGL_CACHE_MAX;
drivers/scsi/fnic/fnic_scsi.c:		io_req->sgl_list =
drivers/scsi/fnic/fnic_scsi.c:			mempool_alloc(fnic->io_sgl_pool[io_req->sgl_type],
drivers/scsi/fnic/fnic_scsi.c:		if (!io_req->sgl_list) {
drivers/scsi/fnic/fnic_scsi.c:		io_req->sgl_list_alloc = io_req->sgl_list;
drivers/scsi/fnic/fnic_scsi.c:		ptr = (unsigned long) io_req->sgl_list;
drivers/scsi/fnic/fnic_scsi.c:			io_req->sgl_list = (struct host_sg_desc *)
drivers/scsi/fnic/fnic_scsi.c:	io_req->port_id = rport->port_id;
drivers/scsi/fnic/fnic_scsi.c:	io_req->start_time = jiffies;
drivers/scsi/fnic/fnic_scsi.c:	start_time = io_req->start_time;
drivers/scsi/fnic/fnic_scsi.c:	io_req->io_completed = 1;
drivers/scsi/fnic/fnic_scsi.c:	start_time = io_req->start_time;
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->abts_done)
drivers/scsi/fnic/fnic_scsi.c:			complete(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->abts_done) {
drivers/scsi/fnic/fnic_scsi.c:			complete(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->dr_done)
drivers/scsi/fnic/fnic_scsi.c:			complete(io_req->dr_done);
drivers/scsi/fnic/fnic_scsi.c:			if (io_req && io_req->dr_done)
drivers/scsi/fnic/fnic_scsi.c:				complete(io_req->dr_done);
drivers/scsi/fnic/fnic_scsi.c:			else if (io_req && io_req->abts_done)
drivers/scsi/fnic/fnic_scsi.c:				complete(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:		start_time = io_req->start_time;
drivers/scsi/fnic/fnic_scsi.c:	start_time = io_req->start_time;
drivers/scsi/fnic/fnic_scsi.c:				     0, task_req, tag, fc_lun, io_req->port_id,
drivers/scsi/fnic/fnic_scsi.c:		if (!io_req || io_req->port_id != port_id) {
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->abts_done) {
drivers/scsi/fnic/fnic_scsi.c:			"fnic_rport_exch_reset: io_req->abts_done is set "
drivers/scsi/fnic/fnic_scsi.c:		BUG_ON(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->abts_done) {
drivers/scsi/fnic/fnic_scsi.c:			"fnic_terminate_rport_io: io_req->abts_done is set "
drivers/scsi/fnic/fnic_scsi.c:		BUG_ON(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:	io_req->abts_done = &tm_done;
drivers/scsi/fnic/fnic_scsi.c:	abt_issued_time = jiffies_to_msecs(jiffies) - jiffies_to_msecs(io_req->start_time);
drivers/scsi/fnic/fnic_scsi.c:			io_req->abts_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:	io_req->abts_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:	start_time = io_req->start_time;
drivers/scsi/fnic/fnic_scsi.c:				     fc_lun.scsi_lun, io_req->port_id,
drivers/scsi/fnic/fnic_scsi.c:		if (io_req->abts_done)
drivers/scsi/fnic/fnic_scsi.c:			  "%s: io_req->abts_done is set state is %s\n",
drivers/scsi/fnic/fnic_scsi.c:		BUG_ON(io_req->abts_done);
drivers/scsi/fnic/fnic_scsi.c:		io_req->abts_done = &tm_done;
drivers/scsi/fnic/fnic_scsi.c:				io_req->abts_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:		io_req->abts_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:		io_req->port_id = rport->port_id;
drivers/scsi/fnic/fnic_scsi.c:	io_req->dr_done = &tm_done;
drivers/scsi/fnic/fnic_scsi.c:			io_req->dr_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:	io_req->dr_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:				io_req->abts_done = &tm_done;
drivers/scsi/fnic/fnic_scsi.c:				io_req->abts_done = NULL;
drivers/scsi/fnic/fnic_scsi.c:		start_time = io_req->start_time;
drivers/scsi/scsi_lib.c:	req->timeout = timeout;
drivers/scsi/scsi_lib.c:	req->cmd_flags |= flags;
drivers/scsi/scsi_lib.c:	req->rq_flags |= rq_flags | RQF_QUIET;
drivers/scsi/scsi_lib.c:		add_disk_randomness(req->rq_disk);
drivers/scsi/scsi_lib.c:	wait_for = (cmd->allowed + 1) * req->timeout;
drivers/scsi/scsi_lib.c:		if (!(req->rq_flags & RQF_QUIET)) {
drivers/scsi/scsi_lib.c:	 * we already took a copy of the original into sreq->result which
drivers/scsi/scsi_lib.c:		else if (req->rq_flags & RQF_QUIET)
drivers/scsi/scsi_lib.c:	if (req->bio) {
drivers/scsi/scsi_lib.c:		if (req && WARN_ON_ONCE(!(req->rq_flags & RQF_PM)))
drivers/scsi/scsi_lib.c:		if (req && !(req->rq_flags & RQF_PM))
drivers/scsi/scsi_lib.c:	struct scsi_device *sdev = req->q->queuedata;
drivers/scsi/scsi_lib.c:	cmd->tag = req->tag;
drivers/scsi/scsi_lib.c:	struct request_queue *q = req->q;
drivers/scsi/scsi_lib.c:	if (!(req->rq_flags & RQF_DONTPREP)) {
drivers/scsi/scsi_lib.c:		req->rq_flags |= RQF_DONTPREP;
drivers/scsi/scsi_lib.c:		if (req->rq_flags & RQF_DONTPREP)
drivers/scsi/scsi_lib.c:		if (req->rq_flags & RQF_DONTPREP)
drivers/scsi/sg.c:	sense = req->sense;
drivers/scsi/sg.c:	result = req->result;
drivers/scsi/sg.c:	resid = req->resid_len;
drivers/scsi/sg.c:	if (req->sense_len)
drivers/scsi/sg.c:		memcpy(srp->sense_b, req->sense, SCSI_SENSE_BUFFERSIZE);
drivers/scsi/sg.c:		req->cmd = long_cmdp;
drivers/scsi/sg.c:	memcpy(req->cmd, cmd, hp->cmd_len);
drivers/scsi/sg.c:	req->cmd_len = hp->cmd_len;
drivers/scsi/sg.c:	req->retries = SG_DEFAULT_RETRIES;
drivers/scsi/sg.c:				      "sg_unlink_reserve: req->k_use_sg=%d\n",
drivers/scsi/mvsas/mv_sas.c:			mvi_dev->running_req--;
drivers/scsi/mvsas/mv_sas.c:		mvi_dev->running_req--;
drivers/scsi/qla2xxx/qla_nx2.c:		ha->isp_ops->get_flash_version(vha, vha->req->ring);
drivers/scsi/qla2xxx/qla_mid.c:	host->can_queue = base_vha->req->length + 128;
drivers/scsi/qla2xxx/qla_mid.c:	uint16_t que_id = req->id;
drivers/scsi/qla2xxx/qla_mid.c:	dma_free_coherent(&ha->pdev->dev, (req->length + 1) *
drivers/scsi/qla2xxx/qla_mid.c:		sizeof(request_t), req->ring, req->dma);
drivers/scsi/qla2xxx/qla_mid.c:	req->ring = NULL;
drivers/scsi/qla2xxx/qla_mid.c:	req->dma = 0;
drivers/scsi/qla2xxx/qla_mid.c:	kfree(req->outstanding_cmds);
drivers/scsi/qla2xxx/qla_mid.c:		req->options |= BIT_0;
drivers/scsi/qla2xxx/qla_mid.c:					    req->id);
drivers/scsi/qla2xxx/qla_mid.c:	req->length = REQUEST_ENTRY_CNT_24XX;
drivers/scsi/qla2xxx/qla_mid.c:	req->ring = dma_alloc_coherent(&ha->pdev->dev,
drivers/scsi/qla2xxx/qla_mid.c:			(req->length + 1) * sizeof(request_t),
drivers/scsi/qla2xxx/qla_mid.c:			&req->dma, GFP_KERNEL);
drivers/scsi/qla2xxx/qla_mid.c:	if (req->ring == NULL) {
drivers/scsi/qla2xxx/qla_mid.c:	req->rid = rid;
drivers/scsi/qla2xxx/qla_mid.c:	req->vp_idx = vp_idx;
drivers/scsi/qla2xxx/qla_mid.c:	req->qos = qos;
drivers/scsi/qla2xxx/qla_mid.c:	    que_id, req->rid, req->vp_idx, req->qos);
drivers/scsi/qla2xxx/qla_mid.c:	    que_id, req->rid, req->vp_idx, req->qos);
drivers/scsi/qla2xxx/qla_mid.c:		req->rsp = NULL;
drivers/scsi/qla2xxx/qla_mid.c:		req->rsp = ha->rsp_q_map[rsp_que];
drivers/scsi/qla2xxx/qla_mid.c:	if (MSB(req->rid))
drivers/scsi/qla2xxx/qla_mid.c:	if (LSB(req->rid))
drivers/scsi/qla2xxx/qla_mid.c:	req->options = options;
drivers/scsi/qla2xxx/qla_mid.c:	    "options=0x%x.\n", req->options);
drivers/scsi/qla2xxx/qla_mid.c:	    "options=0x%x.\n", req->options);
drivers/scsi/qla2xxx/qla_mid.c:	for (cnt = 1; cnt < req->num_outstanding_cmds; cnt++)
drivers/scsi/qla2xxx/qla_mid.c:		req->outstanding_cmds[cnt] = NULL;
drivers/scsi/qla2xxx/qla_mid.c:	req->current_outstanding_cmd = 1;
drivers/scsi/qla2xxx/qla_mid.c:	req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_mid.c:	req->ring_index = 0;
drivers/scsi/qla2xxx/qla_mid.c:	req->cnt = req->length;
drivers/scsi/qla2xxx/qla_mid.c:	req->id = que_id;
drivers/scsi/qla2xxx/qla_mid.c:	req->req_q_in = &reg->isp25mq.req_q_in;
drivers/scsi/qla2xxx/qla_mid.c:	req->req_q_out = &reg->isp25mq.req_q_out;
drivers/scsi/qla2xxx/qla_mid.c:	req->max_q_depth = ha->req_q_map[0]->max_q_depth;
drivers/scsi/qla2xxx/qla_mid.c:	req->out_ptr = (uint16_t *)(req->ring + req->length);
drivers/scsi/qla2xxx/qla_mid.c:	    req->ring_ptr, req->ring_index,
drivers/scsi/qla2xxx/qla_mid.c:	    req->cnt, req->id, req->max_q_depth);
drivers/scsi/qla2xxx/qla_mid.c:	    req->ring_ptr, req->ring_index, req->cnt,
drivers/scsi/qla2xxx/qla_mid.c:	    req->id, req->max_q_depth);
drivers/scsi/qla2xxx/qla_mid.c:	return req->id;
drivers/scsi/qla2xxx/qla_mbx.c:	for (handle = 1; handle < req->num_outstanding_cmds; handle++) {
drivers/scsi/qla2xxx/qla_mbx.c:		if (req->outstanding_cmds[handle] == sp)
drivers/scsi/qla2xxx/qla_mbx.c:	if (handle == req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_mbx.c:	lg->handle = make_handle(req->id, lg->handle);
drivers/scsi/qla2xxx/qla_mbx.c:	lg->handle = make_handle(req->id, lg->handle);
drivers/scsi/qla2xxx/qla_mbx.c:	for (handle = 1; handle < req->num_outstanding_cmds; handle++) {
drivers/scsi/qla2xxx/qla_mbx.c:		if (req->outstanding_cmds[handle] == sp)
drivers/scsi/qla2xxx/qla_mbx.c:	if (handle == req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_mbx.c:	abt->handle = make_handle(req->id, abt->handle);
drivers/scsi/qla2xxx/qla_mbx.c:	abt->handle_to_abort = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_mbx.c:	abt->req_que_no = cpu_to_le16(req->id);
drivers/scsi/qla2xxx/qla_mbx.c:	tsk->p.tsk.handle = make_handle(req->id, tsk->p.tsk.handle);
drivers/scsi/qla2xxx/qla_mbx.c:		req->options |= BIT_13;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[1] = req->options;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[2] = MSW(LSD(req->dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[3] = LSW(LSD(req->dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[6] = MSW(MSD(req->dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[7] = LSW(MSD(req->dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[5] = req->length;
drivers/scsi/qla2xxx/qla_mbx.c:	if (req->rsp)
drivers/scsi/qla2xxx/qla_mbx.c:		mcp->mb[10] = req->rsp->id;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[12] = req->qos;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[11] = req->vp_idx;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[13] = req->rid;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[4] = req->id;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[9] = *req->out_ptr = 0;
drivers/scsi/qla2xxx/qla_mbx.c:	if (!(req->options & BIT_0)) {
drivers/scsi/qla2xxx/qla_mbx.c:		wrt_reg_dword(req->req_q_in, 0);
drivers/scsi/qla2xxx/qla_mbx.c:			wrt_reg_dword(req->req_q_out, 0);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[1] = mreq->options | BIT_6;	// BIT_6 specifies 64 bit addressing
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[10] = LSW(mreq->transfer_size);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[11] = MSW(mreq->transfer_size);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[14] = LSW(mreq->send_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[15] = MSW(mreq->send_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[20] = LSW(MSD(mreq->send_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[21] = MSW(MSD(mreq->send_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[16] = LSW(mreq->rcv_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[17] = MSW(mreq->rcv_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[6] = LSW(MSD(mreq->rcv_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[7] = MSW(MSD(mreq->rcv_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[18] = LSW(mreq->iteration_count);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[19] = MSW(mreq->iteration_count);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->buf_size = mreq->transfer_size;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[1] = mreq->options | BIT_15 | BIT_6;
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[16] = LSW(mreq->rcv_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[17] = MSW(mreq->rcv_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[6] = LSW(MSD(mreq->rcv_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[7] = MSW(MSD(mreq->rcv_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[10] = LSW(mreq->transfer_size);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[14] = LSW(mreq->send_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[15] = MSW(mreq->send_dma);
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[20] = LSW(MSD(mreq->send_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->mb[21] = MSW(MSD(mreq->send_dma));
drivers/scsi/qla2xxx/qla_mbx.c:	mcp->buf_size = mreq->transfer_size;
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	cont_pkt = (cont_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	cont_pkt = (cont_a64_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c: * req->current_outstanding_cmd + 1. The caller must hold the lock that is
drivers/scsi/qla2xxx/qla_iocb.c:	uint32_t index, handle = req->current_outstanding_cmd;
drivers/scsi/qla2xxx/qla_iocb.c:	for (index = 1; index < req->num_outstanding_cmds; index++) {
drivers/scsi/qla2xxx/qla_iocb.c:		if (handle == req->num_outstanding_cmds)
drivers/scsi/qla2xxx/qla_iocb.c:		if (!req->outstanding_cmds[handle])
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:			    (req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (cmd_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	wrt_reg_word(ISP_REQ_Q_IN(ha, reg), req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:	device_reg_t *reg = ISP_QUE_REG(ha, req->id);
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:			req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:			req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:			req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:			wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:			wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:			wrt_reg_dword(&reg->ispfx00.req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:			wrt_reg_dword(&reg->isp24.req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:				req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:			mrk24->handle = make_handle(req->id, mrk24->handle);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_iocb.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (struct cmd_type_7 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:	rsp = req->rsp;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_iocb.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (struct cmd_type_crc_2 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	    req->ring_ptr, tot_dsds, tot_prot_dsds, fw_prot_opts) !=
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:		req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_iocb.c:		req->cnt += req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_iocb.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (struct cmd_type_7 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_iocb.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (struct cmd_type_crc_2 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	    req->ring_ptr, tot_dsds, tot_prot_dsds, fw_prot_opts) !=
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_iocb.c:		req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_iocb.c:		req->cnt += req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	device_reg_t *reg = ISP_QUE_REG(ha, req->id);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < req_cnt + 2) {
drivers/scsi/qla2xxx/qla_iocb.c:			cnt = *req->out_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:		if  (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:			    (req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < req_cnt + 2)
drivers/scsi/qla2xxx/qla_iocb.c:		req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:		req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	pkt = req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	tsk->handle = make_handle(req->id, tsk->handle);
drivers/scsi/qla2xxx/qla_iocb.c:		for (h = 1; h < sp->qpair->req->num_outstanding_cmds; h++) {
drivers/scsi/qla2xxx/qla_iocb.c:			if (sp->qpair->req->outstanding_cmds[h] == sp) {
drivers/scsi/qla2xxx/qla_iocb.c:				sp->qpair->req->outstanding_cmds[h] = NULL;
drivers/scsi/qla2xxx/qla_iocb.c:		for (h = 1; h < sp->qpair->req->num_outstanding_cmds; h++) {
drivers/scsi/qla2xxx/qla_iocb.c:			if (sp->qpair->req->outstanding_cmds[h] == sp) {
drivers/scsi/qla2xxx/qla_iocb.c:				sp->qpair->req->outstanding_cmds[h] = NULL;
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:			if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:				req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:				req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:					(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:			if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:		cmd_pkt = (struct cmd_type_6 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:		cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_iocb.c:			if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:				req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:				req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:					(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_iocb.c:		cmd_pkt = (struct cmd_type_7 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:		cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_iocb.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_iocb.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_iocb.c:	dbval = dbval | (req->id << 8) | (req->ring_index << 16);
drivers/scsi/qla2xxx/qla_iocb.c:	abt_iocb->handle = make_handle(req->id, sp->handle);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < req_cnt + 2) {
drivers/scsi/qla2xxx/qla_iocb.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_iocb.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_iocb.c:		if  (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_iocb.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_iocb.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_iocb.c:	if (req->cnt < req_cnt + 2) {
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt = (struct cmd_bidir *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_iocb.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_iocb.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_iocb.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_iocb.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_target.c:	resp = (struct abts_resp_to_24xx *)qpair->req->ring_ptr;
drivers/scsi/qla2xxx/qla_target.c:		qpair->req->outstanding_cmds[h] = (srb_t *)mcmd;
drivers/scsi/qla2xxx/qla_target.c:	resp->handle = make_handle(qpair->req->id, h);
drivers/scsi/qla2xxx/qla_target.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_target.c:		cnt = (uint16_t)(qpair->use_shadow_reg ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_target.c:		    rd_reg_dword_relaxed(req->req_q_out));
drivers/scsi/qla2xxx/qla_target.c:		if  (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_target.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_target.c:			req->cnt = req->length - (req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_target.c:		if (unlikely(req->cnt < (req_cnt + 2)))
drivers/scsi/qla2xxx/qla_target.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_target.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_target.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_target.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_target.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_target.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_target.c:	return (cont_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_target.c:	h = req->current_outstanding_cmd;
drivers/scsi/qla2xxx/qla_target.c:	for (index = 1; index < req->num_outstanding_cmds; index++) {
drivers/scsi/qla2xxx/qla_target.c:		if (h == req->num_outstanding_cmds)
drivers/scsi/qla2xxx/qla_target.c:		if (!req->outstanding_cmds[h]) {
drivers/scsi/qla2xxx/qla_target.c:		req->current_outstanding_cmd = h;
drivers/scsi/qla2xxx/qla_target.c:	pkt = (struct ctio7_to_24xx *)qpair->req->ring_ptr;
drivers/scsi/qla2xxx/qla_target.c:		qpair->req->outstanding_cmds[h] = (srb_t *)prm->cmd;
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle = make_handle(qpair->req->id, h);
drivers/scsi/qla2xxx/qla_target.c:	pkt = (struct ctio_crc2_to_fw *)qpair->req->ring_ptr;
drivers/scsi/qla2xxx/qla_target.c:		qpair->req->outstanding_cmds[h] = (srb_t *)prm->cmd;
drivers/scsi/qla2xxx/qla_target.c:	pkt->handle  = make_handle(qpair->req->id, h);
drivers/scsi/qla2xxx/qla_target.c:	qpair->req->outstanding_cmds[h] = NULL;
drivers/scsi/qla2xxx/qla_target.c:		qpair->req->cnt += full_req_cnt;
drivers/scsi/qla2xxx/qla_target.c:		qpair->req->cnt += prm.req_cnt;
drivers/scsi/qla2xxx/qla_target.c:	if (qid == rsp->req->id) {
drivers/scsi/qla2xxx/qla_target.c:		if (unlikely(h >= req->num_outstanding_cmds)) {
drivers/scsi/qla2xxx/qla_target.c:		cmd = req->outstanding_cmds[h];
drivers/scsi/qla2xxx/qla_target.c:			    "qla_target(%d): Suspicious: unable to find the command with handle %x req->id %d rsp->id %d\n",
drivers/scsi/qla2xxx/qla_target.c:				vha->vp_idx, handle, req->id, rsp->id);
drivers/scsi/qla2xxx/qla_target.c:		req->outstanding_cmds[h] = NULL;
drivers/scsi/qla2xxx/qla_target.c:	tgt->sg_tablesize = QLA_TGT_MAX_SG_24XX(base_vha->req->length - 3);
drivers/scsi/qla2xxx/qla_sup.c:	struct qla_flt_location *fltl = (void *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	uint32_t *dcode = (uint32_t *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	uint8_t *buf = (void *)req->ring, *bcode,  last_image;
drivers/scsi/qla2xxx/qla_sup.c:	wptr = (__force __le16 *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	__le16 *wptr = (__force __le16 *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	struct qla_fdt_layout *fdt = (struct qla_fdt_layout *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	wptr = (__force __le32 *)req->ring;
drivers/scsi/qla2xxx/qla_sup.c:	ha->isp_ops->read_optrom(vha, req->ring, QLA82XX_IDC_PARAM_ADDR, 8);
drivers/scsi/qla2xxx/qla_nvme.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_nvme.c:		cnt = IS_SHADOW_REG_CAPABLE(ha) ? *req->out_ptr :
drivers/scsi/qla2xxx/qla_nvme.c:		    rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_nvme.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_nvme.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_nvme.c:			req->cnt = req->length - (req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_nvme.c:		if (req->cnt < (req_cnt + 2)){
drivers/scsi/qla2xxx/qla_nvme.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_nvme.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_nvme.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_nvme.c:	cmd_pkt = (struct cmd_nvme *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_nvme.c:	cmd_pkt->handle = make_handle(req->id, handle);
drivers/scsi/qla2xxx/qla_nvme.c:			req->ring_index++;
drivers/scsi/qla2xxx/qla_nvme.c:			if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_nvme.c:				req->ring_index = 0;
drivers/scsi/qla2xxx/qla_nvme.c:				req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_nvme.c:				req->ring_ptr++;
drivers/scsi/qla2xxx/qla_nvme.c:			cont_pkt = (cont_a64_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_nvme.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_nvme.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_nvme.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_nvme.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_nvme.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_nvme.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_tmpl.c:				    req->length : REQUEST_ENTRY_CNT_24XX;
drivers/scsi/qla2xxx/qla_tmpl.c:				qla27xx_insertbuf(req ? req->ring : NULL,
drivers/scsi/qla2xxx/qla_tmpl.c:				    length * sizeof(*req->ring), buf, len);
drivers/scsi/qla2xxx/qla_tmpl.c:				qla27xx_insert32(req && req->out_ptr ?
drivers/scsi/qla2xxx/qla_tmpl.c:				    *req->out_ptr : 0, buf, len);
drivers/scsi/qla2xxx/qla_mr.c:	ha->fw_transfer_size = REQUEST_ENTRY_SIZE * req->length;
drivers/scsi/qla2xxx/qla_mr.c:	req->length_fx00 = req->length;
drivers/scsi/qla2xxx/qla_mr.c:	req->ring_fx00 = req->ring;
drivers/scsi/qla2xxx/qla_mr.c:	req->dma_fx00 = req->dma;
drivers/scsi/qla2xxx/qla_mr.c:	    "req->dma_fx00: 0x%llx\n", req, req->ring_fx00,
drivers/scsi/qla2xxx/qla_mr.c:	    req->length_fx00, (u64)req->dma_fx00);
drivers/scsi/qla2xxx/qla_mr.c:	req->length = ha->req_que_len;
drivers/scsi/qla2xxx/qla_mr.c:	req->ring = (void __force *)ha->iobase + ha->req_que_off;
drivers/scsi/qla2xxx/qla_mr.c:	req->dma = bar2_hdl + ha->req_que_off;
drivers/scsi/qla2xxx/qla_mr.c:	if ((!req->ring) || (req->length == 0)) {
drivers/scsi/qla2xxx/qla_mr.c:	    "req off 0x%x\n, req->dma: 0x%llx",
drivers/scsi/qla2xxx/qla_mr.c:	    req, req->ring, req->length,
drivers/scsi/qla2xxx/qla_mr.c:	    ha->req_que_off, (u64)req->dma);
drivers/scsi/qla2xxx/qla_mr.c:	if (handle < req->num_outstanding_cmds)
drivers/scsi/qla2xxx/qla_mr.c:		sp = req->outstanding_cmds[handle];
drivers/scsi/qla2xxx/qla_mr.c:		req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_mr.c:	req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_mr.c:		if (handle < req->num_outstanding_cmds)
drivers/scsi/qla2xxx/qla_mr.c:			sp = req->outstanding_cmds[handle];
drivers/scsi/qla2xxx/qla_mr.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_mr.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_mr.c:	cont_pkt = (cont_a64_entry_t *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_mr.c:	if (req->cnt < (req_cnt + 2)) {
drivers/scsi/qla2xxx/qla_mr.c:		cnt = rd_reg_dword_relaxed(req->req_q_out);
drivers/scsi/qla2xxx/qla_mr.c:		if (req->ring_index < cnt)
drivers/scsi/qla2xxx/qla_mr.c:			req->cnt = cnt - req->ring_index;
drivers/scsi/qla2xxx/qla_mr.c:			req->cnt = req->length -
drivers/scsi/qla2xxx/qla_mr.c:				(req->ring_index - cnt);
drivers/scsi/qla2xxx/qla_mr.c:		if (req->cnt < (req_cnt + 2))
drivers/scsi/qla2xxx/qla_mr.c:	req->current_outstanding_cmd = handle;
drivers/scsi/qla2xxx/qla_mr.c:	req->outstanding_cmds[handle] = sp;
drivers/scsi/qla2xxx/qla_mr.c:	req->cnt -= req_cnt;
drivers/scsi/qla2xxx/qla_mr.c:	cmd_pkt = (struct cmd_type_7_fx00 *)req->ring_ptr;
drivers/scsi/qla2xxx/qla_mr.c:	lcmd_pkt.handle = make_handle(req->id, sp->handle);
drivers/scsi/qla2xxx/qla_mr.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_mr.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_mr.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_mr.c:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_mr.c:	tm_iocb.handle = make_handle(req->id, sp->handle);
drivers/scsi/qla2xxx/qla_mr.c:	abt_iocb.handle = make_handle(req->id, sp->handle);
drivers/scsi/qla2xxx/qla_mr.c:	abt_iocb.abort_handle = make_handle(req->id, fxio->u.abt.cmd_hndl);
drivers/scsi/qla2xxx/qla_mr.c:	abt_iocb.req_que_no = cpu_to_le16(req->id);
drivers/scsi/qla2xxx/qla_os.c:		if (req && req->ring_fx00)
drivers/scsi/qla2xxx/qla_os.c:			    (req->length_fx00 + 1) * sizeof(request_t),
drivers/scsi/qla2xxx/qla_os.c:			    req->ring_fx00, req->dma_fx00);
drivers/scsi/qla2xxx/qla_os.c:	} else if (req && req->ring)
drivers/scsi/qla2xxx/qla_os.c:		(req->length + 1) * sizeof(request_t),
drivers/scsi/qla2xxx/qla_os.c:		req->ring, req->dma);
drivers/scsi/qla2xxx/qla_os.c:		kfree(req->outstanding_cmds);
drivers/scsi/qla2xxx/qla_os.c:		cnt < req->num_outstanding_cmds; cnt++) {
drivers/scsi/qla2xxx/qla_os.c:		sp = req->outstanding_cmds[cnt];
drivers/scsi/qla2xxx/qla_os.c:	for (cnt = 1; cnt < req->num_outstanding_cmds; cnt++) {
drivers/scsi/qla2xxx/qla_os.c:		sp = req->outstanding_cmds[cnt];
drivers/scsi/qla2xxx/qla_os.c:			req->outstanding_cmds[cnt] = NULL;
drivers/scsi/qla2xxx/qla_os.c:	scsi_change_queue_depth(sdev, req->max_q_depth);
drivers/scsi/qla2xxx/qla_os.c:	req->max_q_depth = MAX_Q_DEPTH;
drivers/scsi/qla2xxx/qla_os.c:		req->max_q_depth = ql2xmaxqdepth;
drivers/scsi/qla2xxx/qla_os.c:	req->rsp = rsp;
drivers/scsi/qla2xxx/qla_os.c:	req->req_q_in = &ha->iobase->isp24.req_q_in;
drivers/scsi/qla2xxx/qla_os.c:	req->req_q_out = &ha->iobase->isp24.req_q_out;
drivers/scsi/qla2xxx/qla_os.c:		req->req_q_in = &ha->mqiobase->isp25mq.req_q_in;
drivers/scsi/qla2xxx/qla_os.c:		req->req_q_out = &ha->mqiobase->isp25mq.req_q_out;
drivers/scsi/qla2xxx/qla_os.c:		req->req_q_in = &ha->iobase->ispfx00.req_q_in;
drivers/scsi/qla2xxx/qla_os.c:		req->req_q_out = &ha->iobase->ispfx00.req_q_out;
drivers/scsi/qla2xxx/qla_os.c:		req->req_q_out = &ha->iobase->isp82.req_q_out[0];
drivers/scsi/qla2xxx/qla_os.c:	    "rsp_q_map=%p req_q_map=%p rsp->req=%p req->rsp=%p.\n",
drivers/scsi/qla2xxx/qla_os.c:	    ha->rsp_q_map, ha->req_q_map, rsp->req, req->rsp);
drivers/scsi/qla2xxx/qla_os.c:	    "req->req_q_in=%p req->req_q_out=%p "
drivers/scsi/qla2xxx/qla_os.c:	    req->req_q_in, req->req_q_out,
drivers/scsi/qla2xxx/qla_os.c:	    "rsp_q_map=%p req_q_map=%p rsp->req=%p req->rsp=%p.\n",
drivers/scsi/qla2xxx/qla_os.c:	    ha->rsp_q_map, ha->req_q_map, rsp->req, req->rsp);
drivers/scsi/qla2xxx/qla_os.c:	    "req->req_q_in=%p req->req_q_out=%p rsp->rsp_q_in=%p rsp->rsp_q_out=%p.\n",
drivers/scsi/qla2xxx/qla_os.c:	    req->req_q_in, req->req_q_out, rsp->rsp_q_in, rsp->rsp_q_out);
drivers/scsi/qla2xxx/qla_os.c:		host->can_queue = req->num_outstanding_cmds - 10;
drivers/scsi/qla2xxx/qla_os.c:	    "req=%p req->length=%d req->ring=%p rsp=%p "
drivers/scsi/qla2xxx/qla_os.c:				    index < req->num_outstanding_cmds;
drivers/scsi/qla2xxx/qla_os.c:					sp = req->outstanding_cmds[index];
drivers/scsi/qla2xxx/qla_inline.h:	req->ring_index++;
drivers/scsi/qla2xxx/qla_inline.h:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_inline.h:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_inline.h:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_inline.h:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_inline.h:	wrt_reg_dword(req->req_q_in, req->ring_index);
drivers/scsi/qla2xxx/qla_isr.c:	if (index >= req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_isr.c:	sp = req->outstanding_cmds[index];
drivers/scsi/qla2xxx/qla_isr.c:		req->outstanding_cmds[index] = NULL;
drivers/scsi/qla2xxx/qla_isr.c:	if (index >= req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_isr.c:	sp = req->outstanding_cmds[index];
drivers/scsi/qla2xxx/qla_isr.c:	req->outstanding_cmds[index] = NULL;
drivers/scsi/qla2xxx/qla_isr.c:	if (index >= req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_isr.c:	sp = req->outstanding_cmds[index];
drivers/scsi/qla2xxx/qla_isr.c:		    req->id, index);
drivers/scsi/qla2xxx/qla_isr.c:	req->outstanding_cmds[index] = NULL;
drivers/scsi/qla2xxx/qla_isr.c:	if (handle < req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_isr.c:		sp = req->outstanding_cmds[handle];
drivers/scsi/qla2xxx/qla_isr.c:		req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_isr.c:		req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_isr.c:	req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_dbg.c:	memcpy(ptr, req->ring, req->length *
drivers/scsi/qla2xxx/qla_dbg.c:	ptr += req->length * sizeof(request_t);
drivers/scsi/qla2xxx/qla_dbg.c:		    (req->length * sizeof(request_t)));
drivers/scsi/qla2xxx/qla_dbg.c:		qh->size = htonl(req->length * sizeof(request_t));
drivers/scsi/qla2xxx/qla_dbg.c:		memcpy(ptr, req->ring, req->length * sizeof(request_t));
drivers/scsi/qla2xxx/qla_dbg.c:		ptr += req->length * sizeof(request_t);
drivers/scsi/qla2xxx/qla_nx.c:	icb->request_q_length = cpu_to_le16(req->length);
drivers/scsi/qla2xxx/qla_nx.c:	put_unaligned_le64(req->dma, &icb->request_q_address);
drivers/scsi/qla2xxx/qla_nx.c:	req->ring_index++;
drivers/scsi/qla2xxx/qla_nx.c:	if (req->ring_index == req->length) {
drivers/scsi/qla2xxx/qla_nx.c:		req->ring_index = 0;
drivers/scsi/qla2xxx/qla_nx.c:		req->ring_ptr = req->ring;
drivers/scsi/qla2xxx/qla_nx.c:		req->ring_ptr++;
drivers/scsi/qla2xxx/qla_nx.c:	dbval = dbval | (req->id << 8) | (req->ring_index << 16);
drivers/scsi/qla2xxx/qla_nx.c:		ha->isp_ops->get_flash_version(vha, req->ring);
drivers/scsi/qla2xxx/qla_nx.c:			for (cnt = 1; cnt < req->num_outstanding_cmds; cnt++) {
drivers/scsi/qla2xxx/qla_nx.c:				sp = req->outstanding_cmds[cnt];
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.port_id.port_id = port_id_to_be_id(fcport->d_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gid_pt.port_type = NS_NX_PORT_TYPE;
drivers/scsi/qla2xxx/qla_gs.c:		ct_req->req.port_id.port_id = port_id_to_be_id(list[i].d_id);
drivers/scsi/qla2xxx/qla_gs.c:		ct_req->req.port_id.port_id = port_id_to_be_id(list[i].d_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rft_id.port_id = port_id_to_be_id(vha->d_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rft_id.fc4_types[2] = 0x01;		/* FCP-3 */
drivers/scsi/qla2xxx/qla_gs.c:		ct_req->req.rft_id.fc4_types[6] = 1;    /* NVMe type 28h */
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rff_id.port_id = port_id_to_be_id(*d_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rff_id.fc4_feature = fc4feature;
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rff_id.fc4_type = fc4type;		/* SCSI - FCP */
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rnn_id.port_id = port_id_to_be_id(vha->d_id);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rnn_id.node_name, vha->node_name, WWN_SIZE);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rsnn_nn.node_name, vha->node_name, WWN_SIZE);
drivers/scsi/qla2xxx/qla_gs.c:	qla2x00_get_sym_node_name(vha, ct_req->req.rsnn_nn.sym_node_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rsnn_nn.sym_node_name));
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rsnn_nn.name_len =
drivers/scsi/qla2xxx/qla_gs.c:	    (uint8_t)strlen(ct_req->req.rsnn_nn.sym_node_name);
drivers/scsi/qla2xxx/qla_gs.c:	sp->u.iocb_cmd.u.ctarg.req_size = 24 + 1 + ct_req->req.rsnn_nn.name_len;
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rhba.hba_identifier, vha->port_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rhba.hba_identifier));
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rhba.hba_identifier);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rhba.entry_count = cpu_to_be32(1);
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rhba.entry_count);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rhba.port_name, vha->port_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rhba.port_name));
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rhba.port_name);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rhba.attrs.count = cpu_to_be32(count);
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rhba.attrs.count);
drivers/scsi/qla2xxx/qla_gs.c:	entries = &ct_req->req.rhba.attrs.entry;
drivers/scsi/qla2xxx/qla_gs.c:	    wwn_to_u64(ct_req->req.rhba.hba_identifier),
drivers/scsi/qla2xxx/qla_gs.c:	    wwn_to_u64(ct_req->req.rhba.port_name));
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.dhba.port_name, vha->port_name, WWN_SIZE);
drivers/scsi/qla2xxx/qla_gs.c:	    "DHBA portname = %8phN.\n", ct_req->req.dhba.port_name);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rprt.hba_identifier, base_vha->port_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rprt.hba_identifier));
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rprt.hba_identifier);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rprt.port_name, vha->port_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rprt.port_name));
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rprt.port_name);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rprt.attrs.count = cpu_to_be32(count);
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rprt.attrs.count);
drivers/scsi/qla2xxx/qla_gs.c:	entries = ct_req->req.rprt.attrs.entry;
drivers/scsi/qla2xxx/qla_gs.c:	    wwn_to_u64(ct_req->req.rprt.port_name),
drivers/scsi/qla2xxx/qla_gs.c:	    wwn_to_u64(ct_req->req.rprt.port_name));
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.rpa.port_name, vha->port_name,
drivers/scsi/qla2xxx/qla_gs.c:	    sizeof(ct_req->req.rpa.port_name));
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rpa.port_name);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.rpa.attrs.count = cpu_to_be32(count);
drivers/scsi/qla2xxx/qla_gs.c:	size += sizeof(ct_req->req.rpa.attrs.count);
drivers/scsi/qla2xxx/qla_gs.c:	entries = ct_req->req.rpa.attrs.entry;
drivers/scsi/qla2xxx/qla_gs.c:	    "RPA %016llx.\n", wwn_to_u64(ct_req->req.rpa.port_name));
drivers/scsi/qla2xxx/qla_gs.c:		ct_req->req.port_id.port_id = port_id_to_be_id(list[i].d_id);
drivers/scsi/qla2xxx/qla_gs.c:		memcpy(ct_req->req.gpsc.port_name, list[i].fabric_port_name,
drivers/scsi/qla2xxx/qla_gs.c:		ct_req->req.port_id.port_id = port_id_to_be_id(list[i].d_id);
drivers/scsi/qla2xxx/qla_gs.c:	memcpy(ct_req->req.gpsc.port_name, fcport->fabric_port_name,
drivers/scsi/qla2xxx/qla_gs.c:		    sp->name, res, sp->gen1, &ct_req->req.port_id.port_id,
drivers/scsi/qla2xxx/qla_gs.c:		    sp->name, sp->gen1, &ct_req->req.port_id.port_id,
drivers/scsi/qla2xxx/qla_gs.c:	ea.id = be_to_port_id(ct_req->req.port_id.port_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.port_id.port_id = port_id_to_be_id(*id);
drivers/scsi/qla2xxx/qla_gs.c:	    sp->handle, &ct_req->req.port_id.port_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gff_id.port_id[0] = fcport->d_id.b.domain;
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gff_id.port_id[1] = fcport->d_id.b.area;
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gff_id.port_id[2] = fcport->d_id.b.al_pa;
drivers/scsi/qla2xxx/qla_gs.c:	u16 cmd = be16_to_cpu(ct_req->command);
drivers/scsi/qla2xxx/qla_gs.c:	u16 cmd = be16_to_cpu(ct_req->command);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gpn_ft.port_type = fc4_type;
drivers/scsi/qla2xxx/qla_gs.c:	    sp->handle, ct_req->req.gpn_ft.port_type);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.gpn_ft.port_type = fc4_type;
drivers/scsi/qla2xxx/qla_gs.c:	    sp->handle, ct_req->req.gpn_ft.port_type);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.port_id.port_id = port_id_to_be_id(fcport->d_id);
drivers/scsi/qla2xxx/qla_gs.c:	ct_req->req.port_id.port_id = port_id_to_be_id(fcport->d_id);
drivers/scsi/qla2xxx/qla_init.c:	for (handle = 1; handle < qpair->req->num_outstanding_cmds; handle++) {
drivers/scsi/qla2xxx/qla_init.c:		if (sp->cmd_sp && (qpair->req->outstanding_cmds[handle] ==
drivers/scsi/qla2xxx/qla_init.c:			qpair->req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_init.c:		if (qpair->req->outstanding_cmds[handle] == sp) {
drivers/scsi/qla2xxx/qla_init.c:			qpair->req->outstanding_cmds[handle] = NULL;
drivers/scsi/qla2xxx/qla_init.c:	abt_iocb->u.abt.req_que_no = cpu_to_le16(cmd_sp->qpair->req->id);
drivers/scsi/qla2xxx/qla_init.c:			for (h = 1; h < sp->qpair->req->num_outstanding_cmds;
drivers/scsi/qla2xxx/qla_init.c:				if (sp->qpair->req->outstanding_cmds[h] ==
drivers/scsi/qla2xxx/qla_init.c:					sp->qpair->req->outstanding_cmds[h] =
drivers/scsi/qla2xxx/qla_init.c:			for (h = 1; h < sp->qpair->req->num_outstanding_cmds;
drivers/scsi/qla2xxx/qla_init.c:				if (sp->qpair->req->outstanding_cmds[h] ==
drivers/scsi/qla2xxx/qla_init.c:					sp->qpair->req->outstanding_cmds[h] =
drivers/scsi/qla2xxx/qla_init.c:		for (h = 1; h < sp->qpair->req->num_outstanding_cmds; h++) {
drivers/scsi/qla2xxx/qla_init.c:			if (sp->qpair->req->outstanding_cmds[h] == sp) {
drivers/scsi/qla2xxx/qla_init.c:				sp->qpair->req->outstanding_cmds[h] = NULL;
drivers/scsi/qla2xxx/qla_init.c:	for (handle = 1; handle < req->num_outstanding_cmds; handle++) {
drivers/scsi/qla2xxx/qla_init.c:		if (req->outstanding_cmds[handle] == sp)
drivers/scsi/qla2xxx/qla_init.c:	if (handle == req->num_outstanding_cmds) {
drivers/scsi/qla2xxx/qla_init.c:	ha->isp_ops->get_flash_version(vha, req->ring);
drivers/scsi/qla2xxx/qla_init.c:	if (req->length > 1024)
drivers/scsi/qla2xxx/qla_init.c:		    req->length;
drivers/scsi/qla2xxx/qla_init.c:	ha->fw_transfer_size = REQUEST_ENTRY_SIZE * req->length;
drivers/scsi/qla2xxx/qla_init.c:			    (req->length * sizeof(request_t));
drivers/scsi/qla2xxx/qla_init.c:		req_q_size = req->length * sizeof(request_t);
drivers/scsi/qla2xxx/qla_init.c:	if (req->outstanding_cmds)
drivers/scsi/qla2xxx/qla_init.c:		req->num_outstanding_cmds = DEFAULT_OUTSTANDING_COMMANDS;
drivers/scsi/qla2xxx/qla_init.c:			req->num_outstanding_cmds = ha->cur_fw_xcb_count;
drivers/scsi/qla2xxx/qla_init.c:			req->num_outstanding_cmds = ha->cur_fw_iocb_count;
drivers/scsi/qla2xxx/qla_init.c:	req->outstanding_cmds = kcalloc(req->num_outstanding_cmds,
drivers/scsi/qla2xxx/qla_init.c:	if (!req->outstanding_cmds) {
drivers/scsi/qla2xxx/qla_init.c:		req->num_outstanding_cmds = MIN_OUTSTANDING_COMMANDS;
drivers/scsi/qla2xxx/qla_init.c:		req->outstanding_cmds = kcalloc(req->num_outstanding_cmds,
drivers/scsi/qla2xxx/qla_init.c:		if (!req->outstanding_cmds) {
drivers/scsi/qla2xxx/qla_init.c:			req->num_outstanding_cmds = 0;
drivers/scsi/qla2xxx/qla_init.c:	ha->init_cb->request_q_length = cpu_to_le16(req->length);
drivers/scsi/qla2xxx/qla_init.c:	put_unaligned_le64(req->dma, &ha->init_cb->request_q_address);
drivers/scsi/qla2xxx/qla_init.c:	icb->request_q_length = cpu_to_le16(req->length);
drivers/scsi/qla2xxx/qla_init.c:	put_unaligned_le64(req->dma, &icb->request_q_address);
drivers/scsi/qla2xxx/qla_init.c:		req->out_ptr = (uint16_t *)(req->ring + req->length);
drivers/scsi/qla2xxx/qla_init.c:		*req->out_ptr = 0;
drivers/scsi/qla2xxx/qla_init.c:		for (cnt = 1; cnt < req->num_outstanding_cmds; cnt++)
drivers/scsi/qla2xxx/qla_init.c:			req->outstanding_cmds[cnt] = NULL;
drivers/scsi/qla2xxx/qla_init.c:		req->current_outstanding_cmd = 1;
drivers/scsi/qla2xxx/qla_init.c:		req->ring_ptr  = req->ring;
drivers/scsi/qla2xxx/qla_init.c:		req->ring_index    = 0;
drivers/scsi/qla2xxx/qla_init.c:		req->cnt      = req->length;
drivers/scsi/qla2xxx/qla_init.c:		ha->isp_ops->get_flash_version(vha, req->ring);
drivers/scsi/qla2xxx/qla_init.c:			req->options &= ~BIT_0;
drivers/scsi/qla2xxx/qla_init.c:				    __func__, req->id);
drivers/scsi/qla2xxx/qla_init.c:				    __func__, req->id);
drivers/scsi/qla2xxx/qla_init.c:	dcode = (uint32_t *)req->ring;
drivers/scsi/qla2xxx/qla_init.c:	dcode = (uint32_t *)req->ring;
drivers/scsi/qla2xxx/qla_init.c:			rval = qla2x00_load_ram(vha, req->dma, risc_addr, dlen);
drivers/scsi/qla2xxx/qla_init.c:		dcode = (uint32_t *)req->ring;
drivers/scsi/qla2xxx/qla_init.c:	wcode = (uint16_t *)req->ring;
drivers/scsi/qla2xxx/qla_init.c:			rval = qla2x00_load_ram(vha, req->dma, risc_addr,
drivers/scsi/qla2xxx/qla_init.c:	dcode = (uint32_t *)req->ring;
drivers/scsi/qla2xxx/qla_init.c:			rval = qla2x00_load_ram(vha, req->dma, risc_addr, dlen);
drivers/scsi/qla2xxx/qla_bsg.c:		for (cnt = 1; cnt < req->num_outstanding_cmds; cnt++) {
drivers/scsi/qla2xxx/qla_bsg.c:			sp = req->outstanding_cmds[cnt];
drivers/scsi/qla2xxx/qla_bsg.c:					req->outstanding_cmds[cnt] = NULL;
drivers/scsi/ibmvscsi/ibmvscsi.c:	req->common.type = cpu_to_be32(VIOSRP_CAPABILITIES_TYPE);
drivers/scsi/ibmvscsi/ibmvscsi.c:	req->buffer = cpu_to_be64(hostdata->caps_addr);
drivers/scsi/ibmvscsi/ibmvscsi.c:		req->common.length =
drivers/scsi/ibmvscsi/ibmvscsi.c:		req->common.length = cpu_to_be16(sizeof(hostdata->caps) -
drivers/scsi/ibmvscsi/ibmvscsi.c:	req->common.type = cpu_to_be32(VIOSRP_ADAPTER_INFO_TYPE);
drivers/scsi/ibmvscsi/ibmvscsi.c:	req->common.length = cpu_to_be16(sizeof(hostdata->madapter_info));
drivers/scsi/ibmvscsi/ibmvscsi.c:	req->buffer = cpu_to_be64(hostdata->adapter_info_addr);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		if (io_req->cmd_type != BNX2FC_SCSI_CMD) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				       &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			memcpy(&io_req->err_entry, err_entry,
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				      &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		set_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		if (io_req->cmd_type != BNX2FC_SCSI_CMD) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		memcpy(&io_req->err_entry, err_entry,
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	cmd_type = io_req->cmd_type;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:			      io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct scsi_cmnd *sc_cmd = orig_io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct bnx2fc_rport *tgt = seq_clnp_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct fcoe_bd_ctx *bd = orig_io_req->bd_tbl->bd_tbl;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	u16 orig_xid = orig_io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	u64 phys_addr = (u64)orig_io_req->bd_tbl->bd_tbl_dma;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	bd_count = orig_io_req->bd_tbl->bd_valid;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct bnx2fc_mp_req *mp_req = &(io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	if ((io_req->cmd_type == BNX2FC_TASK_MGMT_CMD) ||
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	    (io_req->cmd_type == BNX2FC_ELS)) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	} else if (io_req->cmd_type == BNX2FC_ABTS) {
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	io_req->task = task;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		io_req->cmd_type, task_type);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				(u32)mp_req->mp_req_bd_dma;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				(u32)((u64)mp_req->mp_req_bd_dma >> 32);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	task->rxwr_txrd.const_ctx.data_2_trns = io_req->data_xfer_len;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	fc_hdr = &(mp_req->req_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		fc_hdr->fh_ox_id = cpu_to_be16(io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		fc_hdr->fh_rx_id = cpu_to_be16(io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		sgl->mul_sgl.cur_sge_addr.lo = (u32)mp_req->mp_resp_bd_dma;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:				(u32)((u64)mp_req->mp_resp_bd_dma >> 32);
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct io_bdt *bd_tbl = io_req->bd_tbl;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	io_req->task = task;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		io_req->rec_retry = 0;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:		io_req->rec_retry = 0;
drivers/scsi/bnx2fc/bnx2fc_hwi.c:	task->rxwr_txrd.const_ctx.data_2_trns = io_req->data_xfer_len;
drivers/scsi/bnx2fc/bnx2fc_debug.c:	if (io_req && io_req->port && io_req->port->lport &&
drivers/scsi/bnx2fc/bnx2fc_debug.c:	    io_req->port->lport->host)
drivers/scsi/bnx2fc/bnx2fc_debug.c:		shost_printk(KERN_INFO, io_req->port->lport->host,
drivers/scsi/bnx2fc/bnx2fc_debug.c:			     io_req->xid, &vaf);
drivers/scsi/bnx2fc/bnx2fc_els.c:		   orig_io_req->xid, rrq_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_and_clear_bit(BNX2FC_FLAG_ELS_TIMEOUT, &rrq_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			   rrq_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:		if (rrq_req->on_active_queue) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			list_del_init(&rrq_req->link);
drivers/scsi/bnx2fc/bnx2fc_els.c:			rrq_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_els.c:	struct bnx2fc_rport *tgt = aborted_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:		   aborted_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	rrq.rrq_ox_id = htons(aborted_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	rrq.rrq_rx_id = htons(aborted_io_req->task->rxwr_txrd.var_ctx.rx_id);
drivers/scsi/bnx2fc/bnx2fc_els.c:			aborted_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&aborted_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_and_clear_bit(BNX2FC_FLAG_ELS_TIMEOUT, &els_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:		if (els_req->on_active_queue) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			list_del_init(&els_req->link);
drivers/scsi/bnx2fc/bnx2fc_els.c:			els_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_els.c:	tgt = els_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req = &(els_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_els.c:	fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:	resp_buf = mp_req->resp_buf;
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_and_clear_bit(BNX2FC_FLAG_ELS_TIMEOUT, &srr_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:		if (test_bit(BNX2FC_FLAG_IO_COMPL, &orig_io_req->req_flags) ||
drivers/scsi/bnx2fc/bnx2fc_els.c:		    test_bit(BNX2FC_FLAG_ISSUE_ABTS, &orig_io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:				      orig_io_req->xid, orig_io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_els.c:		orig_io_req->srr_retry++;
drivers/scsi/bnx2fc/bnx2fc_els.c:		if (orig_io_req->srr_retry <= SRR_RETRY_COUNT) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			struct bnx2fc_rport *tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:					     orig_io_req->srr_offset,
drivers/scsi/bnx2fc/bnx2fc_els.c:					     orig_io_req->srr_rctl);
drivers/scsi/bnx2fc/bnx2fc_els.c:				orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_bit(BNX2FC_FLAG_IO_COMPL, &orig_io_req->req_flags) ||
drivers/scsi/bnx2fc/bnx2fc_els.c:	    test_bit(BNX2FC_FLAG_ISSUE_ABTS, &orig_io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			      orig_io_req->xid, orig_io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req = &(srr_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_els.c:	fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:	resp_buf = mp_req->resp_buf;
drivers/scsi/bnx2fc/bnx2fc_els.c:				orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	BNX2FC_IO_DBG(rec_req, "rec_compl: orig xid = 0x%x", orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_and_clear_bit(BNX2FC_FLAG_ELS_TIMEOUT, &rec_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:		orig_io_req->rec_retry++;
drivers/scsi/bnx2fc/bnx2fc_els.c:		if (orig_io_req->rec_retry <= REC_RETRY_COUNT) {
drivers/scsi/bnx2fc/bnx2fc_els.c:				orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_bit(BNX2FC_FLAG_IO_COMPL, &orig_io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &orig_io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req = &(rec_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_els.c:	fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_els.c:	resp_len = mp_req->resp_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:	acc = resp_buf = mp_req->resp_buf;
drivers/scsi/bnx2fc/bnx2fc_els.c:			new_io_req->sc_cmd = orig_io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_els.c:				&orig_io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_els.c:			     &orig_io_req->err_entry;
drivers/scsi/bnx2fc/bnx2fc_els.c:		sc_cmd = orig_io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_els.c:			if (offset == orig_io_req->data_xfer_len) {
drivers/scsi/bnx2fc/bnx2fc_els.c:					orig_io_req->data_xfer_len) {
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	struct bnx2fc_rport *tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_els.c:	rec.rec_ox_id = htons(orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	rec.rec_rx_id = htons(orig_io_req->task->rxwr_txrd.var_ctx.rx_id);
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	struct bnx2fc_rport *tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_els.c:	srr.srr_ox_id = htons(orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:	srr.srr_rx_id = htons(orig_io_req->task->rxwr_txrd.var_ctx.rx_id);
drivers/scsi/bnx2fc/bnx2fc_els.c:	orig_io_req->srr_offset = offset;
drivers/scsi/bnx2fc/bnx2fc_els.c:	orig_io_req->srr_rctl = r_ctl;
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:		set_bit(BNX2FC_FLAG_SRR_SENT, &orig_io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->cb_func = cb_func;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->cb_arg = cb_arg;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->data_xfer_len = data_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req = (struct bnx2fc_mp_req *)&(els_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&els_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req->req_len = data_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->data_xfer_len = mp_req->req_len;
drivers/scsi/bnx2fc/bnx2fc_els.c:		memcpy(mp_req->req_buf, data, data_len);
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_func = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&els_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	fc_hdr = &(mp_req->req_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_els.c:	xid = els_req->xid;
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_func = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&els_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	els_req->on_active_queue = 1;
drivers/scsi/bnx2fc/bnx2fc_els.c:	list_add_tail(&els_req->link, &tgt->els_queue);
drivers/scsi/bnx2fc/bnx2fc_els.c:			"cmd_type = %d\n", els_req->xid, els_req->cmd_type);
drivers/scsi/bnx2fc/bnx2fc_els.c:			     &els_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:			   "els - 0x%x\n", els_req->xid);
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&els_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (cancel_delayed_work(&els_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_els.c:		kref_put(&els_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_els.c:	if (els_req->on_active_queue) {
drivers/scsi/bnx2fc/bnx2fc_els.c:		list_del_init(&els_req->link);
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req = &(els_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_els.c:	fc_hdr = &(mp_req->resp_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_els.c:	mp_req->resp_len =
drivers/scsi/bnx2fc/bnx2fc_els.c:	if ((els_req->cb_func) && (els_req->cb_arg)) {
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_func(els_req->cb_arg);
drivers/scsi/bnx2fc/bnx2fc_els.c:		els_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_els.c:	kref_put(&els_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_interface *interface = io_req->port->priv;
drivers/scsi/bnx2fc/bnx2fc_io.c:			       &io_req->timeout_work,
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_get(&io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_io.c:	u8 cmd_type = io_req->cmd_type;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:		      "req_flags = %lx\n", cmd_type, io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_and_clear_bit(BNX2FC_FLAG_ISSUE_RRQ, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		clear_bit(BNX2FC_FLAG_RETIRE_OXID, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_and_clear_bit(BNX2FC_FLAG_RETIRE_OXID, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:							&io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:			complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:				    &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:					kref_read(&io_req->refcount));
drivers/scsi/bnx2fc/bnx2fc_io.c:					       &io_req->req_flags))) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:					     &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:					      &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:					      &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:					       &io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:			set_bit(BNX2FC_FLAG_ELS_TIMEOUT, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:			if ((io_req->cb_func) && (io_req->cb_arg)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				io_req->cb_func(io_req->cb_arg);
drivers/scsi/bnx2fc/bnx2fc_io.c:				io_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->cmd_type != BNX2FC_SCSI_CMD)
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_bit(BNX2FC_FLAG_CMD_LOST, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:		       io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		pr_err(PFX "0x%x: sc_cmd->device is NULL.\n", io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		    io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		INIT_LIST_HEAD(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:		INIT_DELAYED_WORK(&io_req->timeout_work, bnx2fc_cmd_timeout);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->xid = xid++;
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_add_tail(&io_req->link,
drivers/scsi/bnx2fc/bnx2fc_io.c:				&cmgr->free_list[io_req->xid %
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_add_tail(&io_req->link,
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_del(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	INIT_LIST_HEAD(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->cmd_mgr = cmd_mgr;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->req_flags = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->cmd_type = type;
drivers/scsi/bnx2fc/bnx2fc_io.c:	bd_tbl = io_req->bd_tbl = cmd_mgr->io_bdt_pool[xid];
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_init(&io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	INIT_LIST_HEAD(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->cmd_mgr = cmd_mgr;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->req_flags = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	bd_tbl = io_req->bd_tbl = cmd_mgr->io_bdt_pool[xid];
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_init(&io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_cmd_mgr *cmd_mgr = io_req->cmd_mgr;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->cmd_type == BNX2FC_SCSI_CMD)
drivers/scsi/bnx2fc/bnx2fc_io.c:		index = io_req->xid % num_possible_cpus();
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->cmd_type != BNX2FC_SCSI_CMD)
drivers/scsi/bnx2fc/bnx2fc_io.c:	cmd_mgr->cmds[io_req->xid] = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_add(&io_req->link,
drivers/scsi/bnx2fc/bnx2fc_io.c:	atomic_dec(&io_req->tgt->num_active_ios);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_mp_req *mp_req = &(io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_interface *interface = io_req->port->priv;
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req->tm_flags = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (mp_req->mp_req_bd) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->mp_req_bd,
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->mp_req_bd_dma);
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->mp_req_bd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (mp_req->mp_resp_bd) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->mp_resp_bd,
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->mp_resp_bd_dma);
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->mp_resp_bd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (mp_req->req_buf) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->req_buf,
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->req_buf_dma);
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->req_buf = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (mp_req->resp_buf) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->resp_buf,
drivers/scsi/bnx2fc/bnx2fc_io.c:				     mp_req->resp_buf_dma);
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->resp_buf = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_interface *interface = io_req->port->priv;
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req = (struct bnx2fc_mp_req *)&(io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->cmd_type != BNX2FC_ELS) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->req_len = sizeof(struct fcp_cmnd);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->data_xfer_len = mp_req->req_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:		mp_req->req_len = io_req->data_xfer_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req->req_buf = dma_alloc_coherent(&hba->pcidev->dev, CNIC_PAGE_SIZE,
drivers/scsi/bnx2fc/bnx2fc_io.c:					     &mp_req->req_buf_dma,
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!mp_req->req_buf) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req->resp_buf = dma_alloc_coherent(&hba->pcidev->dev, CNIC_PAGE_SIZE,
drivers/scsi/bnx2fc/bnx2fc_io.c:					      &mp_req->resp_buf_dma,
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!mp_req->resp_buf) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	memset(mp_req->req_buf, 0, CNIC_PAGE_SIZE);
drivers/scsi/bnx2fc/bnx2fc_io.c:	memset(mp_req->resp_buf, 0, CNIC_PAGE_SIZE);
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req->mp_req_bd = dma_alloc_coherent(&hba->pcidev->dev, sz,
drivers/scsi/bnx2fc/bnx2fc_io.c:						 &mp_req->mp_req_bd_dma,
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!mp_req->mp_req_bd) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req->mp_resp_bd = dma_alloc_coherent(&hba->pcidev->dev, sz,
drivers/scsi/bnx2fc/bnx2fc_io.c:						 &mp_req->mp_resp_bd_dma,
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!mp_req->mp_resp_bd) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	addr = mp_req->req_buf_dma;
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_req_bd = mp_req->mp_req_bd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	mp_resp_bd = mp_req->mp_resp_bd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	addr = mp_req->resp_buf_dma;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->sc_cmd = sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	tm_req = (struct bnx2fc_mp_req *)&(io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->io_req_flags = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	tm_req->tm_flags = tm_flags;
drivers/scsi/bnx2fc/bnx2fc_io.c:	bnx2fc_build_fcp_cmnd(io_req, (struct fcp_cmnd *)tm_req->req_buf);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fcp_cmnd = (struct fcp_cmnd *)tm_req->req_buf;
drivers/scsi/bnx2fc/bnx2fc_io.c:	fc_hdr = &(tm_req->req_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->on_tmf_queue = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_add_tail(&io_req->link, &tgt->active_tm_queue);
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_abts_comp = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:	rc = wait_for_completion_timeout(&io_req->abts_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_abts_comp = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!(test_bit(BNX2FC_FLAG_TM_COMPL, &io_req->req_flags))) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		set_bit(BNX2FC_FLAG_TM_TIMEOUT, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->on_tmf_queue) {
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:			io_req->on_tmf_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->wait_for_cleanup_comp = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:		init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:		rc = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->wait_for_cleanup_comp = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:			kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	port = io_req->port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	abts_io_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	abts_io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	abts_io_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	abts_io_req->data_xfer_len = 0; /* No data transfer for ABTS */
drivers/scsi/bnx2fc/bnx2fc_io.c:	abts_req = (struct bnx2fc_mp_req *)&(abts_io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fc_hdr = &(abts_req->req_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fc_hdr->fh_ox_id = htons(io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fc_hdr->fh_rx_id = htons(io_req->task->rxwr_txrd.var_ctx.rx_id);
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = abts_io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	/* if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags))*/
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:		   orig_io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_get(&orig_io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_io.c:	port = orig_io_req->port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->data_xfer_len = 0; /* No data transfer for cleanup */
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = seq_clnp_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->cb_arg = cb_arg;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	port = io_req->port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	cleanup_io_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	cleanup_io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	cleanup_io_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	cleanup_io_req->data_xfer_len = 0; /* No data transfer for cleanup */
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = cleanup_io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	orig_xid = io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	set_bit(BNX2FC_FLAG_ISSUE_CLEANUP_REQ, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_cleanup_comp = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:	time_left = wait_for_completion_timeout(&io_req->cleanup_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_cleanup_comp = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:		      kref_read(&io_req->refcount));
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_get(&io_req->refcount);
drivers/scsi/bnx2fc/bnx2fc_io.c:	BUG_ON(tgt != io_req->tgt);
drivers/scsi/bnx2fc/bnx2fc_io.c:			"flush in progress\n", io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->on_active_queue == 0) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				"not on active_q\n", io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_add_tail(&io_req->link, &tgt->io_retire_queue);
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	init_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_and_set_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				"already in abts processing\n", io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:			kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:		set_bit(BNX2FC_FLAG_IO_CLEANUP,	&io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:	set_bit(BNX2FC_FLAG_EH_ABORT, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_abts_comp = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->wait_for_cleanup_comp = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:		wait_for_completion(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->wait_for_cleanup_comp = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	time_left = wait_for_completion_timeout(&io_req->abts_done,
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->wait_for_abts_comp = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_bit(BNX2FC_FLAG_IO_COMPL, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				      &io_req->req_flags))) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		       io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_els_cb_arg *cb_arg = seq_clnp_req->cb_arg;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = orig_io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:		   seq_clnp_req->xid, seq_clnp_req->cmd_type);
drivers/scsi/bnx2fc/bnx2fc_io.c:			seq_clnp_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	seq_clnp_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&orig_io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:		   kref_read(&io_req->refcount), io_req->cmd_type);
drivers/scsi/bnx2fc/bnx2fc_io.c:				&io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags) &&
drivers/scsi/bnx2fc/bnx2fc_io.c:	    !test_bit(BNX2FC_FLAG_ABTS_DONE, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		set_bit(BNX2FC_FLAG_ABTS_DONE, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->wait_for_abts_comp)
drivers/scsi/bnx2fc/bnx2fc_io.c:			complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->wait_for_cleanup_comp)
drivers/scsi/bnx2fc/bnx2fc_io.c:		complete(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:		   io_req->xid,
drivers/scsi/bnx2fc/bnx2fc_io.c:		   kref_read(&io_req->refcount), io_req->cmd_type);
drivers/scsi/bnx2fc/bnx2fc_io.c:				       &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_bit(BNX2FC_FLAG_ISSUE_CLEANUP_REQ, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		clear_bit(BNX2FC_FLAG_ISSUE_CLEANUP_REQ, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->wait_for_cleanup_comp)
drivers/scsi/bnx2fc/bnx2fc_io.c:			complete(&io_req->cleanup_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:				&io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_bit(BNX2FC_FLAG_ISSUE_ABTS, &io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:			kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:		set_bit(BNX2FC_FLAG_ISSUE_RRQ, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	set_bit(BNX2FC_FLAG_RETIRE_OXID, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->wait_for_abts_comp) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				       &io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:			complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->on_active_queue) {
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:			io_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:			list_add_tail(&io_req->link, &tgt->io_retire_queue);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:				if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:					kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:			if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:				kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (!(test_bit(BNX2FC_FLAG_TM_TIMEOUT, &io_req->req_flags)))
drivers/scsi/bnx2fc/bnx2fc_io.c:		set_bit(BNX2FC_FLAG_TM_COMPL, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_io.c:	tm_req = &(io_req->mp_req);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fc_hdr = &(tm_req->resp_fc_hdr);
drivers/scsi/bnx2fc/bnx2fc_io.c:	tm_req->resp_len =
drivers/scsi/bnx2fc/bnx2fc_io.c:	rsp_buf = tm_req->resp_buf;
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->fcp_rsp_code == 0) {
drivers/scsi/bnx2fc/bnx2fc_io.c:			if (tm_req->tm_flags & FCP_TMF_LUN_RESET)
drivers/scsi/bnx2fc/bnx2fc_io.c:			else if (tm_req->tm_flags & FCP_TMF_TGT_RESET)
drivers/scsi/bnx2fc/bnx2fc_io.c:	switch (io_req->fcp_status) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->cdb_status == 0) {
drivers/scsi/bnx2fc/bnx2fc_io.c:			sc_cmd->result = (DID_OK << 16) | io_req->cdb_status;
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->fcp_resid)
drivers/scsi/bnx2fc/bnx2fc_io.c:			scsi_set_resid(sc_cmd, io_req->fcp_resid);
drivers/scsi/bnx2fc/bnx2fc_io.c:			   io_req->fcp_status);
drivers/scsi/bnx2fc/bnx2fc_io.c:	sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->on_tmf_queue) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->on_tmf_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->wait_for_abts_comp) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct fcoe_bd_ctx *bd = io_req->bd_tbl->bd_tbl;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_interface *interface = io_req->port->priv;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct fcoe_bd_ctx *bd = io_req->bd_tbl->bd_tbl;
drivers/scsi/bnx2fc/bnx2fc_io.c:			io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct fcoe_bd_ctx *bd = io_req->bd_tbl->bd_tbl;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->bd_tbl->bd_valid = bd_count;
drivers/scsi/bnx2fc/bnx2fc_io.c:		       bd_count, io_req->xid);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_interface *interface = io_req->port->priv;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->bd_tbl->bd_valid && sc && scsi_sg_count(sc)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->bd_tbl->bd_valid = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	fcp_cmnd->fc_dl = htonl(io_req->data_xfer_len);
drivers/scsi/bnx2fc/bnx2fc_io.c:	fcp_cmnd->fc_tm_flags = io_req->mp_req.tm_flags;
drivers/scsi/bnx2fc/bnx2fc_io.c:	fcp_cmnd->fc_flags = io_req->io_req_flags;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->fcp_status = FC_GOOD;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->fcp_resid = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->fcp_resid = fcp_rsp->fcp_resid;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->scsi_comp_flags = rsp_flags;
drivers/scsi/bnx2fc/bnx2fc_io.c:	CMD_SCSI_STATUS(sc_cmd) = io_req->cdb_status =
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->fcp_rsp_len = fcp_rsp_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->fcp_sns_len = fcp_sns_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:			io_req->fcp_rsp_code = rq_data[3];
drivers/scsi/bnx2fc/bnx2fc_io.c:				io_req->fcp_rsp_code);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->sc_cmd = sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct bnx2fc_rport *tgt = io_req->tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (test_and_set_bit(BNX2FC_FLAG_IO_COMPL, &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				       &io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_io.c:	sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	if (io_req->on_active_queue) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:		list_add_tail(&io_req->link, &tgt->io_retire_queue);
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->wait_for_abts_comp)
drivers/scsi/bnx2fc/bnx2fc_io.c:					       &io_req->req_flags))
drivers/scsi/bnx2fc/bnx2fc_io.c:				complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->sc_cmd = NULL;
drivers/scsi/bnx2fc/bnx2fc_io.c:	switch (io_req->fcp_status) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->cdb_status == 0) {
drivers/scsi/bnx2fc/bnx2fc_io.c:				io_req->cdb_status, io_req->fcp_resid);
drivers/scsi/bnx2fc/bnx2fc_io.c:			sc_cmd->result = (DID_OK << 16) | io_req->cdb_status;
drivers/scsi/bnx2fc/bnx2fc_io.c:			if (io_req->cdb_status == SAM_STAT_TASK_SET_FULL ||
drivers/scsi/bnx2fc/bnx2fc_io.c:			    io_req->cdb_status == SAM_STAT_BUSY) {
drivers/scsi/bnx2fc/bnx2fc_io.c:		if (io_req->fcp_resid)
drivers/scsi/bnx2fc/bnx2fc_io.c:			scsi_set_resid(sc_cmd, io_req->fcp_resid);
drivers/scsi/bnx2fc/bnx2fc_io.c:			io_req->fcp_status);
drivers/scsi/bnx2fc/bnx2fc_io.c:	kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	struct scsi_cmnd *sc_cmd = io_req->sc_cmd;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->cmd_type = BNX2FC_SCSI_CMD;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->port = port;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->tgt = tgt;
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->data_xfer_len = scsi_bufflen(sc_cmd);
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->io_req_flags = BNX2FC_READ;
drivers/scsi/bnx2fc/bnx2fc_io.c:		stats->InputBytes += io_req->data_xfer_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->io_req_flags = BNX2FC_WRITE;
drivers/scsi/bnx2fc/bnx2fc_io.c:		stats->OutputBytes += io_req->data_xfer_len;
drivers/scsi/bnx2fc/bnx2fc_io.c:		io_req->io_req_flags = 0;
drivers/scsi/bnx2fc/bnx2fc_io.c:	xid = io_req->xid;
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:		kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_io.c:	io_req->on_active_queue = 1;
drivers/scsi/bnx2fc/bnx2fc_io.c:	list_add_tail(&io_req->link, &tgt->active_cmd_queue);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		io_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		if (cancel_delayed_work(&io_req->timeout_work)) {
drivers/scsi/bnx2fc/bnx2fc_tgt.c:						&io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_tgt.c:				complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		set_bit(BNX2FC_FLAG_IO_COMPL, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		set_bit(BNX2FC_FLAG_IO_CLEANUP, &io_req->req_flags);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			bnx2fc_process_cleanup_compl(io_req, io_req->task, 0);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		io_req->on_tmf_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		if (io_req->wait_for_abts_comp)
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		io_req->on_active_queue = 0;
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		if (cancel_delayed_work(&io_req->timeout_work))
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			kref_put(&io_req->refcount,
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		if ((io_req->cb_func) && (io_req->cb_arg)) {
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			io_req->cb_func(io_req->cb_arg);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			io_req->cb_arg = NULL;
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			bnx2fc_process_cleanup_compl(io_req, io_req->task, 0);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		list_del_init(&io_req->link);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		if (cancel_delayed_work(&io_req->timeout_work)) {
drivers/scsi/bnx2fc/bnx2fc_tgt.c:						&io_req->req_flags)) {
drivers/scsi/bnx2fc/bnx2fc_tgt.c:				if (io_req->wait_for_abts_comp)
drivers/scsi/bnx2fc/bnx2fc_tgt.c:					complete(&io_req->abts_done);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:			kref_put(&io_req->refcount, bnx2fc_cmd_release);
drivers/scsi/bnx2fc/bnx2fc_tgt.c:		clear_bit(BNX2FC_FLAG_ISSUE_RRQ, &io_req->req_flags);
drivers/scsi/mac53c94.c:	struct Scsi_Host *dev = ((struct fsc_state *) dev_id)->current_req->device->host;
drivers/scsi/hptiop.c:			req->header.result = cpu_to_le32(IOP_RESULT_SUCCESS);
drivers/scsi/hptiop.c:			req->header.result = IOP_RESULT_SUCCESS;
drivers/scsi/hptiop.c:	writel(readl(&req->flags) | IOP_REQUEST_FLAG_SYNC_REQUEST, &req->flags);
drivers/scsi/hptiop.c:	writel(0, &req->context);
drivers/scsi/hptiop.c:		if (readl(&req->context))
drivers/scsi/hptiop.c:	writel(0, &req->header.flags);
drivers/scsi/hptiop.c:	writel(IOP_REQUEST_TYPE_GET_CONFIG, &req->header.type);
drivers/scsi/hptiop.c:	writel(sizeof(struct hpt_iop_request_get_config), &req->header.size);
drivers/scsi/hptiop.c:	writel(IOP_RESULT_PENDING, &req->header.result);
drivers/scsi/hptiop.c:	req->header.flags = cpu_to_le32(IOP_REQUEST_FLAG_OUTPUT_CONTEXT);
drivers/scsi/hptiop.c:	req->header.type = cpu_to_le32(IOP_REQUEST_TYPE_GET_CONFIG);
drivers/scsi/hptiop.c:	req->header.size =
drivers/scsi/hptiop.c:	req->header.result = cpu_to_le32(IOP_RESULT_PENDING);
drivers/scsi/hptiop.c:	req->header.context = cpu_to_le32(IOP_REQUEST_TYPE_GET_CONFIG<<5);
drivers/scsi/hptiop.c:	req->header.context_hi32 = 0;
drivers/scsi/hptiop.c:	writel(0, &req->header.flags);
drivers/scsi/hptiop.c:	writel(IOP_REQUEST_TYPE_SET_CONFIG, &req->header.type);
drivers/scsi/hptiop.c:	writel(sizeof(struct hpt_iop_request_set_config), &req->header.size);
drivers/scsi/hptiop.c:	writel(IOP_RESULT_PENDING, &req->header.result);
drivers/scsi/hptiop.c:	req->header.flags = cpu_to_le32(IOP_REQUEST_FLAG_OUTPUT_CONTEXT);
drivers/scsi/hptiop.c:	req->header.type = cpu_to_le32(IOP_REQUEST_TYPE_SET_CONFIG);
drivers/scsi/hptiop.c:	req->header.size =
drivers/scsi/hptiop.c:	req->header.result = cpu_to_le32(IOP_RESULT_PENDING);
drivers/scsi/hptiop.c:	req->header.context = cpu_to_le32(IOP_REQUEST_TYPE_SET_CONFIG<<5);
drivers/scsi/hptiop.c:	req->header.context_hi32 = 0;
drivers/scsi/hptiop.c:	req->header.flags = cpu_to_le32(IOP_REQUEST_FLAG_OUTPUT_CONTEXT);
drivers/scsi/hptiop.c:	req->header.type = cpu_to_le32(IOP_REQUEST_TYPE_SET_CONFIG);
drivers/scsi/hptiop.c:	req->header.size =
drivers/scsi/hptiop.c:	req->header.result = cpu_to_le32(IOP_RESULT_PENDING);
drivers/scsi/hptiop.c:	req->header.context = cpu_to_le32(IOP_REQUEST_TYPE_SET_CONFIG<<5);
drivers/scsi/hptiop.c:	req->header.context_hi32 = 0;
drivers/scsi/hptiop.c:	dprintk("free_req(%d, %p)\n", req->index, req);
drivers/scsi/hptiop.c:	req->next = hba->req_list;
drivers/scsi/hptiop.c:			req, req->header.type, req->header.result,
drivers/scsi/hptiop.c:			req->header.context, tag);
drivers/scsi/hptiop.c:	BUG_ON(!req->header.result);
drivers/scsi/hptiop.c:	BUG_ON(req->header.type != cpu_to_le32(IOP_REQUEST_TYPE_SCSI_COMMAND));
drivers/scsi/hptiop.c:	switch (le32_to_cpu(req->header.result)) {
drivers/scsi/hptiop.c:			scsi_bufflen(scp) - le32_to_cpu(req->dataxfer_length));
drivers/scsi/hptiop.c:			scsi_bufflen(scp) - le32_to_cpu(req->dataxfer_length));
drivers/scsi/hptiop.c:		memcpy(scp->sense_buffer, &req->sg_list, SCSI_SENSE_BUFFERSIZE);
drivers/scsi/hptiop.c:		scsi_bufflen(scp) - le32_to_cpu(req->dataxfer_length));
drivers/scsi/hptiop.c:			req->header.result = cpu_to_le32(IOP_RESULT_SUCCESS);
drivers/scsi/hptiop.c:			req, readl(&req->type), readl(&req->result),
drivers/scsi/hptiop.c:			readl(&req->context), tag);
drivers/scsi/hptiop.c:	BUG_ON(!readl(&req->result));
drivers/scsi/hptiop.c:	BUG_ON(readl(&req->type) != IOP_REQUEST_TYPE_IOCTL_COMMAND);
drivers/scsi/hptiop.c:		(readl(&req->context) |
drivers/scsi/hptiop.c:			((u64)readl(&req->context_hi32)<<32));
drivers/scsi/hptiop.c:	if (readl(&req->result) == IOP_RESULT_SUCCESS) {
drivers/scsi/hptiop.c:	struct hpt_iop_request_header *reqhdr = _req->req_virt;
drivers/scsi/hptiop.c:							(u32)_req->index);
drivers/scsi/hptiop.c:		writel(_req->req_shifted_phy | size_bits,
drivers/scsi/hptiop.c:		writel(_req->req_shifted_phy | IOPMU_QUEUE_ADDR_HOST_BIT,
drivers/scsi/hptiop.c:	struct hpt_iop_request_header *reqhdr = _req->req_virt;
drivers/scsi/hptiop.c:	reqhdr->context = cpu_to_le32(_req->index<<8 |
drivers/scsi/hptiop.c:	mv_inbound_write((_req->req_shifted_phy << 5) |
drivers/scsi/hptiop.c:	struct hpt_iop_request_header *reqhdr = _req->req_virt;
drivers/scsi/hptiop.c:			((_req->req_shifted_phy >> 11) & 0xffff0000));
drivers/scsi/hptiop.c:			(_req->index << 4) | reqhdr->type);
drivers/scsi/hptiop.c:	reqhdr->context_hi32 = cpu_to_le32((_req->req_shifted_phy << 5) &
drivers/scsi/hptiop.c:			(dma_addr_t)_req->req_shifted_phy << 5;
drivers/scsi/hptiop.c:	_req->scp = scp;
drivers/scsi/hptiop.c:			_req->index, _req->req_virt);
drivers/scsi/hptiop.c:	req = _req->req_virt;
drivers/scsi/hptiop.c:	sg_count = hptiop_buildsgl(scp, req->sg_list);
drivers/scsi/hptiop.c:	req->header.flags = cpu_to_le32(IOP_REQUEST_FLAG_OUTPUT_CONTEXT);
drivers/scsi/hptiop.c:	req->header.type = cpu_to_le32(IOP_REQUEST_TYPE_SCSI_COMMAND);
drivers/scsi/hptiop.c:	req->header.result = cpu_to_le32(IOP_RESULT_PENDING);
drivers/scsi/hptiop.c:	req->dataxfer_length = cpu_to_le32(scsi_bufflen(scp));
drivers/scsi/hptiop.c:	req->channel = scp->device->channel;
drivers/scsi/hptiop.c:	req->target = scp->device->id;
drivers/scsi/hptiop.c:	req->lun = scp->device->lun;
drivers/scsi/hptiop.c:	req->header.size = cpu_to_le32(
drivers/scsi/hptiop.c:	memcpy(req->cdb, scp->cmnd, sizeof(req->cdb));
drivers/scsi/be2iscsi/be_main.c:	switch (bsg_req->msgcode) {
drivers/scsi/be2iscsi/be_main.c:				bsg_req->msgcode);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/scsi/be2iscsi/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, func, req->context,
drivers/scsi/be2iscsi/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, valid, req->context, 1);
drivers/scsi/be2iscsi/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, size, req->context, 0);
drivers/scsi/be2iscsi/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, count, req->context,
drivers/scsi/be2iscsi/be_cmds.c:	AMAP_SET_BITS(struct amap_eq_context, delaymult, req->context,
drivers/scsi/be2iscsi/be_cmds.c:	be_dws_cpu_to_le(req->context, sizeof(req->context));
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	void *ctxt = &req->context;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = cpu_to_le16(PAGES_4K_SPANNED(q_mem->va, q_mem->size));
drivers/scsi/be2iscsi/be_cmds.c:		req->hdr.version = MBX_CMD_VER2;
drivers/scsi/be2iscsi/be_cmds.c:		req->page_size = 1;
drivers/scsi/be2iscsi/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	ctxt = &req->context;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);
drivers/scsi/be2iscsi/be_cmds.c:	req->async_evt_bitmap = 1 << ASYNC_EVENT_CODE_LINK_STATE;
drivers/scsi/be2iscsi/be_cmds.c:	req->async_evt_bitmap |= 1 << ASYNC_EVENT_CODE_ISCSI;
drivers/scsi/be2iscsi/be_cmds.c:	req->async_evt_bitmap |= 1 << ASYNC_EVENT_CODE_SLI;
drivers/scsi/be2iscsi/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, subsys, opcode, sizeof(*req));
drivers/scsi/be2iscsi/be_cmds.c:		req->id = cpu_to_le16(q->id);
drivers/scsi/be2iscsi/be_cmds.c:	void *ctxt = &req->context;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);
drivers/scsi/be2iscsi/be_cmds.c:		req->ulp_num = ulp_num;
drivers/scsi/be2iscsi/be_cmds.c:		req->dua_feature |= (1 << BEISCSI_DUAL_ULP_AWARE_BIT);
drivers/scsi/be2iscsi/be_cmds.c:		req->dua_feature |= (1 << BEISCSI_BIND_Q_TO_ULP_BIT);
drivers/scsi/be2iscsi/be_cmds.c:	be_dws_cpu_to_le(ctxt, sizeof(req->context));
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);
drivers/scsi/be2iscsi/be_cmds.c:		req->ulp_num = ulp_num;
drivers/scsi/be2iscsi/be_cmds.c:		req->dua_feature |= (1 << BEISCSI_DUAL_ULP_AWARE_BIT);
drivers/scsi/be2iscsi/be_cmds.c:		req->dua_feature |= (1 << BEISCSI_BIND_Q_TO_ULP_BIT);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	req->num_pages = PAGES_4K_SPANNED(q_mem->va, q_mem->size);
drivers/scsi/be2iscsi/be_cmds.c:	req->type = BEISCSI_TEMPLATE_HDR_TYPE_ISCSI;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_page_addrs_prepare(req->pages, ARRAY_SIZE(req->pages), q_mem);
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	req->type = BEISCSI_TEMPLATE_HDR_TYPE_ISCSI;
drivers/scsi/be2iscsi/be_cmds.c:		be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_cmds.c:		req->num_pages = min(num_pages, curr_pages);
drivers/scsi/be2iscsi/be_cmds.c:		req->page_offset = page_offset;
drivers/scsi/be2iscsi/be_cmds.c:		be_cmd_page_addrs_prepare(req->pages, req->num_pages, q_mem);
drivers/scsi/be2iscsi/be_cmds.c:		q_mem->dma = q_mem->dma + (req->num_pages * PAGE_SIZE);
drivers/scsi/be2iscsi/be_cmds.c:		internal_page_offset += req->num_pages;
drivers/scsi/be2iscsi/be_cmds.c:		page_offset += req->num_pages;
drivers/scsi/be2iscsi/be_cmds.c:		num_pages -= req->num_pages;
drivers/scsi/be2iscsi/be_cmds.c:			req->num_pages = temp_num_pages;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_cmds.c:	req->interface_hndl = phba->interface_handle;
drivers/scsi/be2iscsi/be_cmds.c:	req->vlan_priority = vlan_tag;
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_COMMON,
drivers/scsi/be2iscsi/be_cmds.c:		be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_cmds.c:		req->chute = (1 << ulp);
drivers/scsi/be2iscsi/be_cmds.c:		req->hdr_ring_id = hdr_ring_id;
drivers/scsi/be2iscsi/be_cmds.c:		req->data_ring_id = data_ring_id;
drivers/scsi/be2iscsi/be_mgmt.c:	region =  bsg_req->rqst_data.h_vendor.vendor_cmd[1];
drivers/scsi/be2iscsi/be_mgmt.c:	sector_size =  bsg_req->rqst_data.h_vendor.vendor_cmd[2];
drivers/scsi/be2iscsi/be_mgmt.c:	sector =  bsg_req->rqst_data.h_vendor.vendor_cmd[3];
drivers/scsi/be2iscsi/be_mgmt.c:	offset =  bsg_req->rqst_data.h_vendor.vendor_cmd[4];
drivers/scsi/be2iscsi/be_mgmt.c:	req->region = region;
drivers/scsi/be2iscsi/be_mgmt.c:	req->sector = sector;
drivers/scsi/be2iscsi/be_mgmt.c:	req->offset = offset;
drivers/scsi/be2iscsi/be_mgmt.c:	switch (bsg_req->rqst_data.h_vendor.vendor_cmd[0]) {
drivers/scsi/be2iscsi/be_mgmt.c:		be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_mgmt.c:		be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_mgmt.c:			    bsg_req->rqst_data.h_vendor.vendor_cmd[0]);
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.ip_type = BEISCSI_IP_TYPE_V4;
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.addr[0] = s_addr & 0x000000ff;
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.addr[1] = (s_addr & 0x0000ff00) >> 8;
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.addr[2] = (s_addr & 0x00ff0000) >> 16;
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.addr[3] = (s_addr & 0xff000000) >> 24;
drivers/scsi/be2iscsi/be_mgmt.c:		req->tcp_port = ntohs(daddr_in->sin_port);
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_address.ip_type = BEISCSI_IP_TYPE_V6;
drivers/scsi/be2iscsi/be_mgmt.c:		memcpy(&req->ip_address.addr,
drivers/scsi/be2iscsi/be_mgmt.c:		req->tcp_port = ntohs(daddr_in6->sin6_port);
drivers/scsi/be2iscsi/be_mgmt.c:	req->cid = cid;
drivers/scsi/be2iscsi/be_mgmt.c:	req->cq_id = phwi_context->be_cq[i].id;
drivers/scsi/be2iscsi/be_mgmt.c:		    "BG_%d : i=%d cq_id=%d\n", i, req->cq_id);
drivers/scsi/be2iscsi/be_mgmt.c:	req->defq_id = def_hdr_id;
drivers/scsi/be2iscsi/be_mgmt.c:	req->hdr_ring_id = def_hdr_id;
drivers/scsi/be2iscsi/be_mgmt.c:	req->data_ring_id = def_data_id;
drivers/scsi/be2iscsi/be_mgmt.c:	req->do_offload = 1;
drivers/scsi/be2iscsi/be_mgmt.c:	req->dataout_template_pa.lo = ptemplate_address->lo;
drivers/scsi/be2iscsi/be_mgmt.c:	req->dataout_template_pa.hi = ptemplate_address->hi;
drivers/scsi/be2iscsi/be_mgmt.c:		req->hdr.version = MBX_CMD_VER1;
drivers/scsi/be2iscsi/be_mgmt.c:		req->tcp_window_size = 0x8000;
drivers/scsi/be2iscsi/be_mgmt.c:		req->tcp_window_scale_count = 2;
drivers/scsi/be2iscsi/be_mgmt.c:	req->num_eq = cpu_to_le32(num);
drivers/scsi/be2iscsi/be_mgmt.c:		req->delay[i].eq_id = cpu_to_le32(set_eqd[i].eq_id);
drivers/scsi/be2iscsi/be_mgmt.c:		req->delay[i].phase = 0;
drivers/scsi/be2iscsi/be_mgmt.c:		req->delay[i].delay_multiplier =
drivers/scsi/be2iscsi/be_mgmt.c:		req->hdr.version = 1;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->action = action;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_addr.ip_type = ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:	memcpy(req->ip_addr.addr, gw,
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_type = ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.record_entry_count = 1;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.action = IP_ACTION_DEL;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.interface_hndl =
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.ip_addr.size_of_structure =
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.ip_addr.ip_type = if_info->ip_addr.ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:	memcpy(req->ip_params.ip_record.ip_addr.addr,
drivers/scsi/be2iscsi/be_mgmt.c:	memcpy(req->ip_params.ip_record.ip_addr.subnet_mask,
drivers/scsi/be2iscsi/be_mgmt.c:	if (rc < 0 || req->ip_params.ip_record.status) {
drivers/scsi/be2iscsi/be_mgmt.c:			    rc, req->ip_params.ip_record.status);
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.record_entry_count = 1;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.action = IP_ACTION_ADD;
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.interface_hndl =
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.ip_addr.size_of_structure =
drivers/scsi/be2iscsi/be_mgmt.c:	req->ip_params.ip_record.ip_addr.ip_type = ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:	memcpy(req->ip_params.ip_record.ip_addr.addr, ip, ip_len);
drivers/scsi/be2iscsi/be_mgmt.c:		memcpy(req->ip_params.ip_record.ip_addr.subnet_mask,
drivers/scsi/be2iscsi/be_mgmt.c:	if (rc < 0 || req->ip_params.ip_record.status) {
drivers/scsi/be2iscsi/be_mgmt.c:			    rc, req->ip_params.ip_record.status);
drivers/scsi/be2iscsi/be_mgmt.c:		if (req->ip_params.ip_record.status)
drivers/scsi/be2iscsi/be_mgmt.c:	dhcpreq->flags = 1; /* 1 - blocking; 0 - non-blocking */
drivers/scsi/be2iscsi/be_mgmt.c:	dhcpreq->retry_count = 1;
drivers/scsi/be2iscsi/be_mgmt.c:	dhcpreq->interface_hndl = phba->interface_handle;
drivers/scsi/be2iscsi/be_mgmt.c:	dhcpreq->ip_type = ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:		req->interface_hndl = phba->interface_handle;
drivers/scsi/be2iscsi/be_mgmt.c:		req->ip_type = ip_type;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI_INI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->session_handle = phba->boot_struct.boot_sess.session_handle;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI_INI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->reopen_type = BE_REOPEN_BOOT_SESSIONS;
drivers/scsi/be2iscsi/be_mgmt.c:	req->session_handle = BE_BOOT_INVALID_SHANDLE;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI_INI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->session_handle = phba->boot_struct.s_handle;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI_INI,
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI_INI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->session_handle = beiscsi_ep->fw_handle;
drivers/scsi/be2iscsi/be_mgmt.c:	req->cid = beiscsi_ep->ep_cid;
drivers/scsi/be2iscsi/be_mgmt.c:		req->cleanup_type = BE_CLEANUP_TYPE_INVALIDATE;
drivers/scsi/be2iscsi/be_mgmt.c:		req->cleanup_type = BE_CLEANUP_TYPE_ISSUE_TCP_RST;
drivers/scsi/be2iscsi/be_mgmt.c:	req->save_cfg = 0;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_COMMON_TCP_UPLOAD,
drivers/scsi/be2iscsi/be_mgmt.c:	req->id = beiscsi_ep->ep_cid;
drivers/scsi/be2iscsi/be_mgmt.c:		req->upload_type = BE_UPLOAD_TYPE_GRACEFUL;
drivers/scsi/be2iscsi/be_mgmt.c:		req->upload_type = BE_UPLOAD_TYPE_ABORT;
drivers/scsi/be2iscsi/be_mgmt.c:	be_cmd_hdr_prepare(&req->hdr, CMD_SUBSYSTEM_ISCSI,
drivers/scsi/be2iscsi/be_mgmt.c:	req->ref_handle = 0;
drivers/scsi/be2iscsi/be_mgmt.c:	req->cleanup_type = CMD_ISCSI_COMMAND_INVALIDATE;
drivers/scsi/be2iscsi/be_mgmt.c:		req->table[i].icd = inv_tbl[i].icd;
drivers/scsi/be2iscsi/be_mgmt.c:		req->table[i].cid = inv_tbl[i].cid;
drivers/scsi/be2iscsi/be_mgmt.c:		req->icd_count++;
drivers/scsi/stex.c:		dst = (struct st_sgtable *)req->variable;
drivers/scsi/stex.c:		dst = (struct st_sgtable *)req->variable;
drivers/scsi/stex.c:	req->tag = cpu_to_le16(tag);
drivers/scsi/stex.c:	req->tag = cpu_to_le16(tag);
drivers/scsi/stex.c:	req->lun = lun;
drivers/scsi/stex.c:	req->target = id;
drivers/scsi/stex.c:	memcpy(req->cdb, cmd->cmnd, STEX_CDB_LENGTH);
drivers/scsi/stex.c:		req->data_dir = MSG_DATA_DIR_IN;
drivers/scsi/stex.c:		req->data_dir = MSG_DATA_DIR_OUT;
drivers/scsi/stex.c:		req->data_dir = MSG_DATA_DIR_ND;
drivers/scsi/stex.c:		memset(&req->variable[0], 0, 8);
drivers/scsi/stex.c:		req->cdb[0] = MGT_CMD;
drivers/scsi/stex.c:		req->cdb[1] = MGT_CMD_SIGNATURE;
drivers/scsi/stex.c:		req->cdb[2] = CTLR_CONFIG_CMD;
drivers/scsi/stex.c:		req->cdb[3] = CTLR_SHUTDOWN;
drivers/scsi/stex.c:		req->cdb[0] = MGT_CMD;
drivers/scsi/stex.c:		req->cdb[1] = MGT_CMD_SIGNATURE;
drivers/scsi/stex.c:		req->cdb[2] = CTLR_CONFIG_CMD;
drivers/scsi/stex.c:		req->cdb[3] = PMIC_SHUTDOWN;
drivers/scsi/stex.c:		req->cdb[4] = st_sleep_mic;
drivers/scsi/stex.c:		req->cdb[0] = CONTROLLER_CMD;
drivers/scsi/stex.c:		req->cdb[1] = CTLR_POWER_STATE_CHANGE;
drivers/scsi/stex.c:		req->cdb[2] = CTLR_POWER_SAVING;
drivers/scsi/scsi_transport_iscsi.c:	switch (req->msgcode) {
drivers/scsi/scsi_transport_iscsi.c:		    (req->rqst_data.h_vendor.vendor_id !=
drivers/scsi/device_handler/scsi_dh_alua.c:		req->rq_flags |= RQF_QUIET;
drivers/scsi/device_handler/scsi_dh_hp_sw.c:		req->rq_flags |= RQF_QUIET;
drivers/scsi/device_handler/scsi_dh_rdac.c:		req->rq_flags |= RQF_QUIET;
drivers/scsi/device_handler/scsi_dh_emc.c:		req->rq_flags |= RQF_QUIET;
drivers/scsi/bfa/bfa_svc.c:	bfi_h2i_set(send_req->mh, BFI_MC_FCXP, BFI_FCXP_H2I_SEND_REQ,
drivers/scsi/bfa/bfa_svc.c:	send_req->fcxp_tag = cpu_to_be16(fcxp->fcxp_tag);
drivers/scsi/bfa/bfa_svc.c:		send_req->rport_fw_hndl = rport->fw_handle;
drivers/scsi/bfa/bfa_svc.c:		send_req->max_frmsz = cpu_to_be16(rport->rport_info.max_frmsz);
drivers/scsi/bfa/bfa_svc.c:		if (send_req->max_frmsz == 0)
drivers/scsi/bfa/bfa_svc.c:			send_req->max_frmsz = cpu_to_be16(FC_MAX_PDUSZ);
drivers/scsi/bfa/bfa_svc.c:		send_req->rport_fw_hndl = 0;
drivers/scsi/bfa/bfa_svc.c:		send_req->max_frmsz = cpu_to_be16(FC_MAX_PDUSZ);
drivers/scsi/bfa/bfa_svc.c:	send_req->vf_id = cpu_to_be16(reqi->vf_id);
drivers/scsi/bfa/bfa_svc.c:	send_req->lp_fwtag = bfa_lps_get_fwtag(bfa, reqi->lp_tag);
drivers/scsi/bfa/bfa_svc.c:	send_req->class = reqi->class;
drivers/scsi/bfa/bfa_svc.c:	send_req->rsp_timeout = rspi->rsp_timeout;
drivers/scsi/bfa/bfa_svc.c:	send_req->cts = reqi->cts;
drivers/scsi/bfa/bfa_svc.c:	send_req->fchs = reqi->fchs;
drivers/scsi/bfa/bfa_svc.c:	send_req->req_len = cpu_to_be32(reqi->req_tot_len);
drivers/scsi/bfa/bfa_svc.c:	send_req->rsp_maxlen = cpu_to_be32(rspi->rsp_maxlen);
drivers/scsi/bfa/bfa_svc.c:		bfa_alen_set(&send_req->req_alen, reqi->req_tot_len,
drivers/scsi/bfa/bfa_svc.c:			bfa_alen_set(&send_req->req_alen, reqi->req_tot_len,
drivers/scsi/bfa/bfa_svc.c:			bfa_alen_set(&send_req->rsp_alen, 0, 0);
drivers/scsi/bfa/bfa_svc.c:		bfa_alen_set(&send_req->rsp_alen, rspi->rsp_maxlen,
drivers/scsi/bfa/bfa_svc.c:			bfa_alen_set(&send_req->rsp_alen, rspi->rsp_maxlen,
drivers/scsi/bfa/bfa_svc.c:			bfa_alen_set(&send_req->rsp_alen, 0, 0);
drivers/scsi/bfa/bfa_svc.c:	bfa_reqq_produce(bfa, BFA_REQQ_FCXP, send_req->mh);
drivers/scsi/bfa/bfa_svc.c:	bfi_h2i_set(req->mh, BFI_MC_DIAG, BFI_DIAG_H2I_QTEST,
drivers/scsi/bfa/bfa_svc.c:		req->data[i] = QTEST_PAT_DEFAULT;
drivers/scsi/bfa/bfa_svc.c:	bfa_reqq_produce(fcdiag->bfa, fcdiag->qtest.queue, req->mh);
drivers/scsi/bfa/bfa_svc.c:	bfi_h2i_set(lb_req->mh, BFI_MC_DIAG, BFI_DIAG_H2I_LOOPBACK,
drivers/scsi/bfa/bfa_svc.c:	lb_req->lb_mode = loopback->lb_mode;
drivers/scsi/bfa/bfa_svc.c:	lb_req->speed = loopback->speed;
drivers/scsi/bfa/bfa_svc.c:	lb_req->loopcnt = loopback->loopcnt;
drivers/scsi/bfa/bfa_svc.c:	lb_req->pattern = loopback->pattern;
drivers/scsi/bfa/bfa_svc.c:	bfa_reqq_produce(fcdiag->bfa, BFA_REQQ_DIAG, lb_req->mh);
drivers/scsi/bfa/bfa_ioc.c:	bfi_h2i_set(req->mh, BFI_MC_IOC, BFI_IOC_H2I_DBG_SYNC,
drivers/scsi/bfa/bfa_ioc.c:	req->clscode = cpu_to_be16(ioc->clscode);
drivers/scsi/bfa/bfa_ioc.c:	bfa_trc(sfp, req->memtype);
drivers/scsi/bfa/bfa_ioc.c:	bfi_h2i_set(req->mh, BFI_MC_SFP, BFI_SFP_H2I_SHOW,
drivers/scsi/bfa/bfa_ioc.c:	req->memtype = memtype;
drivers/scsi/bfa/bfa_ioc.c:	bfa_alen_set(&req->alen, sizeof(struct sfp_mem_s), sfp->dbuf_pa);
drivers/scsi/bfa/bfa_ioc.c:	req->memtype = 0;
drivers/scsi/bfa/bfa_ioc.c:	bfa_alen_set(&fwping_req->alen, BFI_DIAG_DMA_BUF_SZ,
drivers/scsi/bfa/bfa_ioc.c:	fwping_req->count = cpu_to_be32(diag->fwping.count);
drivers/scsi/bfa/bfa_ioc.c:	fwping_req->data = diag->fwping.data;
drivers/scsi/bfa/bfa_ioc.c:	bfi_h2i_set(fwping_req->mh, BFI_MC_DIAG, BFI_DIAG_H2I_FWPING,
drivers/scsi/bfa/bfa_ioc.c:	/* mcpy(&ledtest_req->req, ledtest, sizeof(bfa_diag_ledtest_t)); */
drivers/scsi/lpfc/lpfc_nvmet.c: * -> lpfc_nvmet_xmt_ls_rsp/cmp -> req->done.
drivers/scsi/lpfc/lpfc_nvmet.c:	 * nvmet_fc_rcv_fcp_req->lpfc_nvmet_xmt_fcp_op/cmp- req->done
drivers/scsi/lpfc/lpfc_bsg.c:	evt_req_id = ct_req->FsType;
drivers/scsi/lpfc/lpfc_bsg.c:	cmd = ct_req->CommandResponse.bits.CmdRsp;
drivers/scsi/lpfc/lpfc_bsg.c:	ev_mask = ((uint32_t)(unsigned long)event_req->type_mask &
drivers/scsi/lpfc/lpfc_bsg.c:		if (evt->reg_id == event_req->ev_reg_id) {
drivers/scsi/lpfc/lpfc_bsg.c:		evt = lpfc_bsg_event_new(ev_mask, event_req->ev_reg_id,
drivers/scsi/lpfc/lpfc_bsg.c:					event_req->ev_req_id);
drivers/scsi/lpfc/lpfc_bsg.c:		if (evt->reg_id == event_req->ev_reg_id) {
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->RevisionId.bits.Revision = SLI_CT_REVISION;
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->RevisionId.bits.InId = 0;
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->FsType = SLI_CT_ELX_LOOPBACK;
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->FsSubType = 0;
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->CommandResponse.bits.CmdRsp = ELX_LOOPBACK_XRI_SETUP;
drivers/scsi/lpfc/lpfc_bsg.c:	ctreq->CommandResponse.bits.Size = 0;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->RevisionId.bits.Revision = SLI_CT_REVISION;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->RevisionId.bits.InId = 0;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->FsType = SLI_CT_ELX_LOOPBACK;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->FsSubType = 0;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->CommandResponse.bits.CmdRsp = ELX_LOOPBACK_DATA;
drivers/scsi/lpfc/lpfc_bsg.c:			ctreq->CommandResponse.bits.Size   = size;
drivers/scsi/lpfc/lpfc_bsg.c:	phba->mbox_ext_buf_ctx.mbxTag = mbox_req->extMboxTag;
drivers/scsi/lpfc/lpfc_bsg.c:	phba->mbox_ext_buf_ctx.seqNum = mbox_req->extSeqNum;
drivers/scsi/lpfc/lpfc_bsg.c:	phba->mbox_ext_buf_ctx.mbxTag = mbox_req->extMboxTag;
drivers/scsi/lpfc/lpfc_bsg.c:	phba->mbox_ext_buf_ctx.seqNum = mbox_req->extSeqNum;
drivers/scsi/lpfc/lpfc_bsg.c:	if (mbox_req->extMboxTag == 0 && mbox_req->extSeqNum == 0)
drivers/scsi/lpfc/lpfc_bsg.c:		if (mbox_req->extSeqNum == 1) {
drivers/scsi/lpfc/lpfc_bsg.c:					"seq:%d\n", mbox_req->extMboxTag,
drivers/scsi/lpfc/lpfc_bsg.c:					mbox_req->extSeqNum);
drivers/scsi/lpfc/lpfc_bsg.c:	if (mbox_req->extMboxTag != phba->mbox_ext_buf_ctx.mbxTag)
drivers/scsi/lpfc/lpfc_bsg.c:	if (mbox_req->extSeqNum > phba->mbox_ext_buf_ctx.numBuf)
drivers/scsi/lpfc/lpfc_bsg.c:	if (mbox_req->extSeqNum != phba->mbox_ext_buf_ctx.seqNum + 1)
drivers/scsi/lpfc/lpfc_bsg.c:			phba->mbox_ext_buf_ctx.state, mbox_req->extMboxTag,
drivers/scsi/lpfc/lpfc_bsg.c:			mbox_req->extSeqNum);
drivers/scsi/lpfc/lpfc_bsg.c:			mbox_req->extMboxTag, mbox_req->extSeqNum);
drivers/scsi/lpfc/lpfc_bsg.c:	if ((mbox_req->inExtWLen > BSG_MBOX_SIZE/sizeof(uint32_t)) ||
drivers/scsi/lpfc/lpfc_bsg.c:	    (mbox_req->outExtWLen > BSG_MBOX_SIZE/sizeof(uint32_t))) {
drivers/scsi/lpfc/lpfc_bsg.c:	if (mbox_req->inExtWLen || mbox_req->outExtWLen) {
drivers/scsi/lpfc/lpfc_bsg.c:			mbox_req->inExtWLen * sizeof(uint32_t);
drivers/scsi/lpfc/lpfc_bsg.c:			mbox_req->outExtWLen * sizeof(uint32_t);
drivers/scsi/lpfc/lpfc_bsg.c:		pmboxq->mbox_offset_word = mbox_req->mbOffset;
drivers/scsi/lpfc/lpfc_bsg.c:	dd_data->context_un.mbox.mbOffset = mbox_req->mbOffset;
drivers/scsi/lpfc/lpfc_bsg.c:	dd_data->context_un.mbox.inExtWLen = mbox_req->inExtWLen;
drivers/scsi/lpfc/lpfc_bsg.c:	dd_data->context_un.mbox.outExtWLen = mbox_req->outExtWLen;
drivers/scsi/lpfc/lpfc_bsg.c:		mbox_req->extMboxTag = 0;
drivers/scsi/lpfc/lpfc_bsg.c:		mbox_req->extSeqNum = 0;
drivers/scsi/lpfc/lpfc_bsg.c:	action = ras_req->action;
drivers/scsi/lpfc/lpfc_bsg.c:	log_level = ras_req->log_level;
drivers/scsi/lpfc/lpfc_bsg.c:	rd_offset = ras_req->read_offset;
drivers/scsi/lpfc/lpfc_bsg.c:	fwlog_buff = vmalloc(ras_req->read_size);
drivers/scsi/lpfc/lpfc_bsg.c:		memcpy(fwlog_buff, src, ras_req->read_size);
drivers/scsi/lpfc/lpfc_bsg.c:				    fwlog_buff, ras_req->read_size);
drivers/scsi/lpfc/lpfc_ct.c:	ct_rsp->FsType = ct_req->FsType;
drivers/scsi/lpfc/lpfc_ct.c:	ct_rsp->FsSubType = ct_req->FsSubType;
drivers/scsi/lpfc/lpfc_ct.c:	mi_cmd = ct_req->CommandResponse.bits.CmdRsp;
drivers/scsi/lpfc/lpfc_ct.c:	if (ct_req->FsType == SLI_CT_MANAGEMENT_SERVICE &&
drivers/scsi/lpfc/lpfc_ct.c:	    ct_req->FsSubType == SLI_CT_MIB_Subtypes) {
drivers/scsi/lpfc/lpfc_ct.c:					 CTreq->un.gid.Fc4Type,
drivers/scsi/lpfc/lpfc_ct.c:				    CTreq->un.gid.Fc4Type,
drivers/scsi/lpfc/lpfc_ct.c:					 CTreq->un.gid.Fc4Type,
drivers/scsi/lpfc/lpfc_ct.c:				    CTreq->un.gid.Fc4Type,
drivers/scsi/lpfc/lpfc_els.c:			 be32_to_cpu(rdp_req->rdp_des_length),
drivers/scsi/lpfc/lpfc_els.c:			 be32_to_cpu(rdp_req->nport_id_desc.tag),
drivers/scsi/lpfc/lpfc_els.c:			 be32_to_cpu(rdp_req->nport_id_desc.nport_id),
drivers/scsi/lpfc/lpfc_els.c:			 be32_to_cpu(rdp_req->nport_id_desc.length));
drivers/scsi/lpfc/lpfc_els.c:			be32_to_cpu(rdp_req->rdp_des_length))
drivers/scsi/lpfc/lpfc_els.c:	if (RDP_N_PORT_DESC_TAG != be32_to_cpu(rdp_req->nport_id_desc.tag))
drivers/scsi/lpfc/lpfc_els.c:			be32_to_cpu(rdp_req->nport_id_desc.length))
drivers/scsi/lpfc/lpfc_nvme.c: * -> lpfc_nvme_xmt_ls_rsp/cmp -> req->done.
drivers/scsi/lpfc/lpfc_nvme.c:	if (pnvme_lsreq->done)
drivers/scsi/lpfc/lpfc_nvme.c:		pnvme_lsreq->done(pnvme_lsreq, status);
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->addrHigh = le32_to_cpu(putPaddrHigh(pnvme_lsreq->rqstdma));
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->addrLow = le32_to_cpu(putPaddrLow(pnvme_lsreq->rqstdma));
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->tus.f.bdeSize = pnvme_lsreq->rqstlen;
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->addrHigh = le32_to_cpu(putPaddrHigh(pnvme_lsreq->rspdma));
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->addrLow = le32_to_cpu(putPaddrLow(pnvme_lsreq->rspdma));
drivers/scsi/lpfc/lpfc_nvme.c:	bpl->tus.f.bdeSize = pnvme_lsreq->rsplen;
drivers/scsi/lpfc/lpfc_nvme.c:			ndlp->nlp_DID, pnvme_lsreq, pnvme_lsreq->rqstlen,
drivers/scsi/lpfc/lpfc_nvme.c:			pnvme_lsreq->rsplen, &pnvme_lsreq->rqstdma,
drivers/scsi/lpfc/lpfc_nvme.c:			&pnvme_lsreq->rspdma);
drivers/scsi/lpfc/lpfc_nvme.c:	ret = lpfc_nvme_gen_req(vport, bmp, pnvme_lsreq->rqstaddr,
drivers/scsi/lpfc/lpfc_nvme.c:				pnvme_lsreq->timeout, 0);
drivers/scsi/lpfc/lpfc_nvme.c:			 pnvme_lsreq, pnvme_lsreq->rqstlen,
drivers/scsi/lpfc/lpfc_nvme.c:			 pnvme_lsreq->rsplen, &pnvme_lsreq->rqstdma,
drivers/scsi/lpfc/lpfc_nvme.c:			 &pnvme_lsreq->rspdma);
drivers/scsi/lpfc/lpfc_nvme.c:	freqpriv = pnvme_fcreq->private;
drivers/scsi/lpfc/lpfc_nvme.c:	if (!lpfc_queue_info->qidx && !pnvme_fcreq->sg_cnt) {
drivers/scsi/lpfc/lpfc_nvme.c:			pnvme_fcreq->cmdaddr)->sqe.common;
drivers/scsi/lpfc/lpfc_nvme.c:	freqpriv = pnvme_fcreq->private;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	iport = (struct port_id *)req->initiator_port_id;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	tport = (struct port_id *)req->target_port_id;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	fmt = (struct format_code *)&req->req_buf_fmt;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	if (be32_to_cpu(req->req_it_iu_len) > SRP_MAX_IU_LEN)
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	else if (be32_to_cpu(req->req_it_iu_len) < 64)
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	else if (req->req_flags & SRP_MULTICHAN_MULTI)
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	cmd->rsp.tag = req->tag;
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:		cmd->se_cmd.se_tmr_req->response =
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:			cmd->se_cmd.se_tmr_req->response =
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:		switch (se_cmd->se_tmr_req->response) {
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:		se_cmd, (int)se_cmd->se_tmr_req->response);
drivers/scsi/ibmvscsi_tgt/ibmvscsi_tgt.c:	    cmd->se_cmd.se_tmr_req->response == TMR_TASK_DOES_NOT_EXIST) {
drivers/scsi/atp870u.c:			for (l = 0; l < workreq->cmd_len; l++)
drivers/scsi/atp870u.c:				printk(KERN_DEBUG " %x",workreq->cmnd[l]);
drivers/scsi/atp870u.c:				//j=workreq->cmnd[0];
drivers/scsi/atp870u.c:				if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_10)) {
drivers/scsi/atp870u.c:				if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_10))
drivers/scsi/atp870u.c:				if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:				    (workreq->cmnd[0] == WRITE_10))
drivers/scsi/atp870u.c:				workreq->result = atp_readb_io(dev, c, 0x0f);
drivers/scsi/atp870u.c:					workreq->result = SAM_STAT_CHECK_CONDITION;
drivers/scsi/atp870u.c:				workreq->result = SAM_STAT_CHECK_CONDITION;
drivers/scsi/atp870u.c:			(*workreq->scsi_done) (workreq);
drivers/scsi/atp870u.c:			   printk("workreq->scsi_done\n");
drivers/scsi/atp870u.c:	for(i=0;i<workreq->cmd_len;i++) {
drivers/scsi/atp870u.c:		printk(" %x",workreq->cmnd[i]);
drivers/scsi/atp870u.c:	if (workreq->cmnd[0] == READ_CAPACITY) {
drivers/scsi/atp870u.c:	if (workreq->cmnd[0] == TEST_UNIT_READY) {
drivers/scsi/atp870u.c:	atp_writeb_io(dev, c, 0x00, workreq->cmd_len);
drivers/scsi/atp870u.c:	for (i = 0; i < workreq->cmd_len; i++)
drivers/scsi/atp870u.c:		atp_writeb_io(dev, c, 0x03 + i, workreq->cmnd[i]);
drivers/scsi/atp870u.c:	atp_writeb_io(dev, c, 0x0f, workreq->device->lun);
drivers/scsi/atp870u.c:	if (workreq->sc_data_direction == DMA_TO_DEVICE)
drivers/scsi/atp870u.c:		if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_10)) {
drivers/scsi/atp870u.c:		if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_10))
drivers/scsi/atp870u.c:		if ((workreq->cmnd[0] == READ_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == READ_10) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_6) ||
drivers/scsi/atp870u.c:		    (workreq->cmnd[0] == WRITE_10))
drivers/scsi/atp870u.c:	if(workreq->sc_data_direction == DMA_TO_DEVICE) {
drivers/dma/stm32-dma.c:	reg = &sg_req->chan_reg;
drivers/dma/stm32-dma.c:			dma_sm0ar = sg_req->chan_reg.dma_sm0ar;
drivers/dma/stm32-dma.c:			dma_sm1ar = sg_req->chan_reg.dma_sm1ar;
drivers/dma/stm32-dma.c:		return (dma_smar == sg_req->chan_reg.dma_sm0ar);
drivers/dma/stm32-dma.c:	return (dma_smar == sg_req->chan_reg.dma_sm1ar);
drivers/dma/stm32-dma.c:		residue = sg_req->len;
drivers/dma/tegra20-apb-dma.c:		list_del(&sg_req->node);
drivers/dma/tegra20-apb-dma.c:	struct tegra_dma_channel_regs *ch_regs = &sg_req->ch_regs;
drivers/dma/tegra20-apb-dma.c:	tdc_write(tdc, TEGRA_APBDMA_CHAN_APBPTR, nsg_req->ch_regs.apb_ptr);
drivers/dma/tegra20-apb-dma.c:	tdc_write(tdc, TEGRA_APBDMA_CHAN_AHBPTR, nsg_req->ch_regs.ahb_ptr);
drivers/dma/tegra20-apb-dma.c:			  nsg_req->ch_regs.wcount);
drivers/dma/tegra20-apb-dma.c:		  nsg_req->ch_regs.csr | TEGRA_APBDMA_CSR_ENB);
drivers/dma/tegra20-apb-dma.c:	nsg_req->configured = true;
drivers/dma/tegra20-apb-dma.c:	nsg_req->words_xferred = 0;
drivers/dma/tegra20-apb-dma.c:	sg_req->configured = true;
drivers/dma/tegra20-apb-dma.c:	sg_req->words_xferred = 0;
drivers/dma/tegra20-apb-dma.c:	if (!list_is_last(&hsgreq->node, &tdc->pending_sg_req)) {
drivers/dma/tegra20-apb-dma.c:		hnsgreq = list_first_entry(&hsgreq->node, typeof(*hnsgreq),
drivers/dma/tegra20-apb-dma.c:	return sg_req->req_len - (status & TEGRA_APBDMA_STATUS_COUNT_MASK) - 4;
drivers/dma/tegra20-apb-dma.c:		list_move_tail(&sgreq->node, &tdc->free_sg_req);
drivers/dma/tegra20-apb-dma.c:		if (sgreq->last_sg) {
drivers/dma/tegra20-apb-dma.c:			dma_desc = sgreq->dma_desc;
drivers/dma/tegra20-apb-dma.c:	if (!hsgreq->configured) {
drivers/dma/tegra20-apb-dma.c:	dma_desc = sgreq->dma_desc;
drivers/dma/tegra20-apb-dma.c:	dma_desc->bytes_transferred += sgreq->req_len;
drivers/dma/tegra20-apb-dma.c:	list_del(&sgreq->node);
drivers/dma/tegra20-apb-dma.c:	if (sgreq->last_sg) {
drivers/dma/tegra20-apb-dma.c:	list_add_tail(&sgreq->node, &tdc->free_sg_req);
drivers/dma/tegra20-apb-dma.c:	dma_desc = sgreq->dma_desc;
drivers/dma/tegra20-apb-dma.c:		(dma_desc->bytes_transferred + sgreq->req_len) %
drivers/dma/tegra20-apb-dma.c:	sgreq->words_xferred = 0;
drivers/dma/tegra20-apb-dma.c:	if (!list_is_last(&sgreq->node, &tdc->pending_sg_req)) {
drivers/dma/tegra20-apb-dma.c:		list_move_tail(&sgreq->node, &tdc->pending_sg_req);
drivers/dma/tegra20-apb-dma.c:		sgreq->configured = false;
drivers/dma/tegra20-apb-dma.c:		sgreq->dma_desc->bytes_transferred +=
drivers/dma/tegra20-apb-dma.c:	if (!list_is_first(&sg_req->node, &tdc->pending_sg_req))
drivers/dma/tegra20-apb-dma.c:		return sg_req->req_len;
drivers/dma/tegra20-apb-dma.c:		if (sg_req->words_xferred)
drivers/dma/tegra20-apb-dma.c:			wcount = sg_req->req_len - 4;
drivers/dma/tegra20-apb-dma.c:	} else if (wcount < sg_req->words_xferred) {
drivers/dma/tegra20-apb-dma.c:		wcount = sg_req->req_len - 4;
drivers/dma/tegra20-apb-dma.c:		sg_req->words_xferred = wcount;
drivers/dma/tegra20-apb-dma.c:		dma_desc = sg_req->dma_desc;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.apb_ptr = apb_ptr;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.ahb_ptr = mem;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.csr = csr;
drivers/dma/tegra20-apb-dma.c:		tegra_dma_prep_wcount(tdc, &sg_req->ch_regs, len);
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.apb_seq = apb_seq;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.ahb_seq = ahb_seq;
drivers/dma/tegra20-apb-dma.c:		sg_req->configured = false;
drivers/dma/tegra20-apb-dma.c:		sg_req->last_sg = false;
drivers/dma/tegra20-apb-dma.c:		sg_req->dma_desc = dma_desc;
drivers/dma/tegra20-apb-dma.c:		sg_req->req_len = len;
drivers/dma/tegra20-apb-dma.c:		list_add_tail(&sg_req->node, &dma_desc->tx_list);
drivers/dma/tegra20-apb-dma.c:	sg_req->last_sg = true;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.apb_ptr = apb_ptr;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.ahb_ptr = mem;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.csr = csr;
drivers/dma/tegra20-apb-dma.c:		tegra_dma_prep_wcount(tdc, &sg_req->ch_regs, len);
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.apb_seq = apb_seq;
drivers/dma/tegra20-apb-dma.c:		sg_req->ch_regs.ahb_seq = ahb_seq;
drivers/dma/tegra20-apb-dma.c:		sg_req->configured = false;
drivers/dma/tegra20-apb-dma.c:		sg_req->last_sg = false;
drivers/dma/tegra20-apb-dma.c:		sg_req->dma_desc = dma_desc;
drivers/dma/tegra20-apb-dma.c:		sg_req->req_len = len;
drivers/dma/tegra20-apb-dma.c:		list_add_tail(&sg_req->node, &dma_desc->tx_list);
drivers/dma/tegra20-apb-dma.c:	sg_req->last_sg = true;
drivers/dma/tegra20-apb-dma.c:		list_del(&sg_req->node);
drivers/dma/bcm-sba-raid.c:		if (async_tx_test_ack(&req->tx)) {
drivers/dma/bcm-sba-raid.c:			list_move_tail(&req->node, &sba->reqs_alloc_list);
drivers/dma/bcm-sba-raid.c:	req->flags = SBA_REQUEST_STATE_ALLOCED;
drivers/dma/bcm-sba-raid.c:	req->first = req;
drivers/dma/bcm-sba-raid.c:	INIT_LIST_HEAD(&req->next);
drivers/dma/bcm-sba-raid.c:	atomic_set(&req->next_pending_count, 1);
drivers/dma/bcm-sba-raid.c:	dma_async_tx_descriptor_init(&req->tx, &sba->dma_chan);
drivers/dma/bcm-sba-raid.c:	async_tx_ack(&req->tx);
drivers/dma/bcm-sba-raid.c:	req->flags &= ~SBA_REQUEST_STATE_MASK;
drivers/dma/bcm-sba-raid.c:	req->flags |= SBA_REQUEST_STATE_PENDING;
drivers/dma/bcm-sba-raid.c:	list_move_tail(&req->node, &sba->reqs_pending_list);
drivers/dma/bcm-sba-raid.c:	req->flags &= ~SBA_REQUEST_STATE_MASK;
drivers/dma/bcm-sba-raid.c:	req->flags |= SBA_REQUEST_STATE_ACTIVE;
drivers/dma/bcm-sba-raid.c:	list_move_tail(&req->node, &sba->reqs_active_list);
drivers/dma/bcm-sba-raid.c:	if (req->flags & SBA_REQUEST_FENCE)
drivers/dma/bcm-sba-raid.c:	req->flags &= ~SBA_REQUEST_STATE_MASK;
drivers/dma/bcm-sba-raid.c:	req->flags |= SBA_REQUEST_STATE_ABORTED;
drivers/dma/bcm-sba-raid.c:	list_move_tail(&req->node, &sba->reqs_aborted_list);
drivers/dma/bcm-sba-raid.c:	req->flags &= ~SBA_REQUEST_STATE_MASK;
drivers/dma/bcm-sba-raid.c:	req->flags |= SBA_REQUEST_STATE_FREE;
drivers/dma/bcm-sba-raid.c:	list_move_tail(&req->node, &sba->reqs_free_list);
drivers/dma/bcm-sba-raid.c:	struct sba_device *sba = req->sba;
drivers/dma/bcm-sba-raid.c:	list_for_each_entry(nreq, &req->next, next)
drivers/dma/bcm-sba-raid.c:	struct sba_device *sba = req->sba;
drivers/dma/bcm-sba-raid.c:	list_add_tail(&req->next, &first->next);
drivers/dma/bcm-sba-raid.c:	req->first = first;
drivers/dma/bcm-sba-raid.c:	req->msg.error = 0;
drivers/dma/bcm-sba-raid.c:	ret = mbox_send_message(sba->mchan, &req->msg);
drivers/dma/bcm-sba-raid.c:	ret = req->msg.error;
drivers/dma/bcm-sba-raid.c:	struct sba_request *nreq, *first = req->first;
drivers/dma/bcm-sba-raid.c:		if (async_tx_test_ack(&req->tx))
drivers/dma/bcm-sba-raid.c:	list_for_each_entry(nreq, &req->next, next)
drivers/dma/bcm-sba-raid.c:	dma_addr_t resp_dma = req->tx.phys;
drivers/dma/bcm-sba-raid.c:	cmd = sba_cmd_enc(cmd, req->sba->hw_resp_size,
drivers/dma/bcm-sba-raid.c:	cmdsp->data_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:	cmd = sba_cmd_enc(cmd, req->sba->hw_resp_size,
drivers/dma/bcm-sba-raid.c:	if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:		cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:	cmdsp->data_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:	req->flags |= SBA_REQUEST_FENCE;
drivers/dma/bcm-sba-raid.c:	sba_fillup_interrupt_msg(req, req->cmds, &req->msg);
drivers/dma/bcm-sba-raid.c:	req->tx.flags = flags;
drivers/dma/bcm-sba-raid.c:	req->tx.cookie = -EBUSY;
drivers/dma/bcm-sba-raid.c:	return &req->tx;
drivers/dma/bcm-sba-raid.c:	dma_addr_t resp_dma = req->tx.phys;
drivers/dma/bcm-sba-raid.c:	if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:		cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		req->flags |= SBA_REQUEST_FENCE;
drivers/dma/bcm-sba-raid.c:	sba_fillup_memcpy_msg(req, req->cmds, &req->msg,
drivers/dma/bcm-sba-raid.c:	req->tx.flags = flags;
drivers/dma/bcm-sba-raid.c:	req->tx.cookie = -EBUSY;
drivers/dma/bcm-sba-raid.c:	dma_addr_t resp_dma = req->tx.phys;
drivers/dma/bcm-sba-raid.c:	if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:		cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		req->flags |= SBA_REQUEST_FENCE;
drivers/dma/bcm-sba-raid.c:	sba_fillup_xor_msg(req, req->cmds, &req->msg,
drivers/dma/bcm-sba-raid.c:	req->tx.flags = flags;
drivers/dma/bcm-sba-raid.c:	req->tx.cookie = -EBUSY;
drivers/dma/bcm-sba-raid.c:	dma_addr_t resp_dma = req->tx.phys;
drivers/dma/bcm-sba-raid.c:		if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:			cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:			cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		req->flags |= SBA_REQUEST_FENCE;
drivers/dma/bcm-sba-raid.c:			  req->cmds, &req->msg,
drivers/dma/bcm-sba-raid.c:	req->tx.flags = flags;
drivers/dma/bcm-sba-raid.c:	req->tx.cookie = -EBUSY;
drivers/dma/bcm-sba-raid.c:	dma_addr_t resp_dma = req->tx.phys;
drivers/dma/bcm-sba-raid.c:	if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:		cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:	pos = (dpos < req->sba->max_pq_coefs) ?
drivers/dma/bcm-sba-raid.c:		dpos : (req->sba->max_pq_coefs - 1);
drivers/dma/bcm-sba-raid.c:		pos = (dpos < req->sba->max_pq_coefs) ?
drivers/dma/bcm-sba-raid.c:			dpos : (req->sba->max_pq_coefs - 1);
drivers/dma/bcm-sba-raid.c:	if (req->sba->hw_resp_size) {
drivers/dma/bcm-sba-raid.c:		cmdsp->resp_len = req->sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		req->flags |= SBA_REQUEST_FENCE;
drivers/dma/bcm-sba-raid.c:				 req->cmds, &req->msg, off, len,
drivers/dma/bcm-sba-raid.c:	req->tx.flags = flags;
drivers/dma/bcm-sba-raid.c:	req->tx.cookie = -EBUSY;
drivers/dma/bcm-sba-raid.c:	struct sba_device *sba = req->sba;
drivers/dma/bcm-sba-raid.c:		INIT_LIST_HEAD(&req->node);
drivers/dma/bcm-sba-raid.c:		req->sba = sba;
drivers/dma/bcm-sba-raid.c:		req->flags = SBA_REQUEST_STATE_FREE;
drivers/dma/bcm-sba-raid.c:		INIT_LIST_HEAD(&req->next);
drivers/dma/bcm-sba-raid.c:		atomic_set(&req->next_pending_count, 0);
drivers/dma/bcm-sba-raid.c:			req->cmds[j].cmd = 0;
drivers/dma/bcm-sba-raid.c:			req->cmds[j].cmd_dma = sba->cmds_base +
drivers/dma/bcm-sba-raid.c:			req->cmds[j].cmd_dma_addr = sba->cmds_dma_base +
drivers/dma/bcm-sba-raid.c:			req->cmds[j].flags = 0;
drivers/dma/bcm-sba-raid.c:		memset(&req->msg, 0, sizeof(req->msg));
drivers/dma/bcm-sba-raid.c:		dma_async_tx_descriptor_init(&req->tx, &sba->dma_chan);
drivers/dma/bcm-sba-raid.c:		async_tx_ack(&req->tx);
drivers/dma/bcm-sba-raid.c:		req->tx.tx_submit = sba_tx_submit;
drivers/dma/bcm-sba-raid.c:		req->tx.phys = sba->resp_dma_base + i * sba->hw_resp_size;
drivers/dma/bcm-sba-raid.c:		list_add_tail(&req->node, &sba->reqs_free_list);
drivers/dma/ti/k3-udma.c:	cppi5_tr_init(&tr_req->flags, CPPI5_TR_TYPE1, false, false,
drivers/dma/ti/k3-udma.c:	cppi5_tr_csf_set(&tr_req->flags, CPPI5_TR_CSF_SUPR_EVT);
drivers/dma/ti/k3-udma.c:	tr_req->addr = rx_flush->buffer_paddr;
drivers/dma/ti/k3-udma.c:	tr_req->icnt0 = rx_flush->buffer_size;
drivers/dma/ti/k3-udma.c:	tr_req->icnt1 = 1;
drivers/dma/pl330.c:	desc = req->desc;
drivers/dma/pl330.c:	go.addr = req->mc_bus;
drivers/dma/pl330.c:	u8 *buf = req->mc_cpu;
drivers/dma/pl330.c:	PL330_DBGMC_START(req->mc_bus);
drivers/greybus/es2.c:	req->flags = cpu_to_le32(connection_flags);
drivers/greybus/es2.c:	rpc->req->type = type;
drivers/greybus/es2.c:	rpc->req->size = cpu_to_le16(sizeof(*rpc->req) + size);
drivers/greybus/es2.c:	memcpy(rpc->req->data, payload, size);
drivers/greybus/es2.c:		if (rpc->req->id == id)
drivers/greybus/es2.c:	rpc->req->id = cpu_to_le16(es2->arpc_id_cycle++);
drivers/greybus/es2.c:				 rpc->req, le16_to_cpu(rpc->req->size),
drivers/greybus/es2.c:			rpc->req->type, retval);
drivers/greybus/connection.c:	req->phase = phase;
drivers/misc/genwqe/card_dev.c:		req->cmd = SLCMD_MOVE_FLASH;
drivers/misc/genwqe/card_dev.c:		req->cmdopts = cmdopts;
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->__asiv[0]  = cpu_to_be64(dma_addr);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->__asiv[8]  = cpu_to_be64(tocopy);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->__asiv[16] = cpu_to_be64(flash);
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->__asiv[24] = cpu_to_be32(0);
drivers/misc/genwqe/card_dev.c:			req->__asiv[24]	       = load->uid;
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->__asiv[28] = cpu_to_be32(crc);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->__asiv[88] = cpu_to_be64(load->slu_id);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->__asiv[96] = cpu_to_be64(load->app_id);
drivers/misc/genwqe/card_dev.c:			req->asiv_length = 32; /* bytes included in crc calc */
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->asiv[0]  = cpu_to_be64(dma_addr);
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->asiv[8]  = cpu_to_be32(tocopy);
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->asiv[12] = cpu_to_be32(0); /* resvd */
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->asiv[16] = cpu_to_be64(flash);
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->asiv[24] = cpu_to_be32(load->uid<<24);
drivers/misc/genwqe/card_dev.c:			*(__be32 *)&req->asiv[28] = cpu_to_be32(crc);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->asiv[80] = cpu_to_be64(load->slu_id);
drivers/misc/genwqe/card_dev.c:			*(__be64 *)&req->asiv[88] = cpu_to_be64(load->app_id);
drivers/misc/genwqe/card_dev.c:			req->ats = 0x4ULL << 44;
drivers/misc/genwqe/card_dev.c:			req->asiv_length = 40; /* bytes included in crc calc */
drivers/misc/genwqe/card_dev.c:		req->asv_length  = 8;
drivers/misc/genwqe/card_dev.c:		*(u64 *)&req->asv[0] = 0ULL;			/* 0x80 */
drivers/misc/genwqe/card_dev.c:		load->retc = req->retc;
drivers/misc/genwqe/card_dev.c:		load->attn = req->attn;
drivers/misc/genwqe/card_dev.c:		load->progress = req->progress;
drivers/misc/genwqe/card_dev.c:		if (req->retc != DDCB_RETC_COMPLETE) {
drivers/misc/genwqe/card_dev.c:		dma_map = &req->dma_mappings[i];
drivers/misc/genwqe/card_dev.c:		if (req->sgls[i].sgl != NULL)
drivers/misc/genwqe/card_dev.c:			genwqe_free_sync_sgl(cd, &req->sgls[i]);
drivers/misc/genwqe/card_dev.c:	struct genwqe_ddcb_cmd *cmd = &req->cmd;
drivers/misc/genwqe/card_dev.c:				m = &req->dma_mappings[i];
drivers/misc/genwqe/card_dev.c:			rc = genwqe_alloc_sync_sgl(cd, &req->sgls[i],
drivers/misc/genwqe/card_dev.c:			genwqe_setup_sgl(cd, &req->sgls[i],
drivers/misc/genwqe/card_dev.c:				cpu_to_be64(req->sgls[i].sgl_dma_addr);
drivers/misc/genwqe/card_ddcb.c:	return &req->cmd;
drivers/misc/genwqe/card_ddcb.c:	return req->req_state;
drivers/misc/genwqe/card_ddcb.c:	req->req_state = new_state;
drivers/misc/genwqe/card_ddcb.c:	return req->cmd.ddata_addr != 0x0;
drivers/misc/genwqe/card_ddcb.c:	struct ddcb_queue *queue = req->queue;
drivers/misc/genwqe/card_ddcb.c:	struct ddcb *pddcb = &queue->ddcb_vaddr[req->num];
drivers/misc/genwqe/card_ddcb.c:	memcpy(&req->cmd.asv[0], &pddcb->asv[0], DDCB_ASV_LENGTH);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.vcrc     = be16_to_cpu(pddcb->vcrc_16);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.deque_ts = be64_to_cpu(pddcb->deque_ts_64);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.cmplt_ts = be64_to_cpu(pddcb->cmplt_ts_64);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.attn     = be16_to_cpu(pddcb->attn_16);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.progress = be32_to_cpu(pddcb->progress_32);
drivers/misc/genwqe/card_ddcb.c:	req->cmd.retc     = be16_to_cpu(pddcb->retc_16);
drivers/misc/genwqe/card_ddcb.c:		memcpy(&req->debug_data.ddcb_finished, pddcb,
drivers/misc/genwqe/card_ddcb.c:		       sizeof(req->debug_data.ddcb_finished));
drivers/misc/genwqe/card_ddcb.c:		memcpy(&req->debug_data.ddcb_prev, prev_pddcb,
drivers/misc/genwqe/card_ddcb.c:		       sizeof(req->debug_data.ddcb_prev));
drivers/misc/genwqe/card_ddcb.c:		dev_dbg(&pci_dev->dev, "FINISHED DDCB#%d\n", req->num);
drivers/misc/genwqe/card_ddcb.c:				   VCRC_LENGTH(req->cmd.asv_length),
drivers/misc/genwqe/card_ddcb.c:				pddcb->pre, VCRC_LENGTH(req->cmd.asv_length),
drivers/misc/genwqe/card_ddcb.c:	queue = req->queue;
drivers/misc/genwqe/card_ddcb.c:	ddcb_no = req->num;
drivers/misc/genwqe/card_ddcb.c:		struct ddcb_queue *queue = req->queue;
drivers/misc/genwqe/card_ddcb.c:		genwqe_check_ddcb_queue(cd, req->queue);
drivers/misc/genwqe/card_ddcb.c:			__func__, req->num, rc,	ddcb_requ_get_state(req),
drivers/misc/genwqe/card_ddcb.c:		pddcb = &queue->ddcb_vaddr[req->num];
drivers/misc/genwqe/card_ddcb.c:		print_ddcb_info(cd, req->queue);
drivers/misc/genwqe/card_ddcb.c:			__func__, req->num, rc, ddcb_requ_get_state(req));
drivers/misc/genwqe/card_ddcb.c:			__func__, req->num, rc);
drivers/misc/genwqe/card_ddcb.c:	struct ddcb_queue *queue = req->queue;
drivers/misc/genwqe/card_ddcb.c:	pddcb = &queue->ddcb_vaddr[req->num];
drivers/misc/genwqe/card_ddcb.c:		copy_ddcb_results(req, req->num); /* for the failing case */
drivers/misc/genwqe/card_ddcb.c:		copy_ddcb_results(req, req->num);
drivers/misc/genwqe/card_ddcb.c:		queue->ddcb_req[req->num] = NULL; /* delete from array */
drivers/misc/genwqe/card_ddcb.c:		    (queue->ddcb_act == req->num)) {
drivers/misc/genwqe/card_ddcb.c:	dev_dbg(&pci_dev->dev, "UN/FINISHED DDCB#%d\n", req->num);
drivers/misc/genwqe/card_ddcb.c:		__func__, req->num, GENWQE_DDCB_SOFTWARE_TIMEOUT,
drivers/misc/genwqe/card_ddcb.c:	print_ddcb_info(cd, req->queue);
drivers/misc/genwqe/card_ddcb.c:			__func__, req->num);
drivers/misc/genwqe/card_ddcb.c:	queue = req->queue = &cd->queue;
drivers/misc/genwqe/card_ddcb.c:	pddcb = get_next_ddcb(cd, queue, &req->num);	/* get ptr and num */
drivers/misc/genwqe/card_ddcb.c:	if (queue->ddcb_req[req->num] != NULL) {
drivers/misc/genwqe/card_ddcb.c:			__func__, req->num, req);
drivers/misc/genwqe/card_ddcb.c:	queue->ddcb_req[req->num] = req;
drivers/misc/genwqe/card_ddcb.c:	pddcb->cmdopts_16 = cpu_to_be16(req->cmd.cmdopts);
drivers/misc/genwqe/card_ddcb.c:	pddcb->cmd = req->cmd.cmd;
drivers/misc/genwqe/card_ddcb.c:	pddcb->acfunc = req->cmd.acfunc;	/* functional unit */
drivers/misc/genwqe/card_ddcb.c:	pddcb->psp = (((req->cmd.asiv_length / 8) << 4) |
drivers/misc/genwqe/card_ddcb.c:		      ((req->cmd.asv_length  / 8)));
drivers/misc/genwqe/card_ddcb.c:	pddcb->disp_ts_64 = cpu_to_be64(req->cmd.disp_ts);
drivers/misc/genwqe/card_ddcb.c:	 * req->cmd.asiv_length. But simulation benefits from some
drivers/misc/genwqe/card_ddcb.c:		       &req->cmd.__asiv[0],	/* source */
drivers/misc/genwqe/card_ddcb.c:		       DDCB_ASIV_LENGTH);	/* req->cmd.asiv_length */
drivers/misc/genwqe/card_ddcb.c:		pddcb->n.ats_64 = cpu_to_be64(req->cmd.ats);
drivers/misc/genwqe/card_ddcb.c:			&req->cmd.asiv[0],	/* source */
drivers/misc/genwqe/card_ddcb.c:			DDCB_ASIV_LENGTH_ATS);	/* req->cmd.asiv_length */
drivers/misc/genwqe/card_ddcb.c:			   ICRC_LENGTH(req->cmd.asiv_length), 0xffff);
drivers/misc/genwqe/card_ddcb.c:	dev_dbg(&pci_dev->dev, "INPUT DDCB#%d\n", req->num);
drivers/misc/genwqe/card_ddcb.c:		genwqe_init_debug_data(cd, &req->debug_data);
drivers/misc/genwqe/card_ddcb.c:		memcpy(&req->debug_data.ddcb_before, pddcb,
drivers/misc/genwqe/card_ddcb.c:		       sizeof(req->debug_data.ddcb_before));
drivers/misc/genwqe/card_ddcb.c:	enqueue_ddcb(cd, queue, pddcb, req->num);
drivers/misc/genwqe/card_ddcb.c:				 &req->debug_data,
drivers/misc/genwqe/card_ddcb.c:				 &req->debug_data,
drivers/misc/mei/bus-fixup.c:	req->hdr.group_id = MKHI_FWCAPS_GROUP_ID;
drivers/misc/mei/bus-fixup.c:	req->hdr.command = MKHI_FWCAPS_SET_OS_VER_APP_RULE_CMD;
drivers/misc/mei/bus-fixup.c:	fwcaps = (struct mkhi_fwcaps *)req->data;
drivers/misc/mei/hbm.c:	return mei_hbm_add_cl_resp(dev, req->me_addr, status);
drivers/misc/fastrpc.c:		if ((buf->raddr == req->vaddrout) && (buf->size == req->size))
drivers/mmc/host/cavium.c:	int data_len = req->data->blocks * req->data->blksz;
drivers/mmc/host/cavium.c:	req->data->bytes_xfered = bytes_xfered;
drivers/mmc/host/cavium.c:	req->data->error = 0;
drivers/mmc/host/cavium.c:	req->data->bytes_xfered = req->data->blocks * req->data->blksz;
drivers/mmc/host/cavium.c:	req->data->error = 0;
drivers/mmc/host/cavium.c:		req->cmd->resp[0] = (rsp_lo >> 8) & 0xffffffff;
drivers/mmc/host/cavium.c:		req->cmd->resp[1] = 0;
drivers/mmc/host/cavium.c:		req->cmd->resp[2] = 0;
drivers/mmc/host/cavium.c:		req->cmd->resp[3] = 0;
drivers/mmc/host/cavium.c:		req->cmd->resp[3] = rsp_lo & 0xffffffff;
drivers/mmc/host/cavium.c:		req->cmd->resp[2] = (rsp_lo >> 32) & 0xffffffff;
drivers/mmc/host/cavium.c:		req->cmd->resp[1] = rsp_hi & 0xffffffff;
drivers/mmc/host/cavium.c:		req->cmd->resp[0] = (rsp_hi >> 32) & 0xffffffff;
drivers/mmc/host/cavium.c:	if (!host->dma_active && req->data &&
drivers/mmc/host/cavium.c:	if (!(host_done && req->done))
drivers/mmc/host/cavium.c:	req->cmd->error = check_status(rsp_sts);
drivers/mmc/host/cavium.c:	if (host->dma_active && req->data)
drivers/mmc/host/cavium.c:		if (!finish_dma(host, req->data))
drivers/mmc/host/cavium.c:	req->done(req);
drivers/mmc/host/jz4740_mmc.c:	data = req->data;
drivers/mmc/host/jz4740_mmc.c:			host->req->cmd->error = -ETIMEDOUT;
drivers/mmc/host/jz4740_mmc.c:			host->req->cmd->error = -EIO;
drivers/mmc/host/jz4740_mmc.c:			host->req->cmd->error = -ETIMEDOUT;
drivers/mmc/host/jz4740_mmc.c:			host->req->cmd->error = -EIO;
drivers/mmc/host/jz4740_mmc.c:	host->req->cmd->error = -ETIMEDOUT;
drivers/mmc/host/jz4740_mmc.c:	struct mmc_command *cmd = host->req->cmd;
drivers/mmc/host/jz4740_mmc.c:	struct mmc_command *cmd = host->req->cmd;
drivers/mmc/host/jz4740_mmc.c:		if (!req->stop)
drivers/mmc/host/jz4740_mmc.c:		jz4740_mmc_send_command(host, req->stop);
drivers/mmc/host/jz4740_mmc.c:		if (mmc_resp_type(req->stop) & MMC_RSP_BUSY) {
drivers/mmc/host/jz4740_mmc.c:	jz4740_mmc_send_command(host, req->cmd);
drivers/mmc/host/ushc.c:		req->cmd->error = urb->status;
drivers/mmc/host/ushc.c:			req->cmd->error = -EIO;
drivers/mmc/host/ushc.c:			req->cmd->error = -ETIMEDOUT;
drivers/mmc/host/ushc.c:	if (req->data) {
drivers/mmc/host/ushc.c:				req->data->error = -EIO;
drivers/mmc/host/ushc.c:				req->data->error = -ETIMEDOUT;
drivers/mmc/host/ushc.c:			req->data->bytes_xfered = 0;
drivers/mmc/host/ushc.c:			req->data->bytes_xfered = req->data->blksz * req->data->blocks;
drivers/mmc/host/ushc.c:	req->cmd->resp[0] = le32_to_cpu(ushc->csw->response);
drivers/mmc/host/ushc.c:	if (req->cmd->flags & MMC_RSP_136) {
drivers/mmc/host/ushc.c:	if (req->data && ushc->clock_freq < 6000000) {
drivers/mmc/host/ushc.c:	ushc->cbw->cmd_idx = cpu_to_le16(req->cmd->opcode);
drivers/mmc/host/ushc.c:	if (req->data)
drivers/mmc/host/ushc.c:		ushc->cbw->block_size = cpu_to_le16(req->data->blksz);
drivers/mmc/host/ushc.c:	ushc->cbw->arg = cpu_to_le32(req->cmd->arg);
drivers/mmc/host/ushc.c:	if (req->data) {
drivers/mmc/host/ushc.c:		struct mmc_data *data = req->data;
drivers/mmc/host/ushc.c:		req->cmd->error = ret;
drivers/mmc/host/omap.c:	timeout = req->data->timeout_ns / cycle_ns;
drivers/mmc/host/omap.c:	timeout += req->data->timeout_clks;
drivers/mmc/host/omap.c:	struct mmc_data *data = req->data;
drivers/mmc/host/omap.c:	mmc_omap_start_command(host, req->cmd);
drivers/mmc/host/wmt-sdmmc.c:	req->data->bytes_xfered = req->data->blksz * req->data->blocks;
drivers/mmc/host/wmt-sdmmc.c:	if (req->data->flags & MMC_DATA_WRITE)
drivers/mmc/host/wmt-sdmmc.c:		dma_unmap_sg(mmc_dev(priv->mmc), req->data->sg,
drivers/mmc/host/wmt-sdmmc.c:			     req->data->sg_len, DMA_TO_DEVICE);
drivers/mmc/host/wmt-sdmmc.c:		dma_unmap_sg(mmc_dev(priv->mmc), req->data->sg,
drivers/mmc/host/wmt-sdmmc.c:			     req->data->sg_len, DMA_FROM_DEVICE);
drivers/mmc/host/wmt-sdmmc.c:	if ((req->cmd->error) || (req->data->error))
drivers/mmc/host/wmt-sdmmc.c:		if (!req->data->stop) {
drivers/mmc/host/wmt-sdmmc.c:			priv->cmd = req->data->stop;
drivers/mmc/host/wmt-sdmmc.c:			wmt_mci_send_command(priv->mmc, req->data->stop->opcode,
drivers/mmc/host/wmt-sdmmc.c:					     7, req->data->stop->arg, 9);
drivers/mmc/host/wmt-sdmmc.c:		priv->req->data->error = -ETIMEDOUT;
drivers/mmc/host/wmt-sdmmc.c:	priv->req->data->error = 0;
drivers/mmc/host/wmt-sdmmc.c:	if ((!priv->req->data) ||
drivers/mmc/host/wmt-sdmmc.c:	    ((priv->req->data->stop) && (priv->cmd == priv->req->data->stop))) {
drivers/mmc/host/wmt-sdmmc.c:	priv->cmd = req->cmd;
drivers/mmc/host/wmt-sdmmc.c:	command = req->cmd->opcode;
drivers/mmc/host/wmt-sdmmc.c:	arg = req->cmd->arg;
drivers/mmc/host/wmt-sdmmc.c:	rsptype = mmc_resp_type(req->cmd);
drivers/mmc/host/wmt-sdmmc.c:	if (!req->data) {
drivers/mmc/host/wmt-sdmmc.c:	if (req->data) {
drivers/mmc/host/wmt-sdmmc.c:		writew((reg_tmp & 0xF800) | (req->data->blksz - 1),
drivers/mmc/host/wmt-sdmmc.c:		writew(req->data->blocks, priv->sdmmc_base + SDMMC_BLKCNT);
drivers/mmc/host/wmt-sdmmc.c:		if (req->data->flags & MMC_DATA_WRITE) {
drivers/mmc/host/wmt-sdmmc.c:			sg_cnt = dma_map_sg(mmc_dev(mmc), req->data->sg,
drivers/mmc/host/wmt-sdmmc.c:					    req->data->sg_len, DMA_TO_DEVICE);
drivers/mmc/host/wmt-sdmmc.c:			if (req->data->blocks > 1)
drivers/mmc/host/wmt-sdmmc.c:			sg_cnt = dma_map_sg(mmc_dev(mmc), req->data->sg,
drivers/mmc/host/wmt-sdmmc.c:					    req->data->sg_len, DMA_FROM_DEVICE);
drivers/mmc/host/wmt-sdmmc.c:			if (req->data->blocks > 1)
drivers/mmc/host/wmt-sdmmc.c:		for_each_sg(req->data->sg, sg, sg_cnt, i) {
drivers/mmc/host/wmt-sdmmc.c:				wmt_dma_init_descriptor(desc, req->data->blksz,
drivers/mmc/host/wmt-sdmmc.c:				offset += req->data->blksz;
drivers/mmc/host/wmt-sdmmc.c:				if (desc_cnt == req->data->blocks)
drivers/mmc/host/wmt-sdmmc.c:		if (req->data->flags & MMC_DATA_WRITE)
drivers/mmc/host/davinci_mmc.c:	struct mmc_data *data = req->data;
drivers/mmc/host/davinci_mmc.c:		req->cmd->error = -ETIMEDOUT;
drivers/mmc/host/davinci_mmc.c:	mmc_davinci_start_command(host, req->cmd);
drivers/mmc/host/tifm_sd.c:	struct mmc_data *r_data = host->req->cmd->data;
drivers/mmc/host/tifm_sd.c:	struct mmc_command *cmd = host->req->cmd;
drivers/mmc/host/tifm_sd.c:			if (host->req->stop) {
drivers/mmc/host/tifm_sd.c:					tifm_sd_exec(host, host->req->stop);
drivers/mmc/host/tifm_sd.c:			if (host->req->stop) {
drivers/mmc/host/tifm_sd.c:					tifm_sd_exec(host, host->req->stop);
drivers/mmc/host/tifm_sd.c:		r_data = host->req->cmd->data;
drivers/mmc/host/tifm_sd.c:		cmd = host->req->cmd;
drivers/mmc/host/tifm_sd.c:			if (host->req->stop) {
drivers/mmc/host/tifm_sd.c:					host->req->stop->error = cmd_error;
drivers/mmc/host/tifm_sd.c:					tifm_sd_exec(host, host->req->stop);
drivers/mmc/host/tifm_sd.c:					tifm_sd_fetch_resp(host->req->stop,
drivers/mmc/host/tifm_sd.c:	       dev_name(&host->dev->dev), host->req->cmd->opcode, host->cmd_flags);
drivers/mmc/host/tifm_sd.c:		host->req->cmd->error = -ENOMEDIUM;
drivers/mmc/host/tifm_sd.c:		if (host->req->stop)
drivers/mmc/host/tifm_sd.c:			host->req->stop->error = -ENOMEDIUM;
drivers/mmc/host/sunxi-mmc.c:	if (req->cmd->opcode == SD_IO_RW_EXTENDED) {
drivers/mmc/host/sunxi-mmc.c:		      ((req->cmd->arg >> 28) & 0x7);
drivers/mmc/host/sunxi-mmc.c:		if (req->stop)
drivers/mmc/host/sunxi-mmc.c:			req->stop->resp[0] = -ETIMEDOUT;
drivers/mmc/host/sunxi-mmc.c:		if (req->stop)
drivers/mmc/host/sunxi-mmc.c:			req->stop->resp[0] = mmc_readl(host, REG_RESP0);
drivers/mmc/host/mxcmmc.c:	struct mmc_data *data = host->req->data;
drivers/mmc/host/mxcmmc.c:	if (host->req->stop) {
drivers/mmc/host/mxcmmc.c:		if (mxcmci_start_cmd(host, host->req->stop, 0)) {
drivers/mmc/host/mxcmmc.c:	if (!req->stop)
drivers/mmc/host/mxcmmc.c:	if (req->stop) {
drivers/mmc/host/mxcmmc.c:		if (mxcmci_start_cmd(host, req->stop, 0)) {
drivers/mmc/host/mxcmmc.c:	if (req->data) {
drivers/mmc/host/mxcmmc.c:		error = mxcmci_setup_data(host, req->data);
drivers/mmc/host/mxcmmc.c:			req->cmd->error = error;
drivers/mmc/host/mxcmmc.c:		if (req->data->flags & MMC_DATA_WRITE)
drivers/mmc/host/mxcmmc.c:	error = mxcmci_start_cmd(host, req->cmd, cmdat);
drivers/mmc/host/vub300.c:	struct mmc_command *cmd = req->cmd;
drivers/mmc/host/vub300.c:		struct mmc_data *data = req->data;
drivers/mmc/host/omap_hsmmc.c:	struct mmc_data *data = req->data;
drivers/mmc/host/omap_hsmmc.c:	if (!req->data)
drivers/mmc/host/omap_hsmmc.c:	OMAP_HSMMC_WRITE(host->base, BLK, (req->data->blksz)
drivers/mmc/host/omap_hsmmc.c:				| (req->data->blocks << 16));
drivers/mmc/host/omap_hsmmc.c:	set_data_timeout(host, req->data->timeout_ns,
drivers/mmc/host/omap_hsmmc.c:				req->data->timeout_clks);
drivers/mmc/host/omap_hsmmc.c:	chan = omap_hsmmc_get_dma_chan(host, req->data);
drivers/mmc/host/omap_hsmmc.c:	host->data = req->data;
drivers/mmc/host/omap_hsmmc.c:	if (req->data == NULL) {
drivers/mmc/host/omap_hsmmc.c:		if (req->cmd->flags & MMC_RSP_BUSY) {
drivers/mmc/host/omap_hsmmc.c:			timeout = req->cmd->busy_timeout * NSEC_PER_MSEC;
drivers/mmc/host/omap_hsmmc.c:		req->cmd->error = err;
drivers/mmc/host/omap_hsmmc.c:		if (req->data)
drivers/mmc/host/omap_hsmmc.c:			req->data->error = err;
drivers/mmc/host/omap_hsmmc.c:	if (req->sbc && !(host->flags & AUTO_CMD23)) {
drivers/mmc/host/omap_hsmmc.c:		omap_hsmmc_start_command(host, req->sbc, NULL);
drivers/mmc/host/omap_hsmmc.c:	omap_hsmmc_start_command(host, req->cmd, req->data);
drivers/mmc/core/queue.c:	struct request_queue *q = req->q;
drivers/mmc/core/queue.c:	struct mmc_queue *mq = req->q->queuedata;
drivers/mmc/core/queue.c:	struct request_queue *q = req->q;
drivers/mmc/core/queue.c:	struct request_queue *q = req->q;
drivers/mmc/core/queue.c:		req->rq_flags |= RQF_QUIET;
drivers/mmc/core/queue.c:		req->timeout = 600 * HZ;
drivers/mmc/core/queue.c:	if (!(req->rq_flags & RQF_DONTPREP)) {
drivers/mmc/core/queue.c:		req->rq_flags |= RQF_DONTPREP;
drivers/mmc/core/crypto.c:	if (!req->crypt_keyslot)
drivers/mmc/core/crypto.c:	mrq->crypto_key_slot = blk_ksm_get_slot_idx(req->crypt_keyslot);
drivers/mmc/core/crypto.c:	WARN_ON_ONCE(req->crypt_ctx->bc_dun[0] > U32_MAX);
drivers/mmc/core/crypto.c:	mrq->data_unit_num = req->crypt_ctx->bc_dun[0];
drivers/mmc/core/block.c:#define mmc_req_rel_wr(req)	((req->cmd_flags & REQ_FUA) && \
drivers/mmc/core/block.c:	do_rel_wr = (req->cmd_flags & REQ_FUA) &&
drivers/mmc/core/block.c:	brq->mrq.tag = req->tag;
drivers/mmc/core/block.c:		      (req->cmd_flags & REQ_META) &&
drivers/mmc/core/block.c:	struct request_queue *q = req->q;
drivers/mmc/core/block.c:	struct request_queue *q = req->q;
drivers/mmc/core/block.c:	else if (likely(!blk_should_fake_timeout(req->q)))
drivers/mmc/core/block.c:	brq->mrq.tag = req->tag;
drivers/mmc/core/block.c:	struct mmc_queue *mq = req->q->queuedata;
drivers/mmc/core/block.c:		pr_err("%s: recovery failed!\n", req->rq_disk->disk_name);
drivers/mmc/core/block.c:			req->rq_flags |= RQF_QUIET;
drivers/mmc/core/block.c:	struct request_queue *q = req->q;
drivers/mmc/core/block.c:	else if (likely(!blk_should_fake_timeout(req->q)))
drivers/mmc/core/block.c:	struct mmc_queue *mq = req->q->queuedata;
drivers/mmc/core/block.c:	else if (likely(!blk_should_fake_timeout(req->q)))
drivers/mmc/core/block.c:	else if (likely(!blk_should_fake_timeout(req->q)))
drivers/mmc/core/block.c:	struct request_queue *q = req->q;
drivers/infiniband/sw/siw/siw_qp.c:				memcpy(&rreq->ctrl,
drivers/infiniband/sw/siw/siw_qp.c:				rreq->rsvd = 0;
drivers/infiniband/sw/siw/siw_qp.c:				rreq->ddp_qn =
drivers/infiniband/sw/siw/siw_qp.c:				rreq->ddp_msn = htonl(wqe->sqe.sge[0].length);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->ddp_mo = htonl(wqe->processed);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->sink_stag = htonl(wqe->sqe.rkey);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->sink_to = cpu_to_be64(wqe->sqe.raddr);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->read_size = htonl(wqe->sqe.sge[0].length);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->source_stag = htonl(wqe->sqe.sge[0].lkey);
drivers/infiniband/sw/siw/siw_qp.c:				rreq->source_to =
drivers/infiniband/sw/siw/siw_qp.c:	rreq->id = sqe->id;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->opcode = sqe->opcode;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->sge[0].laddr = sqe->sge[0].laddr;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->sge[0].length = sqe->sge[0].length;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->sge[0].lkey = sqe->sge[0].lkey;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->sge[1].lkey = sqe->sge[1].lkey;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->flags = sqe->flags | SIW_WQE_VALID;
drivers/infiniband/sw/siw/siw_qp.c:	rreq->num_sge = 1;
drivers/infiniband/sw/siw/siw_cm.c:	version = __mpa_rr_revision(req->params.bits);
drivers/infiniband/sw/siw/siw_cm.c:	pd_len = be16_to_cpu(req->params.pd_len);
drivers/infiniband/sw/siw/siw_cm.c:	if (memcmp(req->key, MPA_KEY_REQ, 16))
drivers/infiniband/sw/siw/siw_cm.c:	memcpy(req->key, MPA_KEY_REP, 16);
drivers/infiniband/sw/siw/siw_cm.c:	    (req->params.bits & MPA_RR_FLAG_ENHANCED)) {
drivers/infiniband/sw/siw/siw_cm.c:	if (req->params.bits & MPA_RR_FLAG_MARKERS)
drivers/infiniband/sw/siw/siw_cm.c:	if (req->params.bits & MPA_RR_FLAG_CRC) {
drivers/infiniband/sw/siw/siw_cm.c:			req->params.bits |= MPA_RR_FLAG_CRC;
drivers/infiniband/sw/siw/siw_cm.c:		    req->params.bits & MPA_RR_FLAG_CRC ? 1 : 0,
drivers/infiniband/sw/siw/siw_cm.c:		    req->params.bits & MPA_RR_FLAG_MARKERS ? 1 : 0, 0);
drivers/infiniband/sw/siw/siw_cm.c:	req->params.bits &= ~MPA_RR_FLAG_MARKERS;
drivers/infiniband/sw/siw/siw_cm.c:	req->params.bits |= MPA_RR_FLAG_REJECT;
drivers/infiniband/sw/siw/siw_cm.c:		req->params.bits &= ~MPA_RR_FLAG_CRC;
drivers/infiniband/sw/siw/siw_qp_rx.c:	WRITE_ONCE(rreq->flags, 0);
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->time_cfg_udp_port,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->time_cfg_udp_port,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_qpc_cfg, CFG_BT_ATTR_DATA_0_VF_QPC_BA_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_qpc_cfg, CFG_BT_ATTR_DATA_0_VF_QPC_BUF_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_qpc_cfg, CFG_BT_ATTR_DATA_0_VF_QPC_HOPNUM_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_srqc_cfg, CFG_BT_ATTR_DATA_1_VF_SRQC_BA_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_srqc_cfg, CFG_BT_ATTR_DATA_1_VF_SRQC_BUF_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_srqc_cfg, CFG_BT_ATTR_DATA_1_VF_SRQC_HOPNUM_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_cqc_cfg, CFG_BT_ATTR_DATA_2_VF_CQC_BA_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_cqc_cfg, CFG_BT_ATTR_DATA_2_VF_CQC_BUF_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_cqc_cfg, CFG_BT_ATTR_DATA_2_VF_CQC_HOPNUM_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_mpt_cfg, CFG_BT_ATTR_DATA_3_VF_MPT_BA_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_mpt_cfg, CFG_BT_ATTR_DATA_3_VF_MPT_BUF_PGSZ_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_mpt_cfg, CFG_BT_ATTR_DATA_3_VF_MPT_HOPNUM_M,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_sccc_cfg,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_sccc_cfg,
drivers/infiniband/hw/hns/hns_roce_hw_v2.c:	roce_set_field(req->vf_sccc_cfg,
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:		req->reset_stats = reset;
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:	ocrdma_init_mch(&req->hdr, OCRDMA_CMD_GET_DCBX_CONFIG,
drivers/infiniband/hw/ocrdma/ocrdma_hw.c:	req->param_type = ptype;
drivers/infiniband/hw/hfi1/ipoib_tx.c:		if (list_empty(&txreq->list))
drivers/infiniband/hw/hfi1/ipoib_tx.c:			list_add_tail(&txreq->list, &txq->tx_list);
drivers/infiniband/hw/hfi1/ipoib_tx.c:		list_del(&txreq->list);
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->hdr_dwords = 7;
drivers/infiniband/hw/hfi1/ud.c:		ps->s_txreq->hdr_dwords++;
drivers/infiniband/hw/hfi1/ud.c:		grh = &ps->s_txreq->phdr.hdr.ibh.u.l.grh;
drivers/infiniband/hw/hfi1/ud.c:		ps->s_txreq->hdr_dwords +=
drivers/infiniband/hw/hfi1/ud.c:				      ps->s_txreq->hdr_dwords - LRH_9B_DWORDS,
drivers/infiniband/hw/hfi1/ud.c:		ohdr = &ps->s_txreq->phdr.hdr.ibh.u.l.oth;
drivers/infiniband/hw/hfi1/ud.c:		ohdr = &ps->s_txreq->phdr.hdr.ibh.u.oth;
drivers/infiniband/hw/hfi1/ud.c:	len = ps->s_txreq->hdr_dwords + nwords;
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->phdr.hdr.hdr_type = HFI1_PKT_TYPE_9B;
drivers/infiniband/hw/hfi1/ud.c:	hfi1_make_ib_hdr(&ps->s_txreq->phdr.hdr.ibh,
drivers/infiniband/hw/hfi1/ud.c:		ps->s_txreq->hdr_dwords = 6;
drivers/infiniband/hw/hfi1/ud.c:		ps->s_txreq->hdr_dwords = 9;
drivers/infiniband/hw/hfi1/ud.c:			ps->s_txreq->hdr_dwords++;
drivers/infiniband/hw/hfi1/ud.c:	extra_bytes = hfi1_get_16b_padding((ps->s_txreq->hdr_dwords << 2),
drivers/infiniband/hw/hfi1/ud.c:		grh = &ps->s_txreq->phdr.hdr.opah.u.l.grh;
drivers/infiniband/hw/hfi1/ud.c:		ps->s_txreq->hdr_dwords += hfi1_make_grh(
drivers/infiniband/hw/hfi1/ud.c:			ps->s_txreq->hdr_dwords - LRH_16B_DWORDS,
drivers/infiniband/hw/hfi1/ud.c:		ohdr = &ps->s_txreq->phdr.hdr.opah.u.l.oth;
drivers/infiniband/hw/hfi1/ud.c:		ohdr = &ps->s_txreq->phdr.hdr.opah.u.oth;
drivers/infiniband/hw/hfi1/ud.c:		hfi1_16B_set_qpn(&ps->s_txreq->phdr.hdr.opah.u.mgmt,
drivers/infiniband/hw/hfi1/ud.c:	len = (ps->s_txreq->hdr_dwords + nwords) >> 1;
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->phdr.hdr.hdr_type = HFI1_PKT_TYPE_16B;
drivers/infiniband/hw/hfi1/ud.c:	hfi1_make_16b_hdr(&ps->s_txreq->phdr.hdr.opah,
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->s_cur_size = wqe->length;
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->ss = &qp->s_sge;
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->sde = priv->s_sde;
drivers/infiniband/hw/hfi1/ud.c:	ps->s_txreq->psc = priv->s_sendcontext;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->cur_seg = req->cur_seg;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->comp_seg = req->comp_seg;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->ack_seg = req->ack_seg;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->alloc_seg = req->alloc_seg;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->total_segs = req->total_segs;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->setup_head = req->setup_head;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->clear_tail = req->clear_tail;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->flow_idx = req->flow_idx;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->acked_tail = req->acked_tail;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->state = req->state;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->r_ack_psn = req->r_ack_psn;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->r_flow_psn = req->r_flow_psn;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->r_last_acked = req->r_last_acked;
drivers/infiniband/hw/hfi1/trace_tid.h:		__entry->s_next_psn = req->s_next_psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:	 * Therefore, when priv->pkts_ps is used to calculate req->cur_seg
drivers/infiniband/hw/hfi1/tid_rdma.c:	 * during retry, it will lead to req->cur_seg = 0, which is exactly
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_page(flow->req->qp, flow, 0, 0, 0, vaddr);
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_page(flow->req->qp, flow, i, 0, 0,
drivers/infiniband/hw/hfi1/tid_rdma.c:				trace_hfi1_tid_pageset(flow->req->qp, setcount,
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_page(flow->req->qp, flow, i, 1, 0, v0);
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_page(flow->req->qp, flow, i, 1, 1, v1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	u32 length = flow->req->seg_len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	while (length && req->isge < ss->num_sge) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (++req->isge < ss->num_sge)
drivers/infiniband/hw/hfi1/tid_rdma.c:				*sge = ss->sg_list[req->isge - 1];
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow->length = flow->req->seg_len - length;
drivers/infiniband/hw/hfi1/tid_rdma.c:	*last = req->isge == ss->num_sge ? false : true;
drivers/infiniband/hw/hfi1/tid_rdma.c:	dd = flow->req->rcd->dd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_devdata *dd = flow->req->rcd->dd;
drivers/infiniband/hw/hfi1/tid_rdma.c: * segment. All segments are of length flow->req->seg_len.
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_alloc(flow->req->qp, flow->req->setup_head,
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (flow->req->qp->pmtu == enum_to_mtu(OPA_MTU_4096))
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_node_add(flow->req->qp, s, flow->tnode_cnt - 1,
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_ctxtdata *rcd = flow->req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_msg_alloc_tids(flow->req->qp, " insufficient tids: needed ",
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_ctxtdata *rcd = flow->req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	u32 pmtu_pg = flow->req->qp->pmtu >> PAGE_SHIFT;
drivers/infiniband/hw/hfi1/tid_rdma.c:			   flow->req->qp, flow->tidcnt - 1,
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_ctxtdata *rcd = flow->req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:		struct hfi1_ctxtdata *rcd = flow->req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_alloc(flow->req->qp, flow->req->setup_head, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c: * req->flow_idx is the index of the flow which has been prepared in this
drivers/infiniband/hw/hfi1/tid_rdma.c: * invocation of function call. With flow = &req->flows[req->flow_idx],
drivers/infiniband/hw/hfi1/tid_rdma.c: * For the queuing, caller must hold the flow->req->qp s_lock from the send
drivers/infiniband/hw/hfi1/tid_rdma.c:	__must_hold(&req->qp->s_lock)
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[req->setup_head];
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_ctxtdata *rcd = req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_qp_priv *qpriv = req->qp->priv;
drivers/infiniband/hw/hfi1/tid_rdma.c:	u16 clear_tail = req->clear_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:	lockdep_assert_held(&req->qp->s_lock);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (!CIRC_SPACE(req->setup_head, clear_tail, MAX_FLOWS) ||
drivers/infiniband/hw/hfi1/tid_rdma.c:	    CIRC_CNT(req->setup_head, clear_tail, MAX_FLOWS) >=
drivers/infiniband/hw/hfi1/tid_rdma.c:	    req->n_flows)
drivers/infiniband/hw/hfi1/tid_rdma.c:		hfi1_wait_kmem(flow->req->qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (kernel_tid_waiters(rcd, &rcd->rarr_queue, flow->req->qp))
drivers/infiniband/hw/hfi1/tid_rdma.c:	dequeue_tid_waiter(rcd, &rcd->rarr_queue, flow->req->qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->setup_head = (req->setup_head + 1) & (MAX_FLOWS - 1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	queue_qp_for_tid_wait(rcd, &rcd->rarr_queue, flow->req->qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:	__must_hold(&req->qp->s_lock)
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct hfi1_ctxtdata *rcd = req->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	lockdep_assert_held(&req->qp->s_lock);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (!CIRC_CNT(req->setup_head, req->clear_tail, MAX_FLOWS))
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->clear_tail = (req->clear_tail + 1) & (MAX_FLOWS - 1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (fqp == req->qp) {
drivers/infiniband/hw/hfi1/tid_rdma.c:	__must_hold(&req->qp->s_lock)
drivers/infiniband/hw/hfi1/tid_rdma.c:	while (CIRC_CNT(req->setup_head, req->clear_tail, MAX_FLOWS)) {
drivers/infiniband/hw/hfi1/tid_rdma.c:	kfree(req->flows);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->flows = NULL;
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (likely(req->flows))
drivers/infiniband/hw/hfi1/tid_rdma.c:			     req->rcd->numa_id);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->flows = flows;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->qp = qp;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->rcd = qpriv->rcd;
drivers/infiniband/hw/hfi1/tid_rdma.c:	head = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	tail = req->clear_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow = &req->flows[tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[req->flow_idx];
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct rvt_qp *qp = req->qp;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_build_read_pkt(qp, req->flow_idx, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:	KDETH_RESET(rreq->kdeth0, KVER, 0x1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	KDETH_RESET(rreq->kdeth1, JKEY, remote->jkey);
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->reth.vaddr = cpu_to_be64(wqe->rdma_wr.remote_addr +
drivers/infiniband/hw/hfi1/tid_rdma.c:			   req->cur_seg * req->seg_len + flow->sent);
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->reth.rkey = cpu_to_be32(wqe->rdma_wr.rkey);
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->reth.length = cpu_to_be32(*len);
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->tid_flow_psn =
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->tid_flow_qp =
drivers/infiniband/hw/hfi1/tid_rdma.c:	rreq->verbs_qp = cpu_to_be32(qp->remote_qpn);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->cur_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ack_pending++;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->flow_idx = (req->flow_idx + 1) & (MAX_FLOWS - 1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (req->state == TID_REQUEST_SYNC) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		hfi1_kern_clear_hw_flow(req->rcd, qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	 * have been allocated before. In this case, req->flow_idx should
drivers/infiniband/hw/hfi1/tid_rdma.c:	 * fall behind req->setup_head.
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (req->flow_idx == req->setup_head) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->state == TID_REQUEST_RESEND) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			restart_sge(&qp->s_sge, wqe, req->s_next_psn,
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->isge = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_SYNC;
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * The following call will advance req->setup_head after
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_QUEUED;
drivers/infiniband/hw/hfi1/tid_rdma.c:	/* req->flow_idx should only be one slot behind req->setup_head */
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->flow_idx];
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow->flow_state.ib_spsn = req->s_next_psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->s_next_psn += flow->npkts;
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->setup_head];
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->clear_tail = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_rcv_read_req(qp, req->setup_head, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->flow_idx = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->setup_head = (req->setup_head + 1) & (MAX_FLOWS - 1);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->n_flows = qpriv->tid_rdma.local.max_read;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->cur_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->comp_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ack_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->isge = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->seg_len = qpriv->tid_rdma.local.max_len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->total_len = len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->total_segs = 1;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->r_flow_psn = e->psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->r_flow_psn = psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (psn != e->psn || len != req->total_len)
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * req->clear_tail is advanced). However, when an earlier
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->state == TID_REQUEST_RESEND) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_RESEND_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:		} else if (req->state == TID_REQUEST_INIT_RESEND) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_INIT;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (old_req || req->state == TID_REQUEST_INIT ||
drivers/infiniband/hw/hfi1/tid_rdma.c:		    (req->state == TID_REQUEST_SYNC && !req->cur_seg)) {
drivers/infiniband/hw/hfi1/tid_rdma.c:				    req->state == TID_REQUEST_INIT)
drivers/infiniband/hw/hfi1/tid_rdma.c:					req->state = TID_REQUEST_INIT_RESEND;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->clear_tail == req->setup_head)
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (CIRC_CNT(req->flow_idx, req->clear_tail, MAX_FLOWS)) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			fstate = &req->flows[req->clear_tail].flow_state;
drivers/infiniband/hw/hfi1/tid_rdma.c:				CIRC_CNT(req->flow_idx, req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->flow_idx =
drivers/infiniband/hw/hfi1/tid_rdma.c:				CIRC_ADD(req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (CIRC_CNT(req->setup_head, req->flow_idx,
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->cur_seg = delta_psn(psn, e->psn);
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->state = TID_REQUEST_RESEND_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:			    req->cur_seg == req->comp_seg ||
drivers/infiniband/hw/hfi1/tid_rdma.c:			    req->state == TID_REQUEST_INIT ||
drivers/infiniband/hw/hfi1/tid_rdma.c:			    req->state == TID_REQUEST_INIT_RESEND) {
drivers/infiniband/hw/hfi1/tid_rdma.c:				if (req->state == TID_REQUEST_INIT)
drivers/infiniband/hw/hfi1/tid_rdma.c:					req->state = TID_REQUEST_INIT_RESEND;
drivers/infiniband/hw/hfi1/tid_rdma.c:				CIRC_CNT(req->flow_idx,
drivers/infiniband/hw/hfi1/tid_rdma.c:					 req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->flow_idx = req->clear_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->cur_seg = req->comp_seg;
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_build_read_resp(qp, req->clear_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->clear_tail = (req->clear_tail + 1) &
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:			len = restart_sge(&ss, req->e.swqe, ipsn, pmtu);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ack_pending--;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_req_rcv_read_resp(qp, 0, req->e.swqe->wr.opcode,
drivers/infiniband/hw/hfi1/tid_rdma.c:					 req->e.swqe->psn, req->e.swqe->lpsn,
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_rcv_read_resp(qp, req->clear_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (++req->comp_seg >= req->total_segs) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->state = TID_REQUEST_COMPLETE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	if ((req->state == TID_REQUEST_SYNC &&
drivers/infiniband/hw/hfi1/tid_rdma.c:	     req->comp_seg == req->cur_seg) ||
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->state == TID_REQUEST_SYNC)
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:			flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:							      req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (req->comp_seg == req->cur_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_handle_kdeth_eflags(qp, req->clear_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:		fidx = req->acked_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow = &req->flows[fidx];
drivers/infiniband/hw/hfi1/tid_rdma.c:		*bth2 = mask_psn(req->r_ack_psn);
drivers/infiniband/hw/hfi1/tid_rdma.c:		rvt_skip_sge(&qpriv->tid_ss, (req->cur_seg * req->seg_len) +
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->flow_idx = fidx;
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->clear_tail = fidx;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:			for (; CIRC_CNT(req->setup_head, fidx, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->flows[fidx].sent = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->flows[fidx].pkt = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->flows[fidx].tid_idx = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->flows[fidx].tid_offset = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:				req->flows[fidx].resync_npkts = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->cur_seg = req->ack_seg;
drivers/infiniband/hw/hfi1/tid_rdma.c:			fidx = req->acked_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:			/* Pull req->clear_tail back */
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->clear_tail = fidx;
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (req->ack_seg != req->total_segs)
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (req->ack_seg != req->total_segs)
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->n_flows = remote->max_write;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c: *     [request: qpriv->r_tid_alloc, segment: req->alloc_seg]
drivers/infiniband/hw/hfi1/tid_rdma.c: *     [request: qp->s_tail_ack_queue, segment:req->cur_seg]
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->alloc_seg >= req->total_segs)
drivers/infiniband/hw/hfi1/tid_rdma.c:		npkts = rvt_div_round_up_mtu(qp, req->seg_len);
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * If overtaking req->acked_tail, send an RNR NAK. Because the
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!CIRC_SPACE(req->setup_head, req->acked_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:		ret = hfi1_kern_exp_rcv_setup(req, &req->ss, &last);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->alloc_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:	qp->r_psn = e->psn + req->alloc_seg;
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->state = TID_REQUEST_INIT;
drivers/infiniband/hw/hfi1/tid_rdma.c:	    (req->setup_head != req->clear_tail ||
drivers/infiniband/hw/hfi1/tid_rdma.c:	     req->clear_tail != req->acked_tail))
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->n_flows = min_t(u16, num_segs, qpriv->tid_rdma.local.max_write);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->state = TID_REQUEST_INIT;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->cur_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->comp_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ack_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->alloc_seg = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->isge = 0;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->seg_len = qpriv->tid_rdma.local.max_len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->total_len = len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->total_segs = num_segs;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->r_flow_psn = e->psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ss.sge = e->rdma_sge;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->ss.num_sge = 1;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->flow_idx = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->clear_tail = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->acked_tail = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->flow_idx];
drivers/infiniband/hw/hfi1/tid_rdma.c:	switch (req->state) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->cur_seg >= req->alloc_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_build_write_resp(qp, req->flow_idx, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->flow_idx = CIRC_NEXT(req->flow_idx, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_build_write_resp(qp, req->flow_idx, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->flow_idx = CIRC_NEXT(req->flow_idx, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!CIRC_CNT(req->setup_head, req->flow_idx, MAX_FLOWS))
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->cur_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (!CIRC_SPACE(req->setup_head, req->acked_tail, MAX_FLOWS))
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->setup_head];
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow->length = min_t(u32, req->seg_len,
drivers/infiniband/hw/hfi1/tid_rdma.c:			     (wqe->length - (req->comp_seg * req->seg_len)));
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_rcv_write_resp(qp, req->setup_head, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->comp_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->r_last_acked = mask_psn(wqe->psn - 1);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->acked_tail = req->setup_head;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->setup_head = CIRC_NEXT(req->setup_head, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/tid_rdma.c:	    req->comp_seg == req->total_segs) {
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct rvt_qp *qp = req->qp;
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_build_write_data(qp, req->clear_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:		    rvt_div_round_up_mtu(qp, req->seg_len) >
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_SYNC;
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->clear_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:			len = req->comp_seg * req->seg_len;
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (unlikely(req->total_len - len < pmtu))
drivers/infiniband/hw/hfi1/tid_rdma.c:			ss.total_len = req->total_len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	req->comp_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:	if (req->cur_seg < req->total_segs ||
drivers/infiniband/hw/hfi1/tid_rdma.c:			hfi1_mod_tid_reap_timer(req->qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:			hfi1_stop_tid_reap_timer(req->qp);
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[iflow];
drivers/infiniband/hw/hfi1/tid_rdma.c:	flow = &req->flows[req->acked_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:	trace_hfi1_tid_flow_rcv_tid_ack(qp, req->acked_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:	       req->ack_seg < req->cur_seg) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->ack_seg++;
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->acked_tail = CIRC_NEXT(req->acked_tail, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->r_last_acked = flow->flow_state.resp_ib_psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->ack_seg == req->total_segs) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->state = TID_REQUEST_COMPLETE;
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow = &req->flows[req->acked_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:		trace_hfi1_tid_flow_rcv_tid_ack(qp, req->acked_tail, flow);
drivers/infiniband/hw/hfi1/tid_rdma.c:			    req->ack_seg < req->cur_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:			     req->ack_seg == req->total_segs) ||
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (req->ack_seg == req->comp_seg) {
drivers/infiniband/hw/hfi1/tid_rdma.c:			flow = &req->flows[req->acked_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->r_ack_psn = psn;
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->cur_seg = req->ack_seg;
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (!req->flows)
drivers/infiniband/hw/hfi1/tid_rdma.c:			flow = &req->flows[req->acked_tail];
drivers/infiniband/hw/hfi1/tid_rdma.c:			trace_hfi1_tid_flow_rcv_tid_ack(qp, req->acked_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->r_ack_psn = mask_psn(be32_to_cpu(ohdr->bth[2]));
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->cur_seg = req->ack_seg;
drivers/infiniband/hw/hfi1/tid_rdma.c:	struct tid_rdma_flow *flow = &req->flows[fidx];
drivers/infiniband/hw/hfi1/tid_rdma.c:			for (flow_idx = req->clear_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:			     CIRC_CNT(req->setup_head, flow_idx,
drivers/infiniband/hw/hfi1/tid_rdma.c:				flow = &req->flows[flow_idx];
drivers/infiniband/hw/hfi1/tid_rdma.c:	    (e->opcode == TID_OP(WRITE_REQ) && req->cur_seg < req->alloc_seg &&
drivers/infiniband/hw/hfi1/tid_rdma.c:	ohdr = &ps->s_txreq->phdr.hdr.ibh.u.oth;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!req->comp_seg || req->cur_seg == req->comp_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:			req->clear_tail = CIRC_NEXT(req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:			if (++req->cur_seg < req->total_segs) {
drivers/infiniband/hw/hfi1/tid_rdma.c:				if (!CIRC_CNT(req->setup_head, req->clear_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!req->comp_seg) {
drivers/infiniband/hw/hfi1/tid_rdma.c:						     CIRC_PREV(req->setup_head,
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->hdr_dwords = hwords;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->sde = priv->s_sde;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->ss = ss;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->s_cur_size = len;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!req->ack_seg || req->ack_seg == req->total_segs)
drivers/infiniband/hw/hfi1/tid_rdma.c:	    req->ack_seg == req->comp_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->ack_seg +=
drivers/infiniband/hw/hfi1/tid_rdma.c:			CIRC_CNT(req->clear_tail, req->acked_tail,
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->acked_tail = req->clear_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * req->clear_tail points to the segment currently being
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow = CIRC_PREV(req->acked_tail, MAX_FLOWS);
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->ack_seg != req->total_segs)
drivers/infiniband/hw/hfi1/tid_rdma.c:		req->state = TID_REQUEST_COMPLETE;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (!nreq->comp_seg || nreq->ack_seg == nreq->comp_seg)
drivers/infiniband/hw/hfi1/tid_rdma.c:		      full_flow_psn(&req->flows[flow],
drivers/infiniband/hw/hfi1/tid_rdma.c:				    req->flows[flow].flow_state.lpsn)) > 0))) {
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * requests. Therefore, we NAK with the req->acked_tail
drivers/infiniband/hw/hfi1/tid_rdma.c:		 * this point as the req->clear_tail segment for the
drivers/infiniband/hw/hfi1/tid_rdma.c:		flow = req->acked_tail;
drivers/infiniband/hw/hfi1/tid_rdma.c:	} else if (req->ack_seg == req->total_segs &&
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->hdr_dwords = hwords;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->sde = qpriv->s_sde;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->s_cur_size = len;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->ss = NULL;
drivers/infiniband/hw/hfi1/tid_rdma.c:	ps->s_txreq->txreq.flags |= SDMA_TXREQ_F_VIP;
drivers/infiniband/hw/hfi1/tid_rdma.c:		if (req->ack_seg != req->total_segs) {
drivers/infiniband/hw/hfi1/ruc.c:				(ps->s_txreq->hdr_dwords << 2),
drivers/infiniband/hw/hfi1/ruc.c:				ps->s_txreq->s_cur_size);
drivers/infiniband/hw/hfi1/ruc.c:	u32 nwords = SIZE_OF_CRC + ((ps->s_txreq->s_cur_size +
drivers/infiniband/hw/hfi1/ruc.c:		grh = &ps->s_txreq->phdr.hdr.opah.u.l.grh;
drivers/infiniband/hw/hfi1/ruc.c:		ps->s_txreq->hdr_dwords +=
drivers/infiniband/hw/hfi1/ruc.c:				      ps->s_txreq->hdr_dwords - LRH_16B_DWORDS,
drivers/infiniband/hw/hfi1/ruc.c:	hfi1_make_16b_hdr(&ps->s_txreq->phdr.hdr.opah,
drivers/infiniband/hw/hfi1/ruc.c:			  (ps->s_txreq->hdr_dwords + nwords) >> 1,
drivers/infiniband/hw/hfi1/ruc.c:	u8 extra_bytes = -ps->s_txreq->s_cur_size & 3;
drivers/infiniband/hw/hfi1/ruc.c:	u32 nwords = SIZE_OF_CRC + ((ps->s_txreq->s_cur_size +
drivers/infiniband/hw/hfi1/ruc.c:		struct ib_grh *grh = &ps->s_txreq->phdr.hdr.ibh.u.l.grh;
drivers/infiniband/hw/hfi1/ruc.c:		ps->s_txreq->hdr_dwords +=
drivers/infiniband/hw/hfi1/ruc.c:				      ps->s_txreq->hdr_dwords - LRH_9B_DWORDS,
drivers/infiniband/hw/hfi1/ruc.c:	hfi1_make_ib_hdr(&ps->s_txreq->phdr.hdr.ibh,
drivers/infiniband/hw/hfi1/ruc.c:			 ps->s_txreq->hdr_dwords + nwords,
drivers/infiniband/hw/hfi1/mad.c:	unsigned long vl_select_mask = be32_to_cpu(req->vl_select_mask);
drivers/infiniband/hw/hfi1/mad.c:	u8 port_num = req->port_num;
drivers/infiniband/hw/hfi1/mad.c:	num_vls = hweight32(be32_to_cpu(req->vl_select_mask));
drivers/infiniband/hw/hfi1/mad.c:	vl_select_mask = be32_to_cpu(req->vl_select_mask);
drivers/infiniband/hw/hfi1/mad.c:	res_lli = (u8)(be32_to_cpu(req->resolution) & MSK_LLI) >> MSK_LLI_SFT;
drivers/infiniband/hw/hfi1/mad.c:	res_ler = (u8)(be32_to_cpu(req->resolution) & MSK_LER) >> MSK_LER_SFT;
drivers/infiniband/hw/hfi1/mad.c:	port_mask = be64_to_cpu(req->port_select_mask[3]);
drivers/infiniband/hw/hfi1/mad.c:	rsp = &req->port[0];
drivers/infiniband/hw/hfi1/mad.c:	num_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));
drivers/infiniband/hw/hfi1/mad.c:	num_vls = hweight32(be32_to_cpu(req->vl_select_mask));
drivers/infiniband/hw/hfi1/mad.c:	port_mask = be64_to_cpu(req->port_select_mask[3]);
drivers/infiniband/hw/hfi1/mad.c:	rsp = &req->port[0];
drivers/infiniband/hw/hfi1/mad.c:	vl_select_mask = be32_to_cpu(req->vl_select_mask);
drivers/infiniband/hw/hfi1/mad.c:	rsp = &req->port[0];
drivers/infiniband/hw/hfi1/mad.c:	num_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));
drivers/infiniband/hw/hfi1/mad.c:	port_mask = be64_to_cpu(req->port_select_mask[3]);
drivers/infiniband/hw/hfi1/mad.c:	u64 portn = be64_to_cpu(req->port_select_mask[3]);
drivers/infiniband/hw/hfi1/mad.c:	u32 counter_select = be32_to_cpu(req->counter_select_mask);
drivers/infiniband/hw/hfi1/mad.c:	rsp = &req->port[0];
drivers/infiniband/hw/hfi1/mad.c:	num_pslm = hweight64(be64_to_cpu(req->port_select_mask[3]));
drivers/infiniband/hw/hfi1/mad.c:	port_mask = be64_to_cpu(req->port_select_mask[3]);
drivers/infiniband/hw/hfi1/mad.c:	error_info_select = be32_to_cpu(req->error_info_select_mask);
drivers/infiniband/hw/hfi1/rc.c:			ps->s_txreq->mr = e->rdma_sge.mr;
drivers/infiniband/hw/hfi1/rc.c:			if (ps->s_txreq->mr)
drivers/infiniband/hw/hfi1/rc.c:				rvt_get_mr(ps->s_txreq->mr);
drivers/infiniband/hw/hfi1/rc.c:			ps->s_txreq->ss = &qp->s_ack_rdma_sge;
drivers/infiniband/hw/hfi1/rc.c:			if (req->state == TID_REQUEST_RESEND ||
drivers/infiniband/hw/hfi1/rc.c:			    req->state == TID_REQUEST_INIT_RESEND)
drivers/infiniband/hw/hfi1/rc.c:			qp->s_ack_rdma_psn = mask_psn(e->psn + req->cur_seg);
drivers/infiniband/hw/hfi1/rc.c:			ps->s_txreq->mr = e->rdma_sge.mr;
drivers/infiniband/hw/hfi1/rc.c:			if (ps->s_txreq->mr)
drivers/infiniband/hw/hfi1/rc.c:				rvt_get_mr(ps->s_txreq->mr);
drivers/infiniband/hw/hfi1/rc.c:			ps->s_txreq->ss = NULL;
drivers/infiniband/hw/hfi1/rc.c:		ps->s_txreq->ss = &qp->s_ack_rdma_sge;
drivers/infiniband/hw/hfi1/rc.c:		ps->s_txreq->mr = qp->s_ack_rdma_sge.sge.mr;
drivers/infiniband/hw/hfi1/rc.c:		if (ps->s_txreq->mr)
drivers/infiniband/hw/hfi1/rc.c:			rvt_get_mr(ps->s_txreq->mr);
drivers/infiniband/hw/hfi1/rc.c:		    req->cur_seg == req->alloc_seg) {
drivers/infiniband/hw/hfi1/rc.c:							&ps->s_txreq->ss);
drivers/infiniband/hw/hfi1/rc.c:		if (req->cur_seg != req->total_segs)
drivers/infiniband/hw/hfi1/rc.c:		ps->s_txreq->ss = &qp->s_ack_rdma_sge;
drivers/infiniband/hw/hfi1/rc.c:		ps->s_txreq->txreq.flags |= SDMA_TXREQ_F_VIP;
drivers/infiniband/hw/hfi1/rc.c:		ps->s_txreq->ss = NULL;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->sde = qpriv->s_sde;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->s_cur_size = len;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->hdr_dwords = hwords;
drivers/infiniband/hw/hfi1/rc.c:			ohdr = &ps->s_txreq->phdr.hdr.ibh.u.l.oth;
drivers/infiniband/hw/hfi1/rc.c:			ohdr = &ps->s_txreq->phdr.hdr.ibh.u.oth;
drivers/infiniband/hw/hfi1/rc.c:			ohdr = &ps->s_txreq->phdr.hdr.opah.u.l.oth;
drivers/infiniband/hw/hfi1/rc.c:			ohdr = &ps->s_txreq->phdr.hdr.opah.u.oth;
drivers/infiniband/hw/hfi1/rc.c:				priv->pending_tid_w_resp += req->total_segs;
drivers/infiniband/hw/hfi1/rc.c:				req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/rc.c:				req->comp_seg = delta_psn(bth2, wqe->psn);
drivers/infiniband/hw/hfi1/rc.c:				req->setup_head = req->clear_tail;
drivers/infiniband/hw/hfi1/rc.c:					&req->flows[req->setup_head];
drivers/infiniband/hw/hfi1/rc.c:					req->isge = 0;
drivers/infiniband/hw/hfi1/rc.c:					req->clear_tail = req->setup_head;
drivers/infiniband/hw/hfi1/rc.c:					req->flow_idx = req->setup_head;
drivers/infiniband/hw/hfi1/rc.c:					req->state = TID_REQUEST_ACTIVE;
drivers/infiniband/hw/hfi1/rc.c:				req->cur_seg = 0;
drivers/infiniband/hw/hfi1/rc.c:				req->comp_seg = 0;
drivers/infiniband/hw/hfi1/rc.c:				req->ack_pending = 0;
drivers/infiniband/hw/hfi1/rc.c:				req->flow_idx = req->clear_tail;
drivers/infiniband/hw/hfi1/rc.c:				req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/rc.c:			req->s_next_psn = qp->s_psn;
drivers/infiniband/hw/hfi1/rc.c:			len = min_t(u32, req->seg_len,
drivers/infiniband/hw/hfi1/rc.c:				    wqe->length - req->seg_len * req->cur_seg);
drivers/infiniband/hw/hfi1/rc.c:			if (req->cur_seg >= req->total_segs &&
drivers/infiniband/hw/hfi1/rc.c:			qp->s_psn = req->s_next_psn;
drivers/infiniband/hw/hfi1/rc.c:		req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/rc.c:		req->comp_seg = delta_psn(qp->s_psn, wqe->psn);
drivers/infiniband/hw/hfi1/rc.c:		len = wqe->length - (req->comp_seg * remote->max_len);
drivers/infiniband/hw/hfi1/rc.c:		req->cur_seg = delta_psn(qp->s_psn, wqe->psn) / priv->pkts_ps;
drivers/infiniband/hw/hfi1/rc.c:		 * time, we can use the req->state change to check if the
drivers/infiniband/hw/hfi1/rc.c:		req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/rc.c:		if (req->state != TID_REQUEST_ACTIVE) {
drivers/infiniband/hw/hfi1/rc.c:		req->state = TID_REQUEST_RESEND;
drivers/infiniband/hw/hfi1/rc.c:		len = min_t(u32, req->seg_len,
drivers/infiniband/hw/hfi1/rc.c:			    wqe->length - req->seg_len * req->cur_seg);
drivers/infiniband/hw/hfi1/rc.c:		flow = &req->flows[req->flow_idx];
drivers/infiniband/hw/hfi1/rc.c:		req->s_next_psn = flow->flow_state.ib_lpsn + 1;
drivers/infiniband/hw/hfi1/rc.c:		if (req->cur_seg >= req->total_segs &&
drivers/infiniband/hw/hfi1/rc.c:		qp->s_psn = req->s_next_psn;
drivers/infiniband/hw/hfi1/rc.c:		len = min_t(u32, req->seg_len,
drivers/infiniband/hw/hfi1/rc.c:			    wqe->length - req->seg_len * req->cur_seg);
drivers/infiniband/hw/hfi1/rc.c:		if (req->cur_seg >= req->total_segs &&
drivers/infiniband/hw/hfi1/rc.c:		qp->s_psn = req->s_next_psn;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->hdr_dwords = hwords;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->sde = priv->s_sde;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->ss = ss;
drivers/infiniband/hw/hfi1/rc.c:	ps->s_txreq->s_cur_size = len;
drivers/infiniband/hw/hfi1/rc.c:			req->ack_pending = cur_seg - req->comp_seg;
drivers/infiniband/hw/hfi1/rc.c:			priv->pending_tid_r_segs += req->ack_pending;
drivers/infiniband/hw/hfi1/rc.c:			qp->s_num_rd_atomic += req->ack_pending;
drivers/infiniband/hw/hfi1/rc.c:			priv->pending_tid_r_segs += req->total_segs;
drivers/infiniband/hw/hfi1/rc.c:			qp->s_num_rd_atomic += req->total_segs;
drivers/infiniband/hw/hfi1/rc.c:		if (head == tail && req->comp_seg < req->total_segs) {
drivers/infiniband/hw/hfi1/rc.c:		    req->ack_seg < req->cur_seg)
drivers/infiniband/hw/hfi1/verbs.c:		list_add_tail(&ps->s_txreq->txreq.list,
drivers/infiniband/hw/hfi1/verbs.c:	u32 hdrwords = ps->s_txreq->hdr_dwords;
drivers/infiniband/hw/hfi1/verbs.c:	u32 len = ps->s_txreq->s_cur_size;
drivers/infiniband/hw/hfi1/verbs.c:	if (ps->s_txreq->phdr.hdr.hdr_type) {
drivers/infiniband/hw/hfi1/verbs.c:			if (ps->s_txreq->phdr.hdr.hdr_type)
drivers/infiniband/hw/hfi1/verbs.c:				&ps->s_txreq->phdr.hdr, ib_is_sc5(sc5));
drivers/infiniband/hw/hfi1/verbs.c:		list_add_tail(&ps->s_txreq->txreq.list,
drivers/infiniband/hw/hfi1/verbs.c:	u32 hdrwords = ps->s_txreq->hdr_dwords;
drivers/infiniband/hw/hfi1/verbs.c:	struct rvt_sge_state *ss = ps->s_txreq->ss;
drivers/infiniband/hw/hfi1/verbs.c:	u32 len = ps->s_txreq->s_cur_size;
drivers/infiniband/hw/hfi1/verbs.c:	if (ps->s_txreq->phdr.hdr.hdr_type) {
drivers/infiniband/hw/hfi1/verbs.c:		hdr = (u32 *)&ps->s_txreq->phdr.hdr.opah;
drivers/infiniband/hw/hfi1/verbs.c:		hdr = (u32 *)&ps->s_txreq->phdr.hdr.ibh;
drivers/infiniband/hw/hfi1/verbs.c:	sc = ps->s_txreq->psc;
drivers/infiniband/hw/hfi1/verbs.c:		if (ps->s_txreq->phdr.hdr.hdr_type)
drivers/infiniband/hw/hfi1/verbs.c:			       &ps->s_txreq->phdr.hdr, ib_is_sc5(sc5));
drivers/infiniband/hw/hfi1/verbs.c:			hfi1_rc_verbs_aborted(qp, &ps->s_txreq->phdr.hdr);
drivers/infiniband/hw/hfi1/verbs.c:		hfi1_rc_send_complete(qp, &ps->s_txreq->phdr.hdr);
drivers/infiniband/hw/hfi1/verbs.c:	if (ps->s_txreq->phdr.hdr.hdr_type) {
drivers/infiniband/hw/hfi1/verbs.c:		struct hfi1_16b_header *hdr = &ps->s_txreq->phdr.hdr.opah;
drivers/infiniband/hw/hfi1/verbs.c:		struct ib_header *hdr = &ps->s_txreq->phdr.hdr.ibh;
drivers/infiniband/hw/hfi1/verbs.c:				ps->s_txreq->psc,
drivers/infiniband/hw/hfi1/user_sdma.c:	snprintf(buf, 64, "txreq-kmem-cache-%u-%u-%u", dd->unit, uctxt->ctxt,
drivers/infiniband/hw/hfi1/user_sdma.c:	if (iovec[idx].iov_len < sizeof(info) + sizeof(req->hdr)) {
drivers/infiniband/hw/hfi1/user_sdma.c:		   iovec[idx].iov_len, sizeof(info) + sizeof(req->hdr));
drivers/infiniband/hw/hfi1/user_sdma.c:	req->data_iovs = req_iovcnt(info.ctrl) - 1; /* subtract header vector */
drivers/infiniband/hw/hfi1/user_sdma.c:	req->data_len  = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->pq = pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->cq = cq;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->ahg_idx = -1;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->iov_idx = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->sent = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->seqnum = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->seqcomp = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->seqsubmitted = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->tids = NULL;
drivers/infiniband/hw/hfi1/user_sdma.c:	req->has_error = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	INIT_LIST_HEAD(&req->txps);
drivers/infiniband/hw/hfi1/user_sdma.c:	memcpy(&req->info, &info, sizeof(info));
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->data_iovs < 2) {
drivers/infiniband/hw/hfi1/user_sdma.c:		req->data_iovs--;
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!info.npkts || req->data_iovs > MAX_VECTORS_PER_REQ) {
drivers/infiniband/hw/hfi1/user_sdma.c:		SDMA_DBG(req, "Too many vectors (%u/%u)", req->data_iovs,
drivers/infiniband/hw/hfi1/user_sdma.c:	ret = copy_from_user(&req->hdr, iovec[idx].iov_base + sizeof(info),
drivers/infiniband/hw/hfi1/user_sdma.c:			     sizeof(req->hdr));
drivers/infiniband/hw/hfi1/user_sdma.c:		req->hdr.pbc[2] = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	opcode = (be32_to_cpu(req->hdr.bth[0]) >> 24) & 0xff;
drivers/infiniband/hw/hfi1/user_sdma.c:	vl = (le16_to_cpu(req->hdr.pbc[0]) >> 12) & 0xF;
drivers/infiniband/hw/hfi1/user_sdma.c:	sc = (((be16_to_cpu(req->hdr.lrh[0]) >> 12) & 0xF) |
drivers/infiniband/hw/hfi1/user_sdma.c:	      (((le16_to_cpu(req->hdr.pbc[1]) >> 14) & 0x1) << 4));
drivers/infiniband/hw/hfi1/user_sdma.c:	pkey = (u16)be32_to_cpu(req->hdr.bth[0]);
drivers/infiniband/hw/hfi1/user_sdma.c:	slid = be16_to_cpu(req->hdr.lrh[3]);
drivers/infiniband/hw/hfi1/user_sdma.c:	if ((be16_to_cpu(req->hdr.lrh[0]) & 0x3) == HFI1_LRH_GRH) {
drivers/infiniband/hw/hfi1/user_sdma.c:	req->koffset = le32_to_cpu(req->hdr.kdeth.swdata[6]);
drivers/infiniband/hw/hfi1/user_sdma.c:	req->tidoffset = KDETH_GET(req->hdr.kdeth.ver_tid_offset, OFFSET) *
drivers/infiniband/hw/hfi1/user_sdma.c:		(KDETH_GET(req->hdr.kdeth.ver_tid_offset, OM) ?
drivers/infiniband/hw/hfi1/user_sdma.c:					       info.comp_idx, req->tidoffset);
drivers/infiniband/hw/hfi1/user_sdma.c:	for (i = 0; i < req->data_iovs; i++) {
drivers/infiniband/hw/hfi1/user_sdma.c:		req->iovs[i].offset = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:		INIT_LIST_HEAD(&req->iovs[i].list);
drivers/infiniband/hw/hfi1/user_sdma.c:		memcpy(&req->iovs[i].iov,
drivers/infiniband/hw/hfi1/user_sdma.c:		       sizeof(req->iovs[i].iov));
drivers/infiniband/hw/hfi1/user_sdma.c:		ret = pin_vector_pages(req, &req->iovs[i]);
drivers/infiniband/hw/hfi1/user_sdma.c:			req->data_iovs = i;
drivers/infiniband/hw/hfi1/user_sdma.c:		req->data_len += req->iovs[i].iov.iov_len;
drivers/infiniband/hw/hfi1/user_sdma.c:					 info.comp_idx, req->data_len);
drivers/infiniband/hw/hfi1/user_sdma.c:	if (pcount > req->info.npkts)
drivers/infiniband/hw/hfi1/user_sdma.c:		pcount = req->info.npkts;
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req_opcode(req->info.ctrl) == EXPECTED) {
drivers/infiniband/hw/hfi1/user_sdma.c:		u16 ntids = iovec[idx].iov_len / sizeof(*req->tids);
drivers/infiniband/hw/hfi1/user_sdma.c:				  ntids * sizeof(*req->tids));
drivers/infiniband/hw/hfi1/user_sdma.c:		req->tids = tmp;
drivers/infiniband/hw/hfi1/user_sdma.c:		req->n_tids = ntids;
drivers/infiniband/hw/hfi1/user_sdma.c:		req->tididx = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:	dlid = be16_to_cpu(req->hdr.lrh[1]);
drivers/infiniband/hw/hfi1/user_sdma.c:	req->sde = sdma_select_user_engine(dd, selector, vl);
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!req->sde || !sdma_running(req->sde)) {
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req->info.npkts > 1 && HFI1_CAP_IS_USET(SDMA_AHG))
drivers/infiniband/hw/hfi1/user_sdma.c:		req->ahg_idx = sdma_ahg_alloc(req->sde);
drivers/infiniband/hw/hfi1/user_sdma.c:	while (req->seqsubmitted != req->info.npkts) {
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req->seqsubmitted < req->info.npkts) {
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->seqsubmitted)
drivers/infiniband/hw/hfi1/user_sdma.c:				   (req->seqcomp == req->seqsubmitted - 1));
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!req->seqnum) {
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->data_len < sizeof(u32))
drivers/infiniband/hw/hfi1/user_sdma.c:			len = req->data_len;
drivers/infiniband/hw/hfi1/user_sdma.c:			len = ((be16_to_cpu(req->hdr.lrh[2]) << 2) -
drivers/infiniband/hw/hfi1/user_sdma.c:	} else if (req_opcode(req->info.ctrl) == EXPECTED) {
drivers/infiniband/hw/hfi1/user_sdma.c:		u32 tidlen = EXP_TID_GET(req->tids[req->tididx], LEN) *
drivers/infiniband/hw/hfi1/user_sdma.c:		len = min(tidlen - req->tidoffset, (u32)req->info.fragsize);
drivers/infiniband/hw/hfi1/user_sdma.c:		if (unlikely(!len) && ++req->tididx < req->n_tids &&
drivers/infiniband/hw/hfi1/user_sdma.c:		    req->tids[req->tididx]) {
drivers/infiniband/hw/hfi1/user_sdma.c:			tidlen = EXP_TID_GET(req->tids[req->tididx],
drivers/infiniband/hw/hfi1/user_sdma.c:			req->tidoffset = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:			len = min_t(u32, tidlen, req->info.fragsize);
drivers/infiniband/hw/hfi1/user_sdma.c:		len = min(len, req->data_len - req->sent);
drivers/infiniband/hw/hfi1/user_sdma.c:		len = min(req->data_len - req->sent, (u32)req->info.fragsize);
drivers/infiniband/hw/hfi1/user_sdma.c:	trace_hfi1_sdma_user_compute_length(req->pq->dd,
drivers/infiniband/hw/hfi1/user_sdma.c:					    req->pq->ctxt,
drivers/infiniband/hw/hfi1/user_sdma.c:					    req->pq->subctxt,
drivers/infiniband/hw/hfi1/user_sdma.c:					    req->info.comp_idx,
drivers/infiniband/hw/hfi1/user_sdma.c:	u16 pbclen = le16_to_cpu(req->hdr.pbc[0]);
drivers/infiniband/hw/hfi1/user_sdma.c:	u32 lrhlen = get_lrh_len(req->hdr, pad_len(datalen));
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	memcpy(&tx->hdr, &req->hdr, sizeof(tx->hdr));
drivers/infiniband/hw/hfi1/user_sdma.c:			      sizeof(tx->hdr) + datalen, req->ahg_idx,
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	len = offset + req->info.fragsize > PAGE_SIZE ?
drivers/infiniband/hw/hfi1/user_sdma.c:		PAGE_SIZE - offset : req->info.fragsize;
drivers/infiniband/hw/hfi1/user_sdma.c:		     req->iov_idx < req->data_iovs - 1)) {
drivers/infiniband/hw/hfi1/user_sdma.c:		iovec = &req->iovs[++req->iov_idx];
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!req->pq)
drivers/infiniband/hw/hfi1/user_sdma.c:	pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	if (READ_ONCE(req->has_error))
drivers/infiniband/hw/hfi1/user_sdma.c:	if (unlikely(req->seqnum == req->info.npkts)) {
drivers/infiniband/hw/hfi1/user_sdma.c:		if (!list_empty(&req->txps))
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!maxpkts || maxpkts > req->info.npkts - req->seqnum)
drivers/infiniband/hw/hfi1/user_sdma.c:		maxpkts = req->info.npkts - req->seqnum;
drivers/infiniband/hw/hfi1/user_sdma.c:		if (READ_ONCE(req->has_error))
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->seqnum == req->info.npkts - 1)
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->data_len) {
drivers/infiniband/hw/hfi1/user_sdma.c:			iovec = &req->iovs[req->iov_idx];
drivers/infiniband/hw/hfi1/user_sdma.c:				if (++req->iov_idx == req->data_iovs) {
drivers/infiniband/hw/hfi1/user_sdma.c:				iovec = &req->iovs[req->iov_idx];
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->ahg_idx >= 0) {
drivers/infiniband/hw/hfi1/user_sdma.c:			if (!req->seqnum) {
drivers/infiniband/hw/hfi1/user_sdma.c:			ret = sdma_txinit(&tx->txreq, 0, sizeof(req->hdr) +
drivers/infiniband/hw/hfi1/user_sdma.c:		       (req->sent + data_sent) < req->data_len) {
drivers/infiniband/hw/hfi1/user_sdma.c:		req->koffset += datalen;
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req_opcode(req->info.ctrl) == EXPECTED)
drivers/infiniband/hw/hfi1/user_sdma.c:			req->tidoffset += datalen;
drivers/infiniband/hw/hfi1/user_sdma.c:		req->sent += data_sent;
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->data_len)
drivers/infiniband/hw/hfi1/user_sdma.c:		list_add_tail(&tx->txreq.list, &req->txps);
drivers/infiniband/hw/hfi1/user_sdma.c:		tx->seqnum = req->seqnum++;
drivers/infiniband/hw/hfi1/user_sdma.c:	ret = sdma_send_txlist(req->sde,
drivers/infiniband/hw/hfi1/user_sdma.c:			       &req->txps, &count);
drivers/infiniband/hw/hfi1/user_sdma.c:	req->seqsubmitted += count;
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req->seqsubmitted == req->info.npkts) {
drivers/infiniband/hw/hfi1/user_sdma.c:		if (req->ahg_idx >= 0)
drivers/infiniband/hw/hfi1/user_sdma.c:			sdma_ahg_free(req->sde, req->ahg_idx);
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	ret = hfi1_mmu_rb_insert(req->pq->handler, &node->rb);
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req->info.fragsize % PIO_BLOCK_SIZE || lrhlen & 0x3 ||
drivers/infiniband/hw/hfi1/user_sdma.c:	    lrhlen > get_lrh_len(*hdr, req->info.fragsize))
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req_opcode(req->info.ctrl) == EXPECTED) {
drivers/infiniband/hw/hfi1/user_sdma.c:		u32 tidval = req->tids[req->tididx],
drivers/infiniband/hw/hfi1/user_sdma.c:			  (KDETH_GET(req->hdr.kdeth.ver_tid_offset, OM) ?
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	memcpy(hdr, &req->hdr, sizeof(*hdr));
drivers/infiniband/hw/hfi1/user_sdma.c:		if (unlikely(req->seqnum == 2)) {
drivers/infiniband/hw/hfi1/user_sdma.c:			req->hdr.pbc[0] = hdr->pbc[0];
drivers/infiniband/hw/hfi1/user_sdma.c:			req->hdr.lrh[2] = hdr->lrh[2];
drivers/infiniband/hw/hfi1/user_sdma.c:	if (unlikely(!req->seqnum)) {
drivers/infiniband/hw/hfi1/user_sdma.c:				(req_opcode(req->info.ctrl) == EXPECTED),
drivers/infiniband/hw/hfi1/user_sdma.c:				req->seqnum));
drivers/infiniband/hw/hfi1/user_sdma.c:	hdr->kdeth.swdata[6] = cpu_to_le32(req->koffset);
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req_opcode(req->info.ctrl) == EXPECTED) {
drivers/infiniband/hw/hfi1/user_sdma.c:		tidval = req->tids[req->tididx];
drivers/infiniband/hw/hfi1/user_sdma.c:		if ((req->tidoffset) == (EXP_TID_GET(tidval, LEN) *
drivers/infiniband/hw/hfi1/user_sdma.c:			req->tidoffset = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:			if (++req->tididx > req->n_tids - 1 ||
drivers/infiniband/hw/hfi1/user_sdma.c:			    !req->tids[req->tididx]) {
drivers/infiniband/hw/hfi1/user_sdma.c:			tidval = req->tids[req->tididx];
drivers/infiniband/hw/hfi1/user_sdma.c:			pq->dd, pq->ctxt, pq->subctxt, req->info.comp_idx,
drivers/infiniband/hw/hfi1/user_sdma.c:			req->tidoffset, req->tidoffset >> omfactor,
drivers/infiniband/hw/hfi1/user_sdma.c:			  req->tidoffset >> omfactor);
drivers/infiniband/hw/hfi1/user_sdma.c:				    req->info.comp_idx, hdr, tidval);
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_user_sdma_pkt_q *pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	struct hfi1_pkt_header *hdr = &req->hdr;
drivers/infiniband/hw/hfi1/user_sdma.c:	val32 = (be32_to_cpu(hdr->bth[2]) + req->seqnum) &
drivers/infiniband/hw/hfi1/user_sdma.c:			     (__force u16)cpu_to_le16(req->koffset & 0xffff));
drivers/infiniband/hw/hfi1/user_sdma.c:			     (__force u16)cpu_to_le16(req->koffset >> 16));
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req_opcode(req->info.ctrl) == EXPECTED) {
drivers/infiniband/hw/hfi1/user_sdma.c:		tidval = req->tids[req->tididx];
drivers/infiniband/hw/hfi1/user_sdma.c:		if ((req->tidoffset) == (EXP_TID_GET(tidval, LEN) *
drivers/infiniband/hw/hfi1/user_sdma.c:			req->tidoffset = 0;
drivers/infiniband/hw/hfi1/user_sdma.c:			if (++req->tididx > req->n_tids - 1 ||
drivers/infiniband/hw/hfi1/user_sdma.c:			    !req->tids[req->tididx])
drivers/infiniband/hw/hfi1/user_sdma.c:			tidval = req->tids[req->tididx];
drivers/infiniband/hw/hfi1/user_sdma.c:				((req->tidoffset >> omfactor)
drivers/infiniband/hw/hfi1/user_sdma.c:					req->info.comp_idx, req->sde->this_idx,
drivers/infiniband/hw/hfi1/user_sdma.c:					req->ahg_idx, ahg, idx, tidval);
drivers/infiniband/hw/hfi1/user_sdma.c:			datalen, req->ahg_idx, idx,
drivers/infiniband/hw/hfi1/user_sdma.c:			ahg, sizeof(req->hdr),
drivers/infiniband/hw/hfi1/user_sdma.c:	pq = req->pq;
drivers/infiniband/hw/hfi1/user_sdma.c:	cq = req->cq;
drivers/infiniband/hw/hfi1/user_sdma.c:		WRITE_ONCE(req->has_error, 1);
drivers/infiniband/hw/hfi1/user_sdma.c:	req->seqcomp = tx->seqnum;
drivers/infiniband/hw/hfi1/user_sdma.c:	if (req->seqcomp != req->info.npkts - 1)
drivers/infiniband/hw/hfi1/user_sdma.c:	set_comp_state(pq, cq, req->info.comp_idx, state, status);
drivers/infiniband/hw/hfi1/user_sdma.c:	if (!list_empty(&req->txps)) {
drivers/infiniband/hw/hfi1/user_sdma.c:		list_for_each_entry_safe(t, p, &req->txps, list) {
drivers/infiniband/hw/hfi1/user_sdma.c:			sdma_txclean(req->pq->dd, t);
drivers/infiniband/hw/hfi1/user_sdma.c:			kmem_cache_free(req->pq->txreq_cache, tx);
drivers/infiniband/hw/hfi1/user_sdma.c:	for (i = 0; i < req->data_iovs; i++) {
drivers/infiniband/hw/hfi1/user_sdma.c:		struct sdma_mmu_node *node = req->iovs[i].node;
drivers/infiniband/hw/hfi1/user_sdma.c:		req->iovs[i].node = NULL;
drivers/infiniband/hw/hfi1/user_sdma.c:			hfi1_mmu_rb_remove(req->pq->handler,
drivers/infiniband/hw/hfi1/user_sdma.c:	kfree(req->tids);
drivers/infiniband/hw/hfi1/user_sdma.c:	clear_bit(req->info.comp_idx, req->pq->req_in_use);
drivers/infiniband/hw/hfi1/uc.c:			ohdr = &ps->s_txreq->phdr.hdr.ibh.u.l.oth;
drivers/infiniband/hw/hfi1/uc.c:			ohdr = &ps->s_txreq->phdr.hdr.ibh.u.oth;
drivers/infiniband/hw/hfi1/uc.c:			ohdr = &ps->s_txreq->phdr.hdr.opah.u.l.oth;
drivers/infiniband/hw/hfi1/uc.c:			ohdr = &ps->s_txreq->phdr.hdr.opah.u.oth;
drivers/infiniband/hw/hfi1/uc.c:	ps->s_txreq->hdr_dwords = hwords;
drivers/infiniband/hw/hfi1/uc.c:	ps->s_txreq->sde = priv->s_sde;
drivers/infiniband/hw/hfi1/uc.c:	ps->s_txreq->ss = &qp->s_sge;
drivers/infiniband/hw/hfi1/uc.c:	ps->s_txreq->s_cur_size = len;
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:			--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:	if (req->clean)
drivers/infiniband/hw/mlx4/mcg.c:		leave_mask = group->func[req->func].join_state;
drivers/infiniband/hw/mlx4/mcg.c:	status = check_leave(group, req->func, leave_mask);
drivers/infiniband/hw/mlx4/mcg.c:		leave_group(group, req->func, leave_mask);
drivers/infiniband/hw/mlx4/mcg.c:	if (!req->clean)
drivers/infiniband/hw/mlx4/mcg.c:		send_reply_to_slave(req->func, group, &req->sa_mad, status);
drivers/infiniband/hw/mlx4/mcg.c:	--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:	list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:	list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:	struct ib_sa_mcmember_data *sa_data = (struct ib_sa_mcmember_data *)req->sa_mad.data;
drivers/infiniband/hw/mlx4/mcg.c:		status = cmp_rec(&group->rec, sa_data, req->sa_mad.sa_hdr.comp_mask);
drivers/infiniband/hw/mlx4/mcg.c:			join_group(group, req->func, join_mask);
drivers/infiniband/hw/mlx4/mcg.c:		--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:		send_reply_to_slave(req->func, group, &req->sa_mad, status);
drivers/infiniband/hw/mlx4/mcg.c:		list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:		list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:		if (send_join_to_wire(group, &req->sa_mad)) {
drivers/infiniband/hw/mlx4/mcg.c:			--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:						send_reply_to_slave(req->func, group, &req->sa_mad, status);
drivers/infiniband/hw/mlx4/mcg.c:						--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:						list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:						list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:		sa_data = (struct ib_sa_mcmember_data *)req->sa_mad.data;
drivers/infiniband/hw/mlx4/mcg.c:		if (req->sa_mad.mad_hdr.method == IB_SA_METHOD_DELETE)
drivers/infiniband/hw/mlx4/mcg.c:					--group->func[req->func].num_pend_reqs;
drivers/infiniband/hw/mlx4/mcg.c:					list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:					list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:	struct mcast_group *group = req->group;
drivers/infiniband/hw/mlx4/mcg.c:	list_add_tail(&req->group_list, &group->pending_list);
drivers/infiniband/hw/mlx4/mcg.c:	list_add_tail(&req->func_list, &group->func[req->func].pending);
drivers/infiniband/hw/mlx4/mcg.c:		req->func = slave;
drivers/infiniband/hw/mlx4/mcg.c:		req->sa_mad = *sa_mad;
drivers/infiniband/hw/mlx4/mcg.c:		req->group = group;
drivers/infiniband/hw/mlx4/mcg.c:			  be64_to_cpu(req->sa_mad.mad_hdr.tid));
drivers/infiniband/hw/mlx4/mcg.c:		list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:	struct ib_sa_mad *mad = &req->sa_mad;
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->group_list);
drivers/infiniband/hw/mlx4/mcg.c:			list_del(&req->func_list);
drivers/infiniband/hw/mlx4/mcg.c:		if (pend_req->clean) {
drivers/infiniband/hw/mlx4/mcg.c:	req->clean = 1;
drivers/infiniband/hw/mlx4/mcg.c:	req->func = slave;
drivers/infiniband/hw/mlx4/mcg.c:	req->group = group;
drivers/infiniband/hw/qedr/verbs.c:	rc = qedr_init_user_queue(udata, srq->dev, &srq->usrq, ureq->srq_addr,
drivers/infiniband/hw/qedr/verbs.c:				  ureq->srq_len, false, access, 1);
drivers/infiniband/hw/qedr/verbs.c:	srq->prod_umem = ib_umem_get(srq->ibsrq.device, ureq->prod_pair_addr,
drivers/infiniband/hw/qedr/verbs.c:	switch (req->status) {
drivers/infiniband/hw/qedr/verbs.c:		cnt = process_req(dev, qp, cq, num_entries, wc, req->sq_cons,
drivers/infiniband/hw/qedr/verbs.c:		cnt = process_req(dev, qp, cq, num_entries, wc, req->sq_cons,
drivers/infiniband/hw/qedr/verbs.c:				  req->sq_cons - 1, IB_WC_SUCCESS, 0);
drivers/infiniband/hw/qedr/verbs.c:			switch (req->status) {
drivers/infiniband/hw/qedr/verbs.c:			cnt += process_req(dev, qp, cq, 1, wc, req->sq_cons,
drivers/infiniband/hw/qedr/verbs.c:	if (le16_to_cpu(req->sq_cons) == qp->sq.wqe_cons) {
drivers/infiniband/hw/cxgb4/cm.c:	req->cmd = CPL_ABORT_NO_RST;
drivers/infiniband/hw/cxgb4/cm.c:	req->reply_ctrl = htons(REPLY_CHAN_V(0) | QUEUENO_V(ep->rss_qid));
drivers/infiniband/hw/cxgb4/cm.c:		req->local_port = la->sin_port;
drivers/infiniband/hw/cxgb4/cm.c:		req->peer_port = ra->sin_port;
drivers/infiniband/hw/cxgb4/cm.c:		req->local_ip = la->sin_addr.s_addr;
drivers/infiniband/hw/cxgb4/cm.c:		req->peer_ip = ra->sin_addr.s_addr;
drivers/infiniband/hw/cxgb4/cm.c:		req->opt0 = cpu_to_be64(opt0);
drivers/infiniband/hw/cxgb4/cm.c:			req->params = cpu_to_be32(params);
drivers/infiniband/hw/cxgb4/cm.c:			req->opt2 = cpu_to_be32(opt2);
drivers/infiniband/hw/cxgb4/cm.c:				t5req->params =
drivers/infiniband/hw/cxgb4/cm.c:				t5req->rsvd = cpu_to_be32(isn);
drivers/infiniband/hw/cxgb4/cm.c:				pr_debug("snd_isn %u\n", t5req->rsvd);
drivers/infiniband/hw/cxgb4/cm.c:				t5req->opt2 = cpu_to_be32(opt2);
drivers/infiniband/hw/cxgb4/cm.c:				t6req->params =
drivers/infiniband/hw/cxgb4/cm.c:				t6req->rsvd = cpu_to_be32(isn);
drivers/infiniband/hw/cxgb4/cm.c:				pr_debug("snd_isn %u\n", t6req->rsvd);
drivers/infiniband/hw/cxgb4/cm.c:				t6req->opt2 = cpu_to_be32(opt2);
drivers/infiniband/hw/cxgb4/cm.c:	req->op_to_immdlen = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->flowid_len16 = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->plen = cpu_to_be32(mpalen);
drivers/infiniband/hw/cxgb4/cm.c:	req->tunnel_to_proxy = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->op_to_immdlen = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->flowid_len16 = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->plen = cpu_to_be32(mpalen);
drivers/infiniband/hw/cxgb4/cm.c:	req->tunnel_to_proxy = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->op_to_immdlen = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->flowid_len16 = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	req->plen = cpu_to_be32(mpalen);
drivers/infiniband/hw/cxgb4/cm.c:	req->tunnel_to_proxy = cpu_to_be32(
drivers/infiniband/hw/cxgb4/cm.c:	unsigned short tcp_opt = ntohs(req->tcp_opt);
drivers/infiniband/hw/cxgb4/cm.c:	unsigned int atid = TID_TID_G(ntohl(req->tos_atid));
drivers/infiniband/hw/cxgb4/cm.c:		 be32_to_cpu(req->snd_isn), be32_to_cpu(req->rcv_isn));
drivers/infiniband/hw/cxgb4/cm.c:	ep->snd_seq = be32_to_cpu(req->snd_isn);
drivers/infiniband/hw/cxgb4/cm.c:	ep->rcv_seq = be32_to_cpu(req->rcv_isn);
drivers/infiniband/hw/cxgb4/cm.c:	req->op_compl = htonl(WR_OP_V(FW_OFLD_CONNECTION_WR));
drivers/infiniband/hw/cxgb4/cm.c:	req->len16_pkd = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*req), 16)));
drivers/infiniband/hw/cxgb4/cm.c:	req->le.filter = cpu_to_be32(cxgb4_select_ntuple(
drivers/infiniband/hw/cxgb4/cm.c:	req->le.lport = sin->sin_port;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.u.ipv4.lip = sin->sin_addr.s_addr;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.pport = sin->sin_port;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.u.ipv4.pip = sin->sin_addr.s_addr;
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.t_state_to_astid =
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.cplrxdataack_cplpassacceptrpl =
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.tx_max = (__force __be32) jiffies;
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.rcv_adv = htons(1);
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt0 = (__force __be64) (TCAM_BYPASS_F |
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt2 = (__force __be32) (PACE_V(1) |
drivers/infiniband/hw/cxgb4/cm.c:		req->tcb.opt2 |= (__force __be32)TSTAMPS_EN_F;
drivers/infiniband/hw/cxgb4/cm.c:		req->tcb.opt2 |= (__force __be32)SACK_EN_F;
drivers/infiniband/hw/cxgb4/cm.c:		req->tcb.opt2 |= (__force __be32)WND_SCALE_EN_F;
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt0 = cpu_to_be64((__force u64)req->tcb.opt0);
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt2 = cpu_to_be32((__force u32)req->tcb.opt2);
drivers/infiniband/hw/cxgb4/cm.c:		      enable_tcp_timestamps && req->tcpopt.tstamp,
drivers/infiniband/hw/cxgb4/cm.c:	if (enable_tcp_timestamps && req->tcpopt.tstamp)
drivers/infiniband/hw/cxgb4/cm.c:	if (enable_tcp_sack && req->tcpopt.sack)
drivers/infiniband/hw/cxgb4/cm.c:		u32 hlen = ntohl(req->hdr_len);
drivers/infiniband/hw/cxgb4/cm.c:	unsigned int stid = PASS_OPEN_TID_G(ntohl(req->tos_stid));
drivers/infiniband/hw/cxgb4/cm.c:	u16 peer_mss = ntohs(req->tcpopt.mss);
drivers/infiniband/hw/cxgb4/cm.c:		tos = PASS_OPEN_TOS_G(ntohl(req->tos_stid));
drivers/infiniband/hw/cxgb4/cm.c:	       ((enable_tcp_timestamps && req->tcpopt.tstamp) ? 12 : 0);
drivers/infiniband/hw/cxgb4/cm.c:	u16 tcp_opt = ntohs(req->tcp_opt);
drivers/infiniband/hw/cxgb4/cm.c:	ep->snd_seq = be32_to_cpu(req->snd_isn);
drivers/infiniband/hw/cxgb4/cm.c:	ep->rcv_seq = be32_to_cpu(req->rcv_isn);
drivers/infiniband/hw/cxgb4/cm.c:	status = ABORT_RSS_STATUS_G(be32_to_cpu(req->srqidx_status));
drivers/infiniband/hw/cxgb4/cm.c:					be32_to_cpu(req->srqidx_status));
drivers/infiniband/hw/cxgb4/cm.c:	int atid = be32_to_cpu(req->tid);
drivers/infiniband/hw/cxgb4/cm.c:					   (__force u32) req->tid);
drivers/infiniband/hw/cxgb4/cm.c:	switch (req->retval) {
drivers/infiniband/hw/cxgb4/cm.c:		       __func__, req->retval);
drivers/infiniband/hw/cxgb4/cm.c:	       req->retval, atid);
drivers/infiniband/hw/cxgb4/cm.c:	connect_reply_upcall(ep, status2errno(req->retval));
drivers/infiniband/hw/cxgb4/cm.c:	rpl_skb = (struct sk_buff *)(unsigned long)req->cookie;
drivers/infiniband/hw/cxgb4/cm.c:	if (req->retval) {
drivers/infiniband/hw/cxgb4/cm.c:		pr_err("%s passive open failure %d\n", __func__, req->retval);
drivers/infiniband/hw/cxgb4/cm.c:					(__force u32) req->tid)));
drivers/infiniband/hw/cxgb4/cm.c:		switch (req->t_state) {
drivers/infiniband/hw/cxgb4/cm.c:			       __func__, req->t_state);
drivers/infiniband/hw/cxgb4/cm.c:	req->l2info = cpu_to_be16(SYN_INTF_V(intf) |
drivers/infiniband/hw/cxgb4/cm.c:	req->hdr_len =
drivers/infiniband/hw/cxgb4/cm.c:		req->hdr_len |= cpu_to_be32(TCP_HDR_LEN_V(tcp_hdr_len) |
drivers/infiniband/hw/cxgb4/cm.c:		req->hdr_len |= cpu_to_be32(T6_TCP_HDR_LEN_V(tcp_hdr_len) |
drivers/infiniband/hw/cxgb4/cm.c:	req->vlan = vlantag;
drivers/infiniband/hw/cxgb4/cm.c:	req->len = len;
drivers/infiniband/hw/cxgb4/cm.c:	req->tos_stid = cpu_to_be32(PASS_OPEN_TID_V(stid) |
drivers/infiniband/hw/cxgb4/cm.c:	req->tcpopt.mss = htons(tmp_opt.mss_clamp);
drivers/infiniband/hw/cxgb4/cm.c:		req->tcpopt.wsf = tmp_opt.snd_wscale;
drivers/infiniband/hw/cxgb4/cm.c:	req->tcpopt.tstamp = tmp_opt.saw_tstamp;
drivers/infiniband/hw/cxgb4/cm.c:		req->tcpopt.sack = 1;
drivers/infiniband/hw/cxgb4/cm.c:	req->op_compl = htonl(WR_OP_V(FW_OFLD_CONNECTION_WR) | FW_WR_COMPL_F);
drivers/infiniband/hw/cxgb4/cm.c:	req->len16_pkd = htonl(FW_WR_LEN16_V(DIV_ROUND_UP(sizeof(*req), 16)));
drivers/infiniband/hw/cxgb4/cm.c:	req->le.version_cpl = htonl(FW_OFLD_CONNECTION_WR_CPL_F);
drivers/infiniband/hw/cxgb4/cm.c:	req->le.filter = (__force __be32) filter;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.lport = lport;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.pport = rport;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.u.ipv4.lip = laddr;
drivers/infiniband/hw/cxgb4/cm.c:	req->le.u.ipv4.pip = raddr;
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.rcv_nxt = htonl(rcv_isn + 1);
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.rcv_adv = htons(window);
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.t_state_to_astid =
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt2 = htonl(RSS_QUEUE_V(rss_qid));
drivers/infiniband/hw/cxgb4/cm.c:	req->tcb.opt0 = cpu_to_be64(MSS_IDX_V(0xF));
drivers/infiniband/hw/cxgb4/cm.c:	req->cookie = (uintptr_t)skb;
drivers/infiniband/hw/cxgb4/cm.c:	if (cxgb_is_neg_adv(req->status)) {
drivers/infiniband/hw/cxgb4/cm.c:			 ep->hwtid, req->status,
drivers/infiniband/hw/cxgb4/cm.c:			 neg_adv_str(req->status));
drivers/infiniband/hw/cxgb4/mem.c:	req->wr.wr_hi = cpu_to_be32(FW_WR_OP_V(FW_ULPTX_WR) |
drivers/infiniband/hw/cxgb4/mem.c:	req->wr.wr_lo = wr_waitp ? (__force __be64)(unsigned long)wr_waitp : 0L;
drivers/infiniband/hw/cxgb4/mem.c:	req->wr.wr_mid = cpu_to_be32(FW_WR_LEN16_V(DIV_ROUND_UP(wr_len, 16)));
drivers/infiniband/hw/cxgb4/mem.c:	req->cmd = cpu_to_be32(ULPTX_CMD_V(ULP_TX_MEM_WRITE) |
drivers/infiniband/hw/cxgb4/mem.c:	req->dlen = cpu_to_be32(ULP_MEMIO_DATA_LEN_V(len>>5));
drivers/infiniband/hw/cxgb4/mem.c:	req->len16 = cpu_to_be32(DIV_ROUND_UP(wr_len-sizeof(req->wr), 16));
drivers/infiniband/hw/cxgb4/mem.c:	req->lock_addr = cpu_to_be32(ULP_MEMIO_ADDR_V(addr));
drivers/infiniband/hw/cxgb4/mem.c:			req->wr.wr_hi = cpu_to_be32(FW_WR_OP_V(FW_ULPTX_WR) |
drivers/infiniband/hw/cxgb4/mem.c:			req->wr.wr_lo = (__force __be64)(unsigned long)wr_waitp;
drivers/infiniband/hw/cxgb4/mem.c:			req->wr.wr_hi = cpu_to_be32(FW_WR_OP_V(FW_ULPTX_WR));
drivers/infiniband/hw/cxgb4/mem.c:		req->wr.wr_mid = cpu_to_be32(
drivers/infiniband/hw/cxgb4/mem.c:		req->cmd = cmd;
drivers/infiniband/hw/cxgb4/mem.c:		req->dlen = cpu_to_be32(ULP_MEMIO_DATA_LEN_V(
drivers/infiniband/hw/cxgb4/mem.c:		req->len16 = cpu_to_be32(DIV_ROUND_UP(wr_len-sizeof(req->wr),
drivers/infiniband/hw/cxgb4/mem.c:		req->lock_addr = cpu_to_be32(ULP_MEMIO_ADDR_V(addr + i * 3));
drivers/infiniband/hw/bnxt_re/main.c:	rattr.dma_arr = creq->hwq.pbl[PBL_LVL_0].pg_map_arr;
drivers/infiniband/hw/bnxt_re/main.c:	rattr.pages = creq->hwq.pbl[creq->hwq.level].pg_count;
drivers/infiniband/hw/bnxt_re/main.c:	rc = bnxt_re_net_ring_alloc(rdev, &rattr, &creq->ring_id);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	opcode = req->opcode;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	if (req->cmd_size >= HWQ_FREE_SLOTS(hwq)) {
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	req->cookie = cpu_to_le16(cookie);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	size = req->cmd_size;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	 * req->cmd_size is modified here
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	crsqe->resp->cookie = req->cookie;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	crsqe->req_size = req->cmd_size;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	if (req->resp_size && sb) {
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		req->resp_addr = cpu_to_le64(sbuf->dma_addr);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		req->resp_size = (sbuf->size + BNXT_QPLIB_CMDQE_UNITS - 1) /
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		opcode = req->opcode;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		cookie = le16_to_cpu(req->cookie) & RCFW_MAX_COOKIE_VALUE;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		 * is always called with creq->lock held. Using
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	struct bnxt_qplib_hwq *hwq = &creq->hwq;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:			creq->stats.creq_qp_event_processed++;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:				creq->stats.creq_func_event_processed++;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		bnxt_qplib_ring_nq_db(&creq->creq_db.dbinfo,
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	hwq = &creq->hwq;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	tasklet_schedule(&creq->creq_tasklet);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	if (bnxt_qplib_alloc_init_hwq(&creq->hwq, &hwq_attr)) {
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	tasklet_disable(&creq->creq_tasklet);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	bnxt_qplib_ring_nq_db(&creq->creq_db.dbinfo, rcfw->res->cctx, false);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	synchronize_irq(creq->msix_vec);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		tasklet_kill(&creq->creq_tasklet);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	if (creq->requested) {
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		free_irq(creq->msix_vec, rcfw);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		creq->requested = false;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	iounmap(creq->creq_db.reg.bar_reg);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->creq_db.reg.bar_reg = NULL;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->aeq_handler = NULL;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->msix_vec = 0;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	if (creq->requested)
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->msix_vec = msix_vector;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		tasklet_setup(&creq->creq_tasklet, bnxt_qplib_service_creq);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:		tasklet_enable(&creq->creq_tasklet);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	rc = request_irq(creq->msix_vec, bnxt_qplib_creq_irq, 0,
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->requested = true;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	bnxt_qplib_ring_nq_db(&creq->creq_db.dbinfo, rcfw->res->cctx, true);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	init.creq_ring_id = cpu_to_le16(creq->ring_id);
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->stats.creq_qp_event_processed = 0;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->stats.creq_func_event_processed = 0;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.c:	creq->aeq_handler = aeq_handler;
drivers/infiniband/hw/bnxt_re/qplib_rcfw.h:	req->cmd_size = (req->cmd_size + BNXT_QPLIB_CMDQE_UNITS - 1) /
drivers/infiniband/hw/i40iw/i40iw_verbs.c:	total = req->sq_pages + req->rq_pages + req->cq_pages;
drivers/infiniband/hw/i40iw/i40iw_verbs.c:			ret = i40iw_check_mem_contiguous(arr, req->sq_pages, pg_size);
drivers/infiniband/hw/i40iw/i40iw_verbs.c:				ret = i40iw_check_mem_contiguous(&arr[req->sq_pages], req->rq_pages, pg_size);
drivers/infiniband/hw/i40iw/i40iw_verbs.c:			hmc_p->idx = palloc->level1.idx + req->sq_pages;
drivers/infiniband/hw/i40iw/i40iw_verbs.c:			hmc_p->addr = arr[req->sq_pages];
drivers/infiniband/hw/i40iw/i40iw_verbs.c:			ret = i40iw_check_mem_contiguous(arr, req->cq_pages, pg_size);
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	struct i40iw_virtchnl_op_buf *vchnl_msg = vchnl_req->vchnl_msg;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	struct i40iw_virtchnl_op_buf *vchnl_msg = vchnl_req->vchnl_msg;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	struct i40iw_virtchnl_op_buf *vchnl_msg = vchnl_req->vchnl_msg;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	struct i40iw_virtchnl_op_buf *vchnl_msg = vchnl_req->vchnl_msg;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	struct i40iw_virtchnl_op_buf *vchnl_msg = vchnl_req->vchnl_msg;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	vchnl_req->ret_code = (enum i40iw_status_code)vchnl_msg_resp->iw_op_ret_code;
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:	if (len == (sizeof(*vchnl_msg_resp) + vchnl_req->parm_len - 1)) {
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:		if (vchnl_req->parm_len && vchnl_req->parm)
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:			memcpy(vchnl_req->parm, vchnl_msg_resp->iw_chnl_buf, vchnl_req->parm_len);
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:			    vchnl_req->parm_len);
drivers/infiniband/hw/i40iw/i40iw_virtchnl.c:			    len, (u32)(sizeof(*vchnl_msg_resp) + vchnl_req->parm_len - 1));
drivers/infiniband/hw/mlx5/main.c:	int ref_bfregs = req->total_num_bfregs;
drivers/infiniband/hw/mlx5/main.c:	if (req->total_num_bfregs == 0)
drivers/infiniband/hw/mlx5/main.c:	if (req->total_num_bfregs > MLX5_MAX_BFREGS)
drivers/infiniband/hw/mlx5/main.c:	req->total_num_bfregs = ALIGN(req->total_num_bfregs, bfregs_per_sys_page);
drivers/infiniband/hw/mlx5/main.c:	if (req->num_low_latency_bfregs > req->total_num_bfregs - 1)
drivers/infiniband/hw/mlx5/main.c:	bfregi->num_static_sys_pages = req->total_num_bfregs / bfregs_per_sys_page;
drivers/infiniband/hw/mlx5/main.c:	bfregi->total_num_bfregs = req->total_num_bfregs + bfregi->num_dyn_bfregs;
drivers/infiniband/hw/mlx5/main.c:		    req->total_num_bfregs, bfregi->total_num_bfregs,
drivers/infiniband/hw/mlx5/main.c:	/* updates req->total_num_bfregs */
drivers/infiniband/ulp/isert/ib_isert.c:		login->leading_connection = (!login_req->tsih) ? 1 : 0;
drivers/infiniband/ulp/isert/ib_isert.c:			(login_req->flags & ISCSI_FLAG_LOGIN_CURRENT_STAGE_MASK)
drivers/infiniband/ulp/isert/ib_isert.c:		login->version_min	= login_req->min_version;
drivers/infiniband/ulp/isert/ib_isert.c:		login->version_max	= login_req->max_version;
drivers/infiniband/ulp/isert/ib_isert.c:		memcpy(login->isid, login_req->isid, 6);
drivers/infiniband/ulp/isert/ib_isert.c:		login->cmd_sn		= be32_to_cpu(login_req->cmdsn);
drivers/infiniband/ulp/isert/ib_isert.c:		login->init_task_tag	= login_req->itt;
drivers/infiniband/ulp/isert/ib_isert.c:		login->initial_exp_statsn = be32_to_cpu(login_req->exp_statsn);
drivers/infiniband/ulp/isert/ib_isert.c:		login->cid		= be16_to_cpu(login_req->cid);
drivers/infiniband/ulp/isert/ib_isert.c:		login->tsih		= be16_to_cpu(login_req->tsih);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->need_inv = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (likely(req->need_inv_comp))
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		complete(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		complete_rdma_req(req, req->inv_errno, true, false);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	struct rtrs_clt_con *con = req->con;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		.wr_cqe		    = &req->inv_cqe,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		.ex.invalidate_rkey = req->mr->rkey,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->inv_cqe.done = rtrs_clt_inv_rkey_done;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	struct rtrs_clt_con *con = req->con;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (WARN_ON(!req->in_use))
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (WARN_ON(!req->con))
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (req->sg_cnt) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (unlikely(req->dir == DMA_FROM_DEVICE && req->need_inv)) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				req->need_inv_comp = true;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				req->inv_errno = errno;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:					  req->mr->rkey, err);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				wait_for_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		ib_dma_unmap_sg(sess->s.dev->ib_dev, req->sglist,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				req->sg_cnt, req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->in_use = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->con = NULL;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->conf(req->priv, errno);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (unlikely(!req->sg_size)) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	sge.addr   = req->iu->dma_addr;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	sge.length = req->sg_size;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	ib_dma_sync_single_for_device(sess->s.dev->ib_dev, req->iu->dma_addr,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				      req->sg_size, DMA_TO_DEVICE);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	return rtrs_iu_post_rdma_write_imm(&con->c, req->iu, &sge, 1,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->need_inv &= !w_inval;
drivers/infiniband/ulp/rtrs/rtrs-clt.c: * the corresponding buffer of rtrs_iu (req->iu->buf), which later on will
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->permit = permit;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->in_use = true;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->usr_len = usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->data_len = data_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sglist = sg;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sg_cnt = sg_cnt;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->priv = priv;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->dir = dir;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->con = rtrs_permit_to_clt_con(sess, permit);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->conf = conf;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->need_inv = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->need_inv_comp = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->inv_errno = 0;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	len = _copy_from_iter(req->iu->buf, usr_len, &iter);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	reinit_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		.iov_base = fail_req->iu->buf,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		.iov_len  = fail_req->usr_len
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req = &alive_sess->reqs[fail_req->permit->mem_id];
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	rtrs_clt_init_req(req, alive_sess, fail_req->conf, fail_req->permit,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			   fail_req->priv, &vec, fail_req->usr_len,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			   fail_req->sglist, fail_req->sg_cnt,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			   fail_req->data_len, fail_req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	struct ib_sge *sge = req->sge;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	for_each_sg(req->sglist, sg, req->sg_cnt, i) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	sge[i].addr   = req->iu->dma_addr;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	num_sge = 1 + req->sg_cnt;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	ib_dma_sync_single_for_device(sess->s.dev->ib_dev, req->iu->dma_addr,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	return rtrs_iu_post_rdma_write_imm(&con->c, req->iu, sge, num_sge,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	struct rtrs_clt_con *con = req->con;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	const size_t tsize = sizeof(*msg) + req->data_len + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (req->sg_cnt) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		count = ib_dma_map_sg(sess->s.dev->ib_dev, req->sglist,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				      req->sg_cnt, req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	msg = req->iu->buf + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	msg->usr_len = cpu_to_le16(req->usr_len);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	imm = req->permit->mem_off + req->data_len + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	buf_id = req->permit->mem_id;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sg_size = tsize;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	ret = rtrs_post_rdma_write_sg(req->con, req, rbuf,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				       req->usr_len + sizeof(*msg),
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (req->sg_cnt)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			ib_dma_unmap_sg(sess->s.dev->ib_dev, req->sglist,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:					req->sg_cnt, req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	nr = ib_map_mr_sg(req->mr, req->sglist, count, NULL, SZ_4K);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (unlikely(nr < req->sg_cnt))
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	ib_update_fast_reg_key(req->mr, ib_inc_rkey(req->mr->rkey));
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	struct rtrs_clt_con *con = req->con;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	const size_t tsize = sizeof(*msg) + req->data_len + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	if (req->sg_cnt) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		count = ib_dma_map_sg(dev->ib_dev, req->sglist, req->sg_cnt,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				      req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	/* put our message into req->buf after user message*/
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	msg = req->iu->buf + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	msg->usr_len = cpu_to_le16(req->usr_len);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			ib_dma_unmap_sg(dev->ib_dev, req->sglist, req->sg_cnt,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:					req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			.mr = req->mr,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			.key = req->mr->rkey,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		msg->desc[0].addr = cpu_to_le64(req->mr->iova);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		msg->desc[0].key = cpu_to_le32(req->mr->rkey);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		msg->desc[0].len = cpu_to_le32(req->mr->length);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->need_inv = !!RTRS_MSG_NEED_INVAL_F;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	imm = req->permit->mem_off + req->data_len + req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	buf_id = req->permit->mem_id;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sg_size  = sizeof(*msg);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sg_size += le16_to_cpu(msg->sg_cnt) * sizeof(struct rtrs_sg_desc);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	req->sg_size += req->usr_len;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:	ret = rtrs_post_send_rdma(req->con, req, &sess->rbufs[buf_id],
drivers/infiniband/ulp/rtrs/rtrs-clt.c:				   req->data_len, imm, wr);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->need_inv = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (req->sg_cnt)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			ib_dma_unmap_sg(dev->ib_dev, req->sglist,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:					req->sg_cnt, req->dir);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (req->dir == DMA_TO_DEVICE)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			req->in_use = false;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (!req->in_use)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			req->conf(req->priv, err);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (req->mr)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			ib_dereg_mr(req->mr);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		kfree(req->sge);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		rtrs_iu_free(req->iu, sess->s.dev->ib_dev, 1);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->iu = rtrs_iu_alloc(1, sess->max_hdr_size, GFP_KERNEL,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (!req->iu)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->sge = kmalloc_array(clt->max_segments + 1,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:					 sizeof(*req->sge), GFP_KERNEL);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (!req->sge)
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		req->mr = ib_alloc_mr(sess->s.dev->ib_pd, IB_MR_TYPE_MEM_REG,
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		if (IS_ERR(req->mr)) {
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			err = PTR_ERR(req->mr);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			req->mr = NULL;
drivers/infiniband/ulp/rtrs/rtrs-clt.c:		init_completion(&req->inv_comp);
drivers/infiniband/ulp/rtrs/rtrs-clt.c:			req->in_use = false;
drivers/infiniband/ulp/rtrs/rtrs-srv.c:	usr_len = le16_to_cpu(req->usr_len);
drivers/infiniband/ulp/rtrs/rtrs-clt-stats.c:	struct rtrs_clt_con *con = req->con;
drivers/infiniband/ulp/rtrs/rtrs-clt-stats.c:	len = req->usr_len + req->data_len;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_param.flow_control = 1;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_param.retry_count = target->tl_retry_count;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_param.responder_resources = 4;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_param.rnr_retry_count = 7;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_param.max_cm_retries = 15;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_req.opcode = SRP_LOGIN_REQ;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_req.tag = 0;
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_req.req_it_iu_len = cpu_to_be32(max_iu_len);
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_req.req_buf_fmt	= cpu_to_be16(SRP_BUF_FORMAT_DIRECT |
drivers/infiniband/ulp/srp/ib_srp.c:	req->ib_req.req_flags = (multich ? SRP_MULTICHAN_MULTI :
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_req.req_flags |= SRP_IMMED_REQUESTED;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_req.imm_data_offset = cpu_to_be16(SRP_IMM_DATA_OFFSET);
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.flow_control = req->ib_param.flow_control;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.responder_resources =
drivers/infiniband/ulp/srp/ib_srp.c:			req->ib_param.responder_resources;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.initiator_depth = req->ib_param.initiator_depth;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.retry_count = req->ib_param.retry_count;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.rnr_retry_count = req->ib_param.rnr_retry_count;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.private_data = &req->rdma_req;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_param.private_data_len = sizeof(req->rdma_req);
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.opcode = req->ib_req.opcode;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.tag = req->ib_req.tag;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.req_it_iu_len = req->ib_req.req_it_iu_len;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.req_buf_fmt = req->ib_req.req_buf_fmt;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.req_flags	= req->ib_req.req_flags;
drivers/infiniband/ulp/srp/ib_srp.c:		req->rdma_req.imm_data_offset = req->ib_req.imm_data_offset;
drivers/infiniband/ulp/srp/ib_srp.c:		ipi = req->rdma_req.initiator_port_id;
drivers/infiniband/ulp/srp/ib_srp.c:		tpi = req->rdma_req.target_port_id;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.primary_path = &ch->ib_cm.path;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.alternate_path = NULL;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.service_id = target->ib_cm.service_id;
drivers/infiniband/ulp/srp/ib_srp.c:		get_random_bytes(&req->ib_param.starting_psn, 4);
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.starting_psn &= 0xffffff;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.qp_num = ch->qp->qp_num;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.qp_type = ch->qp->qp_type;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.local_cm_response_timeout = subnet_timeout + 2;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.remote_cm_response_timeout = subnet_timeout + 2;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.private_data = &req->ib_req;
drivers/infiniband/ulp/srp/ib_srp.c:		req->ib_param.private_data_len = sizeof(req->ib_req);
drivers/infiniband/ulp/srp/ib_srp.c:		ipi = req->ib_req.initiator_port_id;
drivers/infiniband/ulp/srp/ib_srp.c:		tpi = req->ib_req.target_port_id;
drivers/infiniband/ulp/srp/ib_srp.c:		status = rdma_connect(ch->rdma_cm.cm_id, &req->rdma_param);
drivers/infiniband/ulp/srp/ib_srp.c:		status = ib_send_cm_req(ch->ib_cm.cm_id, &req->ib_param);
drivers/infiniband/ulp/srp/ib_srp.c:			kfree(req->fr_list);
drivers/infiniband/ulp/srp/ib_srp.c:		if (req->indirect_dma_addr) {
drivers/infiniband/ulp/srp/ib_srp.c:			ib_dma_unmap_single(ibdev, req->indirect_dma_addr,
drivers/infiniband/ulp/srp/ib_srp.c:		kfree(req->indirect_desc);
drivers/infiniband/ulp/srp/ib_srp.c:			req->fr_list = mr_list;
drivers/infiniband/ulp/srp/ib_srp.c:		req->indirect_desc = kmalloc(target->indirect_size, GFP_KERNEL);
drivers/infiniband/ulp/srp/ib_srp.c:		if (!req->indirect_desc)
drivers/infiniband/ulp/srp/ib_srp.c:		dma_addr = ib_dma_map_single(ibdev, req->indirect_desc,
drivers/infiniband/ulp/srp/ib_srp.c:		req->indirect_dma_addr = dma_addr;
drivers/infiniband/ulp/srp/ib_srp.c:	wr.wr_cqe = &req->reg_cqe;
drivers/infiniband/ulp/srp/ib_srp.c:	req->reg_cqe.done = srp_inv_rkey_err_done;
drivers/infiniband/ulp/srp/ib_srp.c:		for (i = req->nmdesc, pfr = req->fr_list; i > 0; i--, pfr++) {
drivers/infiniband/ulp/srp/ib_srp.c:		if (req->nmdesc)
drivers/infiniband/ulp/srp/ib_srp.c:			srp_fr_pool_put(ch->fr_pool, req->fr_list,
drivers/infiniband/ulp/srp/ib_srp.c:					req->nmdesc);
drivers/infiniband/ulp/srp/ib_srp.c: * @scmnd: If NULL, take ownership of @req->scmnd. If not NULL, only take
drivers/infiniband/ulp/srp/ib_srp.c: *         ownership of @req->scmnd if it equals @scmnd.
drivers/infiniband/ulp/srp/ib_srp.c:	if (req->scmnd &&
drivers/infiniband/ulp/srp/ib_srp.c:	    (!sdev || req->scmnd->device == sdev) &&
drivers/infiniband/ulp/srp/ib_srp.c:	    (!scmnd || req->scmnd == scmnd)) {
drivers/infiniband/ulp/srp/ib_srp.c:		scmnd = req->scmnd;
drivers/infiniband/ulp/srp/ib_srp.c:		req->scmnd = NULL;
drivers/infiniband/ulp/srp/ib_srp.c:			 dev_name(&req->scmnd->device->sdev_gendev), sg_nents,
drivers/infiniband/ulp/srp/ib_srp.c:	req->reg_cqe.done = srp_reg_mr_err_done;
drivers/infiniband/ulp/srp/ib_srp.c:	wr.wr.wr_cqe = &req->reg_cqe;
drivers/infiniband/ulp/srp/ib_srp.c:	state->fr.next = req->fr_list;
drivers/infiniband/ulp/srp/ib_srp.c:	state->fr.end = req->fr_list + ch->target->mr_per_cmd;
drivers/infiniband/ulp/srp/ib_srp.c:	state.base_dma_addr = req->indirect_dma_addr;
drivers/infiniband/ulp/srp/ib_srp.c:		sg_init_one(idb_sg, req->indirect_desc, idb_len);
drivers/infiniband/ulp/srp/ib_srp.c:		idb_sg->dma_address = req->indirect_dma_addr; /* hack! */
drivers/infiniband/ulp/srp/ib_srp.c:		desc_len += be32_to_cpu(req->indirect_desc[i].len);
drivers/infiniband/ulp/srp/ib_srp.c:		for (i = 0, pfr = req->fr_list; i < state->nmdesc; i++, pfr++)
drivers/infiniband/ulp/srp/ib_srp.c:	if (desc_len != scsi_bufflen(req->scmnd) ||
drivers/infiniband/ulp/srp/ib_srp.c:	    mr_len > scsi_bufflen(req->scmnd))
drivers/infiniband/ulp/srp/ib_srp.c:		       scsi_bufflen(req->scmnd), desc_len, mr_len,
drivers/infiniband/ulp/srp/ib_srp.c:	struct srp_cmd *cmd = req->cmd->buf;
drivers/infiniband/ulp/srp/ib_srp.c:	req->cmd->num_sge = 1;
drivers/infiniband/ulp/srp/ib_srp.c:		struct ib_sge *sge = &req->cmd->sge[1];
drivers/infiniband/ulp/srp/ib_srp.c:		req->nmdesc = 0;
drivers/infiniband/ulp/srp/ib_srp.c:		req->cmd->num_sge += count;
drivers/infiniband/ulp/srp/ib_srp.c:		req->nmdesc = 0;
drivers/infiniband/ulp/srp/ib_srp.c:	ib_dma_sync_single_for_cpu(ibdev, req->indirect_dma_addr,
drivers/infiniband/ulp/srp/ib_srp.c:	state.desc = req->indirect_desc;
drivers/infiniband/ulp/srp/ib_srp.c:	req->nmdesc = state.nmdesc;
drivers/infiniband/ulp/srp/ib_srp.c:		*buf = req->indirect_desc[0];
drivers/infiniband/ulp/srp/ib_srp.c:	memcpy(indirect_hdr->desc_list, req->indirect_desc,
drivers/infiniband/ulp/srp/ib_srp.c:		req->nmdesc++;
drivers/infiniband/ulp/srp/ib_srp.c:	indirect_hdr->table_desc.va = cpu_to_be64(req->indirect_dma_addr);
drivers/infiniband/ulp/srp/ib_srp.c:	ib_dma_sync_single_for_device(ibdev, req->indirect_dma_addr, table_len,
drivers/infiniband/ulp/srp/ib_srp.c:	if (ret == -ENOMEM && req->nmdesc >= target->mr_pool_size)
drivers/infiniband/ulp/srp/ib_srp.c:		.tag = req->tag,
drivers/infiniband/ulp/srp/ib_srp.c:	s32 delta = be32_to_cpu(req->req_lim_delta);
drivers/infiniband/ulp/srp/ib_srp.c:		.tag = req->tag,
drivers/infiniband/ulp/srp/ib_srp.c:	s32 delta = be32_to_cpu(req->req_lim_delta);
drivers/infiniband/ulp/srp/ib_srp.c:		     "ignoring AER for LUN %llu\n", scsilun_to_int(&req->lun));
drivers/infiniband/ulp/srp/ib_srp.c:	req->scmnd    = scmnd;
drivers/infiniband/ulp/srp/ib_srp.c:	req->cmd      = iu;
drivers/infiniband/ulp/srp/ib_srp.c:	req->scmnd = NULL;
drivers/infiniband/ulp/srpt/ib_srpt.c:		send_ioctx->cmd.se_tmr_req->response = TMR_FUNCTION_REJECTED;
drivers/infiniband/ulp/srpt/ib_srpt.c:	it_iu_len = be32_to_cpu(req->req_it_iu_len);
drivers/infiniband/ulp/srpt/ib_srpt.c:		req->initiator_port_id, req->target_port_id, it_iu_len,
drivers/infiniband/ulp/srpt/ib_srpt.c:	nexus = srpt_get_nexus(sport, req->initiator_port_id,
drivers/infiniband/ulp/srpt/ib_srpt.c:			       req->target_port_id);
drivers/infiniband/ulp/srpt/ib_srpt.c:	if (*(__be64 *)req->target_port_id != cpu_to_be64(srpt_service_guid)
drivers/infiniband/ulp/srpt/ib_srpt.c:	    || *(__be64 *)(req->target_port_id + 8) !=
drivers/infiniband/ulp/srpt/ib_srpt.c:		u16 imm_data_offset = req->req_flags & SRP_IMMED_REQUESTED ?
drivers/infiniband/ulp/srpt/ib_srpt.c:			be16_to_cpu(req->imm_data_offset) : 0;
drivers/infiniband/ulp/srpt/ib_srpt.c:		if (req->req_flags & SRP_IMMED_REQUESTED)
drivers/infiniband/ulp/srpt/ib_srpt.c:				 be16_to_cpu(req->imm_data_offset));
drivers/infiniband/ulp/srpt/ib_srpt.c:		ch->req_buf_cache = kmem_cache_create("srpt-req-buf", req_sz,
drivers/infiniband/ulp/srpt/ib_srpt.c:	if ((req->req_flags & SRP_MTCH_ACTION) == SRP_MULTICHAN_SINGLE) {
drivers/infiniband/ulp/srpt/ib_srpt.c:	rsp->tag = req->tag;
drivers/infiniband/ulp/srpt/ib_srpt.c:	rsp->max_ti_iu_len = req->req_it_iu_len;
drivers/infiniband/ulp/srpt/ib_srpt.c:	rej->tag = req->tag;
drivers/infiniband/ulp/srpt/ib_srpt.c:			= tcm_to_srp_tsk_mgmt_status(cmd->se_tmr_req->response);
drivers/infiniband/ulp/srpt/ib_srpt.c:	sdev->req_buf_cache = kmem_cache_create("srpt-srq-req-buf",
drivers/infiniband/ulp/ipoib/ipoib.h:	struct sk_buff *skb = tx_req->skb;
drivers/infiniband/ulp/ipoib/ipoib.h:	u64 *mapping = tx_req->mapping;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	struct sk_buff *skb = tx_req->skb;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	u64 *mapping = tx_req->mapping;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	struct sk_buff *skb = tx_req->skb;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	u64 *mapping = tx_req->mapping;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	dev->stats.tx_bytes += tx_req->skb->len;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	dev_kfree_skb_any(tx_req->skb);
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	struct sk_buff *skb = tx_req->skb;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:	tx_req->skb = skb;
drivers/infiniband/ulp/ipoib/ipoib_ib.c:				dev_kfree_skb_any(tx_req->skb);
drivers/infiniband/ulp/ipoib/ipoib_ib.c:				if (!rx_req->skb)
drivers/infiniband/ulp/ipoib/ipoib_ib.c:				dev_kfree_skb_any(rx_req->skb);
drivers/infiniband/ulp/ipoib/ipoib_ib.c:				rx_req->skb = NULL;
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	rep.rnr_retry_count = req->rnr_retry_count;
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	tx_req->skb = skb;
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	dev->stats.tx_bytes += tx_req->skb->len;
drivers/infiniband/ulp/ipoib/ipoib_cm.c:	dev_kfree_skb_any(tx_req->skb);
drivers/infiniband/ulp/ipoib/ipoib_cm.c:		dev_kfree_skb_any(tx_req->skb);
drivers/infiniband/ulp/iser/iser_initiator.c:	iser_dbg("req op %x flags %x\n", req->opcode, req->flags);
drivers/infiniband/ulp/iser/iser_initiator.c:	if ((req->flags & ISCSI_FULL_FEATURE_PHASE) != ISCSI_FULL_FEATURE_PHASE)
drivers/infiniband/core/mad.c:		if (!memcmp(vendor_class->oui[i], mad_reg_req->oui, 3)) {
drivers/infiniband/core/mad.c:		if (mad_reg_req->mgmt_class_version >= MAX_MGMT_VERSION) {
drivers/infiniband/core/mad.c:					    mad_reg_req->mgmt_class_version);
drivers/infiniband/core/mad.c:		if (mad_reg_req->mgmt_class >= MAX_MGMT_CLASS) {
drivers/infiniband/core/mad.c:			if (mad_reg_req->mgmt_class !=
drivers/infiniband/core/mad.c:					__func__, mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:		} else if (mad_reg_req->mgmt_class == 0) {
drivers/infiniband/core/mad.c:		} else if (is_vendor_class(mad_reg_req->mgmt_class)) {
drivers/infiniband/core/mad.c:			if (!is_vendor_oui(mad_reg_req->oui)) {
drivers/infiniband/core/mad.c:					mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:		if (!ib_is_mad_class_rmpp(mad_reg_req->mgmt_class)) {
drivers/infiniband/core/mad.c:					__func__, mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:			if ((mad_reg_req->mgmt_class !=
drivers/infiniband/core/mad.c:			    (mad_reg_req->mgmt_class !=
drivers/infiniband/core/mad.c:					__func__, mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:			if ((mad_reg_req->mgmt_class ==
drivers/infiniband/core/mad.c:			    (mad_reg_req->mgmt_class ==
drivers/infiniband/core/mad.c:					__func__, mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:		mgmt_class = convert_mgmt_class(mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:			class = port_priv->version[mad_reg_req->
drivers/infiniband/core/mad.c:			vendor = port_priv->version[mad_reg_req->
drivers/infiniband/core/mad.c:	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS) {
drivers/infiniband/core/mad.c:	class = &port_priv->version[mad_reg_req->mgmt_class_version].class;
drivers/infiniband/core/mad.c:	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS)
drivers/infiniband/core/mad.c:	vclass = vendor_class_index(mad_reg_req->mgmt_class);
drivers/infiniband/core/mad.c:				mad_reg_req->mgmt_class_version].vendor;
drivers/infiniband/core/mad.c:			    mad_reg_req->oui, 3)) {
drivers/infiniband/core/mad.c:			       mad_reg_req->oui, 3);
drivers/infiniband/core/mad.c:	for_each_set_bit(i, mad_reg_req->method_mask, IB_MGMT_MAX_METHODS)
drivers/infiniband/core/mad.c:	mgmt_class = convert_mgmt_class(agent_priv->reg_req->mgmt_class);
drivers/infiniband/core/mad.c:			agent_priv->reg_req->mgmt_class_version].class;
drivers/infiniband/core/mad.c:					agent_priv->reg_req->
drivers/infiniband/core/mad.c:	mgmt_class = vendor_class_index(agent_priv->reg_req->mgmt_class);
drivers/infiniband/core/mad.c:			agent_priv->reg_req->mgmt_class_version].vendor;
drivers/infiniband/core/mad.c:		index = find_vendor_oui(vendor_class, agent_priv->reg_req->oui);
drivers/infiniband/core/mad.c:							agent_priv->reg_req->
drivers/infiniband/core/cma.c:	if (rdma_protocol_roce(req->device, req->port))
drivers/infiniband/core/cma.c:	gid_type = listen_id_priv->cma_dev->default_gid_type[req->port - 1];
drivers/infiniband/core/cma.c:	sgid_attr = cma_validate_port(req->device, req->port,
drivers/infiniband/core/cma.c:	id_priv->id.port_num = req->port;
drivers/infiniband/core/cma.c:		req->device	= req_param->listen_id->device;
drivers/infiniband/core/cma.c:		req->port	= req_param->port;
drivers/infiniband/core/cma.c:		memcpy(&req->local_gid, &req_param->primary_path->sgid,
drivers/infiniband/core/cma.c:		       sizeof(req->local_gid));
drivers/infiniband/core/cma.c:		req->has_gid	= true;
drivers/infiniband/core/cma.c:		req->service_id = req_param->primary_path->service_id;
drivers/infiniband/core/cma.c:		req->pkey	= be16_to_cpu(req_param->primary_path->pkey);
drivers/infiniband/core/cma.c:		if (req->pkey != req_param->bth_pkey)
drivers/infiniband/core/cma.c:					    req_param->bth_pkey, req->pkey);
drivers/infiniband/core/cma.c:		req->device	= sidr_param->listen_id->device;
drivers/infiniband/core/cma.c:		req->port	= sidr_param->port;
drivers/infiniband/core/cma.c:		req->has_gid	= false;
drivers/infiniband/core/cma.c:		req->service_id	= sidr_param->service_id;
drivers/infiniband/core/cma.c:		req->pkey	= sidr_param->pkey;
drivers/infiniband/core/cma.c:		if (req->pkey != sidr_param->bth_pkey)
drivers/infiniband/core/cma.c:					    sidr_param->bth_pkey, req->pkey);
drivers/infiniband/core/cma.c:			(struct sockaddr *)&req->listen_addr_storage;
drivers/infiniband/core/cma.c:	struct sockaddr *src_addr = (struct sockaddr *)&req->src_addr_storage;
drivers/infiniband/core/cma.c:	const union ib_gid *gid = req->has_gid ? &req->local_gid : NULL;
drivers/infiniband/core/cma.c:			       req->service_id);
drivers/infiniband/core/cma.c:	if (rdma_protocol_roce(req->device, req->port))
drivers/infiniband/core/cma.c:		net_dev = ib_get_net_dev_by_params(req->device, req->port,
drivers/infiniband/core/cma.c:						   req->pkey,
drivers/infiniband/core/cma.c:			(const struct sockaddr *)&req->listen_addr_storage;
drivers/infiniband/core/cma.c:		return (!id->port_num || id->port_num == req->port) &&
drivers/infiniband/core/cma.c:				 (struct sockaddr *)&req->listen_addr_storage,
drivers/infiniband/core/cma.c:				 (struct sockaddr *)&req->src_addr_storage)) {
drivers/infiniband/core/cma.c:				rdma_ps_from_service_id(req->service_id),
drivers/infiniband/core/cma.c:				cma_port_from_service_id(req->service_id));
drivers/infiniband/core/addr.c:		if (nlh->nlmsg_seq != req->seq)
drivers/infiniband/core/addr.c:		rdma_addr_set_dgid(req->addr, &gid);
drivers/infiniband/core/addr.c:		req->status = 0;
drivers/infiniband/core/addr.c:	mod_delayed_work(addr_wq, &req->work, delay);
drivers/infiniband/core/addr.c:	list_add_tail(&req->list, &req_list);
drivers/infiniband/core/addr.c:	set_timeout(req, req->timeout);
drivers/infiniband/core/addr.c:	if (req->status == -ENODATA) {
drivers/infiniband/core/addr.c:		src_in = (struct sockaddr *)&req->src_addr;
drivers/infiniband/core/addr.c:		dst_in = (struct sockaddr *)&req->dst_addr;
drivers/infiniband/core/addr.c:		req->status = addr_resolve(src_in, dst_in, req->addr,
drivers/infiniband/core/addr.c:					   true, req->resolve_by_gid_attr,
drivers/infiniband/core/addr.c:					   req->seq);
drivers/infiniband/core/addr.c:		if (req->status && time_after_eq(jiffies, req->timeout)) {
drivers/infiniband/core/addr.c:			req->status = -ETIMEDOUT;
drivers/infiniband/core/addr.c:		} else if (req->status == -ENODATA) {
drivers/infiniband/core/addr.c:			if (!list_empty(&req->list))
drivers/infiniband/core/addr.c:				set_timeout(req, req->timeout);
drivers/infiniband/core/addr.c:	req->callback(req->status, (struct sockaddr *)&req->src_addr,
drivers/infiniband/core/addr.c:		req->addr, req->context);
drivers/infiniband/core/addr.c:	req->callback = NULL;
drivers/infiniband/core/addr.c:	cancel_delayed_work(&req->work);
drivers/infiniband/core/addr.c:	if (!list_empty(&req->list)) {
drivers/infiniband/core/addr.c:		list_del_init(&req->list);
drivers/infiniband/core/addr.c:	src_in = (struct sockaddr *) &req->src_addr;
drivers/infiniband/core/addr.c:	dst_in = (struct sockaddr *) &req->dst_addr;
drivers/infiniband/core/addr.c:	req->addr = addr;
drivers/infiniband/core/addr.c:	req->callback = callback;
drivers/infiniband/core/addr.c:	req->context = context;
drivers/infiniband/core/addr.c:	req->resolve_by_gid_attr = resolve_by_gid_attr;
drivers/infiniband/core/addr.c:	INIT_DELAYED_WORK(&req->work, process_one_req);
drivers/infiniband/core/addr.c:	req->seq = (u32)atomic_inc_return(&ib_nl_addr_request_seq);
drivers/infiniband/core/addr.c:	req->status = addr_resolve(src_in, dst_in, addr, true,
drivers/infiniband/core/addr.c:				   req->resolve_by_gid_attr, req->seq);
drivers/infiniband/core/addr.c:	switch (req->status) {
drivers/infiniband/core/addr.c:		req->timeout = jiffies;
drivers/infiniband/core/addr.c:		req->timeout = msecs_to_jiffies(timeout_ms) + jiffies;
drivers/infiniband/core/addr.c:		ret = req->status;
drivers/infiniband/core/addr.c:		if (req->addr == addr) {
drivers/infiniband/core/addr.c:			list_del_init(&req->list);
drivers/soc/qcom/pdr_interface.c:		       req->service_name, ret);
drivers/soc/qcom/pdr_interface.c:		       req->service_name, resp->resp.error);
drivers/soc/qcom/rpmh.c:	req->addr = cmd->addr;
drivers/soc/qcom/rpmh.c:	req->sleep_val = req->wake_val = UINT_MAX;
drivers/soc/qcom/rpmh.c:	list_add_tail(&req->list, &ctrlr->cache);
drivers/soc/qcom/rpmh.c:	old_sleep_val = req->sleep_val;
drivers/soc/qcom/rpmh.c:	old_wake_val = req->wake_val;
drivers/soc/qcom/rpmh.c:		req->wake_val = cmd->data;
drivers/soc/qcom/rpmh.c:		req->sleep_val = cmd->data;
drivers/soc/qcom/rpmh.c:	ctrlr->dirty |= (req->sleep_val != old_sleep_val ||
drivers/soc/qcom/rpmh.c:			 req->wake_val != old_wake_val) &&
drivers/soc/qcom/rpmh.c:			 req->sleep_val != UINT_MAX &&
drivers/soc/qcom/rpmh.c:			 req->wake_val != UINT_MAX;
drivers/soc/qcom/rpmh.c:	memcpy(req->cmd, cmd, n * sizeof(*cmd));
drivers/soc/qcom/rpmh.c:	req->msg.state = state;
drivers/soc/qcom/rpmh.c:	req->msg.cmds = req->cmd;
drivers/soc/qcom/rpmh.c:	req->msg.num_cmds = n;
drivers/soc/qcom/rpmh.c:	list_add_tail(&req->list, &ctrlr->batch_cache);
drivers/soc/qcom/rpmh.c:		for (i = 0; i < req->count; i++) {
drivers/soc/qcom/rpmh.c:			rpm_msg = req->rpm_msgs + i;
drivers/soc/qcom/rpmh.c:		      count * (sizeof(req->rpm_msgs[0]) + sizeof(*compls)),
drivers/soc/qcom/rpmh.c:	req->count = count;
drivers/soc/qcom/rpmh.c:	rpm_msgs = req->rpm_msgs;
drivers/soc/qcom/rpmh.c:	return (req->sleep_val != UINT_MAX &&
drivers/soc/qcom/rpmh.c:		req->wake_val != UINT_MAX &&
drivers/soc/qcom/rpmh.c:		req->sleep_val != req->wake_val);
drivers/soc/qcom/wcnss_ctrl.c:	req->hdr.type = WCNSS_DOWNLOAD_NV_REQ;
drivers/soc/qcom/wcnss_ctrl.c:	req->hdr.len = sizeof(*req) + NV_FRAGMENT_SIZE;
drivers/soc/qcom/wcnss_ctrl.c:	req->last = 0;
drivers/soc/qcom/wcnss_ctrl.c:	req->frag_size = NV_FRAGMENT_SIZE;
drivers/soc/qcom/wcnss_ctrl.c:	req->seq = 0;
drivers/soc/qcom/wcnss_ctrl.c:			req->last = 1;
drivers/soc/qcom/wcnss_ctrl.c:			req->frag_size = left;
drivers/soc/qcom/wcnss_ctrl.c:			req->hdr.len = sizeof(*req) + left;
drivers/soc/qcom/wcnss_ctrl.c:		memcpy(req->fragment, data, req->frag_size);
drivers/soc/qcom/wcnss_ctrl.c:		ret = rpmsg_send(wcnss->channel, req, req->hdr.len);
drivers/soc/qcom/wcnss_ctrl.c:		req->seq++;
drivers/soc/qcom/rpmh-rsc.c:		for (j = 0; j < req->num_cmds; j++) {
drivers/soc/qcom/rpmh-rsc.c:			cmd = &req->cmds[j];
drivers/soc/qcom/rpmh-rsc.c:			   ((req->wait_for_compl || cmd->wait) &&
drivers/soc/imx/soc-imx8m.c:		platform_device_register_simple("imx-cpufreq-dt", -1, NULL, 0);
drivers/soc/tegra/pmc.c:				"nvidia,core-power-req-active-high");
drivers/soc/tegra/pmc.c:				"nvidia,sys-clock-req-active-high");
drivers/firmware/ti_sci.c:	req->id = id;
drivers/firmware/ti_sci.c:	req->state = state;
drivers/firmware/ti_sci.c:	req->id = id;
drivers/firmware/ti_sci.c:	req->id = id;
drivers/firmware/ti_sci.c:	req->resets = reset_state;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->request_state = state;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:		req->parent_id = parent_id;
drivers/firmware/ti_sci.c:		req->parent_id = 255;
drivers/firmware/ti_sci.c:		req->parent_id_32 = parent_id;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->min_freq_hz = min_freq;
drivers/firmware/ti_sci.c:	req->target_freq_hz = target_freq;
drivers/firmware/ti_sci.c:	req->max_freq_hz = max_freq;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->min_freq_hz = min_freq;
drivers/firmware/ti_sci.c:	req->target_freq_hz = target_freq;
drivers/firmware/ti_sci.c:	req->max_freq_hz = max_freq;
drivers/firmware/ti_sci.c:	req->dev_id = dev_id;
drivers/firmware/ti_sci.c:		req->clk_id = clk_id;
drivers/firmware/ti_sci.c:		req->clk_id = 255;
drivers/firmware/ti_sci.c:		req->clk_id_32 = clk_id;
drivers/firmware/ti_sci.c:	req->secondary_host = s_host;
drivers/firmware/ti_sci.c:	req->type = dev_id & MSG_RM_RESOURCE_TYPE_MASK;
drivers/firmware/ti_sci.c:	req->subtype = subtype & MSG_RM_RESOURCE_SUBTYPE_MASK;
drivers/firmware/ti_sci.c:	req->valid_params = valid_params;
drivers/firmware/ti_sci.c:	req->src_id = src_id;
drivers/firmware/ti_sci.c:	req->src_index = src_index;
drivers/firmware/ti_sci.c:	req->dst_id = dst_id;
drivers/firmware/ti_sci.c:	req->dst_host_irq = dst_host_irq;
drivers/firmware/ti_sci.c:	req->ia_id = ia_id;
drivers/firmware/ti_sci.c:	req->vint = vint;
drivers/firmware/ti_sci.c:	req->global_event = global_event;
drivers/firmware/ti_sci.c:	req->vint_status_bit = vint_status_bit;
drivers/firmware/ti_sci.c:	req->secondary_host = s_host;
drivers/firmware/ti_sci.c:	req->valid_params = params->valid_params;
drivers/firmware/ti_sci.c:	req->nav_id = params->nav_id;
drivers/firmware/ti_sci.c:	req->index = params->index;
drivers/firmware/ti_sci.c:	req->addr_lo = params->addr_lo;
drivers/firmware/ti_sci.c:	req->addr_hi = params->addr_hi;
drivers/firmware/ti_sci.c:	req->count = params->count;
drivers/firmware/ti_sci.c:	req->mode = params->mode;
drivers/firmware/ti_sci.c:	req->size = params->size;
drivers/firmware/ti_sci.c:	req->order_id = params->order_id;
drivers/firmware/ti_sci.c:	req->virtid = params->virtid;
drivers/firmware/ti_sci.c:	req->asel = params->asel;
drivers/firmware/ti_sci.c:	req->nav_id = nav_id;
drivers/firmware/ti_sci.c:	req->src_thread = src_thread;
drivers/firmware/ti_sci.c:	req->dst_thread = dst_thread;
drivers/firmware/ti_sci.c:	req->nav_id = nav_id;
drivers/firmware/ti_sci.c:	req->src_thread = src_thread;
drivers/firmware/ti_sci.c:	req->dst_thread = dst_thread;
drivers/firmware/ti_sci.c:	req->valid_params = params->valid_params;
drivers/firmware/ti_sci.c:	req->nav_id = params->nav_id;
drivers/firmware/ti_sci.c:	req->index = params->index;
drivers/firmware/ti_sci.c:	req->tx_pause_on_err = params->tx_pause_on_err;
drivers/firmware/ti_sci.c:	req->tx_filt_einfo = params->tx_filt_einfo;
drivers/firmware/ti_sci.c:	req->tx_filt_pswords = params->tx_filt_pswords;
drivers/firmware/ti_sci.c:	req->tx_atype = params->tx_atype;
drivers/firmware/ti_sci.c:	req->tx_chan_type = params->tx_chan_type;
drivers/firmware/ti_sci.c:	req->tx_supr_tdpkt = params->tx_supr_tdpkt;
drivers/firmware/ti_sci.c:	req->tx_fetch_size = params->tx_fetch_size;
drivers/firmware/ti_sci.c:	req->tx_credit_count = params->tx_credit_count;
drivers/firmware/ti_sci.c:	req->txcq_qnum = params->txcq_qnum;
drivers/firmware/ti_sci.c:	req->tx_priority = params->tx_priority;
drivers/firmware/ti_sci.c:	req->tx_qos = params->tx_qos;
drivers/firmware/ti_sci.c:	req->tx_orderid = params->tx_orderid;
drivers/firmware/ti_sci.c:	req->fdepth = params->fdepth;
drivers/firmware/ti_sci.c:	req->tx_sched_priority = params->tx_sched_priority;
drivers/firmware/ti_sci.c:	req->tx_burst_size = params->tx_burst_size;
drivers/firmware/ti_sci.c:	req->tx_tdtype = params->tx_tdtype;
drivers/firmware/ti_sci.c:	req->extended_ch_type = params->extended_ch_type;
drivers/firmware/ti_sci.c:	req->valid_params = params->valid_params;
drivers/firmware/ti_sci.c:	req->nav_id = params->nav_id;
drivers/firmware/ti_sci.c:	req->index = params->index;
drivers/firmware/ti_sci.c:	req->rx_fetch_size = params->rx_fetch_size;
drivers/firmware/ti_sci.c:	req->rxcq_qnum = params->rxcq_qnum;
drivers/firmware/ti_sci.c:	req->rx_priority = params->rx_priority;
drivers/firmware/ti_sci.c:	req->rx_qos = params->rx_qos;
drivers/firmware/ti_sci.c:	req->rx_orderid = params->rx_orderid;
drivers/firmware/ti_sci.c:	req->rx_sched_priority = params->rx_sched_priority;
drivers/firmware/ti_sci.c:	req->flowid_start = params->flowid_start;
drivers/firmware/ti_sci.c:	req->flowid_cnt = params->flowid_cnt;
drivers/firmware/ti_sci.c:	req->rx_pause_on_err = params->rx_pause_on_err;
drivers/firmware/ti_sci.c:	req->rx_atype = params->rx_atype;
drivers/firmware/ti_sci.c:	req->rx_chan_type = params->rx_chan_type;
drivers/firmware/ti_sci.c:	req->rx_ignore_short = params->rx_ignore_short;
drivers/firmware/ti_sci.c:	req->rx_ignore_long = params->rx_ignore_long;
drivers/firmware/ti_sci.c:	req->rx_burst_size = params->rx_burst_size;
drivers/firmware/ti_sci.c:	req->valid_params = params->valid_params;
drivers/firmware/ti_sci.c:	req->nav_id = params->nav_id;
drivers/firmware/ti_sci.c:	req->flow_index = params->flow_index;
drivers/firmware/ti_sci.c:	req->rx_einfo_present = params->rx_einfo_present;
drivers/firmware/ti_sci.c:	req->rx_psinfo_present = params->rx_psinfo_present;
drivers/firmware/ti_sci.c:	req->rx_error_handling = params->rx_error_handling;
drivers/firmware/ti_sci.c:	req->rx_desc_type = params->rx_desc_type;
drivers/firmware/ti_sci.c:	req->rx_sop_offset = params->rx_sop_offset;
drivers/firmware/ti_sci.c:	req->rx_dest_qnum = params->rx_dest_qnum;
drivers/firmware/ti_sci.c:	req->rx_src_tag_hi = params->rx_src_tag_hi;
drivers/firmware/ti_sci.c:	req->rx_src_tag_lo = params->rx_src_tag_lo;
drivers/firmware/ti_sci.c:	req->rx_dest_tag_hi = params->rx_dest_tag_hi;
drivers/firmware/ti_sci.c:	req->rx_dest_tag_lo = params->rx_dest_tag_lo;
drivers/firmware/ti_sci.c:	req->rx_src_tag_hi_sel = params->rx_src_tag_hi_sel;
drivers/firmware/ti_sci.c:	req->rx_src_tag_lo_sel = params->rx_src_tag_lo_sel;
drivers/firmware/ti_sci.c:	req->rx_dest_tag_hi_sel = params->rx_dest_tag_hi_sel;
drivers/firmware/ti_sci.c:	req->rx_dest_tag_lo_sel = params->rx_dest_tag_lo_sel;
drivers/firmware/ti_sci.c:	req->rx_fdq0_sz0_qnum = params->rx_fdq0_sz0_qnum;
drivers/firmware/ti_sci.c:	req->rx_fdq1_qnum = params->rx_fdq1_qnum;
drivers/firmware/ti_sci.c:	req->rx_fdq2_qnum = params->rx_fdq2_qnum;
drivers/firmware/ti_sci.c:	req->rx_fdq3_qnum = params->rx_fdq3_qnum;
drivers/firmware/ti_sci.c:	req->rx_ps_location = params->rx_ps_location;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/firmware/ti_sci.c:	req->host_id = host_id;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/firmware/ti_sci.c:	req->bootvector_low = bootvector & TI_SCI_ADDR_LOW_MASK;
drivers/firmware/ti_sci.c:	req->bootvector_high = (bootvector & TI_SCI_ADDR_HIGH_MASK) >>
drivers/firmware/ti_sci.c:	req->config_flags_set = config_flags_set;
drivers/firmware/ti_sci.c:	req->config_flags_clear = config_flags_clear;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/firmware/ti_sci.c:	req->control_flags_set = control_flags_set;
drivers/firmware/ti_sci.c:	req->control_flags_clear = control_flags_clear;
drivers/firmware/ti_sci.c:	req->processor_id = proc_id;
drivers/usb/dwc3/gadget.c:	list_del(&req->list);
drivers/usb/dwc3/gadget.c:	req->remaining = 0;
drivers/usb/dwc3/gadget.c:	req->needs_extra_trb = false;
drivers/usb/dwc3/gadget.c:	if (req->request.status == -EINPROGRESS)
drivers/usb/dwc3/gadget.c:		req->request.status = status;
drivers/usb/dwc3/gadget.c:	if (req->trb)
drivers/usb/dwc3/gadget.c:				&req->request, req->direction);
drivers/usb/dwc3/gadget.c:	req->trb = NULL;
drivers/usb/dwc3/gadget.c:	req->status = DWC3_REQUEST_STATUS_COMPLETED;
drivers/usb/dwc3/gadget.c:	usb_gadget_giveback_request(&dep->endpoint, &req->request);
drivers/usb/dwc3/gadget.c:	req->direction	= dep->direction;
drivers/usb/dwc3/gadget.c:	req->epnum	= dep->number;
drivers/usb/dwc3/gadget.c:	req->dep	= dep;
drivers/usb/dwc3/gadget.c:	req->status	= DWC3_REQUEST_STATUS_UNKNOWN;
drivers/usb/dwc3/gadget.c:	return &req->request;
drivers/usb/dwc3/gadget.c:	unsigned int		stream_id = req->request.stream_id;
drivers/usb/dwc3/gadget.c:	unsigned int		short_not_ok = req->request.short_not_ok;
drivers/usb/dwc3/gadget.c:	unsigned int		no_interrupt = req->request.no_interrupt;
drivers/usb/dwc3/gadget.c:	unsigned int		is_last = req->request.is_last;
drivers/usb/dwc3/gadget.c:	else if (req->request.num_sgs > 0)
drivers/usb/dwc3/gadget.c:		dma = sg_dma_address(req->start_sg);
drivers/usb/dwc3/gadget.c:		dma = req->request.dma;
drivers/usb/dwc3/gadget.c:	if (!req->trb) {
drivers/usb/dwc3/gadget.c:		req->trb = trb;
drivers/usb/dwc3/gadget.c:		req->trb_dma = dwc3_trb_dma_offset(dep, trb);
drivers/usb/dwc3/gadget.c:	req->num_trbs++;
drivers/usb/dwc3/gadget.c:	unsigned int rem = req->request.length % maxp;
drivers/usb/dwc3/gadget.c:	if ((req->request.length && req->request.zero && !rem &&
drivers/usb/dwc3/gadget.c:			(!req->direction && rem))
drivers/usb/dwc3/gadget.c:	unsigned int rem = req->request.length % maxp;
drivers/usb/dwc3/gadget.c:	req->needs_extra_trb = num_trbs > 1;
drivers/usb/dwc3/gadget.c:	if (req->direction || req->request.length)
drivers/usb/dwc3/gadget.c:				req->needs_extra_trb, node, false, false);
drivers/usb/dwc3/gadget.c:	if ((!req->direction && !req->request.length) || req->needs_extra_trb)
drivers/usb/dwc3/gadget.c:				req->direction ? 0 : maxp - rem,
drivers/usb/dwc3/gadget.c:	struct scatterlist *sg = req->start_sg;
drivers/usb/dwc3/gadget.c:	unsigned int length = req->request.length;
drivers/usb/dwc3/gadget.c:	unsigned int remaining = req->request.num_mapped_sgs
drivers/usb/dwc3/gadget.c:		- req->num_queued_sgs;
drivers/usb/dwc3/gadget.c:	unsigned int num_trbs = req->num_trbs;
drivers/usb/dwc3/gadget.c:	for_each_sg(req->request.sg, s, req->num_queued_sgs, i)
drivers/usb/dwc3/gadget.c:			req->start_sg = sg_next(s);
drivers/usb/dwc3/gadget.c:		req->num_queued_sgs++;
drivers/usb/dwc3/gadget.c:			req->num_pending_sgs -= req->request.num_mapped_sgs - req->num_queued_sgs;
drivers/usb/dwc3/gadget.c:	return req->num_trbs - num_trbs;
drivers/usb/dwc3/gadget.c:	return dwc3_prepare_last_sg(dep, req, req->request.length, 0);
drivers/usb/dwc3/gadget.c:		if (req->num_pending_sgs > 0) {
drivers/usb/dwc3/gadget.c:			if (!ret || req->num_pending_sgs)
drivers/usb/dwc3/gadget.c:		if (dep->stream_capable && req->request.is_last)
drivers/usb/dwc3/gadget.c:		ret = usb_gadget_map_request_by_dev(dwc->sysdev, &req->request,
drivers/usb/dwc3/gadget.c:		req->sg			= req->request.sg;
drivers/usb/dwc3/gadget.c:		req->start_sg		= req->sg;
drivers/usb/dwc3/gadget.c:		req->num_queued_sgs	= 0;
drivers/usb/dwc3/gadget.c:		req->num_pending_sgs	= req->request.num_mapped_sgs;
drivers/usb/dwc3/gadget.c:		if (req->num_pending_sgs > 0) {
drivers/usb/dwc3/gadget.c:			if (req->num_pending_sgs)
drivers/usb/dwc3/gadget.c:		if (dep->stream_capable && req->request.is_last)
drivers/usb/dwc3/gadget.c:		params.param0 = upper_32_bits(req->trb_dma);
drivers/usb/dwc3/gadget.c:		params.param1 = lower_32_bits(req->trb_dma);
drivers/usb/dwc3/gadget.c:			cmd |= DWC3_DEPCMD_PARAM(req->request.stream_id);
drivers/usb/dwc3/gadget.c:	if (dep->stream_capable && req->request.is_last)
drivers/usb/dwc3/gadget.c:	if (WARN(req->dep != dep, "request %pK belongs to '%s'\n",
drivers/usb/dwc3/gadget.c:				&req->request, req->dep->name))
drivers/usb/dwc3/gadget.c:	if (WARN(req->status < DWC3_REQUEST_STATUS_COMPLETED,
drivers/usb/dwc3/gadget.c:				dep->name, &req->request))
drivers/usb/dwc3/gadget.c:	req->request.actual	= 0;
drivers/usb/dwc3/gadget.c:	req->request.status	= -EINPROGRESS;
drivers/usb/dwc3/gadget.c:	list_add_tail(&req->list, &dep->pending_list);
drivers/usb/dwc3/gadget.c:	req->status = DWC3_REQUEST_STATUS_QUEUED;
drivers/usb/dwc3/gadget.c:	/* If req->trb is not set, then the request has not started */
drivers/usb/dwc3/gadget.c:	if (!req->trb)
drivers/usb/dwc3/gadget.c:	for (i = 0; i < req->num_trbs; i++) {
drivers/usb/dwc3/gadget.c:	req->num_trbs = 0;
drivers/usb/dwc3/gadget.c:	req->num_trbs--;
drivers/usb/dwc3/gadget.c:		req->request.frame_number = frame_number;
drivers/usb/dwc3/gadget.c:	 * TRB. Don't add it to req->remaining calculation.
drivers/usb/dwc3/gadget.c:	req->remaining += count;
drivers/usb/dwc3/gadget.c:	struct scatterlist *sg = req->sg;
drivers/usb/dwc3/gadget.c:	unsigned int pending = req->num_pending_sgs;
drivers/usb/dwc3/gadget.c:		req->sg = sg_next(s);
drivers/usb/dwc3/gadget.c:		req->num_pending_sgs--;
drivers/usb/dwc3/gadget.c:	return req->num_pending_sgs == 0;
drivers/usb/dwc3/gadget.c:	if (req->num_pending_sgs)
drivers/usb/dwc3/gadget.c:	req->request.actual = req->request.length - req->remaining;
drivers/usb/dwc3/gadget.c:	if (req->needs_extra_trb) {
drivers/usb/dwc3/gadget.c:		req->needs_extra_trb = false;
drivers/usb/dwc3/gadget.h:	struct dwc3_ep		*dep = req->dep;
drivers/usb/dwc3/gadget.h:	req->status = DWC3_REQUEST_STATUS_STARTED;
drivers/usb/dwc3/gadget.h:	list_move_tail(&req->list, &dep->started_list);
drivers/usb/dwc3/gadget.h:	struct dwc3_ep		*dep = req->dep;
drivers/usb/dwc3/gadget.h:	req->status = DWC3_REQUEST_STATUS_CANCELLED;
drivers/usb/dwc3/gadget.h:	list_move_tail(&req->list, &dep->cancelled_list);
drivers/usb/dwc3/ep0.c:	req->request.actual	= 0;
drivers/usb/dwc3/ep0.c:	req->request.status	= -EINPROGRESS;
drivers/usb/dwc3/ep0.c:	req->epnum		= dep->number;
drivers/usb/dwc3/ep0.c:	list_add_tail(&req->list, &dep->pending_list);
drivers/usb/dwc3/ep0.c:	memcpy(&timing, req->buf, sizeof(timing));
drivers/usb/dwc3/ep0.c:	req->direction = !!dep->number;
drivers/usb/dwc3/ep0.c:	if (req->request.length == 0) {
drivers/usb/dwc3/ep0.c:		if (!req->direction)
drivers/usb/dwc3/ep0.c:	} else if (!IS_ALIGNED(req->request.length, dep->endpoint.maxpacket)
drivers/usb/dwc3/ep0.c:				&req->request, dep->number);
drivers/usb/dwc3/ep0.c:		rem = req->request.length % maxpacket;
drivers/usb/dwc3/ep0.c:		dwc3_ep0_prepare_one_trb(dep, req->request.dma,
drivers/usb/dwc3/ep0.c:					 req->request.length,
drivers/usb/dwc3/ep0.c:		req->trb = &dwc->ep0_trb[dep->trb_enqueue - 1];
drivers/usb/dwc3/ep0.c:	} else if (IS_ALIGNED(req->request.length, dep->endpoint.maxpacket) &&
drivers/usb/dwc3/ep0.c:		   req->request.length && req->request.zero) {
drivers/usb/dwc3/ep0.c:				&req->request, dep->number);
drivers/usb/dwc3/ep0.c:		dwc3_ep0_prepare_one_trb(dep, req->request.dma,
drivers/usb/dwc3/ep0.c:					 req->request.length,
drivers/usb/dwc3/ep0.c:		req->trb = &dwc->ep0_trb[dep->trb_enqueue - 1];
drivers/usb/dwc3/ep0.c:		if (!req->direction)
drivers/usb/dwc3/ep0.c:				&req->request, dep->number);
drivers/usb/dwc3/ep0.c:		dwc3_ep0_prepare_one_trb(dep, req->request.dma,
drivers/usb/dwc3/ep0.c:				req->request.length, DWC3_TRBCTL_CONTROL_DATA,
drivers/usb/dwc3/ep0.c:		req->trb = &dwc->ep0_trb[dep->trb_enqueue];
drivers/usb/dwc3/trace.h:		__string(name, req->dep->name)
drivers/usb/dwc3/trace.h:		__assign_str(name, req->dep->name);
drivers/usb/dwc3/trace.h:		__entry->actual = req->request.actual;
drivers/usb/dwc3/trace.h:		__entry->length = req->request.length;
drivers/usb/dwc3/trace.h:		__entry->status = req->request.status;
drivers/usb/dwc3/trace.h:		__entry->zero = req->request.zero;
drivers/usb/dwc3/trace.h:		__entry->short_not_ok = req->request.short_not_ok;
drivers/usb/dwc3/trace.h:		__entry->no_interrupt = req->request.no_interrupt;
drivers/usb/dwc2/gadget.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/dwc2/gadget.c:	return &req->req;
drivers/usb/dwc2/gadget.c:	struct usb_request *req = &hs_req->req;
drivers/usb/dwc2/gadget.c:	int buf_pos = hs_req->req.actual;
drivers/usb/dwc2/gadget.c:		to_write, hs_req->req.length, can_write, buf_pos);
drivers/usb/dwc2/gadget.c:	hs_req->req.actual = buf_pos + to_write;
drivers/usb/dwc2/gadget.c:	data = hs_req->req.buf + buf_pos;
drivers/usb/dwc2/gadget.c:		ureq = &hs_ep->req->req;
drivers/usb/dwc2/gadget.c:	if (!ureq || !ureq->num_sgs) {
drivers/usb/dwc2/gadget.c:	for_each_sg(ureq->sg, sg, ureq->num_sgs, i) {
drivers/usb/dwc2/gadget.c:		dma_addr_t dma_addr = hs_req->req.dma;
drivers/usb/dwc2/gadget.c:		if (hs_req->req.num_sgs) {
drivers/usb/dwc2/gadget.c:			WARN_ON(hs_req->req.num_sgs > 1);
drivers/usb/dwc2/gadget.c:			dma_addr = sg_dma_address(hs_req->req.sg);
drivers/usb/dwc2/gadget.c:						 hs_req->req.length);
drivers/usb/dwc2/gadget.c:	struct usb_request *ureq = &hs_req->req;
drivers/usb/dwc2/gadget.c:	length = ureq->length - ureq->actual;
drivers/usb/dwc2/gadget.c:	dev_dbg(hsotg->dev, "ureq->length:%d ureq->actual:%d\n",
drivers/usb/dwc2/gadget.c:		ureq->length, ureq->actual);
drivers/usb/dwc2/gadget.c:	if (dir_in && ureq->zero && !continuing) {
drivers/usb/dwc2/gadget.c:		if ((ureq->length >= hs_ep->ep.maxpacket) &&
drivers/usb/dwc2/gadget.c:		    !(ureq->length % hs_ep->ep.maxpacket))
drivers/usb/dwc2/gadget.c:		__func__, packets, length, ureq->length, epsize, epsize_reg);
drivers/usb/dwc2/gadget.c:			offset = ureq->actual;
drivers/usb/dwc2/gadget.c:		dwc2_gadget_config_nonisoc_xfer_ddma(hs_ep, ureq->dma + offset,
drivers/usb/dwc2/gadget.c:			dwc2_writel(hsotg, ureq->dma, dma_reg);
drivers/usb/dwc2/gadget.c:				__func__, &ureq->dma, dma_reg);
drivers/usb/dwc2/gadget.c:	hs_ep->last_load = ureq->actual;
drivers/usb/dwc2/gadget.c:		__func__, req->buf, req->length);
drivers/usb/dwc2/gadget.c:	void *req_buf = hs_req->req.buf;
drivers/usb/dwc2/gadget.c:	WARN_ON(hs_req->saved_req_buf);
drivers/usb/dwc2/gadget.c:		hs_ep->ep.name, req_buf, hs_req->req.length);
drivers/usb/dwc2/gadget.c:	hs_req->req.buf = kmalloc(hs_req->req.length, GFP_ATOMIC);
drivers/usb/dwc2/gadget.c:	if (!hs_req->req.buf) {
drivers/usb/dwc2/gadget.c:		hs_req->req.buf = req_buf;
drivers/usb/dwc2/gadget.c:	hs_req->saved_req_buf = req_buf;
drivers/usb/dwc2/gadget.c:		memcpy(hs_req->req.buf, req_buf, hs_req->req.length);
drivers/usb/dwc2/gadget.c:	if (!using_dma(hsotg) || !hs_req->saved_req_buf)
drivers/usb/dwc2/gadget.c:		hs_ep->ep.name, hs_req->req.status, hs_req->req.actual);
drivers/usb/dwc2/gadget.c:	if (!hs_ep->dir_in && !hs_req->req.status)
drivers/usb/dwc2/gadget.c:		memcpy(hs_req->saved_req_buf, hs_req->req.buf,
drivers/usb/dwc2/gadget.c:		       hs_req->req.actual);
drivers/usb/dwc2/gadget.c:	kfree(hs_req->req.buf);
drivers/usb/dwc2/gadget.c:	hs_req->req.buf = hs_req->saved_req_buf;
drivers/usb/dwc2/gadget.c:	hs_req->saved_req_buf = NULL;
drivers/usb/dwc2/gadget.c:		ep->name, req, req->length, req->buf, req->no_interrupt,
drivers/usb/dwc2/gadget.c:		req->zero, req->short_not_ok);
drivers/usb/dwc2/gadget.c:	INIT_LIST_HEAD(&hs_req->queue);
drivers/usb/dwc2/gadget.c:	req->actual = 0;
drivers/usb/dwc2/gadget.c:	req->status = -EINPROGRESS;
drivers/usb/dwc2/gadget.c:	    req->length > (hs_ep->mc * hs_ep->ep.maxpacket)) {
drivers/usb/dwc2/gadget.c:		if (hs_ep->dir_in && req->length > maxsize) {
drivers/usb/dwc2/gadget.c:				req->length, maxsize);
drivers/usb/dwc2/gadget.c:		if (!hs_ep->dir_in && req->length > hs_ep->ep.maxpacket) {
drivers/usb/dwc2/gadget.c:				req->length, hs_ep->ep.maxpacket);
drivers/usb/dwc2/gadget.c:	list_add_tail(&hs_req->queue, &hs_ep->queue);
drivers/usb/dwc2/gadget.c:			dma_addr_t dma_addr = hs_req->req.dma;
drivers/usb/dwc2/gadget.c:			if (hs_req->req.num_sgs) {
drivers/usb/dwc2/gadget.c:				WARN_ON(hs_req->req.num_sgs > 1);
drivers/usb/dwc2/gadget.c:				dma_addr = sg_dma_address(hs_req->req.sg);
drivers/usb/dwc2/gadget.c:						   hs_req->req.length);
drivers/usb/dwc2/gadget.c:	if (!hs_ep->index && !req->length && !hs_ep->dir_in &&
drivers/usb/dwc2/gadget.c:	req->buf = hsotg->ep0_buff;
drivers/usb/dwc2/gadget.c:	req->length = length;
drivers/usb/dwc2/gadget.c:	req->zero = 0;
drivers/usb/dwc2/gadget.c:	req->complete = dwc2_hsotg_complete_oursetup;
drivers/usb/dwc2/gadget.c:		memcpy(req->buf, buff, length);
drivers/usb/dwc2/gadget.c:					list_del_init(&hs_req->queue);
drivers/usb/dwc2/gadget.c:					if (hs_req->req.complete) {
drivers/usb/dwc2/gadget.c:							&ep->ep, &hs_req->req);
drivers/usb/dwc2/gadget.c:	if (req->status < 0) {
drivers/usb/dwc2/gadget.c:		dev_dbg(hsotg->dev, "%s: failed %d\n", __func__, req->status);
drivers/usb/dwc2/gadget.c:	if (req->actual == 0)
drivers/usb/dwc2/gadget.c:		dwc2_hsotg_process_control(hsotg, req->buf);
drivers/usb/dwc2/gadget.c:	req->zero = 0;
drivers/usb/dwc2/gadget.c:	req->length = 8;
drivers/usb/dwc2/gadget.c:	req->buf = hsotg->ctrl_buff;
drivers/usb/dwc2/gadget.c:	req->complete = dwc2_hsotg_complete_setup;
drivers/usb/dwc2/gadget.c:	if (!list_empty(&hs_req->queue)) {
drivers/usb/dwc2/gadget.c:		hs_ep, hs_ep->ep.name, hs_req, result, hs_req->req.complete);
drivers/usb/dwc2/gadget.c:	if (hs_req->req.status == -EINPROGRESS)
drivers/usb/dwc2/gadget.c:		hs_req->req.status = result;
drivers/usb/dwc2/gadget.c:	list_del_init(&hs_req->queue);
drivers/usb/dwc2/gadget.c:	if (hs_req->req.complete) {
drivers/usb/dwc2/gadget.c:		usb_gadget_giveback_request(&hs_ep->ep, &hs_req->req);
drivers/usb/dwc2/gadget.c:		ureq = &hs_req->req;
drivers/usb/dwc2/gadget.c:			ureq->actual = ureq->length - ((desc_sts & mask) >>
drivers/usb/dwc2/gadget.c:			if (!hs_ep->dir_in && ureq->length & 0x3)
drivers/usb/dwc2/gadget.c:				ureq->actual += 4 - (ureq->length & 0x3);
drivers/usb/dwc2/gadget.c:			ureq->frame_number =
drivers/usb/dwc2/gadget.c:	read_ptr = hs_req->req.actual;
drivers/usb/dwc2/gadget.c:	max_req = hs_req->req.length - read_ptr;
drivers/usb/dwc2/gadget.c:		__func__, to_read, max_req, read_ptr, hs_req->req.length);
drivers/usb/dwc2/gadget.c:	hs_req->req.actual += to_read;
drivers/usb/dwc2/gadget.c:		       hs_req->req.buf + read_ptr, to_read);
drivers/usb/dwc2/gadget.c:	struct usb_request *req = &hs_req->req;
drivers/usb/dwc2/gadget.c:		req->actual = size_done;
drivers/usb/dwc2/gadget.c:	if (req->actual < req->length && size_left == 0) {
drivers/usb/dwc2/gadget.c:	if (req->actual < req->length && req->short_not_ok) {
drivers/usb/dwc2/gadget.c:			__func__, req->actual, req->length);
drivers/usb/dwc2/gadget.c:		req->frame_number = hsotg->frame_number;
drivers/usb/dwc2/gadget.c:	if (hs_req->req.actual < hs_req->req.length) {
drivers/usb/dwc2/gadget.c:	if (hs_req->req.actual != size_done)
drivers/usb/dwc2/gadget.c:			__func__, hs_req->req.actual, size_done);
drivers/usb/dwc2/gadget.c:	hs_req->req.actual = size_done;
drivers/usb/dwc2/gadget.c:	dev_dbg(hsotg->dev, "req->length:%d req->actual:%d req->zero:%d\n",
drivers/usb/dwc2/gadget.c:		hs_req->req.length, hs_req->req.actual, hs_req->req.zero);
drivers/usb/dwc2/gadget.c:	if (!size_left && hs_req->req.actual < hs_req->req.length) {
drivers/usb/dwc2/gadget.c:	if (req == &hs_ep->req->req)
drivers/usb/dwc2/debugfs.c:			   req, req->req.length, req->req.buf);
drivers/usb/dwc2/debugfs.c:			   req->req.actual, req->req.status);
drivers/usb/class/cdc-wdm.c:	req->bRequestType = (USB_DIR_OUT | USB_TYPE_CLASS |
drivers/usb/class/cdc-wdm.c:	req->bRequest = USB_CDC_SEND_ENCAPSULATED_COMMAND;
drivers/usb/class/cdc-wdm.c:	req->wValue = 0;
drivers/usb/class/cdc-wdm.c:	req->wIndex = desc->inum; /* already converted */
drivers/usb/class/cdc-wdm.c:	req->wLength = cpu_to_le16(count);
drivers/usb/class/cdc-wdm.c:			le16_to_cpu(req->wIndex));
drivers/usb/host/xhci-dbgtty.c:		len = dbc_send_packet(port, req->buf, DBC_MAX_PACKET);
drivers/usb/host/xhci-dbgtty.c:		req->length = len;
drivers/usb/host/xhci-dbgtty.c:		list_del(&req->list_pool);
drivers/usb/host/xhci-dbgtty.c:			list_add(&req->list_pool, pool);
drivers/usb/host/xhci-dbgtty.c:		list_del(&req->list_pool);
drivers/usb/host/xhci-dbgtty.c:		req->length = DBC_MAX_PACKET;
drivers/usb/host/xhci-dbgtty.c:			list_add(&req->list_pool, pool);
drivers/usb/host/xhci-dbgtty.c:	list_add_tail(&req->list_pool, &port->read_queue);
drivers/usb/host/xhci-dbgtty.c:	list_add(&req->list_pool, &port->write_pool);
drivers/usb/host/xhci-dbgtty.c:	switch (req->status) {
drivers/usb/host/xhci-dbgtty.c:			  req->status);
drivers/usb/host/xhci-dbgtty.c:	kfree(req->buf);
drivers/usb/host/xhci-dbgtty.c:		req->length = DBC_MAX_PACKET;
drivers/usb/host/xhci-dbgtty.c:		req->buf = kmalloc(req->length, GFP_KERNEL);
drivers/usb/host/xhci-dbgtty.c:		if (!req->buf) {
drivers/usb/host/xhci-dbgtty.c:		req->complete = fn;
drivers/usb/host/xhci-dbgtty.c:		list_add_tail(&req->list_pool, head);
drivers/usb/host/xhci-dbgtty.c:		list_del(&req->list_pool);
drivers/usb/host/xhci-dbgtty.c:		switch (req->status) {
drivers/usb/host/xhci-dbgtty.c:				req->status);
drivers/usb/host/xhci-dbgtty.c:		if (req->actual) {
drivers/usb/host/xhci-dbgtty.c:			char		*packet = req->buf;
drivers/usb/host/xhci-dbgtty.c:			unsigned int	n, size = req->actual;
drivers/usb/host/xhci-dbgtty.c:		list_move(&req->list_pool, &port->read_pool);
drivers/usb/host/xhci-trace.h:		__entry->dir = req->direction;
drivers/usb/host/xhci-trace.h:		__entry->actual = req->actual;
drivers/usb/host/xhci-trace.h:		__entry->length = req->length;
drivers/usb/host/xhci-trace.h:		__entry->status = req->status;
drivers/usb/host/xhci-dbgcap.c:	struct xhci_dbc		*dbc = req->dbc;
drivers/usb/host/xhci-dbgcap.c:	list_del_init(&req->list_pending);
drivers/usb/host/xhci-dbgcap.c:	req->trb_dma = 0;
drivers/usb/host/xhci-dbgcap.c:	req->trb = NULL;
drivers/usb/host/xhci-dbgcap.c:	if (req->status == -EINPROGRESS)
drivers/usb/host/xhci-dbgcap.c:		req->status = status;
drivers/usb/host/xhci-dbgcap.c:			 req->dma,
drivers/usb/host/xhci-dbgcap.c:			 req->length,
drivers/usb/host/xhci-dbgcap.c:	req->complete(dbc, req);
drivers/usb/host/xhci-dbgcap.c:	union xhci_trb	*trb = req->trb;
drivers/usb/host/xhci-dbgcap.c:	req->dbc = dbc;
drivers/usb/host/xhci-dbgcap.c:	INIT_LIST_HEAD(&req->list_pending);
drivers/usb/host/xhci-dbgcap.c:	INIT_LIST_HEAD(&req->list_pool);
drivers/usb/host/xhci-dbgcap.c:	req->direction = direction;
drivers/usb/host/xhci-dbgcap.c:	struct xhci_dbc		*dbc = req->dbc;
drivers/usb/host/xhci-dbgcap.c:	num_trbs = count_trbs(req->dma, req->length);
drivers/usb/host/xhci-dbgcap.c:	addr	= req->dma;
drivers/usb/host/xhci-dbgcap.c:	length	= TRB_LEN(req->length);
drivers/usb/host/xhci-dbgcap.c:	req->trb = ring->enqueue;
drivers/usb/host/xhci-dbgcap.c:	req->trb_dma = xhci_trb_virt_to_dma(ring->enq_seg, ring->enqueue);
drivers/usb/host/xhci-dbgcap.c:	struct xhci_dbc		*dbc = req->dbc;
drivers/usb/host/xhci-dbgcap.c:	struct dbc_ep		*dep = &dbc->eps[req->direction];
drivers/usb/host/xhci-dbgcap.c:	if (!req->length || !req->buf)
drivers/usb/host/xhci-dbgcap.c:	req->actual		= 0;
drivers/usb/host/xhci-dbgcap.c:	req->status		= -EINPROGRESS;
drivers/usb/host/xhci-dbgcap.c:	req->dma = dma_map_single(dev,
drivers/usb/host/xhci-dbgcap.c:				  req->buf,
drivers/usb/host/xhci-dbgcap.c:				  req->length,
drivers/usb/host/xhci-dbgcap.c:	if (dma_mapping_error(dev, req->dma)) {
drivers/usb/host/xhci-dbgcap.c:				 req->dma,
drivers/usb/host/xhci-dbgcap.c:				 req->length,
drivers/usb/host/xhci-dbgcap.c:	list_add_tail(&req->list_pending, &dep->list_pending);
drivers/usb/host/xhci-dbgcap.c:	struct xhci_dbc		*dbc = req->dbc;
drivers/usb/host/xhci-dbgcap.c:	if (req->direction != BULK_IN &&
drivers/usb/host/xhci-dbgcap.c:	    req->direction != BULK_OUT)
drivers/usb/host/xhci-dbgcap.c:	trace_xhci_dbc_handle_transfer(ring, &req->trb->generic);
drivers/usb/host/xhci-dbgcap.c:	req->actual = req->length - remain_length;
drivers/usb/musb/musb_gadget.c:					(req->map_state != UN_MAPPED))
drivers/usb/musb/musb_gadget.c:	list_del(&req->list);
drivers/usb/musb/musb_gadget.c:	if (req->request.status == -EINPROGRESS)
drivers/usb/musb/musb_gadget.c:		req->request.status = status;
drivers/usb/musb/musb_gadget.c:	musb = req->musb;
drivers/usb/musb/musb_gadget.c:	usb_gadget_giveback_request(&req->ep->end_point, &req->request);
drivers/usb/musb/musb_gadget.c:		musb_g_giveback(ep, &req->request, status);
drivers/usb/musb/musb_gadget.c:	u8			epnum = req->epnum;
drivers/usb/musb/musb_gadget.c:	musb_ep = req->ep;
drivers/usb/musb/musb_gadget.c:	request = &req->request;
drivers/usb/musb/musb_gadget.c:	request = &req->request;
drivers/usb/musb/musb_gadget.c:	const u8		epnum = req->epnum;
drivers/usb/musb/musb_gadget.c:	struct usb_request	*request = &req->request;
drivers/usb/musb/musb_gadget.c:	 * REVISIT an updated g_file_storage can set req->short_not_ok, which
drivers/usb/musb/musb_gadget.c:	request = &req->request;
drivers/usb/musb/musb_gadget.c:	musb_ep_select(musb->mregs, req->epnum);
drivers/usb/musb/musb_gadget.c:	if (req->tx)
drivers/usb/musb/musb_gadget.c:	if (!req->buf)
drivers/usb/musb/musb_gadget.c:	if (!ep || !request || req->ep != musb_ep)
drivers/usb/musb/musb_gadget.c:	if (musb_ep->req_list.next != &req->list || musb_ep->busy)
drivers/usb/musb/musb_trace.h:		__entry->req = &req->request;
drivers/usb/musb/musb_trace.h:		__entry->is_tx = req->tx;
drivers/usb/musb/musb_trace.h:		__entry->epnum = req->epnum;
drivers/usb/musb/musb_trace.h:		__entry->status = req->request.status;
drivers/usb/musb/musb_trace.h:		__entry->buf_len = req->request.length;
drivers/usb/musb/musb_trace.h:		__entry->actual_len = req->request.actual;
drivers/usb/musb/musb_trace.h:		__entry->zero = req->request.zero;
drivers/usb/musb/musb_trace.h:		__entry->short_not_ok = req->request.short_not_ok;
drivers/usb/musb/musb_trace.h:		__entry->no_interrupt = req->request.no_interrupt;
drivers/usb/musb/musb_gadget_ep0.c:		void		*buf = req->buf + req->actual;
drivers/usb/musb/musb_gadget_ep0.c:		unsigned	len = req->length - req->actual;
drivers/usb/musb/musb_gadget_ep0.c:			req->status = -EOVERFLOW;
drivers/usb/musb/musb_gadget_ep0.c:			req->actual += count;
drivers/usb/musb/musb_gadget_ep0.c:		if (count < 64 || req->actual == req->length) {
drivers/usb/musb/musb_gadget_ep0.c:	request = &req->request;
drivers/usb/musb/musb_gadget_ep0.c:		req->bRequestType,
drivers/usb/musb/musb_gadget_ep0.c:		req->bRequest,
drivers/usb/musb/musb_gadget_ep0.c:		le16_to_cpu(req->wValue),
drivers/usb/musb/musb_gadget_ep0.c:		le16_to_cpu(req->wIndex),
drivers/usb/musb/musb_gadget_ep0.c:		le16_to_cpu(req->wLength));
drivers/usb/musb/musb_gadget_ep0.c:	if (req->wLength == 0) {
drivers/usb/musb/musb_gadget_ep0.c:		if (req->bRequestType & USB_DIR_IN)
drivers/usb/musb/musb_gadget_ep0.c:	} else if (req->bRequestType & USB_DIR_IN) {
drivers/usb/musb/musb_gadget_ep0.c:				musb_g_ep0_giveback(musb, &req->request);
drivers/usb/musb/musb_gadget_ep0.c:	req->musb = musb;
drivers/usb/musb/musb_gadget_ep0.c:	req->request.actual = 0;
drivers/usb/musb/musb_gadget_ep0.c:	req->request.status = -EINPROGRESS;
drivers/usb/musb/musb_gadget_ep0.c:	req->tx = ep->is_in;
drivers/usb/musb/musb_gadget_ep0.c:	list_add_tail(&req->list, &ep->req_list);
drivers/usb/musb/musb_gadget_ep0.c:			req->request.length);
drivers/usb/musb/musb_gadget_ep0.c:		if (req->request.length)
drivers/usb/mtu3/mtu3_gadget.c:	struct mtu3 *mtu = mreq->mtu;
drivers/usb/mtu3/mtu3_gadget.c:	list_del(&mreq->list);
drivers/usb/mtu3/mtu3_gadget.c:	if (req->status == -EINPROGRESS)
drivers/usb/mtu3/mtu3_gadget.c:		req->status = status;
drivers/usb/mtu3/mtu3_gadget.c:		mep->name, req, req->status, req->actual, req->length);
drivers/usb/mtu3/mtu3_gadget.c:		mtu3_req_complete(mep, &mreq->request, status);
drivers/usb/mtu3/mtu3_gadget.c:	mreq->request.dma = DMA_ADDR_INVALID;
drivers/usb/mtu3/mtu3_gadget.c:	mreq->epnum = mep->epnum;
drivers/usb/mtu3/mtu3_gadget.c:	mreq->mep = mep;
drivers/usb/mtu3/mtu3_gadget.c:	return &mreq->request;
drivers/usb/mtu3/mtu3_gadget.c:	if (!req->buf)
drivers/usb/mtu3/mtu3_gadget.c:	if (mreq->mep != mep)
drivers/usb/mtu3/mtu3_gadget.c:		__func__, mep->is_in ? "TX" : "RX", mreq->epnum, ep->name,
drivers/usb/mtu3/mtu3_gadget.c:		mreq, ep->maxpacket, mreq->request.length);
drivers/usb/mtu3/mtu3_gadget.c:	if (req->length > GPD_BUF_SIZE ||
drivers/usb/mtu3/mtu3_gadget.c:	    (mtu->gen2cp && req->length > GPD_BUF_SIZE_EL)) {
drivers/usb/mtu3/mtu3_gadget.c:			req->length);
drivers/usb/mtu3/mtu3_gadget.c:	mreq->mtu = mtu;
drivers/usb/mtu3/mtu3_gadget.c:	mreq->request.actual = 0;
drivers/usb/mtu3/mtu3_gadget.c:	mreq->request.status = -EINPROGRESS;
drivers/usb/mtu3/mtu3_gadget.c:	list_add_tail(&mreq->list, &mep->req_list);
drivers/usb/mtu3/mtu3_gadget.c:	if (mreq->mep != mep)
drivers/usb/mtu3/mtu3_trace.h:		__string(name, mreq->mep->name)
drivers/usb/mtu3/mtu3_trace.h:		__assign_str(name, mreq->mep->name);
drivers/usb/mtu3/mtu3_trace.h:		__entry->gpd = mreq->gpd;
drivers/usb/mtu3/mtu3_trace.h:		__entry->actual = mreq->request.actual;
drivers/usb/mtu3/mtu3_trace.h:		__entry->length = mreq->request.length;
drivers/usb/mtu3/mtu3_trace.h:		__entry->status = mreq->request.status;
drivers/usb/mtu3/mtu3_trace.h:		__entry->zero = mreq->request.zero;
drivers/usb/mtu3/mtu3_trace.h:		__entry->no_interrupt = mreq->request.no_interrupt;
drivers/usb/mtu3/mtu3_qmu.c:	struct usb_request *req = &mreq->request;
drivers/usb/mtu3/mtu3_qmu.c:	gpd->buffer = cpu_to_le32(lower_32_bits(req->dma));
drivers/usb/mtu3/mtu3_qmu.c:	ext_addr = GPD_EXT_BUF(mtu, upper_32_bits(req->dma));
drivers/usb/mtu3/mtu3_qmu.c:	gpd->dw3_info = cpu_to_le32(GPD_DATA_LEN(mtu, req->length));
drivers/usb/mtu3/mtu3_qmu.c:	if (req->zero) {
drivers/usb/mtu3/mtu3_qmu.c:	mreq->gpd = gpd;
drivers/usb/mtu3/mtu3_qmu.c:	struct usb_request *req = &mreq->request;
drivers/usb/mtu3/mtu3_qmu.c:	gpd->buffer = cpu_to_le32(lower_32_bits(req->dma));
drivers/usb/mtu3/mtu3_qmu.c:	ext_addr = GPD_EXT_BUF(mtu, upper_32_bits(req->dma));
drivers/usb/mtu3/mtu3_qmu.c:	gpd->dw0_info = cpu_to_le32(GPD_RX_BUF_LEN(mtu, req->length));
drivers/usb/mtu3/mtu3_qmu.c:	mreq->gpd = gpd;
drivers/usb/mtu3/mtu3_qmu.c:	if (mreq && mreq->request.length != 0)
drivers/usb/mtu3/mtu3_qmu.c:		if (mreq == NULL || mreq->gpd != gpd) {
drivers/usb/mtu3/mtu3_qmu.c:		request = &mreq->request;
drivers/usb/mtu3/mtu3_qmu.c:		if (mreq == NULL || mreq->gpd != gpd) {
drivers/usb/mtu3/mtu3_qmu.c:		req = &mreq->request;
drivers/usb/mtu3/mtu3_qmu.c:		req->actual = GPD_DATA_LEN(mtu, le32_to_cpu(gpd->dw3_info));
drivers/usb/mtu3/mtu3_gadget_ep0.c:	memcpy(&sel, req->buf, sizeof(sel));
drivers/usb/mtu3/mtu3_gadget_ep0.c:	mtu = mreq->mtu;
drivers/usb/mtu3/mtu3_gadget_ep0.c:	req = &mreq->request;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		void *buf = req->buf + req->actual;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		unsigned int len = req->length - req->actual;
drivers/usb/mtu3/mtu3_gadget_ep0.c:			req->status = -EOVERFLOW;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		req->actual += count;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		if (count < maxp || req->actual == req->length) {
drivers/usb/mtu3/mtu3_gadget_ep0.c:	req = &mreq->request;
drivers/usb/mtu3/mtu3_gadget_ep0.c:	src = (u8 *)req->buf + req->actual;
drivers/usb/mtu3/mtu3_gadget_ep0.c:	count = min(maxp, req->length - req->actual);
drivers/usb/mtu3/mtu3_gadget_ep0.c:		 __func__, req->actual, req->length, count, maxp, req->zero);
drivers/usb/mtu3/mtu3_gadget_ep0.c:	req->actual += count;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		|| ((req->actual == req->length) && !req->zero))
drivers/usb/mtu3/mtu3_gadget_ep0.c:		ep0_req_giveback(mtu, &mreq->request);
drivers/usb/mtu3/mtu3_gadget_ep0.c:			ep0_req_giveback(mtu, &mreq->request);
drivers/usb/mtu3/mtu3_gadget_ep0.c:		if (mreq && !mreq->request.length)
drivers/usb/mtu3/mtu3_gadget_ep0.c:			ep0_req_giveback(mtu, &mreq->request);
drivers/usb/mtu3/mtu3_gadget_ep0.c:			ep0_req_giveback(mtu, &mreq->request);
drivers/usb/mtu3/mtu3_gadget_ep0.c:	mreq->mtu = mtu;
drivers/usb/mtu3/mtu3_gadget_ep0.c:	mreq->request.actual = 0;
drivers/usb/mtu3/mtu3_gadget_ep0.c:	mreq->request.status = -EINPROGRESS;
drivers/usb/mtu3/mtu3_gadget_ep0.c:		mep->name, decode_ep0_state(mtu), mreq->request.length);
drivers/usb/mtu3/mtu3_gadget_ep0.c:	list_add_tail(&mreq->list, &mep->req_list);
drivers/usb/isp1760/isp1760-udc.c:	req->ep = NULL;
drivers/usb/isp1760/isp1760-udc.c:	req->req.status = status;
drivers/usb/isp1760/isp1760-udc.c:	req->req.complete(&ep->ep, &req->req);
drivers/usb/isp1760/isp1760-udc.c:		__func__, len, req->req.actual, req->req.length);
drivers/usb/isp1760/isp1760-udc.c:	len = min(len, req->req.length - req->req.actual);
drivers/usb/isp1760/isp1760-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/isp1760/isp1760-udc.c:	req->req.actual += len;
drivers/usb/isp1760/isp1760-udc.c:		__func__, req, req->req.actual, req->req.length, ep->maxpacket,
drivers/usb/isp1760/isp1760-udc.c:	if (req->req.actual == req->req.length || len < ep->maxpacket) {
drivers/usb/isp1760/isp1760-udc.c:		list_del(&req->queue);
drivers/usb/isp1760/isp1760-udc.c:	u32 *buf = req->req.buf + req->req.actual;
drivers/usb/isp1760/isp1760-udc.c:	req->packet_size = min(req->req.length - req->req.actual,
drivers/usb/isp1760/isp1760-udc.c:		__func__, req->packet_size, req->req.actual,
drivers/usb/isp1760/isp1760-udc.c:		req->req.length);
drivers/usb/isp1760/isp1760-udc.c:	if (req->packet_size)
drivers/usb/isp1760/isp1760-udc.c:		isp1760_udc_write(udc, DC_BUFLEN, req->packet_size);
drivers/usb/isp1760/isp1760-udc.c:	for (i = req->packet_size; i > 2; i -= 4, ++buf)
drivers/usb/isp1760/isp1760-udc.c:	if (!req->packet_size)
drivers/usb/isp1760/isp1760-udc.c:	req->req.actual += req->packet_size;
drivers/usb/isp1760/isp1760-udc.c:	need_zlp = req->req.actual == req->req.length &&
drivers/usb/isp1760/isp1760-udc.c:		   !(req->req.length % ep->maxpacket) &&
drivers/usb/isp1760/isp1760-udc.c:		   req->packet_size && req->req.zero;
drivers/usb/isp1760/isp1760-udc.c:		 req, req->req.actual, req->req.length, ep->maxpacket,
drivers/usb/isp1760/isp1760-udc.c:		 req->packet_size, req->req.zero, need_zlp);
drivers/usb/isp1760/isp1760-udc.c:	if (req->req.actual == req->req.length && !need_zlp) {
drivers/usb/isp1760/isp1760-udc.c:		list_del(&req->queue);
drivers/usb/isp1760/isp1760-udc.c:	if (req->wLength != cpu_to_le16(2) || req->wValue != cpu_to_le16(0))
drivers/usb/isp1760/isp1760-udc.c:	switch (req->bRequestType) {
drivers/usb/isp1760/isp1760-udc.c:		ep = isp1760_udc_find_ep(udc, le16_to_cpu(req->wIndex));
drivers/usb/isp1760/isp1760-udc.c:	switch (req->bRequest) {
drivers/usb/isp1760/isp1760-udc.c:		switch (req->bRequestType) {
drivers/usb/isp1760/isp1760-udc.c:			u16 index = le16_to_cpu(req->wIndex);
drivers/usb/isp1760/isp1760-udc.c:			if (req->wLength != cpu_to_le16(0) ||
drivers/usb/isp1760/isp1760-udc.c:			    req->wValue != cpu_to_le16(USB_ENDPOINT_HALT))
drivers/usb/isp1760/isp1760-udc.c:		switch (req->bRequestType) {
drivers/usb/isp1760/isp1760-udc.c:			u16 index = le16_to_cpu(req->wIndex);
drivers/usb/isp1760/isp1760-udc.c:			if (req->wLength != cpu_to_le16(0) ||
drivers/usb/isp1760/isp1760-udc.c:			    req->wValue != cpu_to_le16(USB_ENDPOINT_HALT))
drivers/usb/isp1760/isp1760-udc.c:		if (req->bRequestType != (USB_DIR_OUT | USB_RECIP_DEVICE))
drivers/usb/isp1760/isp1760-udc.c:		return isp1760_udc_set_address(udc, le16_to_cpu(req->wValue));
drivers/usb/isp1760/isp1760-udc.c:		if (req->bRequestType != (USB_DIR_OUT | USB_RECIP_DEVICE))
drivers/usb/isp1760/isp1760-udc.c:		usb_gadget_set_state(&udc->gadget, req->wValue ?
drivers/usb/isp1760/isp1760-udc.c:		list_del(&req->queue);
drivers/usb/isp1760/isp1760-udc.c:	return &req->req;
drivers/usb/isp1760/isp1760-udc.c:	_req->status = -EINPROGRESS;
drivers/usb/isp1760/isp1760-udc.c:	_req->actual = 0;
drivers/usb/isp1760/isp1760-udc.c:		_req->length, _req->zero ? " (zlp)" : "", uep, uep->addr);
drivers/usb/isp1760/isp1760-udc.c:	req->ep = uep;
drivers/usb/isp1760/isp1760-udc.c:		if (_req->length != udc->ep0_length &&
drivers/usb/isp1760/isp1760-udc.c:				__func__, _req->length, req);
drivers/usb/isp1760/isp1760-udc.c:			list_add_tail(&req->queue, &uep->queue);
drivers/usb/isp1760/isp1760-udc.c:			list_add_tail(&req->queue, &uep->queue);
drivers/usb/isp1760/isp1760-udc.c:		list_add_tail(&req->queue, &uep->queue);
drivers/usb/isp1760/isp1760-udc.c:		req->ep = NULL;
drivers/usb/isp1760/isp1760-udc.c:	if (req->ep != uep)
drivers/usb/isp1760/isp1760-udc.c:		list_del(&req->queue);
drivers/usb/isp1760/isp1760-if.c:		if (of_property_read_bool(dp, "dreq-polarity"))
drivers/usb/usbip/vudc_transfer.c:		dev_len = req->req.length - req->req.actual;
drivers/usb/usbip/vudc_transfer.c:			rbuf_pos = req->req.buf + req->req.actual;
drivers/usb/usbip/vudc_transfer.c:			req->req.actual += len;
drivers/usb/usbip/vudc_transfer.c:				req->req.status = 0;
drivers/usb/usbip/vudc_transfer.c:				req->req.status = 0;
drivers/usb/usbip/vudc_transfer.c:					req->req.status = -EOVERFLOW;
drivers/usb/usbip/vudc_transfer.c:					req->req.status = 0;
drivers/usb/usbip/vudc_transfer.c:			if (req->req.length == req->req.actual) {
drivers/usb/usbip/vudc_transfer.c:				if (req->req.zero && to_host)
drivers/usb/usbip/vudc_transfer.c:					req->req.status = 0;
drivers/usb/usbip/vudc_transfer.c:		if (req->req.status != -EINPROGRESS) {
drivers/usb/usbip/vudc_transfer.c:			list_del_init(&req->req_entry);
drivers/usb/usbip/vudc_transfer.c:			usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/usbip/vudc_dev.c:		list_del_init(&req->req_entry);
drivers/usb/usbip/vudc_dev.c:		req->req.status = -ESHUTDOWN;
drivers/usb/usbip/vudc_dev.c:		usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/usbip/vudc_dev.c:	INIT_LIST_HEAD(&req->req_entry);
drivers/usb/usbip/vudc_dev.c:	return &req->req;
drivers/usb/usbip/vudc_dev.c:	_req->actual = 0;
drivers/usb/usbip/vudc_dev.c:	_req->status = -EINPROGRESS;
drivers/usb/usbip/vudc_dev.c:	list_add_tail(&req->req_entry, &ep->req_queue);
drivers/usb/usbip/vudc_dev.c:	udc = req->udc;
drivers/usb/usbip/vudc_dev.c:			_req->status = -ECONNRESET;
drivers/usb/usbip/vudc_sysfs.c:	list_del(&usb_req->req_entry);
drivers/usb/usbip/vudc_sysfs.c:	if (usb_req->req.length > sizeof(*ddesc)) {
drivers/usb/usbip/vudc_sysfs.c:	memcpy(ddesc, usb_req->req.buf, sizeof(*ddesc));
drivers/usb/usbip/vudc_sysfs.c:	usb_req->req.status = 0;
drivers/usb/usbip/vudc_sysfs.c:	usb_req->req.actual = usb_req->req.length;
drivers/usb/usbip/vudc_sysfs.c:	usb_gadget_giveback_request(&(ep0->ep), &(usb_req->req));
drivers/usb/usbip/vhci_hcd.c:		switch (ctrlreq->bRequest) {
drivers/usb/usbip/vhci_hcd.c:				 ctrlreq->wValue, vdev->rhport);
drivers/usb/usbip/vhci_hcd.c:			if (ctrlreq->wValue == cpu_to_le16(USB_DT_DEVICE << 8))
drivers/usb/usbip/vhci_hcd.c:				ctrlreq->bRequest,
drivers/usb/usbip/vhci_hcd.c:				ctrlreq->wValue);
drivers/usb/usbip/stub_rx.c:	return (req->bRequest == USB_REQ_CLEAR_FEATURE) &&
drivers/usb/usbip/stub_rx.c:	       (req->bRequestType == USB_RECIP_ENDPOINT) &&
drivers/usb/usbip/stub_rx.c:	       (req->wValue == USB_ENDPOINT_HALT);
drivers/usb/usbip/stub_rx.c:	return (req->bRequest == USB_REQ_SET_INTERFACE) &&
drivers/usb/usbip/stub_rx.c:		(req->bRequestType == USB_RECIP_INTERFACE);
drivers/usb/usbip/stub_rx.c:	return (req->bRequest == USB_REQ_SET_CONFIGURATION) &&
drivers/usb/usbip/stub_rx.c:		(req->bRequestType == USB_RECIP_DEVICE);
drivers/usb/usbip/stub_rx.c:	value = le16_to_cpu(req->wValue);
drivers/usb/usbip/stub_rx.c:	index = le16_to_cpu(req->wIndex);
drivers/usb/usbip/stub_rx.c:	if ((req->bRequest == USB_REQ_SET_FEATURE) &&
drivers/usb/usbip/stub_rx.c:	    (req->bRequestType == USB_RT_PORT) &&
drivers/usb/usbip/stub_rx.c:	target_endp = le16_to_cpu(req->wIndex) & 0x000f;
drivers/usb/usbip/stub_rx.c:	target_dir = le16_to_cpu(req->wIndex) & 0x0080;
drivers/usb/usbip/stub_rx.c:	alternate = le16_to_cpu(req->wValue);
drivers/usb/usbip/stub_rx.c:	interface = le16_to_cpu(req->wIndex);
drivers/usb/usbip/stub_rx.c:	config = le16_to_cpu(req->wValue);
drivers/usb/phy/phy-tegra-usb.c:	val |= UTMIP_BIAS_DEBOUNCE_A(phy->freq->debounce);
drivers/usb/phy/phy-tegra-usb.c:		val |= UTMIP_PLL_ACTIVE_DLY_COUNT(phy->freq->active_delay) |
drivers/usb/phy/phy-tegra-usb.c:			UTMIP_PLLU_STABLE_COUNT(phy->freq->stable_count);
drivers/usb/phy/phy-tegra-usb.c:		val |= UTMIP_XTAL_FREQ_COUNT(phy->freq->xtal_freq_count) |
drivers/usb/phy/phy-tegra-usb.c:			UTMIP_PLLU_ENABLE_DLY_COUNT(phy->freq->enable_delay);
drivers/usb/gadget/udc/renesas_usb3.c:		usb3_ep->num, usb3_req->req.length, usb3_req->req.actual,
drivers/usb/gadget/udc/renesas_usb3.c:	usb3_req->req.status = status;
drivers/usb/gadget/udc/renesas_usb3.c:	list_del_init(&usb3_req->queue);
drivers/usb/gadget/udc/renesas_usb3.c:	usb_gadget_giveback_request(&usb3_ep->ep, &usb3_req->req);
drivers/usb/gadget/udc/renesas_usb3.c:	struct usb_request *req = &usb3_req->req;
drivers/usb/gadget/udc/renesas_usb3.c:	if ((!req->zero && req->actual == req->length) ||
drivers/usb/gadget/udc/renesas_usb3.c:	    (req->actual % usb3_ep->ep.maxpacket) || (req->length == 0))
drivers/usb/gadget/udc/renesas_usb3.c:	int len = min_t(unsigned, usb3_req->req.length - usb3_req->req.actual,
drivers/usb/gadget/udc/renesas_usb3.c:	u8 *buf = usb3_req->req.buf + usb3_req->req.actual;
drivers/usb/gadget/udc/renesas_usb3.c:	usb3_req->req.actual += len;
drivers/usb/gadget/udc/renesas_usb3.c:	int len = min_t(unsigned, usb3_req->req.length - usb3_req->req.actual,
drivers/usb/gadget/udc/renesas_usb3.c:	u8 *buf = usb3_req->req.buf + usb3_req->req.actual;
drivers/usb/gadget/udc/renesas_usb3.c:	usb3_req->req.actual += len;
drivers/usb/gadget/udc/renesas_usb3.c:		if (!usb3_req->req.length)
drivers/usb/gadget/udc/renesas_usb3.c:		if (usb3_req->req.length)
drivers/usb/gadget/udc/renesas_usb3.c:	if (usb3_req->req.length > USB3_DMA_MAX_XFER_SIZE_ALL_PRDS) {
drivers/usb/gadget/udc/renesas_usb3.c:			__func__, usb3_req->req.length);
drivers/usb/gadget/udc/renesas_usb3.c:	if (!usb3_req->req.length)
drivers/usb/gadget/udc/renesas_usb3.c:		if (usb_gadget_map_request(&usb3->gadget, &usb3_req->req,
drivers/usb/gadget/udc/renesas_usb3.c:			usb_gadget_unmap_request(&usb3->gadget, &usb3_req->req,
drivers/usb/gadget/udc/renesas_usb3.c:	u32 remain = usb3_req->req.length;
drivers/usb/gadget/udc/renesas_usb3.c:	u32 dma = usb3_req->req.dma;
drivers/usb/gadget/udc/renesas_usb3.c:	struct usb_request *req = &usb3_req->req;
drivers/usb/gadget/udc/renesas_usb3.c:			len = req->length % USB3_DMA_MAX_XFER_SIZE;
drivers/usb/gadget/udc/renesas_usb3.c:		req->actual += len - remain;
drivers/usb/gadget/udc/renesas_usb3.c:		_req->length);
drivers/usb/gadget/udc/renesas_usb3.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/renesas_usb3.c:	_req->actual = 0;
drivers/usb/gadget/udc/renesas_usb3.c:	list_add_tail(&usb3_req->queue, &usb3_ep->queue);
drivers/usb/gadget/udc/renesas_usb3.c:	usb3->ep0_req->buf = &usb3->ep0_buf;
drivers/usb/gadget/udc/renesas_usb3.c:	usb3->ep0_req->length = len;
drivers/usb/gadget/udc/renesas_usb3.c:	usb3->ep0_req->complete = complete;
drivers/usb/gadget/udc/renesas_usb3.c:			__func__, usb3_req->req.length, usb3_req->req.actual);
drivers/usb/gadget/udc/renesas_usb3.c:	INIT_LIST_HEAD(&usb3_req->queue);
drivers/usb/gadget/udc/renesas_usb3.c:	return &usb3_req->req;
drivers/usb/gadget/udc/renesas_usb3.c:		_req->length);
drivers/usb/gadget/udc/fsl_qe_udc.c:	/* the req->queue pointer is used by ep_queue() func, in which
drivers/usb/gadget/udc/fsl_qe_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/fsl_qe_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (req->mapped) {
drivers/usb/gadget/udc/fsl_qe_udc.c:			req->req.dma, req->req.length,
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->mapped = 0;
drivers/usb/gadget/udc/fsl_qe_udc.c:			req->req.dma, req->req.length,
drivers/usb/gadget/udc/fsl_qe_udc.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/fsl_qe_udc.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/fsl_qe_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/fsl_qe_udc.c:		cp = (u8 *)(req->req.buf) + req->req.actual;
drivers/usb/gadget/udc/fsl_qe_udc.c:			req->req.actual += fsize;
drivers/usb/gadget/udc/fsl_qe_udc.c:					(req->req.actual >= req->req.length)) {
drivers/usb/gadget/udc/fsl_qe_udc.c:		last_len = min_t(unsigned, req->req.length - ep->sent,
drivers/usb/gadget/udc/fsl_qe_udc.c:		/* zlp needed when req->re.zero is set */
drivers/usb/gadget/udc/fsl_qe_udc.c:		if (req->req.zero) {
drivers/usb/gadget/udc/fsl_qe_udc.c:				(req->req.length % ep->ep.maxpacket) != 0)
drivers/usb/gadget/udc/fsl_qe_udc.c:		if (((ep->tx_req->req.length - ep->sent) <= 0) && !zlp) {
drivers/usb/gadget/udc/fsl_qe_udc.c:	size = min_t(u32, (ep->tx_req->req.length - ep->sent),
drivers/usb/gadget/udc/fsl_qe_udc.c:	buf = (u8 *)ep->tx_req->req.buf + ep->sent;
drivers/usb/gadget/udc/fsl_qe_udc.c:		ep->tx_req->req.actual += size;
drivers/usb/gadget/udc/fsl_qe_udc.c:	if ((req->req.length - ep->sent) > 0)
drivers/usb/gadget/udc/fsl_qe_udc.c:		if ((ep->tx_req->req.length - ep->sent) <= 0) {
drivers/usb/gadget/udc/fsl_qe_udc.c:			ep->tx_req->req.actual = (unsigned int)ep->sent;
drivers/usb/gadget/udc/fsl_qe_udc.c:				cp = (u8 *)(req->req.buf) + req->req.actual;
drivers/usb/gadget/udc/fsl_qe_udc.c:					req->req.actual += fsize;
drivers/usb/gadget/udc/fsl_qe_udc.c:						|| (req->req.actual >=
drivers/usb/gadget/udc/fsl_qe_udc.c:							req->req.length)) {
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/fsl_qe_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/fsl_qe_udc.c:	return &req->req;
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (!_req || !req->req.complete || !req->req.buf
drivers/usb/gadget/udc/fsl_qe_udc.c:			|| !list_empty(&req->queue)) {
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->ep = ep;
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (req->req.dma == DMA_ADDR_INVALID) {
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->req.dma = dma_map_single(ep->udc->gadget.dev.parent,
drivers/usb/gadget/udc/fsl_qe_udc.c:					req->req.buf,
drivers/usb/gadget/udc/fsl_qe_udc.c:					req->req.length,
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->mapped = 1;
drivers/usb/gadget/udc/fsl_qe_udc.c:					req->req.dma, req->req.length,
drivers/usb/gadget/udc/fsl_qe_udc.c:		req->mapped = 0;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fsl_qe_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fsl_qe_udc.c:			ep->name, req->req.length);
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (ep_index(ep) == 0 && req->req.length > 0) {
drivers/usb/gadget/udc/fsl_qe_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/fsl_qe_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.buf = NULL;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.length = 2;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.buf = udc->statusbuf;
drivers/usb/gadget/udc/fsl_qe_udc.c:	*(u16 *)req->req.buf = cpu_to_le16(usb_status);
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fsl_qe_udc.c:	req->req.complete = ownercomplete;
drivers/usb/gadget/udc/fsl_qe_udc.c:	status = __qe_ep_queue(&ep->ep, &req->req);
drivers/usb/gadget/udc/bcm63xx_udc.c:	unsigned int bytes_left = breq->req.length - breq->offset;
drivers/usb/gadget/udc/bcm63xx_udc.c:	breq->bd_bytes = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	breq->iudma = iudma;
drivers/usb/gadget/udc/bcm63xx_udc.c:	if ((bytes_left % iudma->max_pkt == 0) && bytes_left && breq->req.zero)
drivers/usb/gadget/udc/bcm63xx_udc.c:		d->address = breq->req.dma + breq->offset;
drivers/usb/gadget/udc/bcm63xx_udc.c:		breq->offset += n_bytes;
drivers/usb/gadget/udc/bcm63xx_udc.c:		breq->bd_bytes += n_bytes;
drivers/usb/gadget/udc/bcm63xx_udc.c:			usb_gadget_unmap_request(&udc->gadget, &breq->req,
drivers/usb/gadget/udc/bcm63xx_udc.c:			list_del(&breq->queue);
drivers/usb/gadget/udc/bcm63xx_udc.c:			breq->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/bcm63xx_udc.c:			usb_gadget_giveback_request(&iudma->bep->ep, &breq->req);
drivers/usb/gadget/udc/bcm63xx_udc.c:	return &breq->req;
drivers/usb/gadget/udc/bcm63xx_udc.c:	if (unlikely(!req || !req->complete || !req->buf || !ep))
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->actual = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->status = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	breq->offset = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:		list_add_tail(&breq->queue, &bep->queue);
drivers/usb/gadget/udc/bcm63xx_udc.c:	usb_gadget_unmap_request(&udc->gadget, &breq->req, bep->iudma->is_tx);
drivers/usb/gadget/udc/bcm63xx_udc.c:		list_del(&breq->queue);
drivers/usb/gadget/udc/bcm63xx_udc.c:		list_del(&breq->queue);
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->status = -ESHUTDOWN;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->complete(ep, req);
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->actual = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	breq->offset = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->status = status;
drivers/usb/gadget/udc/bcm63xx_udc.c:		req->actual = 0;
drivers/usb/gadget/udc/bcm63xx_udc.c:	if (req->complete) {
drivers/usb/gadget/udc/bcm63xx_udc.c:		req->complete(&udc->bep[0].ep, req);
drivers/usb/gadget/udc/bcm63xx_udc.c:	return req->actual;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->buf = udc->ep0_ctrl_buf;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->length = length;
drivers/usb/gadget/udc/bcm63xx_udc.c:	req->complete = NULL;
drivers/usb/gadget/udc/bcm63xx_udc.c:			req->actual += rc;
drivers/usb/gadget/udc/bcm63xx_udc.c:			if (req->actual >= req->length || breq->bd_bytes > rc) {
drivers/usb/gadget/udc/bcm63xx_udc.c:				req->actual = min(req->actual, req->length);
drivers/usb/gadget/udc/bcm63xx_udc.c:		req = &breq->req;
drivers/usb/gadget/udc/bcm63xx_udc.c:			req->actual += rc;
drivers/usb/gadget/udc/bcm63xx_udc.c:			if (req->actual >= req->length || breq->bd_bytes > rc) {
drivers/usb/gadget/udc/bcm63xx_udc.c:				list_del(&breq->queue);
drivers/usb/gadget/udc/bcm63xx_udc.c:				req->actual = min(req->actual, req->length);
drivers/usb/gadget/udc/bcm63xx_udc.c:		if (req->complete)
drivers/usb/gadget/udc/bcm63xx_udc.c:			req->complete(&bep->ep, req);
drivers/usb/gadget/udc/net2280.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/net2280.c:				&req->td_dma);
drivers/usb/gadget/udc/net2280.c:		req->td = td;
drivers/usb/gadget/udc/net2280.c:	return &req->req;
drivers/usb/gadget/udc/net2280.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/net2280.c:	if (req->td)
drivers/usb/gadget/udc/net2280.c:		dma_pool_free(ep->dev->requests, req->td, req->td_dma);
drivers/usb/gadget/udc/net2280.c:		buf = req->buf + req->actual;
drivers/usb/gadget/udc/net2280.c:		total = req->length - req->actual;
drivers/usb/gadget/udc/net2280.c:	u8			*buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/net2280.c:	tmp = req->req.length - req->req.actual;
drivers/usb/gadget/udc/net2280.c:			req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/net2280.c:	req->req.actual += count;
drivers/usb/gadget/udc/net2280.c:			req, req->req.actual, req->req.length);
drivers/usb/gadget/udc/net2280.c:	return is_short || req->req.actual == req->req.length;
drivers/usb/gadget/udc/net2280.c:	struct net2280_dma	*td = req->td;
drivers/usb/gadget/udc/net2280.c:	u32			dmacount = req->req.length;
drivers/usb/gadget/udc/net2280.c:	req->valid = valid;
drivers/usb/gadget/udc/net2280.c:	td->dmaaddr = cpu_to_le32 (req->req.dma);
drivers/usb/gadget/udc/net2280.c:			writel(req->req.dma, &dma->dmaaddr);
drivers/usb/gadget/udc/net2280.c:			tmp = min(tmp, req->req.length);
drivers/usb/gadget/udc/net2280.c:			req->td->dmacount = cpu_to_le32(req->req.length - tmp);
drivers/usb/gadget/udc/net2280.c:			req->td->dmadesc = 0;
drivers/usb/gadget/udc/net2280.c:			req->valid = 1;
drivers/usb/gadget/udc/net2280.c:		if (likely((req->req.length % ep->ep.maxpacket) ||
drivers/usb/gadget/udc/net2280.c:							req->req.zero)){
drivers/usb/gadget/udc/net2280.c:	/* init req->td, pointing to the current dummy */
drivers/usb/gadget/udc/net2280.c:	req->td->dmadesc = cpu_to_le32 (ep->td_dma);
drivers/usb/gadget/udc/net2280.c:	req->td->dmacount |= cpu_to_le32(BIT(END_OF_CHAIN));
drivers/usb/gadget/udc/net2280.c:	start_queue(ep, tmp, req->td_dma);
drivers/usb/gadget/udc/net2280.c:	ep->dummy = req->td;
drivers/usb/gadget/udc/net2280.c:	req->td = end;
drivers/usb/gadget/udc/net2280.c:	ep->td_dma = req->td_dma;
drivers/usb/gadget/udc/net2280.c:	req->td_dma = tmp;
drivers/usb/gadget/udc/net2280.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/net2280.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/net2280.c:		req->req.status = status;
drivers/usb/gadget/udc/net2280.c:		status = req->req.status;
drivers/usb/gadget/udc/net2280.c:		usb_gadget_unmap_request(&dev->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/net2280.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/net2280.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/net2280.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/net2280.c:	if (!_req || !_req->complete || !_req->buf ||
drivers/usb/gadget/udc/net2280.c:				!list_empty(&req->queue)) {
drivers/usb/gadget/udc/net2280.c:	if (_req->length > (~0 & DMA_BYTE_COUNT_MASK)) {
drivers/usb/gadget/udc/net2280.c:	if (ep->dma && _req->length == 0) {
drivers/usb/gadget/udc/net2280.c:			_ep->name, _req, _req->length, _req->buf);
drivers/usb/gadget/udc/net2280.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/net2280.c:	_req->actual = 0;
drivers/usb/gadget/udc/net2280.c:			if (ep->num == 0 && _req->length == 0) {
drivers/usb/gadget/udc/net2280.c:					/* note:  _req->short_not_ok is
drivers/usb/gadget/udc/net2280.c:					 * _req->status doesn't change for
drivers/usb/gadget/udc/net2280.c:					 * short reads (only _req->actual)
drivers/usb/gadget/udc/net2280.c:			expect = likely(req->req.zero ||
drivers/usb/gadget/udc/net2280.c:				(req->req.length % ep->ep.maxpacket));
drivers/usb/gadget/udc/net2280.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/net2280.c:	req->req.actual = req->req.length - (DMA_BYTE_COUNT_MASK & dmacount);
drivers/usb/gadget/udc/net2280.c:		if (!req->valid)
drivers/usb/gadget/udc/net2280.c:		req_dma_count = le32_to_cpup(&req->td->dmacount);
drivers/usb/gadget/udc/net2280.c:		if (unlikely(req->td->dmadesc == 0)) {
drivers/usb/gadget/udc/net2280.c:			   (req->req.length % ep->ep.maxpacket) &&
drivers/usb/gadget/udc/net2280.c:				req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/net2280.c:						req->req.length);
drivers/usb/gadget/udc/net2280.c:					req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/net2280.c:		if (&req->req == _req)
drivers/usb/gadget/udc/net2280.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/net2280.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/net2280.c:			_req->status = -ECONNRESET;
drivers/usb/gadget/udc/net2280.c:			if (likely(ep->queue.next == &req->queue)) {
drivers/usb/gadget/udc/net2280.c:				req->td->dmacount = 0;	/* invalidate */
drivers/usb/gadget/udc/net2280.c:			if (ep->dma && req->td_dma == readl(&ep->dma->dmadesc))
drivers/usb/gadget/udc/net2280.c:					&req->req, req->req.actual,
drivers/usb/gadget/udc/net2280.c:					req->req.length, req->req.buf,
drivers/usb/gadget/udc/net2280.c:					&req->req, req->req.actual,
drivers/usb/gadget/udc/net2280.c:					req->req.length, req->req.buf);
drivers/usb/gadget/udc/net2280.c:				td = req->td;
drivers/usb/gadget/udc/net2280.c:					(u32) req->td_dma,
drivers/usb/gadget/udc/net2280.c:			ep->ep.name, t, req ? &req->req : NULL);
drivers/usb/gadget/udc/net2280.c:					req->req.actual == req->req.length) ||
drivers/usb/gadget/udc/net2280.c:							!= req->td_dma)
drivers/usb/gadget/udc/net2280.c:						  req->td_dma && stuck++ > 5) {
drivers/usb/gadget/udc/net2280.c:				req->td->dmacount = 0;
drivers/usb/gadget/udc/net2280.c:		len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/net2280.c:		req->req.actual += len;
drivers/usb/gadget/udc/net2280.c:		if ((req->req.actual == req->req.length) &&
drivers/usb/gadget/udc/net2280.c:			(!req->req.zero || len != ep->ep.maxpacket) && ep->num)
drivers/usb/gadget/udc/net2280.c:			write_fifo(ep, &req->req);
drivers/usb/gadget/udc/net2280.c:			done(ep, req, (req->req.actual == req->req.length)
drivers/usb/gadget/udc/net2280.c:		 * less than req->length. NAK_OUT_PACKETS may be set,
drivers/usb/gadget/udc/net2272.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/net2272.c:	return &req->req;
drivers/usb/gadget/udc/net2272.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/net2272.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/net2272.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/net2272.c:		req->req.status = status;
drivers/usb/gadget/udc/net2272.c:		status = req->req.status;
drivers/usb/gadget/udc/net2272.c:		usb_gadget_unmap_request(&dev->gadget, &req->req,
drivers/usb/gadget/udc/net2272.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/net2272.c:			req->req.actual, req->req.length, req->req.buf);
drivers/usb/gadget/udc/net2272.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/net2272.c:	length = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/net2272.c:	req->req.actual += length;
drivers/usb/gadget/udc/net2272.c:		ep->ep.name, req->req.actual, req->req.length);
drivers/usb/gadget/udc/net2272.c:		buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/net2272.c:		if (req->req.length == req->req.actual) {
drivers/usb/gadget/udc/net2272.c:	req->req.actual += avail;
drivers/usb/gadget/udc/net2272.c:		ep->ep.name, req->req.actual, req->req.length);
drivers/usb/gadget/udc/net2272.c:		buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/net2272.c:		tmp = req->req.length - req->req.actual;
drivers/usb/gadget/udc/net2272.c:				req->req.actual == req->req.length)) {
drivers/usb/gadget/udc/net2272.c:	if (req->req.length & 1)
drivers/usb/gadget/udc/net2272.c:		ep->ep.name, req, (unsigned long long) req->req.dma);
drivers/usb/gadget/udc/net2272.c:	size = req->req.length;
drivers/usb/gadget/udc/net2272.c:		if (net2272_request_dma(ep->dev, ep->num, req->req.dma, size, 0))
drivers/usb/gadget/udc/net2272.c:		req->req.actual += size;
drivers/usb/gadget/udc/net2272.c:		if (net2272_request_dma(ep->dev, ep->num, req->req.dma, size, 1))
drivers/usb/gadget/udc/net2272.c:	if (!_req || !_req->complete || !_req->buf
drivers/usb/gadget/udc/net2272.c:			|| !list_empty(&req->queue))
drivers/usb/gadget/udc/net2272.c:		_ep->name, _req, _req->length, _req->buf,
drivers/usb/gadget/udc/net2272.c:		(unsigned long long) _req->dma, _req->zero ? "zero" : "!zero");
drivers/usb/gadget/udc/net2272.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/net2272.c:	_req->actual = 0;
drivers/usb/gadget/udc/net2272.c:		if (ep->num == 0 && _req->length == 0) {
drivers/usb/gadget/udc/net2272.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/net2272.c:		if (&req->req == _req)
drivers/usb/gadget/udc/net2272.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/net2272.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/net2272.c:		if ((req->req.length % ep->ep.maxpacket != 0) ||
drivers/usb/gadget/udc/net2272.c:				req->req.zero)
drivers/usb/gadget/udc/net2272.c:		req->req.actual += len;
drivers/usb/gadget/udc/net2272.c:		ep->ep.name, stat0, stat1, req ? &req->req : NULL);
drivers/usb/gadget/udc/net2272.c:				(req->req.actual == req->req.length) ? 0 : -EPROTO);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (WARN_ON(req->status == -EINPROGRESS))
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->buf = ptr;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->length = len;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->complete = NULL;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->zero = true;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	/* req->buf NULL means data is already there */
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (req->req.length == 0)
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		req->last_desc = 1;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (req->last_desc >= 0) {
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		       req->req.actual, req->req.length);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	chunk = req->req.length - req->req.actual;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	else if ((chunk < ep->ep.maxpacket) || !req->req.zero)
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		req->last_desc = 1;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	EPVDBG(ep, "send chunk=%d last=%d, req->act=%d mp=%d\n",
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	       chunk, req->last_desc, req->req.actual, ep->ep.maxpacket);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (chunk && req->req.buf)
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		memcpy(ep->buf, req->req.buf + req->req.actual, chunk);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->req.actual += chunk;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	remain = req->req.length - req->req.actual;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (len && req->req.buf)
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:		memcpy(req->req.buf + req->req.actual, ep->buf, len);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->req.actual += len;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (!u_req || (!u_req->complete && !req->internal)) {
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:				 u_req->complete, req->internal);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (u_req->length && !u_req->buf && !req->internal) {
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	       u_req->length, u_req->zero,
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	       u_req->short_not_ok, ep->ep0.dir_in);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	u_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	u_req->actual = 0;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->last_desc = -1;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	req->active = false;
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	} else if (u_req->length == 0) {
drivers/usb/gadget/udc/aspeed-vhub/ep0.c:	if (req && u_req == &req->req) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	unsigned int act = req->req.actual;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	unsigned int len = req->req.length;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	WARN_ON(req->active);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	else if ((chunk < ep->ep.maxpacket) || !req->req.zero)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		req->last_desc = 1;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	       req, act, len, chunk, req->last_desc);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (!req->req.dma) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:			memcpy(ep->buf, req->req.buf + act, chunk);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:			vhub_dma_workaround(req->req.buf);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		writel(req->req.dma + act, ep->epn.regs + AST_VHUB_EP_DESC_BASE);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->active = true;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	       stat, ep->epn.is_in, req, req ? req->active : 0);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (!req->active)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->active = false;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (!req->req.dma && !ep->epn.is_in && len)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		memcpy(req->req.buf + req->req.actual, ep->buf, len);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->req.actual += len;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		req->last_desc = 1;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (req->last_desc >= 0) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		if (!req || req->active)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	unsigned int act = req->act_count;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	unsigned int len = req->req.length;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->active = true;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (req->last_desc >= 0)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	while (ast_vhub_count_free_descs(ep) && req->last_desc < 0) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:			if (!chunk || !req->req.zero || (chunk % ep->ep.maxpacket) != 0)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:				req->last_desc = d_num;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		       act, len, chunk, req->last_desc, d_num,
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		desc->w0 = cpu_to_le32(req->req.dma + act);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		if (req->last_desc >= 0 || !ast_vhub_count_free_descs(ep))
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		req->act_count = act = act + chunk;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		       d_num, len, req, req ? req->active : 0);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		if (!req || !req->active)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		req->req.actual += len;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		is_last_desc = req->last_desc == d_num;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:					   (req->req.actual >= req->req.length &&
drivers/usb/gadget/udc/aspeed-vhub/epn.c:					    !req->req.zero)),
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		      is_last_desc, len, req->req.actual, req->req.length,
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		      req->req.zero, ep->ep.maxpacket);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (!u_req || !u_req->complete || !u_req->buf) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:				 u_req->complete, req->internal);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	    ((((unsigned long)u_req->buf & 7) == 0) &&
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	     (ep->epn.is_in || !(u_req->length & (u_ep->maxpacket - 1))))) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		u_req->dma = 0;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	       u_req->length, (u32)u_req->dma, u_req->zero,
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	       u_req->short_not_ok, u_req->no_interrupt,
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	u_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	u_req->actual = 0;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->act_count = 0;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->active = false;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	req->last_desc = -1;
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		if (&req->req == u_req)
drivers/usb/gadget/udc/aspeed-vhub/epn.c:	if (&req->req == u_req) {
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		       req, req->active);
drivers/usb/gadget/udc/aspeed-vhub/epn.c:		if (req->active)
drivers/usb/gadget/udc/aspeed-vhub/core.c:	bool internal = req->internal;
drivers/usb/gadget/udc/aspeed-vhub/core.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/aspeed-vhub/core.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/aspeed-vhub/core.c:		req->req.status = status;
drivers/usb/gadget/udc/aspeed-vhub/core.c:	if (req->req.dma) {
drivers/usb/gadget/udc/aspeed-vhub/core.c:						 &req->req, ep->epn.is_in);
drivers/usb/gadget/udc/aspeed-vhub/core.c:		req->req.dma = 0;
drivers/usb/gadget/udc/aspeed-vhub/core.c:		usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/aspeed-vhub/core.c:	/* Beware, lock will be dropped & req-acquired by done() */
drivers/usb/gadget/udc/aspeed-vhub/core.c:	return &req->req;
drivers/usb/gadget/udc/fsl_udc_core.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/fsl_udc_core.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/fsl_udc_core.c:		req->req.status = status;
drivers/usb/gadget/udc/fsl_udc_core.c:		status = req->req.status;
drivers/usb/gadget/udc/fsl_udc_core.c:	next_td = req->head;
drivers/usb/gadget/udc/fsl_udc_core.c:	for (j = 0; j < req->dtd_count; j++) {
drivers/usb/gadget/udc/fsl_udc_core.c:		if (j != req->dtd_count - 1) {
drivers/usb/gadget/udc/fsl_udc_core.c:	usb_gadget_unmap_request(&ep->udc->gadget, &req->req, ep_is_in(ep));
drivers/usb/gadget/udc/fsl_udc_core.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/fsl_udc_core.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/fsl_udc_core.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/fsl_udc_core.c:	 * explicitly through req->req.zero.  This is needed to enable multi-td
drivers/usb/gadget/udc/fsl_udc_core.c: * the main operation is to insert the req->queue to the eq->queue
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/fsl_udc_core.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/fsl_udc_core.c:	return &req->req;
drivers/usb/gadget/udc/fsl_udc_core.c:		lastreq->tail->next_td_ptr =
drivers/usb/gadget/udc/fsl_udc_core.c:			cpu_to_hc32(req->head->td_dma & DTD_ADDR_MASK);
drivers/usb/gadget/udc/fsl_udc_core.c:	fsl_prime_ep(ep, req->head);
drivers/usb/gadget/udc/fsl_udc_core.c:	*length = min(req->req.length - req->req.actual,
drivers/usb/gadget/udc/fsl_udc_core.c:	swap_temp = (u32) (req->req.dma + req->req.actual);
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.actual += *length;
drivers/usb/gadget/udc/fsl_udc_core.c:	/* zlp is needed if req->req.zero is set */
drivers/usb/gadget/udc/fsl_udc_core.c:	if (req->req.zero) {
drivers/usb/gadget/udc/fsl_udc_core.c:		if (*length == 0 || (*length % req->ep->ep.maxpacket) != 0)
drivers/usb/gadget/udc/fsl_udc_core.c:	} else if (req->req.length == req->req.actual)
drivers/usb/gadget/udc/fsl_udc_core.c:	if (*is_last && !req->req.no_interrupt)
drivers/usb/gadget/udc/fsl_udc_core.c:			req->head = dtd;
drivers/usb/gadget/udc/fsl_udc_core.c:		req->dtd_count++;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->tail = dtd;
drivers/usb/gadget/udc/fsl_udc_core.c:	if (!_req || !req->req.complete || !req->req.buf
drivers/usb/gadget/udc/fsl_udc_core.c:			|| !list_empty(&req->queue)) {
drivers/usb/gadget/udc/fsl_udc_core.c:		if (req->req.length > ep->ep.maxpacket)
drivers/usb/gadget/udc/fsl_udc_core.c:	req->ep = ep;
drivers/usb/gadget/udc/fsl_udc_core.c:	ret = usb_gadget_map_request(&ep->udc->gadget, &req->req, ep_is_in(ep));
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->dtd_count = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fsl_udc_core.c:		if (&req->req == _req)
drivers/usb/gadget/udc/fsl_udc_core.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/fsl_udc_core.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/fsl_udc_core.c:		_req->status = -ECONNRESET;
drivers/usb/gadget/udc/fsl_udc_core.c:		if (req->queue.next != &ep->queue) {
drivers/usb/gadget/udc/fsl_udc_core.c:			next_req = list_entry(req->queue.next, struct fsl_req,
drivers/usb/gadget/udc/fsl_udc_core.c:			fsl_prime_ep(ep, next_req->head);
drivers/usb/gadget/udc/fsl_udc_core.c:		prev_req = list_entry(req->queue.prev, struct fsl_req, queue);
drivers/usb/gadget/udc/fsl_udc_core.c:		prev_req->tail->next_td_ptr = req->tail->next_td_ptr;
drivers/usb/gadget/udc/fsl_udc_core.c: * Empty complete function used by this driver to fill in the req->complete
drivers/usb/gadget/udc/fsl_udc_core.c:	req->ep = ep;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.length = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.complete = fsl_noop_complete;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->dtd_count = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	ret = usb_gadget_map_request(&ep->udc->gadget, &req->req, ep_is_in(ep));
drivers/usb/gadget/udc/fsl_udc_core.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fsl_udc_core.c:	*((u16 *) req->req.buf) = cpu_to_le16(tmp);
drivers/usb/gadget/udc/fsl_udc_core.c:	req->ep = ep;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.length = 2;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->req.complete = fsl_noop_complete;
drivers/usb/gadget/udc/fsl_udc_core.c:	req->dtd_count = 0;
drivers/usb/gadget/udc/fsl_udc_core.c:	ret = usb_gadget_map_request(&ep->udc->gadget, &req->req, ep_is_in(ep));
drivers/usb/gadget/udc/fsl_udc_core.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fsl_udc_core.c:	curr_td = curr_req->head;
drivers/usb/gadget/udc/fsl_udc_core.c:	actual = curr_req->req.length;
drivers/usb/gadget/udc/fsl_udc_core.c:	for (j = 0; j < curr_req->dtd_count; j++) {
drivers/usb/gadget/udc/fsl_udc_core.c:		if (j != curr_req->dtd_count - 1)
drivers/usb/gadget/udc/fsl_udc_core.c:	curr_req->req.actual = actual;
drivers/usb/gadget/udc/fsl_udc_core.c:			curr_req->req.status = status;
drivers/usb/gadget/udc/fsl_udc_core.c:				&req->req, req->req.actual,
drivers/usb/gadget/udc/fsl_udc_core.c:				req->req.length, req->req.buf);
drivers/usb/gadget/udc/fsl_udc_core.c:						&req->req, req->req.actual,
drivers/usb/gadget/udc/fsl_udc_core.c:						req->req.length, req->req.buf);
drivers/usb/gadget/udc/fsl_udc_core.c:	udc->status_req->req.buf = kmalloc(8, GFP_KERNEL);
drivers/usb/gadget/udc/fsl_udc_core.c:	if (!udc->status_req->req.buf) {
drivers/usb/gadget/udc/fsl_udc_core.c:	kfree(udc_controller->status_req->req.buf);
drivers/usb/gadget/udc/snps_udc_core.c:	udc_free_request(&ep->ep, &ep->bna_dummy_req->req);
drivers/usb/gadget/udc/snps_udc_core.c:	req->req.dma = DMA_DONT_USE;
drivers/usb/gadget/udc/snps_udc_core.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/snps_udc_core.c:						&req->td_phys);
drivers/usb/gadget/udc/snps_udc_core.c:				(unsigned long)req->td_phys);
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data = dma_desc;
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data_last = NULL;
drivers/usb/gadget/udc/snps_udc_core.c:		req->chain_len = 1;
drivers/usb/gadget/udc/snps_udc_core.c:	return &req->req;
drivers/usb/gadget/udc/snps_udc_core.c:	struct udc_data_dma *td = req->td_data;
drivers/usb/gadget/udc/snps_udc_core.c:	for (i = 1; i < req->chain_len; i++) {
drivers/usb/gadget/udc/snps_udc_core.c:	BUG_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/snps_udc_core.c:	if (req->td_data) {
drivers/usb/gadget/udc/snps_udc_core.c:		VDBG(ep->dev, "req->td_data=%p\n", req->td_data);
drivers/usb/gadget/udc/snps_udc_core.c:		if (req->chain_len > 1)
drivers/usb/gadget/udc/snps_udc_core.c:		dma_pool_free(ep->dev->data_requests, req->td_data,
drivers/usb/gadget/udc/snps_udc_core.c:							req->td_phys);
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->status |= AMD_BIT(UDC_DMA_IN_STS_L);
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->next = req->td_phys;
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->status
drivers/usb/gadget/udc/snps_udc_core.c:			= AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:			req->td_data, req->td_data->status);
drivers/usb/gadget/udc/snps_udc_core.c:	req_buf = req->buf + req->actual;
drivers/usb/gadget/udc/snps_udc_core.c:	remaining = req->length - req->actual;
drivers/usb/gadget/udc/snps_udc_core.c:	buf_space = req->req.length - req->req.actual;
drivers/usb/gadget/udc/snps_udc_core.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/snps_udc_core.c:			req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/snps_udc_core.c:	req->req.actual += bytes;
drivers/usb/gadget/udc/snps_udc_core.c:		|| ((req->req.actual == req->req.length) && !req->req.zero))
drivers/usb/gadget/udc/snps_udc_core.c:	unsigned long bytes = req->req.length;
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->status &= AMD_CLEAR_BIT(UDC_DMA_IN_STS_L);
drivers/usb/gadget/udc/snps_udc_core.c:	len = req->req.length / ep->ep.maxpacket;
drivers/usb/gadget/udc/snps_udc_core.c:	if (req->req.length % ep->ep.maxpacket)
drivers/usb/gadget/udc/snps_udc_core.c:	if (len > req->chain_len) {
drivers/usb/gadget/udc/snps_udc_core.c:		if (req->chain_len > 1)
drivers/usb/gadget/udc/snps_udc_core.c:		req->chain_len = len;
drivers/usb/gadget/udc/snps_udc_core.c:	td = req->td_data;
drivers/usb/gadget/udc/snps_udc_core.c:						req->td_data->next);
drivers/usb/gadget/udc/snps_udc_core.c:			td->bufptr = req->req.dma + i; /* assign buffer */
drivers/usb/gadget/udc/snps_udc_core.c:				req->td_data->next = dma_addr;
drivers/usb/gadget/udc/snps_udc_core.c:			 *	req->td_data->next = virt_to_phys(td);
drivers/usb/gadget/udc/snps_udc_core.c:				req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:					AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data_last = td;
drivers/usb/gadget/udc/snps_udc_core.c:	VDBG(ep->dev, "prep_dma ep%d req->td_data=%p\n",
drivers/usb/gadget/udc/snps_udc_core.c:			ep->num, req->td_data);
drivers/usb/gadget/udc/snps_udc_core.c:	req->td_data->bufptr = req->req.dma;
drivers/usb/gadget/udc/snps_udc_core.c:	req->td_data->status |= AMD_BIT(UDC_DMA_IN_STS_L);
drivers/usb/gadget/udc/snps_udc_core.c:			if (req->req.length == ep->ep.maxpacket) {
drivers/usb/gadget/udc/snps_udc_core.c:				req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:					AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:		VDBG(ep->dev, "IN: use_dma_ppb=%d req->req.len=%d "
drivers/usb/gadget/udc/snps_udc_core.c:				use_dma_ppb, req->req.length,
drivers/usb/gadget/udc/snps_udc_core.c:		if (!use_dma_ppb || req->req.length < ep->ep.maxpacket
drivers/usb/gadget/udc/snps_udc_core.c:			req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:				AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:						req->req.length,
drivers/usb/gadget/udc/snps_udc_core.c:			req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:				AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:			AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:		req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:			AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:		usb_gadget_unmap_request(&dev->gadget, &req->req, ep->in);
drivers/usb/gadget/udc/snps_udc_core.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/snps_udc_core.c:		req->req.status = sts;
drivers/usb/gadget/udc/snps_udc_core.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/snps_udc_core.c:		&req->req, req->req.length, ep->ep.name, sts);
drivers/usb/gadget/udc/snps_udc_core.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/snps_udc_core.c:	td = req->td_data;
drivers/usb/gadget/udc/snps_udc_core.c:	td = req->td_data;
drivers/usb/gadget/udc/snps_udc_core.c:	if (!usbep || !usbreq || !usbreq->complete || !usbreq->buf
drivers/usb/gadget/udc/snps_udc_core.c:			|| !list_empty(&req->queue))
drivers/usb/gadget/udc/snps_udc_core.c:	VDBG(dev, "%s queue req %p, len %d req->td_data=%p buf %p\n",
drivers/usb/gadget/udc/snps_udc_core.c:			usbep->name, usbreq, usbreq->length,
drivers/usb/gadget/udc/snps_udc_core.c:			req->td_data, usbreq->buf);
drivers/usb/gadget/udc/snps_udc_core.c:	usbreq->actual = 0;
drivers/usb/gadget/udc/snps_udc_core.c:	usbreq->status = -EINPROGRESS;
drivers/usb/gadget/udc/snps_udc_core.c:	req->dma_done = 0;
drivers/usb/gadget/udc/snps_udc_core.c:		if (usbreq->length == 0) {
drivers/usb/gadget/udc/snps_udc_core.c:				req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:					AMD_ADDBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:					memcpy(ep->bna_dummy_req->td_data,
drivers/usb/gadget/udc/snps_udc_core.c:						req->td_data,
drivers/usb/gadget/udc/snps_udc_core.c:			writel(req->td_phys, &ep->regs->desptr);
drivers/usb/gadget/udc/snps_udc_core.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/snps_udc_core.c:			req->dma_going = 1;
drivers/usb/gadget/udc/snps_udc_core.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/snps_udc_core.c:		if (ep->dma && req->dma_going) {
drivers/usb/gadget/udc/snps_udc_core.c:				dma_sts = AMD_GETBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:					writel(ep->bna_dummy_req->td_phys,
drivers/usb/gadget/udc/snps_udc_core.c:			dma_done = AMD_GETBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:				memcpy(req->td_data, ep->bna_dummy_req->td_data,
drivers/usb/gadget/udc/snps_udc_core.c:				count = AMD_GETBITS(req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:				VDBG(dev, "req->td_data=%p\n", req->td_data);
drivers/usb/gadget/udc/snps_udc_core.c:					if (!count && req->req.length
drivers/usb/gadget/udc/snps_udc_core.c:			tmp = req->req.length - req->req.actual;
drivers/usb/gadget/udc/snps_udc_core.c:					req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/snps_udc_core.c:			req->req.actual += count;
drivers/usb/gadget/udc/snps_udc_core.c:			req->dma_going = 0;
drivers/usb/gadget/udc/snps_udc_core.c:				if (req->dma_going == 0) {
drivers/usb/gadget/udc/snps_udc_core.c:					writel(req->td_phys,
drivers/usb/gadget/udc/snps_udc_core.c:					req->dma_going = 1;
drivers/usb/gadget/udc/snps_udc_core.c:					writel(ep->bna_dummy_req->td_phys,
drivers/usb/gadget/udc/snps_udc_core.c:					req->req.actual = req->req.length;
drivers/usb/gadget/udc/snps_udc_core.c:				req->req.actual = req->req.length;
drivers/usb/gadget/udc/snps_udc_core.c:			if (req->req.actual == req->req.length) {
drivers/usb/gadget/udc/snps_udc_core.c:				req->dma_going = 0;
drivers/usb/gadget/udc/snps_udc_core.c:				udc_txfifo_write(ep, &req->req);
drivers/usb/gadget/udc/snps_udc_core.c:				len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/snps_udc_core.c:				req->req.actual += len;
drivers/usb/gadget/udc/snps_udc_core.c:				if (req->req.actual == req->req.length
drivers/usb/gadget/udc/snps_udc_core.c:			} else if (req && !req->dma_going) {
drivers/usb/gadget/udc/snps_udc_core.c:				VDBG(dev, "IN DMA : req=%p req->td_data=%p\n",
drivers/usb/gadget/udc/snps_udc_core.c:					req, req->td_data);
drivers/usb/gadget/udc/snps_udc_core.c:				if (req->td_data) {
drivers/usb/gadget/udc/snps_udc_core.c:					req->dma_going = 1;
drivers/usb/gadget/udc/snps_udc_core.c:					if (use_dma_ppb && req->req.length >
drivers/usb/gadget/udc/snps_udc_core.c:						req->td_data->status &=
drivers/usb/gadget/udc/snps_udc_core.c:					writel(req->td_phys, &ep->regs->desptr);
drivers/usb/gadget/udc/snps_udc_core.c:					req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:						req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:				writel(ep->bna_dummy_req->td_phys,
drivers/usb/gadget/udc/snps_udc_core.c:					writel(req->td_phys, &ep->regs->desptr);
drivers/usb/gadget/udc/snps_udc_core.c:					req->td_data->status =
drivers/usb/gadget/udc/snps_udc_core.c:						req->td_data->status,
drivers/usb/gadget/udc/snps_udc_core.c:					req->req.actual = req->req.length;
drivers/usb/gadget/udc/snps_udc_core.c:					udc_txfifo_write(ep, &req->req);
drivers/usb/gadget/udc/snps_udc_core.c:					len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/snps_udc_core.c:					req->req.actual += len;
drivers/usb/gadget/udc/snps_udc_core.c:					if (req->req.actual == req->req.length
drivers/usb/gadget/udc/goku_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/goku_udc.c:	return &req->req;
drivers/usb/gadget/udc/goku_udc.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/goku_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/goku_udc.c:	if (likely(req->req.status == -EINPROGRESS))
drivers/usb/gadget/udc/goku_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/goku_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/goku_udc.c:		usb_gadget_unmap_request(&dev->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/goku_udc.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/goku_udc.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/goku_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/goku_udc.c:	length = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/goku_udc.c:	req->req.actual += length;
drivers/usb/gadget/udc/goku_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/goku_udc.c:		if (likely(req->req.length != req->req.actual)
drivers/usb/gadget/udc/goku_udc.c:				|| req->req.zero)
drivers/usb/gadget/udc/goku_udc.c:		req->req.length - req->req.actual, req);
drivers/usb/gadget/udc/goku_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/goku_udc.c:		bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/goku_udc.c:		req->req.actual += size;
drivers/usb/gadget/udc/goku_udc.c:			req, req->req.actual, req->req.length);
drivers/usb/gadget/udc/goku_udc.c:				if (req->req.status != -EOVERFLOW)
drivers/usb/gadget/udc/goku_udc.c:				req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/goku_udc.c:		if (unlikely(is_short || req->req.actual == req->req.length)) {
drivers/usb/gadget/udc/goku_udc.c:	u32				start = req->req.dma;
drivers/usb/gadget/udc/goku_udc.c:	u32				end = start + req->req.length - 1;
drivers/usb/gadget/udc/goku_udc.c:		if (unlikely(req->req.length == 0))
drivers/usb/gadget/udc/goku_udc.c:		else if ((req->req.length % ep->ep.maxpacket) != 0
drivers/usb/gadget/udc/goku_udc.c:					|| req->req.zero)
drivers/usb/gadget/udc/goku_udc.c:		req->req.actual = readl(&regs->in_dma_current);
drivers/usb/gadget/udc/goku_udc.c:		req->req.actual = readl(&regs->out_dma_current);
drivers/usb/gadget/udc/goku_udc.c:	req->req.actual -= req->req.dma;
drivers/usb/gadget/udc/goku_udc.c:	req->req.actual++;
drivers/usb/gadget/udc/goku_udc.c:		req->req.actual, req->req.length, req);
drivers/usb/gadget/udc/goku_udc.c:	req->req.actual = (curr - req->req.dma) + 1;
drivers/usb/gadget/udc/goku_udc.c:	req->req.status = status;
drivers/usb/gadget/udc/goku_udc.c:		req->req.actual, req->req.length);
drivers/usb/gadget/udc/goku_udc.c:	req->req.actual = req->req.length;
drivers/usb/gadget/udc/goku_udc.c:	req->req.status = 0;
drivers/usb/gadget/udc/goku_udc.c:	if (unlikely(!_req || !_req->complete
drivers/usb/gadget/udc/goku_udc.c:			|| !_req->buf || !list_empty(&req->queue)))
drivers/usb/gadget/udc/goku_udc.c:		status = usb_gadget_map_request(&dev->gadget, &req->req,
drivers/usb/gadget/udc/goku_udc.c:			_ep->name, _req, _req->length, _req->buf);
drivers/usb/gadget/udc/goku_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/goku_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/goku_udc.c:		_req->zero = 1;
drivers/usb/gadget/udc/goku_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/goku_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/goku_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/goku_udc.c:	if (ep->dma && ep->queue.next == &req->queue && !ep->stopped) {
drivers/usb/gadget/udc/goku_udc.c:	} else if (!list_empty(&req->queue))
drivers/usb/gadget/udc/goku_udc.c:			if (ep->dma && req->queue.prev == &ep->queue) {
drivers/usb/gadget/udc/goku_udc.c:				tmp -= req->req.dma;
drivers/usb/gadget/udc/goku_udc.c:				tmp = req->req.actual;
drivers/usb/gadget/udc/goku_udc.c:				   &req->req, tmp, req->req.length,
drivers/usb/gadget/udc/goku_udc.c:				   req->req.buf);
drivers/usb/gadget/udc/r8a66597-udc.c:	if (req->req.length == 0) {
drivers/usb/gadget/udc/r8a66597-udc.c:	return usb_gadget_map_request(&r8a66597->gadget, &req->req, dma->dir);
drivers/usb/gadget/udc/r8a66597-udc.c:	usb_gadget_unmap_request(&r8a66597->gadget, &req->req, ep->dma->dir);
drivers/usb/gadget/udc/r8a66597-udc.c:	BUG_ON(req->req.length == 0);
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597_sudmac_write(r8a66597, req->req.dma, CH0BA);
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597_sudmac_write(r8a66597, req->req.length, CH0BBC);
drivers/usb/gadget/udc/r8a66597-udc.c:	if (req->req.length == 0) {
drivers/usb/gadget/udc/r8a66597-udc.c:				DIV_ROUND_UP(req->req.length, ep->ep.maxpacket),
drivers/usb/gadget/udc/r8a66597-udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/r8a66597-udc.c:		req->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/r8a66597-udc.c:		req->req.status = status;
drivers/usb/gadget/udc/r8a66597-udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/r8a66597-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/r8a66597-udc.c:	size = min(bufsize, req->req.length - req->req.actual);
drivers/usb/gadget/udc/r8a66597-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/r8a66597-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/r8a66597-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/r8a66597-udc.c:	size = min(bufsize, req->req.length - req->req.actual);
drivers/usb/gadget/udc/r8a66597-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/r8a66597-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/r8a66597-udc.c:		req->req.status = -EPIPE;
drivers/usb/gadget/udc/r8a66597-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/r8a66597-udc.c:	req_len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/r8a66597-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/r8a66597-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597->ep0_req->buf = &r8a66597->ep0_data;
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597->ep0_req->length = 2;
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/r8a66597-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/r8a66597-udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/r8a66597-udc.c:	return &req->req;
drivers/usb/gadget/udc/r8a66597-udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/r8a66597-udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/r8a66597-udc.c:	r8a66597->ep0_req->complete = nop_completion;
drivers/usb/gadget/udc/mv_u3d_core.c:	actual = curr_req->req.length;
drivers/usb/gadget/udc/mv_u3d_core.c:	while (!list_empty(&curr_req->trb_list)) {
drivers/usb/gadget/udc/mv_u3d_core.c:		curr_trb = list_entry(curr_req->trb_list.next,
drivers/usb/gadget/udc/mv_u3d_core.c:	curr_req->req.actual = actual;
drivers/usb/gadget/udc/mv_u3d_core.c:	dev_dbg(u3d->dev, "mv_u3d_done: remove req->queue\n");
drivers/usb/gadget/udc/mv_u3d_core.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/mv_u3d_core.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/mv_u3d_core.c:		req->req.status = status;
drivers/usb/gadget/udc/mv_u3d_core.c:		status = req->req.status;
drivers/usb/gadget/udc/mv_u3d_core.c:	if (!req->chain)
drivers/usb/gadget/udc/mv_u3d_core.c:			req->trb_head->trb_hw, req->trb_head->trb_dma);
drivers/usb/gadget/udc/mv_u3d_core.c:			(dma_addr_t)req->trb_head->trb_dma,
drivers/usb/gadget/udc/mv_u3d_core.c:			req->trb_count * sizeof(struct mv_u3d_trb_hw),
drivers/usb/gadget/udc/mv_u3d_core.c:		kfree(req->trb_head->trb_hw);
drivers/usb/gadget/udc/mv_u3d_core.c:	kfree(req->trb_head);
drivers/usb/gadget/udc/mv_u3d_core.c:	usb_gadget_unmap_request(&u3d->gadget, &req->req, mv_u3d_ep_dir(ep));
drivers/usb/gadget/udc/mv_u3d_core.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/mv_u3d_core.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/mv_u3d_core.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/mv_u3d_core.c:			cpu_to_le32(req->trb_head->trb_dma | DCS_ENABLE);
drivers/usb/gadget/udc/mv_u3d_core.c:	*length = req->req.length - req->req.actual;
drivers/usb/gadget/udc/mv_u3d_core.c:	u3d = req->ep->u3d;
drivers/usb/gadget/udc/mv_u3d_core.c:	temp = (u32)(req->req.dma + req->req.actual);
drivers/usb/gadget/udc/mv_u3d_core.c:	if (req->ep->ep_num == 0)
drivers/usb/gadget/udc/mv_u3d_core.c:	req->req.actual += *length;
drivers/usb/gadget/udc/mv_u3d_core.c:	direction = mv_u3d_ep_dir(req->ep);
drivers/usb/gadget/udc/mv_u3d_core.c:	if (!req->req.no_interrupt)
drivers/usb/gadget/udc/mv_u3d_core.c:	*length = min(req->req.length - req->req.actual,
drivers/usb/gadget/udc/mv_u3d_core.c:	u3d = req->ep->u3d;
drivers/usb/gadget/udc/mv_u3d_core.c:	temp = (u32)(req->req.dma + req->req.actual);
drivers/usb/gadget/udc/mv_u3d_core.c:	if (req->ep->ep_num == 0)
drivers/usb/gadget/udc/mv_u3d_core.c:	req->req.actual += *length;
drivers/usb/gadget/udc/mv_u3d_core.c:	direction = mv_u3d_ep_dir(req->ep);
drivers/usb/gadget/udc/mv_u3d_core.c:	/* zlp is needed if req->req.zero is set */
drivers/usb/gadget/udc/mv_u3d_core.c:	if (req->req.zero) {
drivers/usb/gadget/udc/mv_u3d_core.c:		if (*length == 0 || (*length % req->ep->ep.maxpacket) != 0)
drivers/usb/gadget/udc/mv_u3d_core.c:	} else if (req->req.length == req->req.actual)
drivers/usb/gadget/udc/mv_u3d_core.c:	if (*is_last && !req->req.no_interrupt)
drivers/usb/gadget/udc/mv_u3d_core.c:	u3d = req->ep->u3d;
drivers/usb/gadget/udc/mv_u3d_core.c:	INIT_LIST_HEAD(&req->trb_list);
drivers/usb/gadget/udc/mv_u3d_core.c:	length = req->req.length - req->req.actual;
drivers/usb/gadget/udc/mv_u3d_core.c:		list_add_tail(&trb->trb_list, &req->trb_list);
drivers/usb/gadget/udc/mv_u3d_core.c:		req->trb_head = trb;
drivers/usb/gadget/udc/mv_u3d_core.c:		req->trb_count = 1;
drivers/usb/gadget/udc/mv_u3d_core.c:		req->chain = 0;
drivers/usb/gadget/udc/mv_u3d_core.c:			list_add_tail(&trb->trb_list, &req->trb_list);
drivers/usb/gadget/udc/mv_u3d_core.c:			req->trb_count++;
drivers/usb/gadget/udc/mv_u3d_core.c:		req->trb_head = list_entry(req->trb_list.next,
drivers/usb/gadget/udc/mv_u3d_core.c:		req->trb_head->trb_dma = dma_map_single(u3d->gadget.dev.parent,
drivers/usb/gadget/udc/mv_u3d_core.c:					req->trb_head->trb_hw,
drivers/usb/gadget/udc/mv_u3d_core.c:					req->trb_head->trb_dma)) {
drivers/usb/gadget/udc/mv_u3d_core.c:			kfree(req->trb_head->trb_hw);
drivers/usb/gadget/udc/mv_u3d_core.c:			kfree(req->trb_head);
drivers/usb/gadget/udc/mv_u3d_core.c:		req->chain = 1;
drivers/usb/gadget/udc/mv_u3d_core.c:	ret = usb_gadget_map_request(&u3d->gadget, &req->req,
drivers/usb/gadget/udc/mv_u3d_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/mv_u3d_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/mv_u3d_core.c:	req->trb_count = 0;
drivers/usb/gadget/udc/mv_u3d_core.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/mv_u3d_core.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/mv_u3d_core.c:	return &req->req;
drivers/usb/gadget/udc/mv_u3d_core.c:		&& !_req->length) {
drivers/usb/gadget/udc/mv_u3d_core.c:	if (!req->req.complete || !req->req.buf
drivers/usb/gadget/udc/mv_u3d_core.c:			|| !list_empty(&req->queue)) {
drivers/usb/gadget/udc/mv_u3d_core.c:			"req->req.complete: 0x%p, req->req.buf: 0x%p,"
drivers/usb/gadget/udc/mv_u3d_core.c:			req->req.complete, req->req.buf,
drivers/usb/gadget/udc/mv_u3d_core.c:			list_empty(&req->queue));
drivers/usb/gadget/udc/mv_u3d_core.c:		if (req->req.length > ep->ep.maxpacket)
drivers/usb/gadget/udc/mv_u3d_core.c:	req->ep = ep;
drivers/usb/gadget/udc/mv_u3d_core.c:	list_add_tail(&req->list, &ep->req_list);
drivers/usb/gadget/udc/mv_u3d_core.c:		if (&req->req == _req)
drivers/usb/gadget/udc/mv_u3d_core.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/mv_u3d_core.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/mv_u3d_core.c:		_req->status = -ECONNRESET;
drivers/usb/gadget/udc/mv_u3d_core.c:		if (req->queue.next != &ep->queue) {
drivers/usb/gadget/udc/mv_u3d_core.c:			next_req = list_entry(req->queue.next,
drivers/usb/gadget/udc/mv_u3d_core.c:			iowrite32((unsigned long) next_req->trb_head,
drivers/usb/gadget/udc/mv_u3d_core.c:			list_del_init(&req->list);
drivers/usb/gadget/udc/mv_u3d_core.c:			list_del_init(&req->list);
drivers/usb/gadget/udc/mv_u3d_core.c:			curr_req->req.status = status;
drivers/usb/gadget/udc/mv_u3d_core.c:	INIT_LIST_HEAD(&u3d->status_req->queue);
drivers/usb/gadget/udc/mv_u3d_core.c:	u3d->status_req->req.buf = (char *)u3d->status_req
drivers/usb/gadget/udc/mv_u3d_core.c:	u3d->status_req->req.dma = virt_to_phys(u3d->status_req->req.buf);
drivers/usb/gadget/udc/s3c2410_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/s3c2410_udc.c:	if (likely(req->req.status == -EINPROGRESS))
drivers/usb/gadget/udc/s3c2410_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/s3c2410_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/s3c2410_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/s3c2410_udc.c:	unsigned len = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/s3c2410_udc.c:	u8 *buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/s3c2410_udc.c:		req->req.actual, req->req.length, len, req->req.actual + len);
drivers/usb/gadget/udc/s3c2410_udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/s3c2410_udc.c:	else if (req->req.length != req->req.actual || req->req.zero)
drivers/usb/gadget/udc/s3c2410_udc.c:			idx, count, req->req.actual, req->req.length,
drivers/usb/gadget/udc/s3c2410_udc.c:			is_last, req->req.zero);
drivers/usb/gadget/udc/s3c2410_udc.c:	len = min(req->req.length - req->req.actual, avail);
drivers/usb/gadget/udc/s3c2410_udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/s3c2410_udc.c:	if (!req->req.length)
drivers/usb/gadget/udc/s3c2410_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/s3c2410_udc.c:	bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/s3c2410_udc.c:			req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/s3c2410_udc.c:		is_last = (req->req.length <= req->req.actual) ? 1 : 0;
drivers/usb/gadget/udc/s3c2410_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/s3c2410_udc.c:	return &req->req;
drivers/usb/gadget/udc/s3c2410_udc.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/s3c2410_udc.c:	if (unlikely(!_req || !_req->complete
drivers/usb/gadget/udc/s3c2410_udc.c:			|| !_req->buf || !list_empty(&req->queue))) {
drivers/usb/gadget/udc/s3c2410_udc.c:				__func__, !_req->complete, !_req->buf,
drivers/usb/gadget/udc/s3c2410_udc.c:				!list_empty(&req->queue));
drivers/usb/gadget/udc/s3c2410_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/s3c2410_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/s3c2410_udc.c:		 __func__, ep->bEndpointAddress, _req->length);
drivers/usb/gadget/udc/s3c2410_udc.c:				if ((!_req->length)
drivers/usb/gadget/udc/s3c2410_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/s3c2410_udc.c:		if (&req->req == _req) {
drivers/usb/gadget/udc/s3c2410_udc.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/s3c2410_udc.c:			_req->status = -ECONNRESET;
drivers/usb/gadget/udc/s3c2410_udc.c:			req, _ep->name, _req->length, _req->buf);
drivers/usb/gadget/udc/m66592-udc.c:	if (req->req.length == 0) {
drivers/usb/gadget/udc/m66592-udc.c:				(req->req.length + ep->ep.maxpacket - 1)
drivers/usb/gadget/udc/m66592-udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/m66592-udc.c:		req->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/m66592-udc.c:		req->req.status = status;
drivers/usb/gadget/udc/m66592-udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/m66592-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/m66592-udc.c:	size = min(bufsize, req->req.length - req->req.actual);
drivers/usb/gadget/udc/m66592-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/m66592-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/m66592-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/m66592-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/m66592-udc.c:	size = min(bufsize, req->req.length - req->req.actual);
drivers/usb/gadget/udc/m66592-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/m66592-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/m66592-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/m66592-udc.c:		req->req.status = -EPIPE;
drivers/usb/gadget/udc/m66592-udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/m66592-udc.c:	req_len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/m66592-udc.c:	req->req.actual += size;
drivers/usb/gadget/udc/m66592-udc.c:	if ((!req->req.zero && (req->req.actual == req->req.length))
drivers/usb/gadget/udc/m66592-udc.c:	if (req->req.buf) {
drivers/usb/gadget/udc/m66592-udc.c:	m66592->ep0_req->buf = &m66592->ep0_data;
drivers/usb/gadget/udc/m66592-udc.c:	m66592->ep0_req->length = 2;
drivers/usb/gadget/udc/m66592-udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/m66592-udc.c:	return &req->req;
drivers/usb/gadget/udc/m66592-udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/m66592-udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/m66592-udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/m66592-udc.c:	m66592->ep0_req->complete = nop_completion;
drivers/usb/gadget/udc/pxa27x_udc.c:				   &req->req, req->req.actual,
drivers/usb/gadget/udc/pxa27x_udc.c:				   req->req.length, req->req.buf);
drivers/usb/gadget/udc/pxa27x_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/pxa27x_udc.c:	req->in_use = 0;
drivers/usb/gadget/udc/pxa27x_udc.c:	req->udc_usb_ep = container_of(_ep, struct udc_usb_ep, usb_ep);
drivers/usb/gadget/udc/pxa27x_udc.c:	return &req->req;
drivers/usb/gadget/udc/pxa27x_udc.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/pxa27x_udc.c:		req->req.length, udc_ep_readl(ep, UDCCSR));
drivers/usb/gadget/udc/pxa27x_udc.c:	req->in_use = 1;
drivers/usb/gadget/udc/pxa27x_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/pxa27x_udc.c:		req->req.length, udc_ep_readl(ep, UDCCSR));
drivers/usb/gadget/udc/pxa27x_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/pxa27x_udc.c:	req->in_use = 0;
drivers/usb/gadget/udc/pxa27x_udc.c:	if (likely(req->req.status == -EINPROGRESS))
drivers/usb/gadget/udc/pxa27x_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/pxa27x_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/pxa27x_udc.c:			&req->req, status,
drivers/usb/gadget/udc/pxa27x_udc.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/pxa27x_udc.c:	usb_gadget_giveback_request(&req->udc_usb_ep->usb_ep, &req->req);
drivers/usb/gadget/udc/pxa27x_udc.c:	bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/pxa27x_udc.c:	buf = (u32 *)(req->req.buf + req->req.actual);
drivers/usb/gadget/udc/pxa27x_udc.c:	req->req.actual += count;
drivers/usb/gadget/udc/pxa27x_udc.c:	buf = (u32 *)(req->req.buf + req->req.actual);
drivers/usb/gadget/udc/pxa27x_udc.c:	length = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/pxa27x_udc.c:	req->req.actual += length;
drivers/usb/gadget/udc/pxa27x_udc.c:			&req->req, req->req.actual, req->req.length);
drivers/usb/gadget/udc/pxa27x_udc.c:		if (is_short || req->req.actual == req->req.length) {
drivers/usb/gadget/udc/pxa27x_udc.c:			if (likely(req->req.length > req->req.actual)
drivers/usb/gadget/udc/pxa27x_udc.c:					|| req->req.zero)
drivers/usb/gadget/udc/pxa27x_udc.c:			req->req.length - req->req.actual, &req->req);
drivers/usb/gadget/udc/pxa27x_udc.c:			&req->req, req->req.actual, req->req.length);
drivers/usb/gadget/udc/pxa27x_udc.c:		if (is_short || req->req.actual >= req->req.length) {
drivers/usb/gadget/udc/pxa27x_udc.c:		req->req.length - req->req.actual,
drivers/usb/gadget/udc/pxa27x_udc.c:		&req->req, udc_ep_readl(ep, UDCCSR));
drivers/usb/gadget/udc/pxa27x_udc.c: *   (irq->handle_ep0_ctrl_req->gadget_setup->pxa_ep_queue)
drivers/usb/gadget/udc/pxa27x_udc.c:	if (unlikely(!_req || !_req->complete || !_req->buf))
drivers/usb/gadget/udc/pxa27x_udc.c:			&& req->req.length > ep->fifo_size))
drivers/usb/gadget/udc/pxa27x_udc.c:			_req->length, _req->buf);
drivers/usb/gadget/udc/pxa27x_udc.c:		_req->status = -ESHUTDOWN;
drivers/usb/gadget/udc/pxa27x_udc.c:	if (req->in_use) {
drivers/usb/gadget/udc/pxa27x_udc.c:	length = _req->length;
drivers/usb/gadget/udc/pxa27x_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/pxa27x_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/pxa27x_udc.c:		if (&req->req == _req) {
drivers/usb/gadget/udc/mv_udc_core.c:	curr_dtd = curr_req->head;
drivers/usb/gadget/udc/mv_udc_core.c:	actual = curr_req->req.length;
drivers/usb/gadget/udc/mv_udc_core.c:	for (i = 0; i < curr_req->dtd_count; i++) {
drivers/usb/gadget/udc/mv_udc_core.c:		if (i != curr_req->dtd_count - 1)
drivers/usb/gadget/udc/mv_udc_core.c:		bit_pos = 1 << curr_req->ep->ep_num;
drivers/usb/gadget/udc/mv_udc_core.c:		bit_pos = 1 << (16 + curr_req->ep->ep_num);
drivers/usb/gadget/udc/mv_udc_core.c:	curr_req->req.actual = actual;
drivers/usb/gadget/udc/mv_udc_core.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/mv_udc_core.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.status = status;
drivers/usb/gadget/udc/mv_udc_core.c:		status = req->req.status;
drivers/usb/gadget/udc/mv_udc_core.c:	next_td = req->head;
drivers/usb/gadget/udc/mv_udc_core.c:	for (j = 0; j < req->dtd_count; j++) {
drivers/usb/gadget/udc/mv_udc_core.c:		if (j != req->dtd_count - 1)
drivers/usb/gadget/udc/mv_udc_core.c:	usb_gadget_unmap_request(&udc->gadget, &req->req, ep_dir(ep));
drivers/usb/gadget/udc/mv_udc_core.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/mv_udc_core.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/mv_udc_core.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/mv_udc_core.c:		lastreq->tail->dtd_next =
drivers/usb/gadget/udc/mv_udc_core.c:			req->head->td_dma & EP_QUEUE_HEAD_NEXT_POINTER_MASK;
drivers/usb/gadget/udc/mv_udc_core.c:	dqh->next_dtd_ptr = req->head->td_dma
drivers/usb/gadget/udc/mv_udc_core.c:	if (usb_endpoint_xfer_isoc(req->ep->ep.desc)) {
drivers/usb/gadget/udc/mv_udc_core.c:		dqh = req->ep->dqh;
drivers/usb/gadget/udc/mv_udc_core.c:		*length = min(req->req.length - req->req.actual,
drivers/usb/gadget/udc/mv_udc_core.c:				(unsigned)(mult * req->ep->ep.maxpacket));
drivers/usb/gadget/udc/mv_udc_core.c:		*length = min(req->req.length - req->req.actual,
drivers/usb/gadget/udc/mv_udc_core.c:	udc = req->ep->udc;
drivers/usb/gadget/udc/mv_udc_core.c:	temp = (u32)(req->req.dma + req->req.actual);
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.actual += *length;
drivers/usb/gadget/udc/mv_udc_core.c:	/* zlp is needed if req->req.zero is set */
drivers/usb/gadget/udc/mv_udc_core.c:	if (req->req.zero) {
drivers/usb/gadget/udc/mv_udc_core.c:		if (*length == 0 || (*length % req->ep->ep.maxpacket) != 0)
drivers/usb/gadget/udc/mv_udc_core.c:	} else if (req->req.length == req->req.actual)
drivers/usb/gadget/udc/mv_udc_core.c:	if (*is_last && !req->req.no_interrupt)
drivers/usb/gadget/udc/mv_udc_core.c:			req->head = dtd;
drivers/usb/gadget/udc/mv_udc_core.c:		req->dtd_count++;
drivers/usb/gadget/udc/mv_udc_core.c:	req->tail = dtd;
drivers/usb/gadget/udc/mv_udc_core.c:	 * driver handles zero length packet through req->req.zero
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/mv_udc_core.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/mv_udc_core.c:	return &req->req;
drivers/usb/gadget/udc/mv_udc_core.c:	if (!_req || !req->req.complete || !req->req.buf
drivers/usb/gadget/udc/mv_udc_core.c:			|| !list_empty(&req->queue)) {
drivers/usb/gadget/udc/mv_udc_core.c:	req->ep = ep;
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/mv_udc_core.c:	req->dtd_count = 0;
drivers/usb/gadget/udc/mv_udc_core.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/mv_udc_core.c:	dqh->next_dtd_ptr = req->head->td_dma
drivers/usb/gadget/udc/mv_udc_core.c:		if (&req->req == _req)
drivers/usb/gadget/udc/mv_udc_core.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/mv_udc_core.c:	if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/mv_udc_core.c:		_req->status = -ECONNRESET;
drivers/usb/gadget/udc/mv_udc_core.c:		if (req->queue.next != &ep->queue) {
drivers/usb/gadget/udc/mv_udc_core.c:			next_req = list_entry(req->queue.next,
drivers/usb/gadget/udc/mv_udc_core.c:		prev_req = list_entry(req->queue.prev, struct mv_req, queue);
drivers/usb/gadget/udc/mv_udc_core.c:		writel(readl(&req->tail->dtd_next),
drivers/usb/gadget/udc/mv_udc_core.c:				&prev_req->tail->dtd_next);
drivers/usb/gadget/udc/mv_udc_core.c:	dev_info(&udc->dev->dev, "switch to test mode %d\n", req->test_mode);
drivers/usb/gadget/udc/mv_udc_core.c:	if (req->test_mode) {
drivers/usb/gadget/udc/mv_udc_core.c:		mv_set_ptc(udc, req->test_mode);
drivers/usb/gadget/udc/mv_udc_core.c:		req->test_mode = 0;
drivers/usb/gadget/udc/mv_udc_core.c:		*((u16 *) req->req.buf) = cpu_to_le16(status);
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.length = 2;
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.length = 0;
drivers/usb/gadget/udc/mv_udc_core.c:	req->ep = ep;
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/mv_udc_core.c:	req->req.actual = 0;
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.complete = prime_status_complete;
drivers/usb/gadget/udc/mv_udc_core.c:		req->test_mode = udc->test_mode;
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.complete = NULL;
drivers/usb/gadget/udc/mv_udc_core.c:	req->dtd_count = 0;
drivers/usb/gadget/udc/mv_udc_core.c:	if (req->req.dma == DMA_ADDR_INVALID) {
drivers/usb/gadget/udc/mv_udc_core.c:		req->req.dma = dma_map_single(ep->udc->gadget.dev.parent,
drivers/usb/gadget/udc/mv_udc_core.c:				req->req.buf, req->req.length,
drivers/usb/gadget/udc/mv_udc_core.c:		req->mapped = 1;
drivers/usb/gadget/udc/mv_udc_core.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/mv_udc_core.c:	usb_gadget_unmap_request(&udc->gadget, &req->req, ep_dir(ep));
drivers/usb/gadget/udc/mv_udc_core.c:			curr_req->req.status = status;
drivers/usb/gadget/udc/mv_udc_core.c:	INIT_LIST_HEAD(&udc->status_req->queue);
drivers/usb/gadget/udc/mv_udc_core.c:	udc->status_req->req.buf = kzalloc(8, GFP_KERNEL);
drivers/usb/gadget/udc/mv_udc_core.c:	udc->status_req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/gr_udc.c:	int buflen = ep->is_in ? req->req.length : req->req.actual;
drivers/usb/gadget/udc/gr_udc.c:			     rowlen, 4, req->req.buf, plen, false);
drivers/usb/gadget/udc/gr_udc.c:			   &req->req.buf, req->req.actual, req->req.length);
drivers/usb/gadget/udc/gr_udc.c:		next = req->first_desc;
drivers/usb/gadget/udc/gr_udc.c:				   desc == req->curr_desc ? 'c' : ' ',
drivers/usb/gadget/udc/gr_udc.c:		} while (desc != req->last_desc);
drivers/usb/gadget/udc/gr_udc.c:	next = req->first_desc;
drivers/usb/gadget/udc/gr_udc.c:	} while (desc != req->last_desc);
drivers/usb/gadget/udc/gr_udc.c:	req->first_desc = NULL;
drivers/usb/gadget/udc/gr_udc.c:	req->curr_desc = NULL;
drivers/usb/gadget/udc/gr_udc.c:	req->last_desc = NULL;
drivers/usb/gadget/udc/gr_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/gr_udc.c:	if (likely(req->req.status == -EINPROGRESS))
drivers/usb/gadget/udc/gr_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/gr_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/gr_udc.c:	usb_gadget_unmap_request(&dev->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/gr_udc.c:	if (ep->is_in) { /* For OUT, req->req.actual gets updated bit by bit */
drivers/usb/gadget/udc/gr_udc.c:		req->req.actual = req->req.length;
drivers/usb/gadget/udc/gr_udc.c:	} else if (req->oddlen && req->req.actual > req->evenlen) {
drivers/usb/gadget/udc/gr_udc.c:		char *buftail = ((char *)req->req.buf + req->evenlen);
drivers/usb/gadget/udc/gr_udc.c:		memcpy(buftail, ep->tailbuf, req->oddlen);
drivers/usb/gadget/udc/gr_udc.c:		if (req->req.actual > req->req.length) {
drivers/usb/gadget/udc/gr_udc.c:			req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/gr_udc.c:		if (req->setup)
drivers/usb/gadget/udc/gr_udc.c:	} else if (req->req.complete) {
drivers/usb/gadget/udc/gr_udc.c:		usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/gr_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/gr_udc.c:	return &req->req;
drivers/usb/gadget/udc/gr_udc.c:	BUG_ON(!req->curr_desc);
drivers/usb/gadget/udc/gr_udc.c:	if (!ep->is_in && req->oddlen)
drivers/usb/gadget/udc/gr_udc.c:		req->last_desc->data = ep->tailbuf_paddr;
drivers/usb/gadget/udc/gr_udc.c:	gr_write32(&ep->regs->dmaaddr, req->curr_desc->paddr);
drivers/usb/gadget/udc/gr_udc.c:	if (!req->first_desc) {
drivers/usb/gadget/udc/gr_udc.c:		req->first_desc = desc;
drivers/usb/gadget/udc/gr_udc.c:		req->curr_desc = desc;
drivers/usb/gadget/udc/gr_udc.c:		req->last_desc->next_desc = desc;
drivers/usb/gadget/udc/gr_udc.c:		req->last_desc->next = desc->paddr;
drivers/usb/gadget/udc/gr_udc.c:		req->last_desc->ctrl |= GR_DESC_OUT_CTRL_NX;
drivers/usb/gadget/udc/gr_udc.c:	req->last_desc = desc;
drivers/usb/gadget/udc/gr_udc.c: * together covers req->req.length bytes of the buffer at DMA address
drivers/usb/gadget/udc/gr_udc.c: * req->req.dma for the OUT direction.
drivers/usb/gadget/udc/gr_udc.c:	req->first_desc = NULL; /* Signals that no allocation is done yet */
drivers/usb/gadget/udc/gr_udc.c:	bytes_left = req->req.length;
drivers/usb/gadget/udc/gr_udc.c:		dma_addr_t start = req->req.dma + bytes_used;
drivers/usb/gadget/udc/gr_udc.c:			req->evenlen = req->req.length - bytes_left;
drivers/usb/gadget/udc/gr_udc.c:			req->oddlen = size;
drivers/usb/gadget/udc/gr_udc.c:	req->first_desc->ctrl |= GR_DESC_OUT_CTRL_EN;
drivers/usb/gadget/udc/gr_udc.c: * together covers req->req.length bytes of the buffer at DMA address
drivers/usb/gadget/udc/gr_udc.c: * req->req.dma for the IN direction.
drivers/usb/gadget/udc/gr_udc.c:	req->first_desc = NULL; /* Signals that no allocation is done yet */
drivers/usb/gadget/udc/gr_udc.c:	bytes_left = req->req.length;
drivers/usb/gadget/udc/gr_udc.c:		dma_addr_t start = req->req.dma + bytes_used;
drivers/usb/gadget/udc/gr_udc.c:	 * available when req->req.zero is set and the data length is even
drivers/usb/gadget/udc/gr_udc.c:	if (req->req.zero && (req->req.length % ep->ep.maxpacket == 0)) {
drivers/usb/gadget/udc/gr_udc.c:	req->last_desc->ctrl |= GR_DESC_IN_CTRL_PI;
drivers/usb/gadget/udc/gr_udc.c:	if (unlikely(!req->req.buf || !list_empty(&req->queue))) {
drivers/usb/gadget/udc/gr_udc.c:			ep->ep.name, req->req.buf, list_empty(&req->queue));
drivers/usb/gadget/udc/gr_udc.c:	ret = usb_gadget_map_request(&dev->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/gr_udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/gr_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/gr_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/gr_udc.c:		if (!req->req.actual)
drivers/usb/gadget/udc/gr_udc.c:		if (req->req.actual > 0)
drivers/usb/gadget/udc/gr_udc.c:	} else if (!req->req.actual) {
drivers/usb/gadget/udc/gr_udc.c:	for (i = 0; i < req->req.actual; i++)
drivers/usb/gadget/udc/gr_udc.c:		u.raw[i] = ((u8 *)req->req.buf)[i];
drivers/usb/gadget/udc/gr_udc.c:	if (!req->last_desc)
drivers/usb/gadget/udc/gr_udc.c:	if (READ_ONCE(req->last_desc->ctrl) & GR_DESC_IN_CTRL_EN)
drivers/usb/gadget/udc/gr_udc.c:	if (!req->curr_desc)
drivers/usb/gadget/udc/gr_udc.c:	ctrl = READ_ONCE(req->curr_desc->ctrl);
drivers/usb/gadget/udc/gr_udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/gr_udc.c:		req->setup = 1;
drivers/usb/gadget/udc/gr_udc.c:	if (len < ep->ep.maxpacket || req->req.actual >= req->req.length) {
drivers/usb/gadget/udc/gr_udc.c:		req->curr_desc = req->curr_desc->next_desc;
drivers/usb/gadget/udc/gr_udc.c:		req->curr_desc->ctrl |= GR_DESC_OUT_CTRL_EN;
drivers/usb/gadget/udc/gr_udc.c:	WARN(!list_empty(&req->queue),
drivers/usb/gadget/udc/gr_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/gr_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/gr_udc.c:	} else if (!list_empty(&req->queue)) {
drivers/usb/gadget/udc/gr_udc.c:		req->req.buf = buf;
drivers/usb/gadget/udc/gr_udc.c:		req->req.length = MAX_CTRL_PL_SIZE;
drivers/usb/gadget/udc/dummy_hcd.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/dummy_hcd.c:		req->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/dummy_hcd.c:		usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/dummy_hcd.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/dummy_hcd.c:	return &req->req;
drivers/usb/gadget/udc/dummy_hcd.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/dummy_hcd.c:	if (!_req || !list_empty(&req->queue) || !_req->complete)
drivers/usb/gadget/udc/dummy_hcd.c:			ep, _req, _ep->name, _req->length, _req->buf);
drivers/usb/gadget/udc/dummy_hcd.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/dummy_hcd.c:	_req->actual = 0;
drivers/usb/gadget/udc/dummy_hcd.c:			_req->length <= FIFO_SIZE) {
drivers/usb/gadget/udc/dummy_hcd.c:		req->req = *_req;
drivers/usb/gadget/udc/dummy_hcd.c:		req->req.buf = dum->fifo_buf;
drivers/usb/gadget/udc/dummy_hcd.c:		memcpy(dum->fifo_buf, _req->buf, _req->length);
drivers/usb/gadget/udc/dummy_hcd.c:		req->req.context = dum;
drivers/usb/gadget/udc/dummy_hcd.c:		req->req.complete = fifo_complete;
drivers/usb/gadget/udc/dummy_hcd.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/dummy_hcd.c:		_req->actual = _req->length;
drivers/usb/gadget/udc/dummy_hcd.c:		_req->status = 0;
drivers/usb/gadget/udc/dummy_hcd.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/dummy_hcd.c:		if (&req->req == _req) {
drivers/usb/gadget/udc/dummy_hcd.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/dummy_hcd.c:			_req->status = -ECONNRESET;
drivers/usb/gadget/udc/dummy_hcd.c:				req, _ep->name, _req->length, _req->buf);
drivers/usb/gadget/udc/dummy_hcd.c:	rbuf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/dummy_hcd.c:			if ((urb->stream_id != req->req.stream_id))
drivers/usb/gadget/udc/dummy_hcd.c:		dev_len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/dummy_hcd.c:				req->req.status = len;
drivers/usb/gadget/udc/dummy_hcd.c:				req->req.actual += len;
drivers/usb/gadget/udc/dummy_hcd.c:				req->req.status = 0;
drivers/usb/gadget/udc/dummy_hcd.c:				req->req.status = 0;
drivers/usb/gadget/udc/dummy_hcd.c:					req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/dummy_hcd.c:					req->req.status = 0;
drivers/usb/gadget/udc/dummy_hcd.c:			if (req->req.length == req->req.actual) {
drivers/usb/gadget/udc/dummy_hcd.c:				if (req->req.zero && to_host)
drivers/usb/gadget/udc/dummy_hcd.c:					req->req.status = 0;
drivers/usb/gadget/udc/dummy_hcd.c:		if (req->req.status != -EINPROGRESS) {
drivers/usb/gadget/udc/dummy_hcd.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/dummy_hcd.c:			usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/dummy_hcd.c:				list_del_init(&req->queue);
drivers/usb/gadget/udc/dummy_hcd.c:				req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/dummy_hcd.c:				usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/udc-xilinx.c:	src = req->usb_req.dma + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:	if (req->usb_req.length)
drivers/usb/gadget/udc/udc-xilinx.c:	dst = req->usb_req.dma + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/udc-xilinx.c:	if (req->usb_req.status == -EINPROGRESS)
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.status = status;
drivers/usb/gadget/udc/udc-xilinx.c:		status = req->usb_req.status;
drivers/usb/gadget/udc/udc-xilinx.c:	if (udc->dma_enabled && ep->epnumber && req->usb_req.length)
drivers/usb/gadget/udc/udc-xilinx.c:		usb_gadget_unmap_request(&udc->gadget, &req->usb_req,
drivers/usb/gadget/udc/udc-xilinx.c:	if (req->usb_req.complete) {
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.complete(&ep->ep_usb, &req->usb_req);
drivers/usb/gadget/udc/udc-xilinx.c:	buf = req->usb_req.buf + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:	bufferspace = req->usb_req.length - req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:		if (req->usb_req.status != -EOVERFLOW)
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.status = -EOVERFLOW;
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.actual += min(count, bufferspace);
drivers/usb/gadget/udc/udc-xilinx.c:			req->usb_req.actual, req->usb_req.length);
drivers/usb/gadget/udc/udc-xilinx.c:		if ((req->usb_req.actual == req->usb_req.length) || is_short) {
drivers/usb/gadget/udc/udc-xilinx.c:			if (udc->dma_enabled && req->usb_req.length)
drivers/usb/gadget/udc/udc-xilinx.c:							req->usb_req.dma,
drivers/usb/gadget/udc/udc-xilinx.c:							req->usb_req.actual,
drivers/usb/gadget/udc/udc-xilinx.c:	buf = req->usb_req.buf + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:	length = req->usb_req.length - req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.actual += length;
drivers/usb/gadget/udc/udc-xilinx.c:			if (likely(req->usb_req.length !=
drivers/usb/gadget/udc/udc-xilinx.c:				   req->usb_req.actual) || req->usb_req.zero)
drivers/usb/gadget/udc/udc-xilinx.c:			req->usb_req.length - req->usb_req.actual, req);
drivers/usb/gadget/udc/udc-xilinx.c:	req->ep = ep;
drivers/usb/gadget/udc/udc-xilinx.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/udc-xilinx.c:	return &req->usb_req;
drivers/usb/gadget/udc/udc-xilinx.c:	req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/udc-xilinx.c:	req->usb_req.actual = 0;
drivers/usb/gadget/udc/udc-xilinx.c:	list_add_tail(&req->queue, &ep0->queue);
drivers/usb/gadget/udc/udc-xilinx.c:		prefetch(req->usb_req.buf);
drivers/usb/gadget/udc/udc-xilinx.c:		length = req->usb_req.length;
drivers/usb/gadget/udc/udc-xilinx.c:		length = req->usb_req.actual = min_t(u32, length,
drivers/usb/gadget/udc/udc-xilinx.c:		memcpy(corebuf, req->usb_req.buf, length);
drivers/usb/gadget/udc/udc-xilinx.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/udc-xilinx.c:	_req->actual = 0;
drivers/usb/gadget/udc/udc-xilinx.c:		ret = usb_gadget_map_request(&udc->gadget, &req->usb_req,
drivers/usb/gadget/udc/udc-xilinx.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/udc-xilinx.c:		if (&req->usb_req == _req)
drivers/usb/gadget/udc/udc-xilinx.c:	if (&req->usb_req != _req) {
drivers/usb/gadget/udc/udc-xilinx.c:	req->usb_req.length = 0;
drivers/usb/gadget/udc/udc-xilinx.c:	req->usb_req.length = 2;
drivers/usb/gadget/udc/udc-xilinx.c:	*(u16 *)req->usb_req.buf = cpu_to_le16(status);
drivers/usb/gadget/udc/udc-xilinx.c:	req->usb_req.length = 0;
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.actual = req->usb_req.length;
drivers/usb/gadget/udc/udc-xilinx.c:		buffer = req->usb_req.buf + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.actual = req->usb_req.actual + bytes_to_rx;
drivers/usb/gadget/udc/udc-xilinx.c:		if (req->usb_req.length == req->usb_req.actual) {
drivers/usb/gadget/udc/udc-xilinx.c:	bytes_to_tx = req->usb_req.length - req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:		req->usb_req.actual = req->usb_req.length;
drivers/usb/gadget/udc/udc-xilinx.c:			buffer = req->usb_req.buf + req->usb_req.actual;
drivers/usb/gadget/udc/udc-xilinx.c:			req->usb_req.actual = req->usb_req.actual + length;
drivers/usb/gadget/udc/udc-xilinx.c:	udc->req->usb_req.buf = buff;
drivers/usb/gadget/udc/s3c-hsudc.c:	list_del_init(&hsreq->queue);
drivers/usb/gadget/udc/s3c-hsudc.c:	hsreq->req.status = status;
drivers/usb/gadget/udc/s3c-hsudc.c:	usb_gadget_giveback_request(&hsep->ep, &hsreq->req);
drivers/usb/gadget/udc/s3c-hsudc.c:	buf = hsreq->req.buf + hsreq->req.actual;
drivers/usb/gadget/udc/s3c-hsudc.c:	length = hsreq->req.length - hsreq->req.actual;
drivers/usb/gadget/udc/s3c-hsudc.c:	hsreq->req.actual += length;
drivers/usb/gadget/udc/s3c-hsudc.c:		if (hsreq->req.length != hsreq->req.actual || hsreq->req.zero)
drivers/usb/gadget/udc/s3c-hsudc.c:	buf = hsreq->req.buf + hsreq->req.actual;
drivers/usb/gadget/udc/s3c-hsudc.c:	buflen = hsreq->req.length - hsreq->req.actual;
drivers/usb/gadget/udc/s3c-hsudc.c:	hsreq->req.actual += min(rlen, buflen);
drivers/usb/gadget/udc/s3c-hsudc.c:			hsreq->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/s3c-hsudc.c:	if (is_short || hsreq->req.actual == hsreq->req.length) {
drivers/usb/gadget/udc/s3c-hsudc.c:	INIT_LIST_HEAD(&hsreq->queue);
drivers/usb/gadget/udc/s3c-hsudc.c:	return &hsreq->req;
drivers/usb/gadget/udc/s3c-hsudc.c:	WARN_ON(!list_empty(&hsreq->queue));
drivers/usb/gadget/udc/s3c-hsudc.c:	if ((!_req || !_req->complete || !_req->buf ||
drivers/usb/gadget/udc/s3c-hsudc.c:		!list_empty(&hsreq->queue)))
drivers/usb/gadget/udc/s3c-hsudc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/s3c-hsudc.c:	_req->actual = 0;
drivers/usb/gadget/udc/s3c-hsudc.c:	if (!ep_index(hsep) && _req->length == 0) {
drivers/usb/gadget/udc/s3c-hsudc.c:		list_add_tail(&hsreq->queue, &hsep->queue);
drivers/usb/gadget/udc/s3c-hsudc.c:		if (&hsreq->req == _req)
drivers/usb/gadget/udc/s3c-hsudc.c:	if (&hsreq->req != _req) {
drivers/usb/gadget/udc/fusb300_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/fusb300_udc.c:	return &req->req;
drivers/usb/gadget/udc/fusb300_udc.c:	u32 length = req->req.length - req->req.actual;
drivers/usb/gadget/udc/fusb300_udc.c:	tmp = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/fusb300_udc.c:		req->req.actual += SS_CTL_MAX_PACKET_SIZE;
drivers/usb/gadget/udc/fusb300_udc.c:		req->req.actual += length;
drivers/usb/gadget/udc/fusb300_udc.c:		if (req->req.length) {
drivers/usb/gadget/udc/fusb300_udc.c:			printk(KERN_DEBUG "%s : req->req.length = 0x%x\n",
drivers/usb/gadget/udc/fusb300_udc.c:				__func__, req->req.length);
drivers/usb/gadget/udc/fusb300_udc.c:		if ((req->req.length == req->req.actual) ||
drivers/usb/gadget/udc/fusb300_udc.c:		    (req->req.actual < ep->ep.maxpacket))
drivers/usb/gadget/udc/fusb300_udc.c:		if (!req->req.length)
drivers/usb/gadget/udc/fusb300_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fusb300_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fusb300_udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fusb300_udc.c:	tmp = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/fusb300_udc.c:	req->req.actual += length;
drivers/usb/gadget/udc/fusb300_udc.c:	if (req->req.actual > req->req.length)
drivers/usb/gadget/udc/fusb300_udc.c:		printk(KERN_DEBUG "req->req.actual > req->req.length\n");
drivers/usb/gadget/udc/fusb300_udc.c:	fusb300->ep0_req->buf = &fusb300->ep0_data;
drivers/usb/gadget/udc/fusb300_udc.c:	fusb300->ep0_req->length = 2;
drivers/usb/gadget/udc/fusb300_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/fusb300_udc.c:		req->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/fusb300_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/fusb300_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/fusb300_udc.c:			&req->req, DMA_TO_DEVICE);
drivers/usb/gadget/udc/fusb300_udc.c:	fusb300_fill_idma_prdtbl(ep, req->req.dma, req->req.length);
drivers/usb/gadget/udc/fusb300_udc.c:			&req->req, DMA_TO_DEVICE);
drivers/usb/gadget/udc/fusb300_udc.c:	if (req->req.length)
drivers/usb/gadget/udc/fusb300_udc.c:	if ((req->req.length == req->req.actual) || (length < ep->ep.maxpacket))
drivers/usb/gadget/udc/fusb300_udc.c:		if (req->req.length)
drivers/usb/gadget/udc/fusb300_udc.c:			fusb300_rdcxf(ep->fusb300, req->req.buf,
drivers/usb/gadget/udc/fusb300_udc.c:				req->req.length);
drivers/usb/gadget/udc/fusb300_udc.c:		if (req->req.length)
drivers/usb/gadget/udc/fusb300_udc.c:		if ((req->req.length - req->req.actual) < ep->ep.maxpacket)
drivers/usb/gadget/udc/max3420_udc.c:	struct max3420_ep *ep = req->ep;
drivers/usb/gadget/udc/max3420_udc.c:	if (req->usb_req.status == -EINPROGRESS)
drivers/usb/gadget/udc/max3420_udc.c:		req->usb_req.status = status;
drivers/usb/gadget/udc/max3420_udc.c:		status = req->usb_req.status;
drivers/usb/gadget/udc/max3420_udc.c:	if (req->usb_req.complete)
drivers/usb/gadget/udc/max3420_udc.c:		req->usb_req.complete(&ep->ep_usb, &req->usb_req);
drivers/usb/gadget/udc/max3420_udc.c:	buf = req->usb_req.buf + req->usb_req.actual;
drivers/usb/gadget/udc/max3420_udc.c:	length = req->usb_req.length - req->usb_req.actual;
drivers/usb/gadget/udc/max3420_udc.c:	req->usb_req.actual += length;
drivers/usb/gadget/udc/max3420_udc.c:	if (req->usb_req.actual == req->usb_req.length)
drivers/usb/gadget/udc/max3420_udc.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/max3420_udc.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/max3420_udc.c:	req->ep = ep;
drivers/usb/gadget/udc/max3420_udc.c:	return &req->usb_req;
drivers/usb/gadget/udc/max3420_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/max3420_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/max3420_udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/max3420_udc.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/at91_udc.c:		unsigned	length = req->req.actual;
drivers/usb/gadget/udc/at91_udc.c:				&req->req, length,
drivers/usb/gadget/udc/at91_udc.c:				req->req.length, req->req.buf);
drivers/usb/gadget/udc/at91_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/at91_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/at91_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/at91_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/at91_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/at91_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/at91_udc.c:	bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/at91_udc.c:		req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/at91_udc.c:	req->req.actual += count;
drivers/usb/gadget/udc/at91_udc.c:	PACKET("%s %p out/%d%s\n", ep->ep.name, &req->req, count,
drivers/usb/gadget/udc/at91_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/at91_udc.c:	total = req->req.length - req->req.actual;
drivers/usb/gadget/udc/at91_udc.c:		is_last = (count < ep->ep.maxpacket) || !req->req.zero;
drivers/usb/gadget/udc/at91_udc.c:	 * NOTE:  incrementing req->actual before we receive the ACK means
drivers/usb/gadget/udc/at91_udc.c:	req->req.actual += count;
drivers/usb/gadget/udc/at91_udc.c:	PACKET("%s %p in/%d%s\n", ep->ep.name, &req->req, count,
drivers/usb/gadget/udc/at91_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/at91_udc.c:	return &req->req;
drivers/usb/gadget/udc/at91_udc.c:	BUG_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/at91_udc.c:	if (!_req || !_req->complete
drivers/usb/gadget/udc/at91_udc.c:			|| !_req->buf || !list_empty(&req->queue)) {
drivers/usb/gadget/udc/at91_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/at91_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/at91_udc.c:			if (req->req.length == 0) {
drivers/usb/gadget/udc/at91_udc.c:		list_add_tail (&req->queue, &ep->queue);
drivers/usb/gadget/udc/at91_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/at91_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/at91_udc.c:				req->req.status = -EILSEQ;
drivers/usb/gadget/udc/fotg210-udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/fotg210-udc.c:		req->req.status = -ESHUTDOWN;
drivers/usb/gadget/udc/fotg210-udc.c:		req->req.status = status;
drivers/usb/gadget/udc/fotg210-udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/fotg210-udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/fotg210-udc.c:	return &req->req;
drivers/usb/gadget/udc/fotg210-udc.c:			buffer = req->req.buf;
drivers/usb/gadget/udc/fotg210-udc.c:			length = req->req.length;
drivers/usb/gadget/udc/fotg210-udc.c:			buffer = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/fotg210-udc.c:		buffer = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/fotg210-udc.c:		if (req->req.length - req->req.actual > ep->ep.maxpacket)
drivers/usb/gadget/udc/fotg210-udc.c:			length = req->req.length;
drivers/usb/gadget/udc/fotg210-udc.c:	req->req.actual += length;
drivers/usb/gadget/udc/fotg210-udc.c:	if (!req->req.length) {
drivers/usb/gadget/udc/fotg210-udc.c:		if ((req->req.length == req->req.actual) ||
drivers/usb/gadget/udc/fotg210-udc.c:		    (req->req.actual < ep->ep.maxpacket))
drivers/usb/gadget/udc/fotg210-udc.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/fotg210-udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/fotg210-udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/fotg210-udc.c:	fotg210->ep0_req->buf = &fotg210->ep0_data;
drivers/usb/gadget/udc/fotg210-udc.c:	fotg210->ep0_req->length = 2;
drivers/usb/gadget/udc/fotg210-udc.c:		if (req->req.length)
drivers/usb/gadget/udc/fotg210-udc.c:		if ((req->req.length - req->req.actual) < ep->ep.maxpacket)
drivers/usb/gadget/udc/fotg210-udc.c:		if (req->req.length)
drivers/usb/gadget/udc/fotg210-udc.c:		if ((req->req.length - req->req.actual) < ep->ep.maxpacket)
drivers/usb/gadget/udc/fotg210-udc.c:	if (req->req.length)
drivers/usb/gadget/udc/fotg210-udc.c:	if (req->req.length == req->req.actual ||
drivers/usb/gadget/udc/fotg210-udc.c:	    req->req.actual < ep->ep.maxpacket)
drivers/usb/gadget/udc/lpc32xx_udc.c:			u32 length = req->req.actual;
drivers/usb/gadget/udc/lpc32xx_udc.c:				   &req->req, length,
drivers/usb/gadget/udc/lpc32xx_udc.c:				   req->req.length, req->req.buf);
drivers/usb/gadget/udc/lpc32xx_udc.c:	udc->udca_v_base[hwep] = req->dd_desc_ptr->this_dma;
drivers/usb/gadget/udc/lpc32xx_udc.c:	if (req->req.length % ep->ep.maxpacket)
drivers/usb/gadget/udc/lpc32xx_udc.c:		req->send_zlp = 0;
drivers/usb/gadget/udc/lpc32xx_udc.c:	udc->udca_v_base[hwep] = req->dd_desc_ptr->this_dma;
drivers/usb/gadget/udc/lpc32xx_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/lpc32xx_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/lpc32xx_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/lpc32xx_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/lpc32xx_udc.c:		usb_gadget_unmap_request(&udc->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/lpc32xx_udc.c:		udc_dd_free(udc, req->dd_desc_ptr);
drivers/usb/gadget/udc/lpc32xx_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/lpc32xx_udc.c:	tsend = ts = req->req.length - req->req.actual;
drivers/usb/gadget/udc/lpc32xx_udc.c:	udc_write_hwep(udc, EP_IN, (req->req.buf + req->req.actual), ts);
drivers/usb/gadget/udc/lpc32xx_udc.c:	req->req.actual += ts;
drivers/usb/gadget/udc/lpc32xx_udc.c:		if (req->req.length == 0) {
drivers/usb/gadget/udc/lpc32xx_udc.c:		bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/lpc32xx_udc.c:		prefetchw(req->req.buf + req->req.actual);
drivers/usb/gadget/udc/lpc32xx_udc.c:		tr = udc_read_hwep(udc, EP_OUT, req->req.buf + req->req.actual,
drivers/usb/gadget/udc/lpc32xx_udc.c:		req->req.actual += bufferspace;
drivers/usb/gadget/udc/lpc32xx_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/lpc32xx_udc.c:	return &req->req;
drivers/usb/gadget/udc/lpc32xx_udc.c:	BUG_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/lpc32xx_udc.c:	if (!_ep || !_req || !_req->complete || !_req->buf ||
drivers/usb/gadget/udc/lpc32xx_udc.c:	    !list_empty(&req->queue))
drivers/usb/gadget/udc/lpc32xx_udc.c:		req->dd_desc_ptr = dd;
drivers/usb/gadget/udc/lpc32xx_udc.c:		dd->dd_buffer_addr = req->req.dma;
drivers/usb/gadget/udc/lpc32xx_udc.c:				dd->iso_status[0] = req->req.length;
drivers/usb/gadget/udc/lpc32xx_udc.c:				DD_SETUP_DMALENBYTES(req->req.length);
drivers/usb/gadget/udc/lpc32xx_udc.c:	       _req, _req->length, _req->buf, ep->is_in, _req->zero);
drivers/usb/gadget/udc/lpc32xx_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/lpc32xx_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/lpc32xx_udc.c:	req->send_zlp = _req->zero;
drivers/usb/gadget/udc/lpc32xx_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/lpc32xx_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/lpc32xx_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/lpc32xx_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/lpc32xx_udc.c:	dd = req->dd_desc_ptr;
drivers/usb/gadget/udc/lpc32xx_udc.c:			req->req.actual = req->req.length;
drivers/usb/gadget/udc/lpc32xx_udc.c:			req->req.actual = dd->iso_status[0] & 0xFFFF;
drivers/usb/gadget/udc/lpc32xx_udc.c:		req->req.actual += DD_STATUS_CURDMACNT(status);
drivers/usb/gadget/udc/lpc32xx_udc.c:	if (req->send_zlp) {
drivers/usb/gadget/udc/pxa25x_udc.c:	INIT_LIST_HEAD (&req->queue);
drivers/usb/gadget/udc/pxa25x_udc.c:	return &req->req;
drivers/usb/gadget/udc/pxa25x_udc.c:	WARN_ON(!list_empty (&req->queue));
drivers/usb/gadget/udc/pxa25x_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/pxa25x_udc.c:	if (likely (req->req.status == -EINPROGRESS))
drivers/usb/gadget/udc/pxa25x_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/pxa25x_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/pxa25x_udc.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/pxa25x_udc.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/pxa25x_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/pxa25x_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/pxa25x_udc.c:	length = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/pxa25x_udc.c:	req->req.actual += length;
drivers/usb/gadget/udc/pxa25x_udc.c:			if (likely(req->req.length != req->req.actual)
drivers/usb/gadget/udc/pxa25x_udc.c:					|| req->req.zero)
drivers/usb/gadget/udc/pxa25x_udc.c:			req->req.length - req->req.actual, req);
drivers/usb/gadget/udc/pxa25x_udc.c:/* caller asserts req->pending (ep0 irq status nyet cleared); starts
drivers/usb/gadget/udc/pxa25x_udc.c:		req->req.length - req->req.actual, req);
drivers/usb/gadget/udc/pxa25x_udc.c:		count = req->req.length;
drivers/usb/gadget/udc/pxa25x_udc.c:		buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/pxa25x_udc.c:		bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/pxa25x_udc.c:			req->req.actual += min (count, bufferspace);
drivers/usb/gadget/udc/pxa25x_udc.c:			req, req->req.actual, req->req.length);
drivers/usb/gadget/udc/pxa25x_udc.c:				if (req->req.status != -EOVERFLOW)
drivers/usb/gadget/udc/pxa25x_udc.c:				req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/pxa25x_udc.c:				req->req.status = -EHOSTUNREACH;
drivers/usb/gadget/udc/pxa25x_udc.c:		if (is_short || req->req.actual == req->req.length) {
drivers/usb/gadget/udc/pxa25x_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/pxa25x_udc.c:	bufferspace = req->req.length - req->req.actual;
drivers/usb/gadget/udc/pxa25x_udc.c:			if (req->req.status != -EOVERFLOW)
drivers/usb/gadget/udc/pxa25x_udc.c:			req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/pxa25x_udc.c:			req->req.actual++;
drivers/usb/gadget/udc/pxa25x_udc.c:	if (req->req.actual >= req->req.length)
drivers/usb/gadget/udc/pxa25x_udc.c:	if (unlikely (!_req || !_req->complete || !_req->buf
drivers/usb/gadget/udc/pxa25x_udc.c:			|| !list_empty(&req->queue))) {
drivers/usb/gadget/udc/pxa25x_udc.c:			&& req->req.length > usb_endpoint_maxp(ep->ep.desc)))
drivers/usb/gadget/udc/pxa25x_udc.c:		_ep->name, _req, _req->length, _req->buf);
drivers/usb/gadget/udc/pxa25x_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/pxa25x_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/pxa25x_udc.c:			unsigned	length = _req->length;
drivers/usb/gadget/udc/pxa25x_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/pxa25x_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/pxa25x_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/pxa25x_udc.c:					&req->req, req->req.actual,
drivers/usb/gadget/udc/pxa25x_udc.c:					req->req.length, req->req.buf);
drivers/usb/gadget/udc/omap_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/omap_udc.c:	return &req->req;
drivers/usb/gadget/udc/omap_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/omap_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/omap_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/omap_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/omap_udc.c:		usb_gadget_unmap_request(&udc->gadget, &req->req,
drivers/usb/gadget/udc/omap_udc.c:			ep->ep.name, &req->req, status,
drivers/usb/gadget/udc/omap_udc.c:			req->req.actual, req->req.length);
drivers/usb/gadget/udc/omap_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/omap_udc.c:	len = min(req->req.length - req->req.actual, max);
drivers/usb/gadget/udc/omap_udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/omap_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:	else if (req->req.length == req->req.actual
drivers/usb/gadget/udc/omap_udc.c:			&& !req->req.zero)
drivers/usb/gadget/udc/omap_udc.c:	len = min(req->req.length - req->req.actual, avail);
drivers/usb/gadget/udc/omap_udc.c:	req->req.actual += len;
drivers/usb/gadget/udc/omap_udc.c:	buf = req->req.buf + req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:				req->req.status = -EOVERFLOW;
drivers/usb/gadget/udc/omap_udc.c:		} else if (req->req.length == req->req.actual)
drivers/usb/gadget/udc/omap_udc.c:	unsigned	length = req->req.length - req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:		OMAP_DMA_AMODE_POST_INC, req->req.dma + req->req.actual,
drivers/usb/gadget/udc/omap_udc.c:	req->dma_bytes = length;
drivers/usb/gadget/udc/omap_udc.c:		req->req.actual += req->dma_bytes;
drivers/usb/gadget/udc/omap_udc.c:		if (req->req.actual < req->req.length)
drivers/usb/gadget/udc/omap_udc.c:		if (req->req.zero
drivers/usb/gadget/udc/omap_udc.c:				&& req->dma_bytes != 0
drivers/usb/gadget/udc/omap_udc.c:				&& (req->req.actual % ep->maxpacket) == 0)
drivers/usb/gadget/udc/omap_udc.c:		req->req.actual += dma_src_len(ep, req->req.dma
drivers/usb/gadget/udc/omap_udc.c:							+ req->req.actual);
drivers/usb/gadget/udc/omap_udc.c:	unsigned packets = req->req.length - req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:	req->dma_bytes = packets * ep->ep.maxpacket;
drivers/usb/gadget/udc/omap_udc.c:		OMAP_DMA_AMODE_POST_INC, req->req.dma + req->req.actual,
drivers/usb/gadget/udc/omap_udc.c:		ep->dma_counter = (u16) (req->req.dma + req->req.actual);
drivers/usb/gadget/udc/omap_udc.c:	count = dma_dest_len(ep, req->req.dma + req->req.actual);
drivers/usb/gadget/udc/omap_udc.c:	count += req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:	if (count <= req->req.length)
drivers/usb/gadget/udc/omap_udc.c:		req->req.actual = count;
drivers/usb/gadget/udc/omap_udc.c:	if (count != req->dma_bytes || status)
drivers/usb/gadget/udc/omap_udc.c:	else if (req->req.actual < req->req.length)
drivers/usb/gadget/udc/omap_udc.c:	if (!_req || !req->req.complete || !req->req.buf
drivers/usb/gadget/udc/omap_udc.c:			|| !list_empty(&req->queue)) {
drivers/usb/gadget/udc/omap_udc.c:		if (req->req.length > ep->ep.maxpacket)
drivers/usb/gadget/udc/omap_udc.c:			&& (req->req.length % ep->ep.maxpacket) != 0) {
drivers/usb/gadget/udc/omap_udc.c:		usb_gadget_map_request(&udc->gadget, &req->req,
drivers/usb/gadget/udc/omap_udc.c:		ep->ep.name, _req, _req->length, _req->buf);
drivers/usb/gadget/udc/omap_udc.c:	req->req.status = -EINPROGRESS;
drivers/usb/gadget/udc/omap_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/omap_udc.c:			if (!req->req.length) {
drivers/usb/gadget/udc/omap_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/omap_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/omap_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/omap_udc.c:	if (use_dma && ep->dma_channel && ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/omap_udc.c:			unsigned	length = req->req.actual;
drivers/usb/gadget/udc/omap_udc.c:					(ep, req->req.dma + length);
drivers/usb/gadget/udc/omap_udc.c:					&req->req, length,
drivers/usb/gadget/udc/omap_udc.c:					req->req.length, req->req.buf);
drivers/usb/gadget/udc/pch_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/pch_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/pch_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/pch_udc.c:		status = req->req.status;
drivers/usb/gadget/udc/pch_udc.c:	if (req->dma_mapped) {
drivers/usb/gadget/udc/pch_udc.c:		if (req->dma == DMA_ADDR_INVALID) {
drivers/usb/gadget/udc/pch_udc.c:				dma_unmap_single(&dev->pdev->dev, req->req.dma,
drivers/usb/gadget/udc/pch_udc.c:						 req->req.length,
drivers/usb/gadget/udc/pch_udc.c:				dma_unmap_single(&dev->pdev->dev, req->req.dma,
drivers/usb/gadget/udc/pch_udc.c:						 req->req.length,
drivers/usb/gadget/udc/pch_udc.c:			req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/pch_udc.c:				dma_unmap_single(&dev->pdev->dev, req->dma,
drivers/usb/gadget/udc/pch_udc.c:						 req->req.length,
drivers/usb/gadget/udc/pch_udc.c:				dma_unmap_single(&dev->pdev->dev, req->dma,
drivers/usb/gadget/udc/pch_udc.c:						 req->req.length,
drivers/usb/gadget/udc/pch_udc.c:				memcpy(req->req.buf, req->buf, req->req.length);
drivers/usb/gadget/udc/pch_udc.c:			kfree(req->buf);
drivers/usb/gadget/udc/pch_udc.c:			req->dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/pch_udc.c:		req->dma_mapped = 0;
drivers/usb/gadget/udc/pch_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/pch_udc.c:	struct pch_udc_data_dma_desc *td = req->td_data;
drivers/usb/gadget/udc/pch_udc.c:	unsigned i = req->chain_len;
drivers/usb/gadget/udc/pch_udc.c:	req->chain_len = 1;
drivers/usb/gadget/udc/pch_udc.c:	struct pch_udc_data_dma_desc *td = req->td_data, *last;
drivers/usb/gadget/udc/pch_udc.c:	unsigned long bytes = req->req.length, i = 0;
drivers/usb/gadget/udc/pch_udc.c:	if (req->chain_len > 1)
drivers/usb/gadget/udc/pch_udc.c:	if (req->dma == DMA_ADDR_INVALID)
drivers/usb/gadget/udc/pch_udc.c:		td->dataptr = req->req.dma;
drivers/usb/gadget/udc/pch_udc.c:		td->dataptr = req->dma;
drivers/usb/gadget/udc/pch_udc.c:		td->dataptr = req->td_data->dataptr + i;
drivers/usb/gadget/udc/pch_udc.c:	req->td_data_last = td;
drivers/usb/gadget/udc/pch_udc.c:	td->next = req->td_data_phys;
drivers/usb/gadget/udc/pch_udc.c:	req->chain_len = len;
drivers/usb/gadget/udc/pch_udc.c:		req->chain_len = len;
drivers/usb/gadget/udc/pch_udc.c:	req->chain_len = 1;
drivers/usb/gadget/udc/pch_udc.c:		req->td_data->status = (req->td_data->status &
drivers/usb/gadget/udc/pch_udc.c:	td_data = req->td_data;
drivers/usb/gadget/udc/pch_udc.c:	pch_udc_ep_set_ddptr(ep, req->td_data_phys);
drivers/usb/gadget/udc/pch_udc.c:	req->dma_going = 1;
drivers/usb/gadget/udc/pch_udc.c:	req->req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/pch_udc.c:	req->dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/pch_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/pch_udc.c:		return &req->req;
drivers/usb/gadget/udc/pch_udc.c:				  &req->td_data_phys);
drivers/usb/gadget/udc/pch_udc.c:	req->td_data = dma_desc;
drivers/usb/gadget/udc/pch_udc.c:	req->td_data_last = dma_desc;
drivers/usb/gadget/udc/pch_udc.c:	req->chain_len = 1;
drivers/usb/gadget/udc/pch_udc.c:	return &req->req;
drivers/usb/gadget/udc/pch_udc.c:	if (!list_empty(&req->queue))
drivers/usb/gadget/udc/pch_udc.c:	if (req->td_data != NULL) {
drivers/usb/gadget/udc/pch_udc.c:		if (req->chain_len > 1)
drivers/usb/gadget/udc/pch_udc.c:		dma_pool_free(ep->dev->data_requests, req->td_data,
drivers/usb/gadget/udc/pch_udc.c:			      req->td_data_phys);
drivers/usb/gadget/udc/pch_udc.c:	if (!usbep || !usbreq || !usbreq->complete || !usbreq->buf)
drivers/usb/gadget/udc/pch_udc.c:	if (!list_empty(&req->queue))
drivers/usb/gadget/udc/pch_udc.c:	if (usbreq->length &&
drivers/usb/gadget/udc/pch_udc.c:	    ((usbreq->dma == DMA_ADDR_INVALID) || !usbreq->dma)) {
drivers/usb/gadget/udc/pch_udc.c:		if (!((unsigned long)(usbreq->buf) & 0x03)) {
drivers/usb/gadget/udc/pch_udc.c:				usbreq->dma = dma_map_single(&dev->pdev->dev,
drivers/usb/gadget/udc/pch_udc.c:							     usbreq->buf,
drivers/usb/gadget/udc/pch_udc.c:							     usbreq->length,
drivers/usb/gadget/udc/pch_udc.c:				usbreq->dma = dma_map_single(&dev->pdev->dev,
drivers/usb/gadget/udc/pch_udc.c:							     usbreq->buf,
drivers/usb/gadget/udc/pch_udc.c:							     usbreq->length,
drivers/usb/gadget/udc/pch_udc.c:			req->buf = kzalloc(usbreq->length, GFP_ATOMIC);
drivers/usb/gadget/udc/pch_udc.c:			if (!req->buf) {
drivers/usb/gadget/udc/pch_udc.c:				memcpy(req->buf, usbreq->buf, usbreq->length);
drivers/usb/gadget/udc/pch_udc.c:				req->dma = dma_map_single(&dev->pdev->dev,
drivers/usb/gadget/udc/pch_udc.c:							  req->buf,
drivers/usb/gadget/udc/pch_udc.c:							  usbreq->length,
drivers/usb/gadget/udc/pch_udc.c:				req->dma = dma_map_single(&dev->pdev->dev,
drivers/usb/gadget/udc/pch_udc.c:							  req->buf,
drivers/usb/gadget/udc/pch_udc.c:							  usbreq->length,
drivers/usb/gadget/udc/pch_udc.c:		req->dma_mapped = 1;
drivers/usb/gadget/udc/pch_udc.c:	if (usbreq->length > 0) {
drivers/usb/gadget/udc/pch_udc.c:	usbreq->actual = 0;
drivers/usb/gadget/udc/pch_udc.c:	usbreq->status = -EINPROGRESS;
drivers/usb/gadget/udc/pch_udc.c:	req->dma_done = 0;
drivers/usb/gadget/udc/pch_udc.c:		if (!usbreq->length) {
drivers/usb/gadget/udc/pch_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/pch_udc.c:		if (&req->req == usbreq) {
drivers/usb/gadget/udc/pch_udc.c:			if (!list_empty(&req->queue))
drivers/usb/gadget/udc/pch_udc.c:	if (req->dma_going)
drivers/usb/gadget/udc/pch_udc.c:	if (!req->td_data)
drivers/usb/gadget/udc/pch_udc.c:	req->dma_going = 1;
drivers/usb/gadget/udc/pch_udc.c:	td_data = req->td_data;
drivers/usb/gadget/udc/pch_udc.c:	pch_udc_ep_set_ddptr(ep, req->td_data_phys);
drivers/usb/gadget/udc/pch_udc.c:	if ((req->td_data_last->status & PCH_UDC_BUFF_STS) !=
drivers/usb/gadget/udc/pch_udc.c:	if ((req->td_data_last->status & PCH_UDC_RXTX_STS) !=
drivers/usb/gadget/udc/pch_udc.c:		       (req->td_data_last->status & PCH_UDC_RXTX_STS),
drivers/usb/gadget/udc/pch_udc.c:	req->req.actual = req->req.length;
drivers/usb/gadget/udc/pch_udc.c:	req->td_data_last->status = PCH_UDC_BS_HST_BSY | PCH_UDC_DMA_LAST;
drivers/usb/gadget/udc/pch_udc.c:	req->td_data->status = PCH_UDC_BS_HST_BSY | PCH_UDC_DMA_LAST;
drivers/usb/gadget/udc/pch_udc.c:	req->dma_going = 0;
drivers/usb/gadget/udc/pch_udc.c:	if ((req->td_data_last->status & PCH_UDC_BUFF_STS) ==
drivers/usb/gadget/udc/pch_udc.c:		td = req->td_data_last;
drivers/usb/gadget/udc/pch_udc.c:		td = req->td_data;
drivers/usb/gadget/udc/pch_udc.c:				(req->td_data->status & PCH_UDC_RXTX_STS),
drivers/usb/gadget/udc/pch_udc.c:		if (td == req->td_data_last) {
drivers/usb/gadget/udc/pch_udc.c:	if (!count && (req->req.length == UDC_DMA_MAXPACKET))
drivers/usb/gadget/udc/pch_udc.c:	req->td_data->status |= PCH_UDC_DMA_LAST;
drivers/usb/gadget/udc/pch_udc.c:	req->dma_going = 0;
drivers/usb/gadget/udc/pch_udc.c:	req->req.actual = count;
drivers/usb/gadget/udc/pch_udc.c:		if ((req->td_data_last->status & PCH_UDC_BUFF_STS) !=
drivers/usb/gadget/udc/pch_udc.c:			if (!req->dma_going)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (req->usb_req.length == 0)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	remaining = req->usb_req.length % BD_MAX_BUFF_SIZE;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	remaining = req->usb_req.length / BD_MAX_BUFF_SIZE;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->ep->dir = 0;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req_len = req->usb_req.length;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	dma_addr_t buf_add = req->usb_req.dma;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	ep = req->ep;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	bd_xfr = &req->bd_xfr;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req_len = req->usb_req.length;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	tfs = roundup(req->usb_req.length, maxp);
drivers/usb/gadget/udc/bdc/bdc_ep.c:		if (!req->ep->dir)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	ep = req->ep;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	list_del(&req->queue);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.status = status;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	usb_gadget_unmap_request(&bdc->gadget, &req->usb_req, ep->dir);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (req->usb_req.complete) {
drivers/usb/gadget/udc/bdc/bdc_ep.c:		usb_gadget_giveback_request(&ep->usb_ep, &req->usb_req);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	status_req->ep = ep;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	status_req->usb_req.length = 0;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	status_req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	status_req->usb_req.actual = 0;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	status_req->usb_req.complete = NULL;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.actual = 0;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->epnum = ep->ep_num;
drivers/usb/gadget/udc/bdc/bdc_ep.c:		if (req->usb_req.length == 0)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	ret = usb_gadget_map_request(&bdc->gadget, &req->usb_req, ep->dir);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.actual = 0;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->epnum = ep->ep_num;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	ret = usb_gadget_map_request(&bdc->gadget, &req->usb_req, ep->dir);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	start_bdi = req->bd_xfr.start_bdi;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	end_bdi = find_end_bdi(ep, req->bd_xfr.next_hwd_bdi);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	tbi = bdi_to_tbi(ep, req->bd_xfr.next_hwd_bdi);
drivers/usb/gadget/udc/bdc/bdc_ep.c:			sizeof(struct bdc_bd)*(req->bd_xfr.next_hwd_bdi -
drivers/usb/gadget/udc/bdc/bdc_ep.c:	bd_xfr = &req->bd_xfr;
drivers/usb/gadget/udc/bdc/bdc_ep.c:		req->usb_req.actual = actual_length;
drivers/usb/gadget/udc/bdc/bdc_ep.c:		req->usb_req.actual = req->usb_req.length -
drivers/usb/gadget/udc/bdc/bdc_ep.c:			req->usb_req.length, req->usb_req.actual,
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (req->usb_req.actual < req->usb_req.length) {
drivers/usb/gadget/udc/bdc/bdc_ep.c:		if (req->usb_req.short_not_ok)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (!_req || !_req->complete || !_req->buf)
drivers/usb/gadget/udc/bdc/bdc_ep.c:				_req, ep->name, _req->length, _req->zero);
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (_req->length > MAX_XFR_LEN) {
drivers/usb/gadget/udc/bdc/bdc_ep.c:			MAX_XFR_LEN, _req->length);
drivers/usb/gadget/udc/bdc/bdc_ep.c:		if (&req->usb_req == _req)
drivers/usb/gadget/udc/bdc/bdc_ep.c:	if (&req->usb_req != _req) {
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->ep = ep;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->epnum = ep->ep_num;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	req->usb_req.dma = DMA_ADDR_INVALID;
drivers/usb/gadget/udc/bdc/bdc_ep.c:	return &req->usb_req;
drivers/usb/gadget/udc/trace.h:		__entry->length = req->length;
drivers/usb/gadget/udc/trace.h:		__entry->actual = req->actual;
drivers/usb/gadget/udc/trace.h:		__entry->num_sgs = req->num_sgs;
drivers/usb/gadget/udc/trace.h:		__entry->num_mapped_sgs = req->num_mapped_sgs;
drivers/usb/gadget/udc/trace.h:		__entry->stream_id = req->stream_id;
drivers/usb/gadget/udc/trace.h:		__entry->no_interrupt = req->no_interrupt;
drivers/usb/gadget/udc/trace.h:		__entry->zero = req->zero;
drivers/usb/gadget/udc/trace.h:		__entry->short_not_ok = req->short_not_ok;
drivers/usb/gadget/udc/trace.h:		__entry->status = req->status;
drivers/usb/gadget/udc/core.c: * @req->complete() will be called exactly once, when the Gadget core and
drivers/usb/gadget/udc/core.c:	if (req->length == 0)
drivers/usb/gadget/udc/core.c:	if (req->num_sgs) {
drivers/usb/gadget/udc/core.c:		mapped = dma_map_sg(dev, req->sg, req->num_sgs,
drivers/usb/gadget/udc/core.c:		req->num_mapped_sgs = mapped;
drivers/usb/gadget/udc/core.c:		if (is_vmalloc_addr(req->buf)) {
drivers/usb/gadget/udc/core.c:		} else if (object_is_on_stack(req->buf)) {
drivers/usb/gadget/udc/core.c:		req->dma = dma_map_single(dev, req->buf, req->length,
drivers/usb/gadget/udc/core.c:		if (dma_mapping_error(dev, req->dma)) {
drivers/usb/gadget/udc/core.c:		req->dma_mapped = 1;
drivers/usb/gadget/udc/core.c:	if (req->length == 0)
drivers/usb/gadget/udc/core.c:	if (req->num_mapped_sgs) {
drivers/usb/gadget/udc/core.c:		dma_unmap_sg(dev, req->sg, req->num_sgs,
drivers/usb/gadget/udc/core.c:		req->num_mapped_sgs = 0;
drivers/usb/gadget/udc/core.c:	} else if (req->dma_mapped) {
drivers/usb/gadget/udc/core.c:		dma_unmap_single(dev, req->dma, req->length,
drivers/usb/gadget/udc/core.c:		req->dma_mapped = 0;
drivers/usb/gadget/udc/core.c:	if (likely(req->status == 0))
drivers/usb/gadget/udc/core.c:	req->complete(ep, req);
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->req.buf, req->req.length,
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->req.no_interrupt ? 'i' : 'I',
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->req.zero ? 'Z' : 'z',
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->req.short_not_ok ? 's' : 'S',
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->req.status,
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->submitted ? 'F' : 'f',
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->using_dma ? 'D' : 'd',
drivers/usb/gadget/udc/atmel_usba_udc.c:				req->last_transaction ? 'L' : 'l');
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:	transaction_len = req->req.length - req->req.actual;
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->last_transaction = 1;
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->last_transaction = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:	} else if (transaction_len == ep->ep.maxpacket && req->req.zero)
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->last_transaction = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->last_transaction ? ", done" : "");
drivers/usb/gadget/udc/atmel_usba_udc.c:	memcpy_toio(ep->fifo, req->req.buf + req->req.actual, transaction_len);
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->req.actual += transaction_len;
drivers/usb/gadget/udc/atmel_usba_udc.c:		ep->ep.name, req, req->req.length);
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->req.actual = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->submitted = 1;
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (req->using_dma) {
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->req.length == 0) {
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->req.zero)
drivers/usb/gadget/udc/atmel_usba_udc.c:		usba_dma_writel(ep, ADDRESS, req->req.dma);
drivers/usb/gadget/udc/atmel_usba_udc.c:		usba_dma_writel(ep, CONTROL, req->ctrl);
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->last_transaction) {
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (!req->submitted)
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->req.actual + bytecount >= req->req.length) {
drivers/usb/gadget/udc/atmel_usba_udc.c:			bytecount = req->req.length - req->req.actual;
drivers/usb/gadget/udc/atmel_usba_udc.c:		memcpy_fromio(req->req.buf + req->req.actual,
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->req.actual += bytecount;
drivers/usb/gadget/udc/atmel_usba_udc.c:			req->req.status = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:			usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/atmel_usba_udc.c:	WARN_ON(!list_empty(&req->queue));
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (req->req.status == -EINPROGRESS)
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->req.status = status;
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (req->using_dma)
drivers/usb/gadget/udc/atmel_usba_udc.c:		usb_gadget_unmap_request(&udc->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/atmel_usba_udc.c:		ep->ep.name, req, req->req.status, req->req.actual);
drivers/usb/gadget/udc/atmel_usba_udc.c:	usb_gadget_giveback_request(&ep->ep, &req->req);
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:	INIT_LIST_HEAD(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:	return &req->req;
drivers/usb/gadget/udc/atmel_usba_udc.c:		ep->ep.name, req->req.length, &req->req.dma,
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->req.zero ? 'Z' : 'z',
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->req.short_not_ok ? 'S' : 's',
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->req.no_interrupt ? 'I' : 'i');
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (req->req.length > 0x10000) {
drivers/usb/gadget/udc/atmel_usba_udc.c:		DBG(DBG_ERR, "invalid request length %u\n", req->req.length);
drivers/usb/gadget/udc/atmel_usba_udc.c:	ret = usb_gadget_map_request(&udc->gadget, &req->req, ep->is_in);
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->using_dma = 1;
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->ctrl = USBA_BF(DMA_BUF_LEN, req->req.length)
drivers/usb/gadget/udc/atmel_usba_udc.c:		req->ctrl |= USBA_DMA_END_TR_EN | USBA_DMA_END_TR_IE;
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:			ep->ep.name, req, _req->length);
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->submitted = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->using_dma = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->last_transaction = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:	_req->status = -EINPROGRESS;
drivers/usb/gadget/udc/atmel_usba_udc.c:	_req->actual = 0;
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_add_tail(&req->queue, &ep->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:	req->req.actual = req->req.length - USBA_BFEXT(DMA_BUF_LEN, status);
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (&req->req == _req)
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (&req->req != _req) {
drivers/usb/gadget/udc/atmel_usba_udc.c:	if (req->using_dma) {
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (ep->queue.next == &req->queue) {
drivers/usb/gadget/udc/atmel_usba_udc.c:	list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->submitted)
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->last_transaction) {
drivers/usb/gadget/udc/atmel_usba_udc.c:				list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:				list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:				list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:		if (req->using_dma) {
drivers/usb/gadget/udc/atmel_usba_udc.c:			list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:			if (req->submitted)
drivers/usb/gadget/udc/atmel_usba_udc.c:			if (req->last_transaction) {
drivers/usb/gadget/udc/atmel_usba_udc.c:				list_del_init(&req->queue);
drivers/usb/gadget/udc/atmel_usba_udc.c:		list_del_init(&req->queue);
drivers/usb/gadget/udc/tegra-xudc.c:	if (likely(req->usb_req.status == -EINPROGRESS))
drivers/usb/gadget/udc/tegra-xudc.c:		req->usb_req.status = status;
drivers/usb/gadget/udc/tegra-xudc.c:	list_del_init(&req->list);
drivers/usb/gadget/udc/tegra-xudc.c:		usb_gadget_unmap_request(&xudc->gadget, &req->usb_req,
drivers/usb/gadget/udc/tegra-xudc.c:		usb_gadget_unmap_request(&xudc->gadget, &req->usb_req,
drivers/usb/gadget/udc/tegra-xudc.c:	usb_gadget_giveback_request(&ep->usb_ep, &req->usb_req);
drivers/usb/gadget/udc/tegra-xudc.c:	len = min_t(size_t, XUDC_TRB_MAX_BUFFER_SIZE, req->usb_req.length -
drivers/usb/gadget/udc/tegra-xudc.c:		    req->buf_queued);
drivers/usb/gadget/udc/tegra-xudc.c:		buf_addr = req->usb_req.dma + req->buf_queued;
drivers/usb/gadget/udc/tegra-xudc.c:	trb_write_td_size(trb, req->trbs_needed - req->trbs_queued - 1);
drivers/usb/gadget/udc/tegra-xudc.c:	if (req->trbs_queued == req->trbs_needed - 1 ||
drivers/usb/gadget/udc/tegra-xudc.c:		(req->need_zlp && req->trbs_queued == req->trbs_needed - 2))
drivers/usb/gadget/udc/tegra-xudc.c:		trb_write_stream_id(trb, req->usb_req.stream_id);
drivers/usb/gadget/udc/tegra-xudc.c:	req->trbs_queued++;
drivers/usb/gadget/udc/tegra-xudc.c:	req->buf_queued += len;
drivers/usb/gadget/udc/tegra-xudc.c:	count = req->trbs_needed - req->trbs_queued;
drivers/usb/gadget/udc/tegra-xudc.c:	if (req->need_zlp && usb_endpoint_xfer_control(ep->desc) && count > 1)
drivers/usb/gadget/udc/tegra-xudc.c:	if (!req->first_trb)
drivers/usb/gadget/udc/tegra-xudc.c:		req->first_trb = &ep->transfer_ring[ep->enq_ptr];
drivers/usb/gadget/udc/tegra-xudc.c:		req->last_trb = trb;
drivers/usb/gadget/udc/tegra-xudc.c:		val |= DB_STREAMID(req->usb_req.stream_id);
drivers/usb/gadget/udc/tegra-xudc.c:		err = usb_gadget_map_request(&xudc->gadget, &req->usb_req,
drivers/usb/gadget/udc/tegra-xudc.c:		err = usb_gadget_map_request(&xudc->gadget, &req->usb_req,
drivers/usb/gadget/udc/tegra-xudc.c:	req->first_trb = NULL;
drivers/usb/gadget/udc/tegra-xudc.c:	req->last_trb = NULL;
drivers/usb/gadget/udc/tegra-xudc.c:	req->buf_queued = 0;
drivers/usb/gadget/udc/tegra-xudc.c:	req->trbs_queued = 0;
drivers/usb/gadget/udc/tegra-xudc.c:	req->need_zlp = false;
drivers/usb/gadget/udc/tegra-xudc.c:	req->trbs_needed = DIV_ROUND_UP(req->usb_req.length,
drivers/usb/gadget/udc/tegra-xudc.c:	if (req->usb_req.length == 0)
drivers/usb/gadget/udc/tegra-xudc.c:		req->trbs_needed++;
drivers/usb/gadget/udc/tegra-xudc.c:	    req->usb_req.zero && req->usb_req.length &&
drivers/usb/gadget/udc/tegra-xudc.c:	    ((req->usb_req.length % ep->usb_ep.maxpacket) == 0)) {
drivers/usb/gadget/udc/tegra-xudc.c:		req->trbs_needed++;
drivers/usb/gadget/udc/tegra-xudc.c:		req->need_zlp = true;
drivers/usb/gadget/udc/tegra-xudc.c:	req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/tegra-xudc.c:	req->usb_req.actual = 0;
drivers/usb/gadget/udc/tegra-xudc.c:	list_add_tail(&req->list, &ep->queue);
drivers/usb/gadget/udc/tegra-xudc.c:	struct tegra_xudc_trb *trb = req->first_trb;
drivers/usb/gadget/udc/tegra-xudc.c:	ep->enq_ptr = req->first_trb - ep->transfer_ring;
drivers/usb/gadget/udc/tegra-xudc.c:		req->usb_req.status = -EINPROGRESS;
drivers/usb/gadget/udc/tegra-xudc.c:		req->usb_req.actual = 0;
drivers/usb/gadget/udc/tegra-xudc.c:		req->first_trb = NULL;
drivers/usb/gadget/udc/tegra-xudc.c:		req->last_trb = NULL;
drivers/usb/gadget/udc/tegra-xudc.c:		req->buf_queued = 0;
drivers/usb/gadget/udc/tegra-xudc.c:		req->trbs_queued = 0;
drivers/usb/gadget/udc/tegra-xudc.c:		req->first_trb, req->last_trb, trb);
drivers/usb/gadget/udc/tegra-xudc.c:	if (trb >= req->first_trb && (trb <= req->last_trb ||
drivers/usb/gadget/udc/tegra-xudc.c:				      req->last_trb < req->first_trb))
drivers/usb/gadget/udc/tegra-xudc.c:	if (trb < req->first_trb && trb <= req->last_trb &&
drivers/usb/gadget/udc/tegra-xudc.c:	    req->last_trb < req->first_trb)
drivers/usb/gadget/udc/tegra-xudc.c:		__func__, req->first_trb, req->last_trb, enq_trb, trb);
drivers/usb/gadget/udc/tegra-xudc.c:	if (trb < req->first_trb && (enq_trb <= trb ||
drivers/usb/gadget/udc/tegra-xudc.c:				     req->first_trb < enq_trb))
drivers/usb/gadget/udc/tegra-xudc.c:	if (trb > req->first_trb && req->first_trb < enq_trb && enq_trb <= trb)
drivers/usb/gadget/udc/tegra-xudc.c:	if (!req->trbs_queued) {
drivers/usb/gadget/udc/tegra-xudc.c:		req->usb_req.actual = ep_ctx_read_edtla(ep->context);
drivers/usb/gadget/udc/tegra-xudc.c:		if (req->usb_req.actual > 0) {
drivers/usb/gadget/udc/tegra-xudc.c:	INIT_LIST_HEAD(&req->list);
drivers/usb/gadget/udc/tegra-xudc.c:	return &req->usb_req;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.buf = NULL;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.dma = 0;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.length = 0;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.complete = cmpl;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.context = xudc;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.buf = buf;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.length = len;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.complete = cmpl;
drivers/usb/gadget/udc/tegra-xudc.c:	xudc->ep0_req->usb_req.context = xudc;
drivers/usb/gadget/udc/tegra-xudc.c:	struct tegra_xudc *xudc = req->context;
drivers/usb/gadget/udc/tegra-xudc.c:	struct tegra_xudc *xudc = req->context;
drivers/usb/gadget/udc/tegra-xudc.c:		if (!req->trbs_queued)
drivers/usb/gadget/udc/tegra-xudc.c:		(req->trbs_needed == req->trbs_queued)))) {
drivers/usb/gadget/udc/tegra-xudc.c:		struct tegra_xudc_trb *last = req->last_trb;
drivers/usb/gadget/udc/tegra-xudc.c:		req->usb_req.actual = req->usb_req.length - residual;
drivers/usb/gadget/udc/tegra-xudc.c:			req->usb_req.actual, req->usb_req.length);
drivers/usb/gadget/udc/tegra-xudc.c:				   &xudc->ep0_req->usb_req);
drivers/usb/gadget/u_f.c:		req->length = usb_endpoint_dir_out(ep->desc) ?
drivers/usb/gadget/u_f.c:		req->buf = kmalloc(req->length, GFP_ATOMIC);
drivers/usb/gadget/u_f.c:		if (!req->buf) {
drivers/usb/gadget/function/f_uvc.c:	struct uvc_device *uvc = req->context;
drivers/usb/gadget/function/f_uvc.c:		uvc_event->data.length = req->actual;
drivers/usb/gadget/function/f_uvc.c:		memcpy(&uvc_event->data.data, req->buf, req->actual);
drivers/usb/gadget/function/f_uvc.c:	uvc->control_req->buf = uvc->control_buf;
drivers/usb/gadget/function/f_uvc.c:	uvc->control_req->complete = uvc_function_ep0_complete;
drivers/usb/gadget/function/f_uvc.c:	uvc->control_req->context = uvc;
drivers/usb/gadget/function/f_tcm.c:	struct usbg_cmd *cmd = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0) {
drivers/usb/gadget/function/f_tcm.c:	fu->bot_status.req->context = cmd;
drivers/usb/gadget/function/f_tcm.c:	struct usbg_cmd *cmd = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0)
drivers/usb/gadget/function/f_tcm.c:			req->length = ep->maxpacket;
drivers/usb/gadget/function/f_tcm.c:			req->length = cmd->data_len;
drivers/usb/gadget/function/f_tcm.c:			req->length = ep->maxpacket;
drivers/usb/gadget/function/f_tcm.c:			req->length = cmd->data_len;
drivers/usb/gadget/function/f_tcm.c:		req->complete = bot_err_compl;
drivers/usb/gadget/function/f_tcm.c:		req->context = cmd;
drivers/usb/gadget/function/f_tcm.c:		req->buf = fu->cmd.buf;
drivers/usb/gadget/function/f_tcm.c:		fu->bot_status.req->context = cmd;
drivers/usb/gadget/function/f_tcm.c:	struct usbg_cmd *cmd = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0)
drivers/usb/gadget/function/f_tcm.c:	struct f_uas *fu = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0)
drivers/usb/gadget/function/f_tcm.c:	ret = bot_submit_command(fu, req->buf, req->actual);
drivers/usb/gadget/function/f_tcm.c:	fu->bot_status.req->buf = &fu->bot_status.csw;
drivers/usb/gadget/function/f_tcm.c:	fu->bot_status.req->length = US_BULK_CS_WRAP_LEN;
drivers/usb/gadget/function/f_tcm.c:	fu->bot_status.req->complete = bot_status_complete;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->complete = bot_cmd_complete;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->buf = fu->cmd.buf;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->length = fu->ep_out->maxpacket;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->context = fu;
drivers/usb/gadget/function/f_tcm.c:		ret_lun = cdev->req->buf;
drivers/usb/gadget/function/f_tcm.c:		cdev->req->length = 1;
drivers/usb/gadget/function/f_tcm.c:	struct usbg_cmd *cmd = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0)
drivers/usb/gadget/function/f_tcm.c:	struct f_uas *fu = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0)
drivers/usb/gadget/function/f_tcm.c:	ret = usbg_submit_command(fu, req->buf, req->actual);
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->complete = uasp_cmd_complete;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->buf = fu->cmd.buf;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->length = fu->ep_cmd->maxpacket;
drivers/usb/gadget/function/f_tcm.c:	fu->cmd.req->context = fu;
drivers/usb/gadget/function/f_tcm.c:	struct usbg_cmd *cmd = req->context;
drivers/usb/gadget/function/f_tcm.c:	if (req->status < 0) {
drivers/usb/gadget/function/f_tcm.c:	if (req->num_sgs == 0) {
drivers/usb/gadget/function/f_tcm.c:		req->buf = cmd->data_buf;
drivers/usb/gadget/function/f_tcm.c:		req->buf = NULL;
drivers/usb/gadget/function/f_tcm.c:		req->num_sgs = se_cmd->t_data_nents;
drivers/usb/gadget/function/f_tcm.c:		req->sg = se_cmd->t_data_sg;
drivers/usb/gadget/function/f_tcm.c:	req->is_last = 1;
drivers/usb/gadget/function/f_tcm.c:	req->complete = usbg_data_write_cmpl;
drivers/usb/gadget/function/f_tcm.c:	req->length = se_cmd->data_length;
drivers/usb/gadget/function/f_tcm.c:	req->context = cmd;
drivers/usb/gadget/function/f_uac1_legacy.c:	struct f_audio *audio = req->context;
drivers/usb/gadget/function/f_uac1_legacy.c:	if (audio_buf_size - copy_buf->actual < req->actual) {
drivers/usb/gadget/function/f_uac1_legacy.c:	memcpy(copy_buf->buf + copy_buf->actual, req->buf, req->actual);
drivers/usb/gadget/function/f_uac1_legacy.c:	copy_buf->actual += req->actual;
drivers/usb/gadget/function/f_uac1_legacy.c:	struct f_audio *audio = req->context;
drivers/usb/gadget/function/f_uac1_legacy.c:	int status = req->status;
drivers/usb/gadget/function/f_uac1_legacy.c:			memcpy(&data, req->buf, req->length);
drivers/usb/gadget/function/f_uac1_legacy.c:	req->context = audio;
drivers/usb/gadget/function/f_uac1_legacy.c:	req->complete = f_audio_complete;
drivers/usb/gadget/function/f_uac1_legacy.c:	req->context = audio;
drivers/usb/gadget/function/f_uac1_legacy.c:	req->complete = f_audio_complete;
drivers/usb/gadget/function/f_uac1_legacy.c:	memcpy(req->buf, &value, len);
drivers/usb/gadget/function/f_uac1_legacy.c:		req->zero = 0;
drivers/usb/gadget/function/f_uac1_legacy.c:		req->length = value;
drivers/usb/gadget/function/f_uac1_legacy.c:					req->buf = kzalloc(req_buf_size,
drivers/usb/gadget/function/f_uac1_legacy.c:					if (req->buf) {
drivers/usb/gadget/function/f_uac1_legacy.c:						req->length = req_buf_size;
drivers/usb/gadget/function/f_uac1_legacy.c:						req->context = audio;
drivers/usb/gadget/function/f_uac1_legacy.c:						req->complete =
drivers/usb/gadget/function/f_fs.c:	struct ffs_data *ffs = req->context;
drivers/usb/gadget/function/f_fs.c:	req->zero     = len < le16_to_cpu(ffs->ev.setup.wLength);
drivers/usb/gadget/function/f_fs.c:	req->buf      = data;
drivers/usb/gadget/function/f_fs.c:	req->length   = len;
drivers/usb/gadget/function/f_fs.c:	if (req->buf == NULL)
drivers/usb/gadget/function/f_fs.c:		req->buf = (void *)0xDEADBABE;
drivers/usb/gadget/function/f_fs.c:	return req->status ? req->status : req->actual;
drivers/usb/gadget/function/f_fs.c:	if (req->context) {
drivers/usb/gadget/function/f_fs.c:		ep->status = req->status ? req->status : req->actual;
drivers/usb/gadget/function/f_fs.c:		complete(req->context);
drivers/usb/gadget/function/f_fs.c:	int ret = io_data->req->status ? io_data->req->status :
drivers/usb/gadget/function/f_fs.c:					 io_data->req->actual;
drivers/usb/gadget/function/f_fs.c:	struct ffs_io_data *io_data = req->context;
drivers/usb/gadget/function/f_fs.c:			req->buf = NULL;
drivers/usb/gadget/function/f_fs.c:			req->sg	= io_data->sgt.sgl;
drivers/usb/gadget/function/f_fs.c:			req->num_sgs = io_data->sgt.nents;
drivers/usb/gadget/function/f_fs.c:			req->buf = data;
drivers/usb/gadget/function/f_fs.c:			req->num_sgs = 0;
drivers/usb/gadget/function/f_fs.c:		req->length = data_len;
drivers/usb/gadget/function/f_fs.c:		req->context  = &done;
drivers/usb/gadget/function/f_fs.c:		req->complete = ffs_epfile_io_complete;
drivers/usb/gadget/function/f_fs.c:			 * condition with req->complete callback.
drivers/usb/gadget/function/f_fs.c:			req->buf = NULL;
drivers/usb/gadget/function/f_fs.c:			req->sg	= io_data->sgt.sgl;
drivers/usb/gadget/function/f_fs.c:			req->num_sgs = io_data->sgt.nents;
drivers/usb/gadget/function/f_fs.c:			req->buf = data;
drivers/usb/gadget/function/f_fs.c:			req->num_sgs = 0;
drivers/usb/gadget/function/f_fs.c:		req->length = data_len;
drivers/usb/gadget/function/f_fs.c:		req->context  = io_data;
drivers/usb/gadget/function/f_fs.c:		req->complete = ffs_epfile_async_io_complete;
drivers/usb/gadget/function/f_fs.c:	ffs->ep0req->complete = ffs_ep0_complete;
drivers/usb/gadget/function/f_fs.c:	ffs->ep0req->context = ffs;
drivers/usb/gadget/function/f_fs.c:	pr_vdebug("creq->bRequestType = %02x\n", creq->bRequestType);
drivers/usb/gadget/function/f_fs.c:	pr_vdebug("creq->bRequest     = %02x\n", creq->bRequest);
drivers/usb/gadget/function/f_fs.c:	pr_vdebug("creq->wValue       = %04x\n", le16_to_cpu(creq->wValue));
drivers/usb/gadget/function/f_fs.c:	pr_vdebug("creq->wIndex       = %04x\n", le16_to_cpu(creq->wIndex));
drivers/usb/gadget/function/f_fs.c:	pr_vdebug("creq->wLength      = %04x\n", le16_to_cpu(creq->wLength));
drivers/usb/gadget/function/f_fs.c:	switch (creq->bRequestType & USB_RECIP_MASK) {
drivers/usb/gadget/function/f_fs.c:		ret = ffs_func_revmap_intf(func, le16_to_cpu(creq->wIndex));
drivers/usb/gadget/function/f_fs.c:		ret = ffs_func_revmap_ep(func, le16_to_cpu(creq->wIndex));
drivers/usb/gadget/function/f_fs.c:			ret = le16_to_cpu(creq->wIndex);
drivers/usb/gadget/function/f_fs.c:	return creq->wLength == 0 ? USB_GADGET_DELAYED_STATUS : 0;
drivers/usb/gadget/function/f_fs.c:	switch (creq->bRequestType & USB_RECIP_MASK) {
drivers/usb/gadget/function/f_fs.c:					     le16_to_cpu(creq->wIndex)) >= 0);
drivers/usb/gadget/function/f_fs.c:					   le16_to_cpu(creq->wIndex)) >= 0);
drivers/usb/gadget/function/f_ncm.c:	event = req->buf;
drivers/usb/gadget/function/f_ncm.c:		req->length = sizeof *event;
drivers/usb/gadget/function/f_ncm.c:		req->length = NCM_STATUS_BYTECOUNT;
drivers/usb/gadget/function/f_ncm.c:		data = req->buf + sizeof *event;
drivers/usb/gadget/function/f_ncm.c:	struct f_ncm			*ncm = req->context;
drivers/usb/gadget/function/f_ncm.c:	struct usb_cdc_notification	*event = req->buf;
drivers/usb/gadget/function/f_ncm.c:	switch (req->status) {
drivers/usb/gadget/function/f_ncm.c:			event->bNotificationType, req->status);
drivers/usb/gadget/function/f_ncm.c:	struct usb_function	*f = req->context;
drivers/usb/gadget/function/f_ncm.c:	req->context = NULL;
drivers/usb/gadget/function/f_ncm.c:	if (req->status || req->actual != req->length) {
drivers/usb/gadget/function/f_ncm.c:	in_size = get_unaligned_le32(req->buf);
drivers/usb/gadget/function/f_ncm.c:		memcpy(req->buf, &ntb_parameters, value);
drivers/usb/gadget/function/f_ncm.c:		put_unaligned_le32(ncm->port.fixed_in_len, req->buf);
drivers/usb/gadget/function/f_ncm.c:		req->complete = ncm_ep0out_complete;
drivers/usb/gadget/function/f_ncm.c:		req->length = w_length;
drivers/usb/gadget/function/f_ncm.c:		req->context = f;
drivers/usb/gadget/function/f_ncm.c:		value = req->length;
drivers/usb/gadget/function/f_ncm.c:		put_unaligned_le16(format, req->buf);
drivers/usb/gadget/function/f_ncm.c:		put_unaligned_le16(is_crc, req->buf);
drivers/usb/gadget/function/f_ncm.c:		req->zero = 0;
drivers/usb/gadget/function/f_ncm.c:		req->length = value;
drivers/usb/gadget/function/f_ncm.c:	ncm->notify_req->buf = kmalloc(NCM_STATUS_BYTECOUNT, GFP_KERNEL);
drivers/usb/gadget/function/f_ncm.c:	if (!ncm->notify_req->buf)
drivers/usb/gadget/function/f_ncm.c:	ncm->notify_req->context = ncm;
drivers/usb/gadget/function/f_ncm.c:	ncm->notify_req->complete = ncm_notify_complete;
drivers/usb/gadget/function/f_ncm.c:		kfree(ncm->notify_req->buf);
drivers/usb/gadget/function/f_ncm.c:	kfree(ncm->notify_req->buf);
drivers/usb/gadget/function/uvc_video.c:	void *mem = req->buf;
drivers/usb/gadget/function/uvc_video.c:	req->length = video->req_size - len;
drivers/usb/gadget/function/uvc_video.c:	req->zero = video->payload_size == video->max_payload_size;
drivers/usb/gadget/function/uvc_video.c:	void *mem = req->buf;
drivers/usb/gadget/function/uvc_video.c:	req->length = video->req_size - len;
drivers/usb/gadget/function/uvc_video.c:	struct uvc_video *video = req->context;
drivers/usb/gadget/function/uvc_video.c:	switch (req->status) {
drivers/usb/gadget/function/uvc_video.c:			  req->status);
drivers/usb/gadget/function/uvc_video.c:	list_add_tail(&req->list, &video->req_free);
drivers/usb/gadget/function/uvc_video.c:		list_del(&req->list);
drivers/usb/gadget/function/uvc_video.c:	list_add_tail(&req->list, &video->req_free);
drivers/usb/gadget/function/f_uac1.c:		req->zero = 0;
drivers/usb/gadget/function/f_uac1.c:		req->length = value;
drivers/usb/gadget/function/uvc_v4l2.c:	req->length = min_t(unsigned int, uvc->event_length, data->length);
drivers/usb/gadget/function/uvc_v4l2.c:	req->zero = data->length < uvc->event_length;
drivers/usb/gadget/function/uvc_v4l2.c:	memcpy(req->buf, data->data, req->length);
drivers/usb/gadget/function/f_hid.c:	count = min_t(unsigned int, count, req->actual - list->pos);
drivers/usb/gadget/function/f_hid.c:	count -= copy_to_user(buffer, req->buf + list->pos, count);
drivers/usb/gadget/function/f_hid.c:	if (list->pos == req->actual) {
drivers/usb/gadget/function/f_hid.c:		req->length = hidg->report_length;
drivers/usb/gadget/function/f_hid.c:	if (req->status != 0) {
drivers/usb/gadget/function/f_hid.c:			"End Point Request ERROR: %d\n", req->status);
drivers/usb/gadget/function/f_hid.c:	status = copy_from_user(req->buf, buffer, count);
drivers/usb/gadget/function/f_hid.c:	req->status   = 0;
drivers/usb/gadget/function/f_hid.c:	req->zero     = 0;
drivers/usb/gadget/function/f_hid.c:	req->length   = count;
drivers/usb/gadget/function/f_hid.c:	req->complete = f_hidg_req_complete;
drivers/usb/gadget/function/f_hid.c:	req->context  = hidg;
drivers/usb/gadget/function/f_hid.c:	struct f_hidg *hidg = (struct f_hidg *) req->context;
drivers/usb/gadget/function/f_hid.c:	switch (req->status) {
drivers/usb/gadget/function/f_hid.c:		ERROR(cdev, "Set report failed %d\n", req->status);
drivers/usb/gadget/function/f_hid.c:		memset(req->buf, 0x0, length);
drivers/usb/gadget/function/f_hid.c:		((u8 *) req->buf)[0] = hidg->protocol;
drivers/usb/gadget/function/f_hid.c:			memcpy(req->buf, &hidg_desc_copy, length);
drivers/usb/gadget/function/f_hid.c:			memcpy(req->buf, hidg->report_desc, length);
drivers/usb/gadget/function/f_hid.c:	req->zero = 0;
drivers/usb/gadget/function/f_hid.c:	req->length = length;
drivers/usb/gadget/function/f_hid.c:				req->complete = hidg_set_report_complete;
drivers/usb/gadget/function/f_hid.c:				req->context  = hidg;
drivers/usb/gadget/function/f_midi.c:	u8 *buf = req->buf;
drivers/usb/gadget/function/f_midi.c:	for (i = 0; i + 3 < req->actual; i += 4)
drivers/usb/gadget/function/f_midi.c:	int status = req->status;
drivers/usb/gadget/function/f_midi.c:			req->length = 0;
drivers/usb/gadget/function/f_midi.c:				req->actual, req->length);
drivers/usb/gadget/function/f_midi.c:				status, req->actual, req->length);
drivers/usb/gadget/function/f_midi.c:				ep->name, req->length, status);
drivers/usb/gadget/function/f_midi.c:		req->length = 0;
drivers/usb/gadget/function/f_midi.c:		req->complete = f_midi_complete;
drivers/usb/gadget/function/f_midi.c:		req->complete = f_midi_complete;
drivers/usb/gadget/function/f_midi.c:			if (req->buf != NULL)
drivers/usb/gadget/function/f_midi.c:		unsigned int length = req->length;
drivers/usb/gadget/function/f_midi.c:		u8 *buf = (u8 *)req->buf + length;
drivers/usb/gadget/function/f_midi.c:		req->length = length + sizeof(p);
drivers/usb/gadget/function/f_midi.c:	if (req->length > 0)
drivers/usb/gadget/function/f_midi.c:		while (req->length + 3 < midi->buflen) {
drivers/usb/gadget/function/f_midi.c:	if (req->length <= 0)
drivers/usb/gadget/function/f_midi.c:		req->length = 0; /* Re-use request next time. */
drivers/usb/gadget/function/f_loopback.c:	int			status = req->status;
drivers/usb/gadget/function/f_loopback.c:			struct usb_request *in_req = req->context;
drivers/usb/gadget/function/f_loopback.c:			in_req->zero = (req->actual < req->length);
drivers/usb/gadget/function/f_loopback.c:			in_req->length = req->actual;
drivers/usb/gadget/function/f_loopback.c:			req = req->context;
drivers/usb/gadget/function/f_loopback.c:				status, req->actual, req->length);
drivers/usb/gadget/function/f_loopback.c:				    req->context);
drivers/usb/gadget/function/f_loopback.c:		in_req->complete = loopback_complete;
drivers/usb/gadget/function/f_loopback.c:		out_req->complete = loopback_complete;
drivers/usb/gadget/function/f_loopback.c:		in_req->buf = out_req->buf;
drivers/usb/gadget/function/f_loopback.c:		in_req->context = out_req;
drivers/usb/gadget/function/f_loopback.c:		out_req->context = in_req;
drivers/usb/gadget/function/f_ecm.c:	event = req->buf;
drivers/usb/gadget/function/f_ecm.c:		req->length = sizeof *event;
drivers/usb/gadget/function/f_ecm.c:		req->length = ECM_STATUS_BYTECOUNT;
drivers/usb/gadget/function/f_ecm.c:		data = req->buf + sizeof *event;
drivers/usb/gadget/function/f_ecm.c:	struct f_ecm			*ecm = req->context;
drivers/usb/gadget/function/f_ecm.c:	struct usb_cdc_notification	*event = req->buf;
drivers/usb/gadget/function/f_ecm.c:	switch (req->status) {
drivers/usb/gadget/function/f_ecm.c:			event->bNotificationType, req->status);
drivers/usb/gadget/function/f_ecm.c:		req->zero = 0;
drivers/usb/gadget/function/f_ecm.c:		req->length = value;
drivers/usb/gadget/function/f_ecm.c:	ecm->notify_req->buf = kmalloc(ECM_STATUS_BYTECOUNT, GFP_KERNEL);
drivers/usb/gadget/function/f_ecm.c:	if (!ecm->notify_req->buf)
drivers/usb/gadget/function/f_ecm.c:	ecm->notify_req->context = ecm;
drivers/usb/gadget/function/f_ecm.c:	ecm->notify_req->complete = ecm_notify_complete;
drivers/usb/gadget/function/f_ecm.c:		kfree(ecm->notify_req->buf);
drivers/usb/gadget/function/f_ecm.c:	kfree(ecm->notify_req->buf);
drivers/usb/gadget/function/f_rndis.c:	__le32				*data = req->buf;
drivers/usb/gadget/function/f_rndis.c:	struct f_rndis			*rndis = req->context;
drivers/usb/gadget/function/f_rndis.c:	int				status = req->status;
drivers/usb/gadget/function/f_rndis.c:			req->actual, req->length);
drivers/usb/gadget/function/f_rndis.c:	struct f_rndis			*rndis = req->context;
drivers/usb/gadget/function/f_rndis.c:	status = rndis_msg_parser(rndis->params, (u8 *) req->buf);
drivers/usb/gadget/function/f_rndis.c:			status, req->actual, req->length);
drivers/usb/gadget/function/f_rndis.c:		req->complete = rndis_command_complete;
drivers/usb/gadget/function/f_rndis.c:		req->context = rndis;
drivers/usb/gadget/function/f_rndis.c:				memcpy(req->buf, buf, n);
drivers/usb/gadget/function/f_rndis.c:				req->complete = rndis_response_complete;
drivers/usb/gadget/function/f_rndis.c:				req->context = rndis;
drivers/usb/gadget/function/f_rndis.c:		req->zero = (value < w_length);
drivers/usb/gadget/function/f_rndis.c:		req->length = value;
drivers/usb/gadget/function/f_rndis.c:	rndis->notify_req->buf = kmalloc(STATUS_BYTECOUNT, GFP_KERNEL);
drivers/usb/gadget/function/f_rndis.c:	if (!rndis->notify_req->buf)
drivers/usb/gadget/function/f_rndis.c:	rndis->notify_req->length = STATUS_BYTECOUNT;
drivers/usb/gadget/function/f_rndis.c:	rndis->notify_req->context = rndis;
drivers/usb/gadget/function/f_rndis.c:	rndis->notify_req->complete = rndis_response_complete;
drivers/usb/gadget/function/f_rndis.c:		kfree(rndis->notify_req->buf);
drivers/usb/gadget/function/f_rndis.c:	kfree(rndis->notify_req->buf);
drivers/usb/gadget/function/u_ether.c:	req->buf = skb->data;
drivers/usb/gadget/function/u_ether.c:	req->length = size;
drivers/usb/gadget/function/u_ether.c:	req->complete = rx_complete;
drivers/usb/gadget/function/u_ether.c:	req->context = skb;
drivers/usb/gadget/function/u_ether.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/u_ether.c:	struct sk_buff	*skb = req->context, *skb2;
drivers/usb/gadget/function/u_ether.c:	int		status = req->status;
drivers/usb/gadget/function/u_ether.c:		skb_put(skb, req->actual);
drivers/usb/gadget/function/u_ether.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/u_ether.c:		list_add(&req->list, list);
drivers/usb/gadget/function/u_ether.c:		next = req->list.next;
drivers/usb/gadget/function/u_ether.c:		list_del(&req->list);
drivers/usb/gadget/function/u_ether.c:		list_del_init(&req->list);
drivers/usb/gadget/function/u_ether.c:	struct sk_buff	*skb = req->context;
drivers/usb/gadget/function/u_ether.c:	switch (req->status) {
drivers/usb/gadget/function/u_ether.c:		VDBG(dev, "tx err %d\n", req->status);
drivers/usb/gadget/function/u_ether.c:	list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/u_ether.c:	list_del(&req->list);
drivers/usb/gadget/function/u_ether.c:	req->buf = skb->data;
drivers/usb/gadget/function/u_ether.c:	req->context = skb;
drivers/usb/gadget/function/u_ether.c:	req->complete = tx_complete;
drivers/usb/gadget/function/u_ether.c:		req->zero = 0;
drivers/usb/gadget/function/u_ether.c:		req->zero = 1;
drivers/usb/gadget/function/u_ether.c:	if (req->zero && !dev->zlp && (length % in->maxpacket) == 0)
drivers/usb/gadget/function/u_ether.c:	req->length = length;
drivers/usb/gadget/function/u_ether.c:		list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/u_ether.c:		list_del(&req->list);
drivers/usb/gadget/function/u_ether.c:		list_del(&req->list);
drivers/usb/gadget/function/f_acm.c:	if (req->status != 0) {
drivers/usb/gadget/function/f_acm.c:			acm->port_num, req->status);
drivers/usb/gadget/function/f_acm.c:	if (req->actual != sizeof(acm->port_line_coding)) {
drivers/usb/gadget/function/f_acm.c:			acm->port_num, req->actual);
drivers/usb/gadget/function/f_acm.c:		struct usb_cdc_line_coding	*value = req->buf;
drivers/usb/gadget/function/f_acm.c:		req->complete = acm_complete_set_line_coding;
drivers/usb/gadget/function/f_acm.c:		memcpy(req->buf, &acm->port_line_coding, value);
drivers/usb/gadget/function/f_acm.c:		req->zero = 0;
drivers/usb/gadget/function/f_acm.c:		req->length = value;
drivers/usb/gadget/function/f_acm.c:	req->length = len;
drivers/usb/gadget/function/f_acm.c:	notify = req->buf;
drivers/usb/gadget/function/f_acm.c:	struct f_acm		*acm = req->context;
drivers/usb/gadget/function/f_acm.c:	if (req->status != -ESHUTDOWN)
drivers/usb/gadget/function/f_acm.c:	acm->notify_req->complete = acm_cdc_notify_complete;
drivers/usb/gadget/function/f_acm.c:	acm->notify_req->context = acm;
drivers/usb/gadget/function/f_printer.c:		req->length = len;
drivers/usb/gadget/function/f_printer.c:		req->buf = kmalloc(len, gfp_flags);
drivers/usb/gadget/function/f_printer.c:		if (req->buf == NULL) {
drivers/usb/gadget/function/f_printer.c:		kfree(req->buf);
drivers/usb/gadget/function/f_printer.c:	int			status = req->status;
drivers/usb/gadget/function/f_printer.c:	list_del_init(&req->list);	/* Remode from Active List */
drivers/usb/gadget/function/f_printer.c:		if (req->actual > 0) {
drivers/usb/gadget/function/f_printer.c:			list_add_tail(&req->list, &dev->rx_buffers);
drivers/usb/gadget/function/f_printer.c:			DBG(dev, "G_Printer : rx length %d\n", req->actual);
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:	switch (req->status) {
drivers/usb/gadget/function/f_printer.c:		VDBG(dev, "tx err %d\n", req->status);
drivers/usb/gadget/function/f_printer.c:	list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:	list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:		req->length = USB_BUFSIZE;
drivers/usb/gadget/function/f_printer.c:		req->complete = rx_complete;
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		else if (list_empty(&req->list))
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->rx_reqs_active);
drivers/usb/gadget/function/f_printer.c:			list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:			if (req->actual && req->buf) {
drivers/usb/gadget/function/f_printer.c:				current_rx_bytes = req->actual;
drivers/usb/gadget/function/f_printer.c:				current_rx_buf = req->buf;
drivers/usb/gadget/function/f_printer.c:				list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:			list_add(&current_rx_req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:			list_add(&current_rx_req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:		req->complete = tx_complete;
drivers/usb/gadget/function/f_printer.c:		req->length = size;
drivers/usb/gadget/function/f_printer.c:			req->zero = 0;
drivers/usb/gadget/function/f_printer.c:			req->zero = ((len % dev->in_ep->maxpacket) == 0);
drivers/usb/gadget/function/f_printer.c:		if (copy_from_user(req->buf, buf, size)) {
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->tx_reqs_active);
drivers/usb/gadget/function/f_printer.c:			list_del(&req->list);
drivers/usb/gadget/function/f_printer.c:			list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&dev->current_rx_req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del_init(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:	u8			*buf = req->buf;
drivers/usb/gadget/function/f_printer.c:		req->length = value;
drivers/usb/gadget/function/f_printer.c:		req->zero = value < wLength;
drivers/usb/gadget/function/f_printer.c:			req->status = 0;
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->tx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_add(&req->list, &dev->rx_reqs);
drivers/usb/gadget/function/f_printer.c:		list_del(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_del(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_del(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_del(&req->list);
drivers/usb/gadget/function/f_printer.c:		list_del(&req->list);
drivers/usb/gadget/function/f_eem.c:	struct sk_buff *skb = (struct sk_buff *)req->context;
drivers/usb/gadget/function/f_eem.c:				skb_copy_bits(skb2, 0, req->buf, skb2->len);
drivers/usb/gadget/function/f_eem.c:				req->length = skb2->len;
drivers/usb/gadget/function/f_eem.c:				req->complete = eem_cmd_complete;
drivers/usb/gadget/function/f_eem.c:				req->zero = 1;
drivers/usb/gadget/function/f_eem.c:				req->context = skb2;
drivers/usb/gadget/function/f_sourcesink.c:	u8			*buf = req->buf;
drivers/usb/gadget/function/f_sourcesink.c:	for (i = 0; i < req->actual; i++, buf++) {
drivers/usb/gadget/function/f_sourcesink.c:	u8		*buf = req->buf;
drivers/usb/gadget/function/f_sourcesink.c:		memset(req->buf, 0, req->length);
drivers/usb/gadget/function/f_sourcesink.c:		for  (i = 0; i < req->length; i++)
drivers/usb/gadget/function/f_sourcesink.c:	int				status = req->status;
drivers/usb/gadget/function/f_sourcesink.c:				memset(req->buf, 0x55, req->length);
drivers/usb/gadget/function/f_sourcesink.c:				req->actual, req->length);
drivers/usb/gadget/function/f_sourcesink.c:				status, req->actual, req->length);
drivers/usb/gadget/function/f_sourcesink.c:				ep->name, req->length, status);
drivers/usb/gadget/function/f_sourcesink.c:		req->complete = source_sink_complete;
drivers/usb/gadget/function/f_sourcesink.c:			memset(req->buf, 0x55, req->length);
drivers/usb/gadget/function/f_sourcesink.c:	req->length = USB_COMP_EP0_BUFSIZ;
drivers/usb/gadget/function/f_sourcesink.c:	 * NOTE:  the Control-OUT data stays in req->buf ... better
drivers/usb/gadget/function/f_sourcesink.c:		if (w_length > req->length)
drivers/usb/gadget/function/f_sourcesink.c:		if (w_length > req->length)
drivers/usb/gadget/function/f_sourcesink.c:		req->zero = 0;
drivers/usb/gadget/function/f_sourcesink.c:		req->length = value;
drivers/usb/gadget/function/f_mass_storage.c:	bh->outreq->length = length;
drivers/usb/gadget/function/f_mass_storage.c:	struct fsg_buffhd	*bh = req->context;
drivers/usb/gadget/function/f_mass_storage.c:	if (req->status || req->actual != req->length)
drivers/usb/gadget/function/f_mass_storage.c:		    req->status, req->actual, req->length);
drivers/usb/gadget/function/f_mass_storage.c:	if (req->status == -ECONNRESET)		/* Request was cancelled */
drivers/usb/gadget/function/f_mass_storage.c:	struct fsg_buffhd	*bh = req->context;
drivers/usb/gadget/function/f_mass_storage.c:	dump_msg(common, "bulk-out", req->buf, req->actual);
drivers/usb/gadget/function/f_mass_storage.c:	if (req->status || req->actual != bh->bulk_out_intended_length)
drivers/usb/gadget/function/f_mass_storage.c:		    req->status, req->actual, bh->bulk_out_intended_length);
drivers/usb/gadget/function/f_mass_storage.c:	if (req->status == -ECONNRESET)		/* Request was cancelled */
drivers/usb/gadget/function/f_mass_storage.c:	req->context = NULL;
drivers/usb/gadget/function/f_mass_storage.c:	req->length = 0;
drivers/usb/gadget/function/f_mass_storage.c:		*(u8 *)req->buf = _fsg_common_get_max_lun(fsg->common);
drivers/usb/gadget/function/f_mass_storage.c:		req->length = min((u16)1, w_length);
drivers/usb/gadget/function/f_mass_storage.c:		dump_msg(fsg, "bulk-in", req->buf, req->length);
drivers/usb/gadget/function/f_mass_storage.c:		req->status = rc;
drivers/usb/gadget/function/f_mass_storage.c:				!(rc == -EOPNOTSUPP && req->length == 0))
drivers/usb/gadget/function/f_mass_storage.c:			bh->inreq->length = 0;
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->length = nread;
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->zero = 0;
drivers/usb/gadget/function/f_mass_storage.c:		if (bh->outreq->status != 0) {
drivers/usb/gadget/function/f_mass_storage.c:		amount = bh->outreq->actual;
drivers/usb/gadget/function/f_mass_storage.c:		if (bh->outreq->actual < bh->bulk_out_intended_length) {
drivers/usb/gadget/function/f_mass_storage.c:		if (bh->outreq->actual < bh->bulk_out_intended_length ||
drivers/usb/gadget/function/f_mass_storage.c:				bh->outreq->status != 0) {
drivers/usb/gadget/function/f_mass_storage.c:			bh->inreq->zero = 0;
drivers/usb/gadget/function/f_mass_storage.c:			bh->inreq->zero = 1;
drivers/usb/gadget/function/f_mass_storage.c:	bh->inreq->length = US_BULK_CS_WRAP_LEN;
drivers/usb/gadget/function/f_mass_storage.c:	bh->inreq->zero = 0;
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->length = reply;
drivers/usb/gadget/function/f_mass_storage.c:	struct bulk_cb_wrap	*cbw = req->buf;
drivers/usb/gadget/function/f_mass_storage.c:	if (req->status || test_bit(IGNORE_BULK_OUT, &fsg->atomic_bitflags))
drivers/usb/gadget/function/f_mass_storage.c:	if (req->actual != US_BULK_CB_WRAP_LEN ||
drivers/usb/gadget/function/f_mass_storage.c:				req->actual,
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->buf = bh->outreq->buf = bh->buf;
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->context = bh->outreq->context = bh;
drivers/usb/gadget/function/f_mass_storage.c:		bh->inreq->complete = bulk_in_complete;
drivers/usb/gadget/function/f_mass_storage.c:		bh->outreq->complete = bulk_out_complete;
drivers/usb/gadget/function/u_audio.c:	int status = req->status;
drivers/usb/gadget/function/u_audio.c:	struct uac_rtd_params *prm = req->context;
drivers/usb/gadget/function/u_audio.c:	if (req->status == -ESHUTDOWN)
drivers/usb/gadget/function/u_audio.c:			__func__, status, req->actual, req->length);
drivers/usb/gadget/function/u_audio.c:		req->length = uac->p_pktsize;
drivers/usb/gadget/function/u_audio.c:			req->length += uac->p_framesize;
drivers/usb/gadget/function/u_audio.c:		req->actual = req->length;
drivers/usb/gadget/function/u_audio.c:		if (unlikely(pending < req->actual)) {
drivers/usb/gadget/function/u_audio.c:			memcpy(req->buf, runtime->dma_area + hw_ptr, pending);
drivers/usb/gadget/function/u_audio.c:			memcpy(req->buf + pending, runtime->dma_area,
drivers/usb/gadget/function/u_audio.c:			       req->actual - pending);
drivers/usb/gadget/function/u_audio.c:			memcpy(req->buf, runtime->dma_area + hw_ptr,
drivers/usb/gadget/function/u_audio.c:			       req->actual);
drivers/usb/gadget/function/u_audio.c:		if (unlikely(pending < req->actual)) {
drivers/usb/gadget/function/u_audio.c:			memcpy(runtime->dma_area + hw_ptr, req->buf, pending);
drivers/usb/gadget/function/u_audio.c:			memcpy(runtime->dma_area, req->buf + pending,
drivers/usb/gadget/function/u_audio.c:			       req->actual - pending);
drivers/usb/gadget/function/u_audio.c:			memcpy(runtime->dma_area + hw_ptr, req->buf,
drivers/usb/gadget/function/u_audio.c:			       req->actual);
drivers/usb/gadget/function/u_audio.c:	prm->hw_ptr = (hw_ptr + req->actual) % runtime->dma_bytes;
drivers/usb/gadget/function/u_audio.c:	if ((hw_ptr % snd_pcm_lib_period_bytes(substream)) < req->actual)
drivers/usb/gadget/function/u_audio.c:			req->zero = 0;
drivers/usb/gadget/function/u_audio.c:			req->context = prm;
drivers/usb/gadget/function/u_audio.c:			req->length = req_len;
drivers/usb/gadget/function/u_audio.c:			req->complete = u_audio_iso_complete;
drivers/usb/gadget/function/u_audio.c:			req->buf = prm->rbuf + i * ep->maxpacket;
drivers/usb/gadget/function/u_audio.c:			req->zero = 0;
drivers/usb/gadget/function/u_audio.c:			req->context = prm;
drivers/usb/gadget/function/u_audio.c:			req->length = req_len;
drivers/usb/gadget/function/u_audio.c:			req->complete = u_audio_iso_complete;
drivers/usb/gadget/function/u_audio.c:			req->buf = prm->rbuf + i * ep->maxpacket;
drivers/usb/gadget/function/u_serial.c:		req->length = len;
drivers/usb/gadget/function/u_serial.c:		req->buf = kmalloc(len, kmalloc_flags);
drivers/usb/gadget/function/u_serial.c:		if (req->buf == NULL) {
drivers/usb/gadget/function/u_serial.c:	kfree(req->buf);
drivers/usb/gadget/function/u_serial.c:		len = gs_send_packet(port, req->buf, in->maxpacket);
drivers/usb/gadget/function/u_serial.c:		req->length = len;
drivers/usb/gadget/function/u_serial.c:		list_del(&req->list);
drivers/usb/gadget/function/u_serial.c:		req->zero = kfifo_is_empty(&port->port_write_buf);
drivers/usb/gadget/function/u_serial.c:		pr_vdebug("ttyGS%d: tx len=%d, %3ph ...\n", port->port_num, len, req->buf);
drivers/usb/gadget/function/u_serial.c:			list_add(&req->list, pool);
drivers/usb/gadget/function/u_serial.c:		list_del(&req->list);
drivers/usb/gadget/function/u_serial.c:		req->length = out->maxpacket;
drivers/usb/gadget/function/u_serial.c:			list_add(&req->list, pool);
drivers/usb/gadget/function/u_serial.c:		switch (req->status) {
drivers/usb/gadget/function/u_serial.c:				port->port_num, req->status);
drivers/usb/gadget/function/u_serial.c:		if (req->actual && tty) {
drivers/usb/gadget/function/u_serial.c:			char		*packet = req->buf;
drivers/usb/gadget/function/u_serial.c:			unsigned	size = req->actual;
drivers/usb/gadget/function/u_serial.c:					  port->port_num, count, req->actual);
drivers/usb/gadget/function/u_serial.c:		list_move(&req->list, &port->read_pool);
drivers/usb/gadget/function/u_serial.c:	list_add_tail(&req->list, &port->read_queue);
drivers/usb/gadget/function/u_serial.c:	list_add(&req->list, &port->write_pool);
drivers/usb/gadget/function/u_serial.c:	switch (req->status) {
drivers/usb/gadget/function/u_serial.c:			__func__, ep->name, req->status);
drivers/usb/gadget/function/u_serial.c:		list_del(&req->list);
drivers/usb/gadget/function/u_serial.c:		req->complete = fn;
drivers/usb/gadget/function/u_serial.c:		list_add_tail(&req->list, head);
drivers/usb/gadget/function/u_serial.c:	struct gs_console *cons = req->context;
drivers/usb/gadget/function/u_serial.c:	switch (req->status) {
drivers/usb/gadget/function/u_serial.c:			__func__, ep->name, req->status);
drivers/usb/gadget/function/u_serial.c:		req->length = 0;
drivers/usb/gadget/function/u_serial.c:	if (req->length)
drivers/usb/gadget/function/u_serial.c:	size = kfifo_out(&cons->buf, req->buf, ep->maxpacket);
drivers/usb/gadget/function/u_serial.c:	req->length = size;
drivers/usb/gadget/function/u_serial.c:		req->length = 0;
drivers/usb/gadget/function/u_serial.c:	if (cons->req && !cons->req->length)
drivers/usb/gadget/function/u_serial.c:	req->complete = gs_console_complete_out;
drivers/usb/gadget/function/u_serial.c:	req->context = cons;
drivers/usb/gadget/function/u_serial.c:	req->length = 0;
drivers/usb/gadget/function/f_uac2.c:		memcpy(req->buf, &c, value);
drivers/usb/gadget/function/f_uac2.c:		*(u8 *)req->buf = 1;
drivers/usb/gadget/function/f_uac2.c:		memcpy(req->buf, &r, value);
drivers/usb/gadget/function/f_uac2.c:		req->length = value;
drivers/usb/gadget/function/f_uac2.c:		req->zero = value < w_length;
drivers/usb/gadget/function/f_uac2.c:			req->status = 0;
drivers/usb/gadget/function/f_phonet.c:	struct sk_buff *skb = req->context;
drivers/usb/gadget/function/f_phonet.c:	switch (req->status) {
drivers/usb/gadget/function/f_phonet.c:	req->buf = skb->data;
drivers/usb/gadget/function/f_phonet.c:	req->length = skb->len;
drivers/usb/gadget/function/f_phonet.c:	req->complete = pn_tx_complete;
drivers/usb/gadget/function/f_phonet.c:	req->zero = 1;
drivers/usb/gadget/function/f_phonet.c:	req->context = skb;
drivers/usb/gadget/function/f_phonet.c:	req->buf = page_address(page);
drivers/usb/gadget/function/f_phonet.c:	req->length = PAGE_SIZE;
drivers/usb/gadget/function/f_phonet.c:	req->context = page;
drivers/usb/gadget/function/f_phonet.c:	struct page *page = req->context;
drivers/usb/gadget/function/f_phonet.c:	int status = req->status;
drivers/usb/gadget/function/f_phonet.c:		if (req->actual < req->length) /* Last fragment */
drivers/usb/gadget/function/f_phonet.c:				skb->len <= 1, req->actual, PAGE_SIZE);
drivers/usb/gadget/function/f_phonet.c:		if (req->actual < req->length) { /* Last fragment */
drivers/usb/gadget/function/f_phonet.c:		req->complete = pn_rx_complete;
drivers/usb/gadget/legacy/raw_gadget.c:	struct raw_dev *dev = req->context;
drivers/usb/gadget/legacy/raw_gadget.c:	if (req->status)
drivers/usb/gadget/legacy/raw_gadget.c:		dev->ep0_status = req->status;
drivers/usb/gadget/legacy/raw_gadget.c:		dev->ep0_status = req->actual;
drivers/usb/gadget/legacy/raw_gadget.c:	dev->req->context = dev;
drivers/usb/gadget/legacy/raw_gadget.c:	dev->req->complete = gadget_ep0_complete;
drivers/usb/gadget/legacy/raw_gadget.c:	dev->req->buf = data;
drivers/usb/gadget/legacy/raw_gadget.c:	dev->req->length = io->length;
drivers/usb/gadget/legacy/raw_gadget.c:	dev->req->zero = usb_raw_io_flags_zero(io->flags);
drivers/usb/gadget/legacy/raw_gadget.c:	if (req->status)
drivers/usb/gadget/legacy/raw_gadget.c:		r_ep->status = req->status;
drivers/usb/gadget/legacy/raw_gadget.c:		r_ep->status = req->actual;
drivers/usb/gadget/legacy/raw_gadget.c:	complete((struct completion *)req->context);
drivers/usb/gadget/legacy/raw_gadget.c:	ep->req->context = &done;
drivers/usb/gadget/legacy/raw_gadget.c:	ep->req->complete = gadget_ep_complete;
drivers/usb/gadget/legacy/raw_gadget.c:	ep->req->buf = data;
drivers/usb/gadget/legacy/raw_gadget.c:	ep->req->length = io->length;
drivers/usb/gadget/legacy/raw_gadget.c:	ep->req->zero = usb_raw_io_flags_zero(io->flags);
drivers/usb/gadget/legacy/dbgp.c:	int status = req->status;
drivers/usb/gadget/legacy/dbgp.c:	dbgp_consume(req->buf, req->actual);
drivers/usb/gadget/legacy/dbgp.c:	req->length = DBGP_REQ_LEN;
drivers/usb/gadget/legacy/dbgp.c:	kfree(req->buf);
drivers/usb/gadget/legacy/dbgp.c:	req->buf = kmalloc(DBGP_REQ_LEN, GFP_KERNEL);
drivers/usb/gadget/legacy/dbgp.c:	if (!req->buf) {
drivers/usb/gadget/legacy/dbgp.c:	req->complete = dbgp_complete;
drivers/usb/gadget/legacy/dbgp.c:	req->length = DBGP_REQ_LEN;
drivers/usb/gadget/legacy/dbgp.c:	kfree(req->buf);
drivers/usb/gadget/legacy/dbgp.c:		kfree(dbgp.req->buf);
drivers/usb/gadget/legacy/dbgp.c:	dbgp.req->buf = kmalloc(DBGP_REQ_EP0_LEN, GFP_KERNEL);
drivers/usb/gadget/legacy/dbgp.c:	if (!dbgp.req->buf) {
drivers/usb/gadget/legacy/dbgp.c:	dbgp.req->length = DBGP_REQ_EP0_LEN;
drivers/usb/gadget/legacy/dbgp.c:		req->status, req->actual, req->length);
drivers/usb/gadget/legacy/dbgp.c:	req->length = min(length, len);
drivers/usb/gadget/legacy/dbgp.c:	req->zero = len < req->length;
drivers/usb/gadget/legacy/dbgp.c:	if (data && req->length)
drivers/usb/gadget/legacy/dbgp.c:		memcpy(req->buf, data, req->length);
drivers/usb/gadget/legacy/dbgp.c:	req->complete = dbgp_setup_complete;
drivers/usb/gadget/legacy/inode.c:	if (!req->context)
drivers/usb/gadget/legacy/inode.c:	if (req->status)
drivers/usb/gadget/legacy/inode.c:		epdata->status = req->status;
drivers/usb/gadget/legacy/inode.c:		epdata->status = req->actual;
drivers/usb/gadget/legacy/inode.c:	complete ((struct completion *)req->context);
drivers/usb/gadget/legacy/inode.c:		req->context = &done;
drivers/usb/gadget/legacy/inode.c:		req->complete = epio_complete;
drivers/usb/gadget/legacy/inode.c:		req->buf = buf;
drivers/usb/gadget/legacy/inode.c:		req->length = len;
drivers/usb/gadget/legacy/inode.c:	struct kiocb		*iocb = req->context;
drivers/usb/gadget/legacy/inode.c:	if (priv->to_free == NULL || unlikely(req->actual == 0)) {
drivers/usb/gadget/legacy/inode.c:		kfree(req->buf);
drivers/usb/gadget/legacy/inode.c:		iocb->ki_complete(iocb, req->actual ? req->actual : req->status,
drivers/usb/gadget/legacy/inode.c:				req->status);
drivers/usb/gadget/legacy/inode.c:		if (unlikely(0 != req->status))
drivers/usb/gadget/legacy/inode.c:				ep->name, req->status, req->actual);
drivers/usb/gadget/legacy/inode.c:		priv->buf = req->buf;
drivers/usb/gadget/legacy/inode.c:		priv->actual = req->actual;
drivers/usb/gadget/legacy/inode.c:	req->buf = buf;
drivers/usb/gadget/legacy/inode.c:	req->length = len;
drivers/usb/gadget/legacy/inode.c:	req->complete = ep_aio_complete;
drivers/usb/gadget/legacy/inode.c:	req->context = iocb;
drivers/usb/gadget/legacy/inode.c:	if (req->buf != dev->rbuf) {
drivers/usb/gadget/legacy/inode.c:		kfree(req->buf);
drivers/usb/gadget/legacy/inode.c:		req->buf = dev->rbuf;
drivers/usb/gadget/legacy/inode.c:	req->complete = epio_complete;
drivers/usb/gadget/legacy/inode.c:		dev->setup_out_error = (req->status != 0);
drivers/usb/gadget/legacy/inode.c:	if (free && req->buf != &dev->rbuf)
drivers/usb/gadget/legacy/inode.c:	req->complete = epio_complete;
drivers/usb/gadget/legacy/inode.c:		req->buf = kmalloc(len, GFP_ATOMIC);
drivers/usb/gadget/legacy/inode.c:	if (req->buf == NULL) {
drivers/usb/gadget/legacy/inode.c:		req->buf = dev->rbuf;
drivers/usb/gadget/legacy/inode.c:	req->complete = ep0_complete;
drivers/usb/gadget/legacy/inode.c:	req->length = len;
drivers/usb/gadget/legacy/inode.c:	req->zero = 0;
drivers/usb/gadget/legacy/inode.c:				len = min (len, (size_t)dev->req->actual);
drivers/usb/gadget/legacy/inode.c:				if (copy_to_user (buf, dev->req->buf, len))
drivers/usb/gadget/legacy/inode.c:				if (copy_from_user (dev->req->buf, buf, len))
drivers/usb/gadget/legacy/inode.c:						dev->req->zero = 1;
drivers/usb/gadget/legacy/inode.c:		dev->req->buf = dev->hs_config;
drivers/usb/gadget/legacy/inode.c:		dev->req->buf = dev->config;
drivers/usb/gadget/legacy/inode.c:	((u8 *)dev->req->buf) [1] = type;
drivers/usb/gadget/legacy/inode.c:	req->buf = dev->rbuf;
drivers/usb/gadget/legacy/inode.c:	req->context = NULL;
drivers/usb/gadget/legacy/inode.c:			req->buf = dev->dev;
drivers/usb/gadget/legacy/inode.c:		*(u8 *)req->buf = dev->current_config;
drivers/usb/gadget/legacy/inode.c:		req->length = value;
drivers/usb/gadget/legacy/inode.c:		req->zero = value < w_length;
drivers/usb/gadget/legacy/inode.c:			req->status = 0;
drivers/usb/gadget/legacy/inode.c:	dev->req->context = NULL;
drivers/usb/gadget/legacy/inode.c:	dev->req->complete = epio_complete;
drivers/usb/gadget/u_f.h: * usb_requests's length (req->length) to refer to the allocated buffer size.
drivers/usb/gadget/u_f.h:	WARN_ON(req->buf == NULL);
drivers/usb/gadget/u_f.h:	kfree(req->buf);
drivers/usb/gadget/u_f.h:	req->buf = NULL;
drivers/usb/gadget/composite.c:			return config_buf(c, speed, cdev->req->buf, type);
drivers/usb/gadget/composite.c:	struct usb_bos_descriptor	*bos = cdev->req->buf;
drivers/usb/gadget/composite.c:	usb_ext = cdev->req->buf + le16_to_cpu(bos->wTotalLength);
drivers/usb/gadget/composite.c:		ss_cap = cdev->req->buf + le16_to_cpu(bos->wTotalLength);
drivers/usb/gadget/composite.c:		ssp_cap = cdev->req->buf + le16_to_cpu(bos->wTotalLength);
drivers/usb/gadget/composite.c:	struct usb_qualifier_descriptor	*qual = cdev->req->buf;
drivers/usb/gadget/composite.c:	if (req->status || req->actual != req->length)
drivers/usb/gadget/composite.c:				req->status, req->actual, req->length);
drivers/usb/gadget/composite.c:	if (!req->context)
drivers/usb/gadget/composite.c:	cdev = req->context;
drivers/usb/gadget/composite.c:	req->zero = 0;
drivers/usb/gadget/composite.c:	req->context = cdev;
drivers/usb/gadget/composite.c:	req->complete = composite_setup_complete;
drivers/usb/gadget/composite.c:	req->length = 0;
drivers/usb/gadget/composite.c:			memcpy(req->buf, &cdev->desc, value);
drivers/usb/gadget/composite.c:			value = get_string(cdev, req->buf,
drivers/usb/gadget/composite.c:				memcpy(req->buf, config->descriptors[0], value);
drivers/usb/gadget/composite.c:			*(u8 *)req->buf = cdev->config->bConfigurationValue;
drivers/usb/gadget/composite.c:			*(u8 *)req->buf = 0;
drivers/usb/gadget/composite.c:		*((u8 *)req->buf) = value;
drivers/usb/gadget/composite.c:			*((u8 *)req->buf) = gadget->host_request_flag;
drivers/usb/gadget/composite.c:		put_unaligned_le16(0, req->buf);
drivers/usb/gadget/composite.c:		put_unaligned_le16(status & 0x0000ffff, req->buf);
drivers/usb/gadget/composite.c:			req->context = cdev;
drivers/usb/gadget/composite.c:			req->complete = composite_setup_complete;
drivers/usb/gadget/composite.c:			buf = req->buf;
drivers/usb/gadget/composite.c:		req->length = value;
drivers/usb/gadget/composite.c:		req->context = cdev;
drivers/usb/gadget/composite.c:		req->zero = value < w_length;
drivers/usb/gadget/composite.c:			req->status = 0;
drivers/usb/gadget/composite.c:	cdev->req->buf = kmalloc(USB_COMP_EP0_BUFSIZ, GFP_KERNEL);
drivers/usb/gadget/composite.c:	if (!cdev->req->buf)
drivers/usb/gadget/composite.c:	cdev->req->complete = composite_setup_complete;
drivers/usb/gadget/composite.c:	cdev->req->context = cdev;
drivers/usb/gadget/composite.c:	kfree(cdev->req->buf);
drivers/usb/gadget/composite.c:	cdev->os_desc_req->buf = kmalloc(USB_COMP_EP0_OS_DESC_BUFSIZ,
drivers/usb/gadget/composite.c:	if (!cdev->os_desc_req->buf) {
drivers/usb/gadget/composite.c:	cdev->os_desc_req->context = cdev;
drivers/usb/gadget/composite.c:	cdev->os_desc_req->complete = composite_setup_complete;
drivers/usb/gadget/composite.c:		kfree(cdev->os_desc_req->buf);
drivers/usb/gadget/composite.c:		cdev->os_desc_req->buf = NULL;
drivers/usb/gadget/composite.c:		kfree(cdev->req->buf);
drivers/usb/gadget/composite.c:		cdev->req->buf = NULL;
drivers/usb/gadget/composite.c:		req->length = 0;
drivers/usb/gadget/composite.c:		req->context = cdev;
drivers/usb/gadget/composite.c:			req->status = 0;
drivers/usb/renesas_usbhs/common.c:	req->bRequest		= (val >> 8) & 0xFF;
drivers/usb/renesas_usbhs/common.c:	req->bRequestType	= (val >> 0) & 0xFF;
drivers/usb/renesas_usbhs/common.c:	req->wValue	= cpu_to_le16(usbhs_read(priv, USBVAL));
drivers/usb/renesas_usbhs/common.c:	req->wIndex	= cpu_to_le16(usbhs_read(priv, USBINDX));
drivers/usb/renesas_usbhs/common.c:	req->wLength	= cpu_to_le16(usbhs_read(priv, USBLENG));
drivers/usb/renesas_usbhs/common.c:	usbhs_write(priv, USBREQ,  (req->bRequest << 8) | req->bRequestType);
drivers/usb/renesas_usbhs/common.c:	usbhs_write(priv, USBVAL,  le16_to_cpu(req->wValue));
drivers/usb/renesas_usbhs/common.c:	usbhs_write(priv, USBINDX, le16_to_cpu(req->wIndex));
drivers/usb/renesas_usbhs/common.c:	usbhs_write(priv, USBLENG, le16_to_cpu(req->wLength));
drivers/usb/renesas_usbhs/mod_host.c:	usbhs_pkt_init(&ureq->pkt);
drivers/usb/renesas_usbhs/mod_host.c:	ureq->urb = urb;
drivers/usb/renesas_usbhs/mod_host.c:	usbhsh_urb_to_ureq(ureq->urb) = NULL;
drivers/usb/renesas_usbhs/mod_host.c:	ureq->urb = NULL;
drivers/usb/renesas_usbhs/mod_host.c:	struct urb *urb = ureq->urb;
drivers/usb/renesas_usbhs/mod_host.c:	usbhs_pkt_push(pipe, &ureq->pkt, usbhsh_queue_done,
drivers/usb/renesas_usbhs/mod_host.c:	if ((DeviceOutRequest    == req->bRequestType << 8) &&
drivers/usb/renesas_usbhs/mod_host.c:	    (USB_REQ_SET_ADDRESS == req->bRequest))
drivers/usb/renesas_usbhs/mod_host.c:	usbhs_pkt_push(pipe, &ureq->pkt,
drivers/usb/renesas_usbhs/mod_host.c:	usbhs_pkt_push(pipe, &ureq->pkt,
drivers/usb/renesas_usbhs/mod_host.c:		struct urb *urb = ureq->urb;
drivers/usb/renesas_usbhs/mod_host.c:		struct usbhs_pkt *pkt = &ureq->pkt;
drivers/usb/renesas_usbhs/mod_gadget.c:	ureq->req.status = status;
drivers/usb/renesas_usbhs/mod_gadget.c:	usb_gadget_giveback_request(&uep->ep, &ureq->req);
drivers/usb/renesas_usbhs/mod_gadget.c:	ureq->req.actual = pkt->actual;
drivers/usb/renesas_usbhs/mod_gadget.c:	struct usb_request *req = &ureq->req;
drivers/usb/renesas_usbhs/mod_gadget.c:	req->actual = 0;
drivers/usb/renesas_usbhs/mod_gadget.c:	req->status = -EINPROGRESS;
drivers/usb/renesas_usbhs/mod_gadget.c:		       req->buf, req->length, req->zero, -1);
drivers/usb/renesas_usbhs/mod_gadget.c:		req->length);
drivers/usb/renesas_usbhs/mod_gadget.c:	struct usb_request *req = &ureq->req;
drivers/usb/renesas_usbhs/mod_gadget.c:		WARN_ON(req->num_sgs);
drivers/usb/renesas_usbhs/mod_gadget.c:		pkt->dma = req->dma;
drivers/usb/renesas_usbhs/mod_gadget.c:	kfree(ureq->pkt.buf);
drivers/usb/renesas_usbhs/mod_gadget.c:	req->complete	= __usbhsg_recip_send_complete;
drivers/usb/renesas_usbhs/mod_gadget.c:	req->buf	= buf;
drivers/usb/renesas_usbhs/mod_gadget.c:	req->length	= sizeof(*buf);
drivers/usb/renesas_usbhs/mod_gadget.c:	req->zero	= 0;
drivers/usb/renesas_usbhs/mod_gadget.c:	return &ureq->req;
drivers/usb/renesas_usbhs/mod_gadget.c:	WARN_ON(!list_empty(&ureq->pkt.node));
drivers/usb/misc/usbtest.c:			retval = req->status;
drivers/usb/misc/yurex.c:	dev->cntl_req->bRequestType = USB_DIR_OUT | USB_TYPE_CLASS |
drivers/usb/misc/yurex.c:	dev->cntl_req->bRequest	= HID_REQ_SET_REPORT;
drivers/usb/misc/yurex.c:	dev->cntl_req->wValue	= cpu_to_le16((HID_OUTPUT_REPORT + 1) << 8);
drivers/usb/misc/yurex.c:	dev->cntl_req->wIndex	= cpu_to_le16(iface_desc->desc.bInterfaceNumber);
drivers/usb/misc/yurex.c:	dev->cntl_req->wLength	= cpu_to_le16(YUREX_BUF_SIZE);
drivers/usb/chipidea/debug.c:			list_for_each_entry_safe(node, tmpnode, &req->tds, td) {
drivers/usb/chipidea/trace.h:		__entry->req = &hwreq->req;
drivers/usb/chipidea/udc.c:		u32 mul = hwreq->req.length / hwep->ep.maxpacket;
drivers/usb/chipidea/udc.c:		if (hwreq->req.length == 0
drivers/usb/chipidea/udc.c:				|| hwreq->req.length % hwep->ep.maxpacket)
drivers/usb/chipidea/udc.c:		temp = (u32) (sg_dma_address(s) + hwreq->req.actual);
drivers/usb/chipidea/udc.c:		temp = (u32) (hwreq->req.dma + hwreq->req.actual);
drivers/usb/chipidea/udc.c:	hwreq->req.actual += length;
drivers/usb/chipidea/udc.c:	if (!list_empty(&hwreq->tds)) {
drivers/usb/chipidea/udc.c:		lastnode = list_entry(hwreq->tds.prev,
drivers/usb/chipidea/udc.c:	list_add_tail(&node->td, &hwreq->tds);
drivers/usb/chipidea/udc.c:	unsigned int rest = hwreq->req.length;
drivers/usb/chipidea/udc.c:	if (hwreq->req.dma % PAGE_SIZE)
drivers/usb/chipidea/udc.c:		unsigned int count = min(hwreq->req.length - hwreq->req.actual,
drivers/usb/chipidea/udc.c:	if (hwreq->req.zero && hwreq->req.length && hwep->dir == TX
drivers/usb/chipidea/udc.c:	    && (hwreq->req.length % hwep->ep.maxpacket == 0)) {
drivers/usb/chipidea/udc.c:	hwreq->req.actual = 0;
drivers/usb/chipidea/udc.c:	struct usb_request *req = &hwreq->req;
drivers/usb/chipidea/udc.c:	struct scatterlist *s = req->sg;
drivers/usb/chipidea/udc.c:	if (!s || req->zero || req->length == 0) {
drivers/usb/chipidea/udc.c:	while (i++ < req->num_mapped_sgs) {
drivers/usb/chipidea/udc.c:			node = list_entry(hwreq->tds.prev,
drivers/usb/chipidea/udc.c:	if (hwreq->req.status == -EALREADY)
drivers/usb/chipidea/udc.c:	hwreq->req.status = -EALREADY;
drivers/usb/chipidea/udc.c:					    &hwreq->req, hwep->dir);
drivers/usb/chipidea/udc.c:	if (hwreq->req.num_mapped_sgs)
drivers/usb/chipidea/udc.c:	lastnode = list_entry(hwreq->tds.prev,
drivers/usb/chipidea/udc.c:	if (!hwreq->req.no_interrupt)
drivers/usb/chipidea/udc.c:	list_for_each_entry_safe(firstnode, lastnode, &hwreq->tds, td)
drivers/usb/chipidea/udc.c:	firstnode = list_first_entry(&hwreq->tds, struct td_node, td);
drivers/usb/chipidea/udc.c:	hwreq->req.actual = 0;
drivers/usb/chipidea/udc.c:		u32 mul = hwreq->req.length / hwep->ep.maxpacket;
drivers/usb/chipidea/udc.c:		if (hwreq->req.length == 0
drivers/usb/chipidea/udc.c:				|| hwreq->req.length % hwep->ep.maxpacket)
drivers/usb/chipidea/udc.c:	unsigned actual = hwreq->req.length;
drivers/usb/chipidea/udc.c:	if (hwreq->req.status != -EALREADY)
drivers/usb/chipidea/udc.c:	hwreq->req.status = 0;
drivers/usb/chipidea/udc.c:	list_for_each_entry_safe(node, tmpnode, &hwreq->tds, td) {
drivers/usb/chipidea/udc.c:			hwreq->req.status = -EALREADY;
drivers/usb/chipidea/udc.c:		hwreq->req.status = tmptoken & TD_STATUS;
drivers/usb/chipidea/udc.c:		if ((TD_STATUS_HALTED & hwreq->req.status)) {
drivers/usb/chipidea/udc.c:			hwreq->req.status = -EPIPE;
drivers/usb/chipidea/udc.c:		} else if ((TD_STATUS_DT_ERR & hwreq->req.status)) {
drivers/usb/chipidea/udc.c:			hwreq->req.status = -EPROTO;
drivers/usb/chipidea/udc.c:		} else if ((TD_STATUS_TR_ERR & hwreq->req.status)) {
drivers/usb/chipidea/udc.c:			hwreq->req.status = -EILSEQ;
drivers/usb/chipidea/udc.c:				hwreq->req.status = -EPROTO;
drivers/usb/chipidea/udc.c:					&hwreq->req, hwep->dir);
drivers/usb/chipidea/udc.c:	hwreq->req.actual += actual;
drivers/usb/chipidea/udc.c:	if (hwreq->req.status)
drivers/usb/chipidea/udc.c:		return hwreq->req.status;
drivers/usb/chipidea/udc.c:	return hwreq->req.actual;
drivers/usb/chipidea/udc.c:		list_for_each_entry_safe(node, tmpnode, &hwreq->tds, td) {
drivers/usb/chipidea/udc.c:		list_del_init(&hwreq->queue);
drivers/usb/chipidea/udc.c:		hwreq->req.status = -ESHUTDOWN;
drivers/usb/chipidea/udc.c:		if (hwreq->req.complete != NULL) {
drivers/usb/chipidea/udc.c:			usb_gadget_giveback_request(&hwep->ep, &hwreq->req);
drivers/usb/chipidea/udc.c:	kfree(req->buf);
drivers/usb/chipidea/udc.c:		if (req->length)
drivers/usb/chipidea/udc.c:	    hwreq->req.length > hwep->ep.mult * hwep->ep.maxpacket) {
drivers/usb/chipidea/udc.c:	if (!list_empty(&hwreq->queue)) {
drivers/usb/chipidea/udc.c:	hwreq->req.status = -EINPROGRESS;
drivers/usb/chipidea/udc.c:	hwreq->req.actual = 0;
drivers/usb/chipidea/udc.c:		list_add_tail(&hwreq->queue, &hwep->qh.queue);
drivers/usb/chipidea/udc.c:	req->complete = isr_get_status_complete;
drivers/usb/chipidea/udc.c:	req->length   = 2;
drivers/usb/chipidea/udc.c:	req->buf      = kzalloc(req->length, gfp_flags);
drivers/usb/chipidea/udc.c:	if (req->buf == NULL) {
drivers/usb/chipidea/udc.c:		*(u16 *)req->buf = (ci->remote_wakeup << 1) |
drivers/usb/chipidea/udc.c:		*(u16 *)req->buf = hw_ep_get_halt(ci, num, dir);
drivers/usb/chipidea/udc.c:	kfree(req->buf);
drivers/usb/chipidea/udc.c:	struct ci_hdrc *ci = req->context;
drivers/usb/chipidea/udc.c:		list_del_init(&hwreq->queue);
drivers/usb/chipidea/udc.c:		if (hwreq->req.complete != NULL) {
drivers/usb/chipidea/udc.c:					hwreq->req.length)
drivers/usb/chipidea/udc.c:			usb_gadget_giveback_request(&hweptemp->ep, &hwreq->req);
drivers/usb/chipidea/udc.c:		INIT_LIST_HEAD(&hwreq->queue);
drivers/usb/chipidea/udc.c:		INIT_LIST_HEAD(&hwreq->tds);
drivers/usb/chipidea/udc.c:	return (hwreq == NULL) ? NULL : &hwreq->req;
drivers/usb/chipidea/udc.c:	} else if (!list_empty(&hwreq->queue)) {
drivers/usb/chipidea/udc.c:	list_for_each_entry_safe(node, tmpnode, &hwreq->tds, td) {
drivers/usb/chipidea/udc.c:	if (ep == NULL || req == NULL || hwreq->req.status != -EALREADY ||
drivers/usb/chipidea/udc.c:		hwep->ep.desc == NULL || list_empty(&hwreq->queue) ||
drivers/usb/chipidea/udc.c:	list_for_each_entry_safe(node, tmpnode, &hwreq->tds, td) {
drivers/usb/chipidea/udc.c:	list_del_init(&hwreq->queue);
drivers/usb/chipidea/udc.c:	req->status = -ECONNRESET;
drivers/usb/chipidea/udc.c:	if (hwreq->req.complete != NULL) {
drivers/usb/chipidea/udc.c:		usb_gadget_giveback_request(&hwep->ep, &hwreq->req);
drivers/usb/core/message.c:	struct usb_device *udev = req->udev;
drivers/usb/core/message.c:	list_del(&req->node);
drivers/usb/core/message.c:	if (req->config >= -1)		/* Is req still valid? */
drivers/usb/core/message.c:		usb_set_configuration(udev, req->config);
drivers/usb/core/message.c:		if (req->udev == udev)
drivers/usb/core/message.c:			req->config = -999;	/* Mark as cancelled */
drivers/usb/core/message.c:	req->udev = udev;
drivers/usb/core/message.c:	req->config = config;
drivers/usb/core/message.c:	INIT_WORK(&req->work, driver_set_config_work);
drivers/usb/core/message.c:	list_add(&req->node, &set_config_list);
drivers/usb/core/message.c:	schedule_work(&req->work);
drivers/usb/cdns3/cdns3-ep0.c:	u32 config = le16_to_cpu(ctrl_req->wValue);
drivers/usb/cdns3/cdns3-ep0.c:	addr = le16_to_cpu(ctrl_req->wValue);
drivers/usb/cdns3/cdns3-ep0.c:	if (le16_to_cpu(ctrl_req->wLength) != 6) {
drivers/usb/cdns3/cdns3-ep0.c:			ctrl_req->wLength);
drivers/usb/cdns3/cdns3-ep0.c:	if (ctrl_req->wIndex || ctrl_req->wLength)
drivers/usb/cdns3/cdns3-ep0.c:	priv_dev->isoch_delay = le16_to_cpu(ctrl_req->wValue);
drivers/usb/cdns3/cdns3-ep0.c:	switch (ctrl_req->bRequest) {
drivers/usb/cdns3/cdnsp-ring.c:	return cdnsp_get_transfer_ring(pdev, preq->pep,
drivers/usb/cdns3/cdnsp-ring.c:				       preq->request.stream_id);
drivers/usb/cdns3/cdnsp-ring.c:	if (!preq->direction) {
drivers/usb/cdns3/cdnsp-ring.c:	len = sg_pcopy_from_buffer(preq->request.sg, preq->request.num_sgs,
drivers/usb/cdns3/cdnsp-ring.c:	cur_td = &preq->td;
drivers/usb/cdns3/cdnsp-ring.c:	hw_deq = cdnsp_get_hw_deq(pdev, pep->idx, preq->request.stream_id);
drivers/usb/cdns3/cdnsp-ring.c:		cdnsp_find_new_dequeue_state(pdev, pep, preq->request.stream_id,
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.actual > preq->request.length) {
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.actual = 0;
drivers/usb/cdns3/cdnsp-ring.c:	preq->pep->stream_info.td_count--;
drivers/usb/cdns3/cdnsp-ring.c:	cdnsp_gadget_giveback(preq->pep, preq, *status);
drivers/usb/cdns3/cdnsp-ring.c:		td->preq->request.actual = td->preq->request.length - remaining;
drivers/usb/cdns3/cdnsp-ring.c:		td->preq->request.actual = td->preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:	requested = preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.status = 0;
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.status = 0;
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.status = -EOVERFLOW;
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.status  = 0;
drivers/usb/cdns3/cdnsp-ring.c:		preq->request.status = -1;
drivers/usb/cdns3/cdnsp-ring.c:	td->preq->request.actual += td_length;
drivers/usb/cdns3/cdnsp-ring.c:	td->preq->request.status = -EXDEV;
drivers/usb/cdns3/cdnsp-ring.c:	td->preq->request.actual = 0;
drivers/usb/cdns3/cdnsp-ring.c:	requested = td->preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:		td->preq->request.actual = remaining;
drivers/usb/cdns3/cdnsp-ring.c:	td->preq->request.actual = ep_trb_len;
drivers/usb/cdns3/cdnsp-ring.c:		desc = td->preq->pep->endpoint.desc;
drivers/usb/cdns3/cdnsp-ring.c:	ep_ring = cdnsp_get_transfer_ring(pdev, preq->pep,
drivers/usb/cdns3/cdnsp-ring.c:					  preq->request.stream_id);
drivers/usb/cdns3/cdnsp-ring.c:				 GET_EP_CTX_STATE(preq->pep->out_ctx),
drivers/usb/cdns3/cdnsp-ring.c:	INIT_LIST_HEAD(&preq->td.td_list);
drivers/usb/cdns3/cdnsp-ring.c:	preq->td.preq = preq;
drivers/usb/cdns3/cdnsp-ring.c:	list_add_tail(&preq->td.td_list, &ep_ring->td_list);
drivers/usb/cdns3/cdnsp-ring.c:	preq->pep->stream_info.td_count++;
drivers/usb/cdns3/cdnsp-ring.c:	preq->td.start_seg = ep_ring->enq_seg;
drivers/usb/cdns3/cdnsp-ring.c:	preq->td.first_trb = ep_ring->enqueue;
drivers/usb/cdns3/cdnsp-ring.c:	return cdnsp_count_trbs(preq->request.dma, preq->request.length);
drivers/usb/cdns3/cdnsp-ring.c:	full_len = preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:	for_each_sg(preq->request.sg, sg, preq->request.num_sgs, i) {
drivers/usb/cdns3/cdnsp-ring.c:	return cdnsp_count_trbs(preq->request.dma, preq->request.length);
drivers/usb/cdns3/cdnsp-ring.c:	if (running_total != preq->request.length)
drivers/usb/cdns3/cdnsp-ring.c:		dev_err(preq->pep->pdev->dev,
drivers/usb/cdns3/cdnsp-ring.c:			preq->pep->name, running_total,
drivers/usb/cdns3/cdnsp-ring.c:			preq->request.length, preq->request.actual);
drivers/usb/cdns3/cdnsp-ring.c:	maxp = usb_endpoint_maxp(preq->pep->endpoint.desc);
drivers/usb/cdns3/cdnsp-ring.c:	max_pkt = usb_endpoint_maxp(preq->pep->endpoint.desc);
drivers/usb/cdns3/cdnsp-ring.c:	if (new_buff_len > (preq->request.length - enqd_len))
drivers/usb/cdns3/cdnsp-ring.c:		new_buff_len = (preq->request.length - enqd_len);
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->direction) {
drivers/usb/cdns3/cdnsp-ring.c:		sg_pcopy_to_buffer(preq->request.sg,
drivers/usb/cdns3/cdnsp-ring.c:				   preq->request.num_mapped_sgs,
drivers/usb/cdns3/cdnsp-ring.c:	full_len = preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.num_sgs) {
drivers/usb/cdns3/cdnsp-ring.c:		num_sgs = preq->request.num_sgs;
drivers/usb/cdns3/cdnsp-ring.c:		sg = preq->request.sg;
drivers/usb/cdns3/cdnsp-ring.c:		addr = (u64)preq->request.dma;
drivers/usb/cdns3/cdnsp-ring.c:	pep = preq->pep;
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.zero && preq->request.length &&
drivers/usb/cdns3/cdnsp-ring.c:					preq->td.bounce_seg = ring->enq_seg;
drivers/usb/cdns3/cdnsp-ring.c:				preq->td.last_trb = ring->enqueue;
drivers/usb/cdns3/cdnsp-ring.c:		if (!preq->direction)
drivers/usb/cdns3/cdnsp-ring.c:	ret = cdnsp_giveback_first_trb(pdev, pep, preq->request.stream_id,
drivers/usb/cdns3/cdnsp-ring.c:		preq->td.drbl = 1;
drivers/usb/cdns3/cdnsp-ring.c:	struct cdnsp_ep *pep = preq->pep;
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.length > 0) {
drivers/usb/cdns3/cdnsp-ring.c:		remainder = cdnsp_td_remainder(pdev, 0, preq->request.length,
drivers/usb/cdns3/cdnsp-ring.c:					       preq->request.length, preq, 1);
drivers/usb/cdns3/cdnsp-ring.c:		length_field = TRB_LEN(preq->request.length) |
drivers/usb/cdns3/cdnsp-ring.c:				lower_32_bits(preq->request.dma),
drivers/usb/cdns3/cdnsp-ring.c:				upper_32_bits(preq->request.dma), length_field,
drivers/usb/cdns3/cdnsp-ring.c:	preq->td.last_trb = ep_ring->enqueue;
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.length == 0)
drivers/usb/cdns3/cdnsp-ring.c:	if (preq->request.length > 0 && pdev->ep0_expect_in)
drivers/usb/cdns3/cdnsp-ring.c:	cdnsp_ring_ep_doorbell(pdev, pep, preq->request.stream_id);
drivers/usb/cdns3/cdnsp-ring.c:	max_burst = preq->pep->endpoint.comp_desc->bMaxBurst;
drivers/usb/cdns3/cdnsp-ring.c:		max_burst = preq->pep->endpoint.comp_desc->bMaxBurst;
drivers/usb/cdns3/cdnsp-ring.c:	ep_ring = preq->pep->ring;
drivers/usb/cdns3/cdnsp-ring.c:	td_len = preq->request.length;
drivers/usb/cdns3/cdnsp-ring.c:	addr = (u64)preq->request.dma;
drivers/usb/cdns3/cdnsp-ring.c:	max_pkt = usb_endpoint_maxp(preq->pep->endpoint.desc);
drivers/usb/cdns3/cdnsp-ring.c:		if (usb_endpoint_dir_out(preq->pep->endpoint.desc))
drivers/usb/cdns3/cdnsp-ring.c:			preq->td.last_trb = ep_ring->enqueue;
drivers/usb/cdns3/cdnsp-ring.c:	cdnsp_giveback_first_trb(pdev, preq->pep, preq->request.stream_id,
drivers/usb/cdns3/cdnsp-ring.c:	list_del_init(&preq->td.td_list);
drivers/usb/cdns3/cdnsp-ring.c:	preq->td.last_trb = ep_ring->enqueue;
drivers/usb/cdns3/cdnsp-ring.c:	cdnsp_td_to_noop(pdev, ep_ring, &preq->td, true);
drivers/usb/cdns3/cdnsp-ring.c:	ep_ring->enqueue = preq->td.first_trb;
drivers/usb/cdns3/cdnsp-ring.c:	ep_ring->enq_seg = preq->td.start_seg;
drivers/usb/cdns3/cdnsp-ring.c:	ep_ring = preq->pep->ring;
drivers/usb/cdns3/cdnsp-ring.c:	ep_state = GET_EP_CTX_STATE(preq->pep->out_ctx);
drivers/usb/cdns3/cdns3-trace.h:		__string(name, req->priv_ep->name)
drivers/usb/cdns3/cdns3-trace.h:		__assign_str(name, req->priv_ep->name);
drivers/usb/cdns3/cdns3-trace.h:		__entry->buf = req->request.buf;
drivers/usb/cdns3/cdns3-trace.h:		__entry->actual = req->request.actual;
drivers/usb/cdns3/cdns3-trace.h:		__entry->length = req->request.length;
drivers/usb/cdns3/cdns3-trace.h:		__entry->status = req->request.status;
drivers/usb/cdns3/cdns3-trace.h:		__entry->zero = req->request.zero;
drivers/usb/cdns3/cdns3-trace.h:		__entry->short_not_ok = req->request.short_not_ok;
drivers/usb/cdns3/cdns3-trace.h:		__entry->no_interrupt = req->request.no_interrupt;
drivers/usb/cdns3/cdns3-trace.h:		__entry->start_trb = req->start_trb;
drivers/usb/cdns3/cdns3-trace.h:		__entry->end_trb = req->end_trb;
drivers/usb/cdns3/cdns3-trace.h:		__entry->start_trb_addr = req->trb;
drivers/usb/cdns3/cdns3-trace.h:		__entry->flags = req->flags;
drivers/usb/cdns3/cdns3-trace.h:		__entry->stream_id = req->request.stream_id;
drivers/usb/cdns3/cdns3-trace.h:		__string(name, req->priv_ep->name)
drivers/usb/cdns3/cdns3-trace.h:		__assign_str(name, req->priv_ep->name);
drivers/usb/cdns3/cdns3-trace.h:		__entry->actual = req->request.length;
drivers/usb/cdns3/cdns3-trace.h:		__entry->length = req->request.actual;
drivers/usb/cdns3/cdns3-trace.h:		__entry->stream_id = req->request.stream_id;
drivers/usb/cdns3/cdns3-trace.h:		__string(name, priv_req->priv_ep->name)
drivers/usb/cdns3/cdns3-trace.h:		__assign_str(name, priv_req->priv_ep->name);
drivers/usb/cdns3/cdns3-trace.h:		__entry->req = &priv_req->request;
drivers/usb/cdns3/cdns3-trace.h:		__entry->buf = priv_req->request.buf;
drivers/usb/cdns3/cdns3-trace.h:		__entry->dma = priv_req->request.dma;
drivers/usb/cdns3/cdns3-trace.h:		__entry->aligned_buf = priv_req->aligned_buf->buf;
drivers/usb/cdns3/cdns3-trace.h:		__entry->aligned_dma = priv_req->aligned_buf->dma;
drivers/usb/cdns3/cdns3-trace.h:		__entry->aligned_buf_size = priv_req->aligned_buf->size;
drivers/usb/cdns3/cdns3-trace.h:		__string(name, priv_req->priv_ep->name)
drivers/usb/cdns3/cdns3-trace.h:		__assign_str(name, priv_req->priv_ep->name);
drivers/usb/cdns3/cdns3-trace.h:		__entry->req = &priv_req->request;
drivers/usb/cdns3/cdns3-trace.h:		__entry->buf = priv_req->request.buf;
drivers/usb/cdns3/cdns3-trace.h:		__entry->dma = priv_req->request.dma;
drivers/usb/cdns3/cdns3-trace.h:		__entry->dequeue_idx = priv_req->priv_ep->dequeue;
drivers/usb/cdns3/cdns3-trace.h:		__entry->enqueue_idx = priv_req->priv_ep->enqueue;
drivers/usb/cdns3/cdns3-trace.h:		__entry->start_trb = priv_req->start_trb;
drivers/usb/cdns3/cdns3-trace.h:		__entry->end_trb = priv_req->end_trb;
drivers/usb/cdns3/cdnsp-trace.h:		__string(name, preq->pep->name)
drivers/usb/cdns3/cdnsp-trace.h:		__assign_str(name, preq->pep->name);
drivers/usb/cdns3/cdnsp-trace.h:		__string(name, req->pep->name)
drivers/usb/cdns3/cdnsp-trace.h:		__assign_str(name, req->pep->name);
drivers/usb/cdns3/cdnsp-trace.h:		__entry->request = &req->request;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->buf = req->request.buf;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->actual = req->request.actual;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->length = req->request.length;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->status = req->request.status;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->dma = req->request.dma;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->stream_id = req->request.stream_id;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->zero = req->request.zero;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->short_not_ok = req->request.short_not_ok;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->no_interrupt = req->request.no_interrupt;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->sg = req->request.sg;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->num_sgs = req->request.num_sgs;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->num_mapped_sgs = req->request.num_mapped_sgs;
drivers/usb/cdns3/cdnsp-trace.h:		__string(name, preq->pep->name)
drivers/usb/cdns3/cdnsp-trace.h:		__assign_str(name, preq->pep->name);
drivers/usb/cdns3/cdnsp-trace.h:		__entry->request = &preq->request;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->first_trb = preq->td.first_trb;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->last_trb = preq->td.last_trb;
drivers/usb/cdns3/cdnsp-trace.h:		__entry->trb_dma = cdnsp_trb_virt_to_dma(preq->td.start_seg,
drivers/usb/cdns3/cdnsp-trace.h:							 preq->td.first_trb)
drivers/usb/cdns3/cdnsp-gadget.c:	if (preq->epnum == 0 && !list_empty(&pep->pending_list)) {
drivers/usb/cdns3/cdnsp-gadget.c:	request = &preq->request;
drivers/usb/cdns3/cdnsp-gadget.c:	preq->direction = pep->direction;
drivers/usb/cdns3/cdnsp-gadget.c:	preq->epnum = pep->number;
drivers/usb/cdns3/cdnsp-gadget.c:	preq->td.drbl = 0;
drivers/usb/cdns3/cdnsp-gadget.c:	list_add_tail(&preq->list, &pep->pending_list);
drivers/usb/cdns3/cdnsp-gadget.c:	usb_gadget_unmap_request_by_dev(pdev->dev, &preq->request,
drivers/usb/cdns3/cdnsp-gadget.c:	list_del(&preq->list);
drivers/usb/cdns3/cdnsp-gadget.c:	preq->epnum = pep->number;
drivers/usb/cdns3/cdnsp-gadget.c:	preq->pep = pep;
drivers/usb/cdns3/cdnsp-gadget.c:	return &preq->request;
drivers/usb/cdns3/cdnsp-gadget.c:	list_del(&preq->list);
drivers/usb/cdns3/cdnsp-gadget.c:	if (preq->request.status == -EINPROGRESS)
drivers/usb/cdns3/cdnsp-gadget.c:		preq->request.status = status;
drivers/usb/cdns3/cdnsp-gadget.c:	usb_gadget_unmap_request_by_dev(pdev->dev, &preq->request,
drivers/usb/cdns3/cdnsp-gadget.c:					preq->direction);
drivers/usb/cdns3/cdnsp-gadget.c:		usb_gadget_giveback_request(&pep->endpoint, &preq->request);
drivers/usb/cdns3/cdns3-gadget.c:	struct cdns3_endpoint *priv_ep = priv_req->priv_ep;
drivers/usb/cdns3/cdns3-gadget.c:	int current_trb = priv_req->start_trb;
drivers/usb/cdns3/cdns3-gadget.c:	while (current_trb != priv_req->end_trb) {
drivers/usb/cdns3/cdns3-gadget.c:		if ((priv_req->flags & REQUEST_INTERNAL) ||
drivers/usb/cdns3/cdns3-gadget.c:	int length = request->actual + descmiss_req->actual;
drivers/usb/cdns3/cdns3-gadget.c:			       descmiss_req->buf,
drivers/usb/cdns3/cdns3-gadget.c:			       descmiss_req->actual);
drivers/usb/cdns3/cdns3-gadget.c:				descmiss_req->buf,
drivers/usb/cdns3/cdns3-gadget.c:				descmiss_req->actual);
drivers/usb/cdns3/cdns3-gadget.c:		descmiss_req = &descmiss_priv_req->request;
drivers/usb/cdns3/cdns3-gadget.c:		if (descmiss_priv_req->flags & REQUEST_PENDING)
drivers/usb/cdns3/cdns3-gadget.c:		chunk_end = descmiss_priv_req->flags & REQUEST_INTERNAL_CH;
drivers/usb/cdns3/cdns3-gadget.c:		request->status = descmiss_req->status;
drivers/usb/cdns3/cdns3-gadget.c:		list_del_init(&descmiss_priv_req->list);
drivers/usb/cdns3/cdns3-gadget.c:		kfree(descmiss_req->buf);
drivers/usb/cdns3/cdns3-gadget.c:	    priv_req->flags & REQUEST_INTERNAL) {
drivers/usb/cdns3/cdns3-gadget.c:		    req->length != req->actual) {
drivers/usb/cdns3/cdns3-gadget.c:		if (req->status == -EINPROGRESS)
drivers/usb/cdns3/cdns3-gadget.c:			req->status = 0;
drivers/usb/cdns3/cdns3-gadget.c:		list_del_init(&req->list);
drivers/usb/cdns3/cdns3-gadget.c:	return &priv_req->request;
drivers/usb/cdns3/cdns3-gadget.c:		    !(priv_req->flags & REQUEST_INTERNAL)) {
drivers/usb/cdns3/cdns3-gadget.c:						     &priv_req->request);
drivers/usb/cdns3/cdns3-gadget.c:			list_add_tail(&priv_req->request.list,
drivers/usb/cdns3/cdns3-gadget.c:					      priv_req->request.status);
drivers/usb/cdns3/cdns3-gadget.c:		if (priv_req->flags & REQUEST_INTERNAL)
drivers/usb/cdns3/cdns3-gadget.c:			list_add_tail(&priv_req->list,
drivers/usb/cdns3/cdns3-gadget.c:		chain = !!(priv_req->flags & REQUEST_INTERNAL_CH);
drivers/usb/cdns3/cdns3-gadget.c:		kfree(priv_req->request.buf);
drivers/usb/cdns3/cdns3-gadget.c:					     &priv_req->request);
drivers/usb/cdns3/cdns3-gadget.c:		list_del_init(&priv_req->list);
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->flags |= REQUEST_INTERNAL;
drivers/usb/cdns3/cdns3-gadget.c:		priv_ep->descmis_req->flags |= REQUEST_INTERNAL_CH;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->request.buf = kzalloc(CDNS3_DESCMIS_BUF_SIZE,
drivers/usb/cdns3/cdns3-gadget.c:	if (!priv_req->request.buf) {
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->request.length = CDNS3_DESCMIS_BUF_SIZE;
drivers/usb/cdns3/cdns3-gadget.c:				&priv_ep->descmis_req->request,
drivers/usb/cdns3/cdns3-gadget.c:	struct usb_request *request = &priv_req->request;
drivers/usb/cdns3/cdns3-gadget.c:	if ((priv_req->flags & REQUEST_UNALIGNED) &&
drivers/usb/cdns3/cdns3-gadget.c:		memcpy(request->buf, priv_req->aligned_buf->buf,
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->flags &= ~(REQUEST_PENDING | REQUEST_UNALIGNED);
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->finished_trb = 0;
drivers/usb/cdns3/cdns3-gadget.c:	struct cdns3_endpoint *priv_ep = priv_req->priv_ep;
drivers/usb/cdns3/cdns3-gadget.c:	if (!((uintptr_t)priv_req->request.buf & 0x7))
drivers/usb/cdns3/cdns3-gadget.c:	buf = priv_req->aligned_buf;
drivers/usb/cdns3/cdns3-gadget.c:	if (!buf || priv_req->request.length > buf->size) {
drivers/usb/cdns3/cdns3-gadget.c:		buf->size = priv_req->request.length;
drivers/usb/cdns3/cdns3-gadget.c:		if (priv_req->aligned_buf) {
drivers/usb/cdns3/cdns3-gadget.c:			priv_req->aligned_buf->in_use = 0;
drivers/usb/cdns3/cdns3-gadget.c:		priv_req->aligned_buf = buf;
drivers/usb/cdns3/cdns3-gadget.c:		memcpy(buf->buf, priv_req->request.buf,
drivers/usb/cdns3/cdns3-gadget.c:		       priv_req->request.length);
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->flags |= REQUEST_UNALIGNED;
drivers/usb/cdns3/cdns3-gadget.c:	if (priv_req->flags & REQUEST_UNALIGNED)
drivers/usb/cdns3/cdns3-gadget.c:		trb_dma = priv_req->aligned_buf->dma;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->start_trb = priv_ep->enqueue;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->end_trb = priv_req->start_trb;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->trb = trb;
drivers/usb/cdns3/cdns3-gadget.c:		  TRB_STREAM_ID(priv_req->request.stream_id) | TRB_ISP;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->flags |= REQUEST_PENDING;
drivers/usb/cdns3/cdns3-gadget.c:	trace_cdns3_prepare_trb(priv_ep, priv_req->trb);
drivers/usb/cdns3/cdns3-gadget.c:		priv_ep->last_stream_id = priv_req->request.stream_id;
drivers/usb/cdns3/cdns3-gadget.c:		writel(EP_CMD_ERDY_SID(priv_req->request.stream_id) |
drivers/usb/cdns3/cdns3-gadget.c:	if (priv_req->flags & REQUEST_UNALIGNED)
drivers/usb/cdns3/cdns3-gadget.c:		trb_dma = priv_req->aligned_buf->dma;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->start_trb = priv_ep->enqueue;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->trb = trb;
drivers/usb/cdns3/cdns3-gadget.c:			priv_req->trb->control = cpu_to_le32(control);
drivers/usb/cdns3/cdns3-gadget.c:		priv_req->end_trb = priv_ep->enqueue;
drivers/usb/cdns3/cdns3-gadget.c:	trb = priv_req->trb;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->flags |= REQUEST_PENDING;
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->num_of_trb = num_trb;
drivers/usb/cdns3/cdns3-gadget.c:		trace_cdns3_prepare_trb(priv_ep, priv_req->trb);
drivers/usb/cdns3/cdns3-gadget.c:					priv_req->start_trb * TRB_SIZE),
drivers/usb/cdns3/cdns3-gadget.c: * ST = priv_req->start_trb - index of first TRB in transfer ring
drivers/usb/cdns3/cdns3-gadget.c: * ET = priv_req->end_trb - index of last TRB in transfer ring
drivers/usb/cdns3/cdns3-gadget.c:	if (priv_req->start_trb < priv_req->end_trb) {
drivers/usb/cdns3/cdns3-gadget.c:		if (priv_ep->dequeue > priv_req->end_trb)
drivers/usb/cdns3/cdns3-gadget.c:		if (priv_ep->dequeue < priv_req->start_trb)
drivers/usb/cdns3/cdns3-gadget.c:	if ((priv_req->start_trb > priv_req->end_trb) &&
drivers/usb/cdns3/cdns3-gadget.c:		(priv_ep->dequeue > priv_req->end_trb) &&
drivers/usb/cdns3/cdns3-gadget.c:		(priv_ep->dequeue < priv_req->start_trb))
drivers/usb/cdns3/cdns3-gadget.c:	if ((priv_req->start_trb == priv_req->end_trb) &&
drivers/usb/cdns3/cdns3-gadget.c:		(priv_ep->dequeue != priv_req->end_trb))
drivers/usb/cdns3/cdns3-gadget.c:				priv_req->finished_trb++;
drivers/usb/cdns3/cdns3-gadget.c:				if (priv_req->finished_trb >= priv_req->num_of_trb)
drivers/usb/cdns3/cdns3-gadget.c:				if (priv_req->num_of_trb > 1 &&
drivers/usb/cdns3/cdns3-gadget.c:			if (trb != priv_req->trb)
drivers/usb/cdns3/cdns3-gadget.c:					 priv_req->trb, trb);
drivers/usb/cdns3/cdns3-gadget.c:	priv_req->priv_ep = priv_ep;
drivers/usb/cdns3/cdns3-gadget.c:	return &priv_req->request;
drivers/usb/cdns3/cdns3-gadget.c:	if (priv_req->aligned_buf)
drivers/usb/cdns3/cdns3-gadget.c:		priv_req->aligned_buf->in_use = 0;
drivers/usb/cdns3/cdns3-gadget.c:		kfree(priv_req->request.buf);
drivers/usb/cdns3/cdns3-gadget.c:					     &priv_req->request);
drivers/usb/cdns3/cdns3-gadget.c:		list_del_init(&priv_req->list);
drivers/usb/cdns3/cdns3-gadget.c:		priv_req->flags |= REQUEST_ZLP;
drivers/usb/cdns3/cdns3-gadget.c:	link_trb = priv_req->trb;
drivers/usb/cdns3/cdns3-gadget.c:			((priv_req->end_trb + 1) * TRB_SIZE)));
drivers/usb/cdns3/cdns3-gadget.c:		if (priv_ep->wa1_trb == priv_req->trb)
drivers/usb/cdns3/cdns3-gadget.c:		trb = priv_req->trb;
drivers/usb/cdns3/cdnsp-ep0.c:			list_del(&preq->list);
drivers/devfreq/governor_userspace.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/governor_userspace.c:	data = devfreq->data;
drivers/devfreq/governor_userspace.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/governor_userspace.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/governor_userspace.c:	data = devfreq->data;
drivers/devfreq/governor_userspace.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/governor_userspace.c:	devfreq->data = data;
drivers/devfreq/governor_userspace.c:	err = sysfs_create_group(&devfreq->dev.kobj, &dev_attr_group);
drivers/devfreq/governor_userspace.c:	if (devfreq->dev.kobj.sd)
drivers/devfreq/governor_userspace.c:		sysfs_remove_group(&devfreq->dev.kobj, &dev_attr_group);
drivers/devfreq/governor_userspace.c:	kfree(devfreq->data);
drivers/devfreq/governor_userspace.c:	devfreq->data = NULL;
drivers/devfreq/governor_powersave.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/governor_powersave.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/event/exynos-ppmu.c:#include <linux/devfreq-event.h>
drivers/devfreq/event/exynos-ppmu.c: * The devfreq-event ops structure for PPMU v1.1
drivers/devfreq/event/exynos-ppmu.c: * The devfreq-event ops structure for PPMU v2.0
drivers/devfreq/event/exynos-ppmu.c:			"failed to get child node of devfreq-event devices\n");
drivers/devfreq/event/exynos-ppmu.c:				"failed to add devfreq-event device\n");
drivers/devfreq/event/exynos-nocp.c:#include <linux/devfreq-event.h>
drivers/devfreq/event/exynos-nocp.c: * The devfreq-event ops structure for nocp probe.
drivers/devfreq/event/exynos-nocp.c:	/* Add devfreq-event device to measure the bandwidth of NoC */
drivers/devfreq/event/exynos-nocp.c:			"failed to add devfreq-event device\n");
drivers/devfreq/event/rockchip-dfi.c:#include <linux/devfreq-event.h>
drivers/devfreq/event/rockchip-dfi.c:			"failed to add devfreq-event device\n");
drivers/devfreq/event/Kconfig:	  The devfreq-event device provide the raw data and events which
drivers/devfreq/event/Kconfig:	  indicate the current state of devfreq-event device. The provided
drivers/devfreq/event/Kconfig:	  data from devfreq-event device is used to monitor the state of
drivers/devfreq/event/Kconfig:	  The devfreq-event device can support the various type of events
drivers/devfreq/event/Kconfig:	  This add the devfreq-event driver for Exynos SoC. It provides NoC
drivers/devfreq/event/Kconfig:	  This add the devfreq-event driver for Exynos SoC. It provides PPMU
drivers/devfreq/event/Kconfig:	  This add the devfreq-event driver for Rockchip SoC. It provides DFI
drivers/devfreq/devfreq.c:		if (tmp_devfreq->dev.parent == dev)
drivers/devfreq/devfreq.c:	opp = dev_pm_opp_find_freq_ceil(devfreq->dev.parent, &min_freq);
drivers/devfreq/devfreq.c:	opp = dev_pm_opp_find_freq_floor(devfreq->dev.parent, &max_freq);
drivers/devfreq/devfreq.c:	unsigned long *freq_table = devfreq->profile->freq_table;
drivers/devfreq/devfreq.c:	lockdep_assert_held(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (freq_table[0] < freq_table[devfreq->profile->max_state - 1]) {
drivers/devfreq/devfreq.c:		*max_freq = freq_table[devfreq->profile->max_state - 1];
drivers/devfreq/devfreq.c:		*min_freq = freq_table[devfreq->profile->max_state - 1];
drivers/devfreq/devfreq.c:	qos_min_freq = dev_pm_qos_read_value(devfreq->dev.parent,
drivers/devfreq/devfreq.c:	qos_max_freq = dev_pm_qos_read_value(devfreq->dev.parent,
drivers/devfreq/devfreq.c:	*min_freq = max(*min_freq, devfreq->scaling_min_freq);
drivers/devfreq/devfreq.c:	*max_freq = min(*max_freq, devfreq->scaling_max_freq);
drivers/devfreq/devfreq.c:	for (lev = 0; lev < devfreq->profile->max_state; lev++)
drivers/devfreq/devfreq.c:		if (freq == devfreq->profile->freq_table[lev])
drivers/devfreq/devfreq.c:	struct devfreq_dev_profile *profile = devfreq->profile;
drivers/devfreq/devfreq.c:	count = dev_pm_opp_get_opp_count(devfreq->dev.parent);
drivers/devfreq/devfreq.c:	profile->freq_table = devm_kcalloc(devfreq->dev.parent,
drivers/devfreq/devfreq.c:		opp = dev_pm_opp_find_freq_ceil(devfreq->dev.parent, &freq);
drivers/devfreq/devfreq.c:			devm_kfree(devfreq->dev.parent, profile->freq_table);
drivers/devfreq/devfreq.c:	lockdep_assert_held(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (!devfreq->previous_freq)
drivers/devfreq/devfreq.c:	prev_lev = devfreq_get_freq_level(devfreq, devfreq->previous_freq);
drivers/devfreq/devfreq.c:	devfreq->stats.time_in_state[prev_lev] +=
drivers/devfreq/devfreq.c:			cur_time - devfreq->stats.last_update;
drivers/devfreq/devfreq.c:		devfreq->stats.trans_table[
drivers/devfreq/devfreq.c:			(prev_lev * devfreq->profile->max_state) + lev]++;
drivers/devfreq/devfreq.c:		devfreq->stats.total_trans++;
drivers/devfreq/devfreq.c:	devfreq->stats.last_update = cur_time;
drivers/devfreq/devfreq.c:		srcu_notifier_call_chain(&devfreq->transition_notifier_list,
drivers/devfreq/devfreq.c:		srcu_notifier_call_chain(&devfreq->transition_notifier_list,
drivers/devfreq/devfreq.c:	if (devfreq->profile->get_cur_freq)
drivers/devfreq/devfreq.c:		devfreq->profile->get_cur_freq(devfreq->dev.parent, &cur_freq);
drivers/devfreq/devfreq.c:		cur_freq = devfreq->previous_freq;
drivers/devfreq/devfreq.c:	err = devfreq->profile->target(devfreq->dev.parent, &new_freq, flags);
drivers/devfreq/devfreq.c:		dev_err(&devfreq->dev,
drivers/devfreq/devfreq.c:	devfreq->previous_freq = new_freq;
drivers/devfreq/devfreq.c:	if (devfreq->suspend_freq)
drivers/devfreq/devfreq.c:		devfreq->resume_freq = cur_freq;
drivers/devfreq/devfreq.c: * Note: Lock devfreq->lock before calling devfreq_update_target. This function
drivers/devfreq/devfreq.c:	lockdep_assert_held(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (!devfreq->governor)
drivers/devfreq/devfreq.c:	err = devfreq->governor->get_target_freq(devfreq, &freq);
drivers/devfreq/devfreq.c: * Note: Lock devfreq->lock before calling update_devfreq
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:		dev_err(&devfreq->dev, "dvfs failed with (%d) error\n", err);
drivers/devfreq/devfreq.c:	queue_delayed_work(devfreq_wq, &devfreq->work,
drivers/devfreq/devfreq.c:				msecs_to_jiffies(devfreq->profile->polling_ms));
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (IS_SUPPORTED_FLAG(devfreq->governor->flags, IRQ_DRIVEN))
drivers/devfreq/devfreq.c:	switch (devfreq->profile->timer) {
drivers/devfreq/devfreq.c:		INIT_DEFERRABLE_WORK(&devfreq->work, devfreq_monitor);
drivers/devfreq/devfreq.c:		INIT_DELAYED_WORK(&devfreq->work, devfreq_monitor);
drivers/devfreq/devfreq.c:	if (devfreq->profile->polling_ms)
drivers/devfreq/devfreq.c:		queue_delayed_work(devfreq_wq, &devfreq->work,
drivers/devfreq/devfreq.c:			msecs_to_jiffies(devfreq->profile->polling_ms));
drivers/devfreq/devfreq.c:	if (IS_SUPPORTED_FLAG(devfreq->governor->flags, IRQ_DRIVEN))
drivers/devfreq/devfreq.c:	cancel_delayed_work_sync(&devfreq->work);
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (devfreq->stop_polling) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq_update_status(devfreq, devfreq->previous_freq);
drivers/devfreq/devfreq.c:	devfreq->stop_polling = true;
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (IS_SUPPORTED_FLAG(devfreq->governor->flags, IRQ_DRIVEN))
drivers/devfreq/devfreq.c:	cancel_delayed_work_sync(&devfreq->work);
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (IS_SUPPORTED_FLAG(devfreq->governor->flags, IRQ_DRIVEN))
drivers/devfreq/devfreq.c:	if (!devfreq->stop_polling)
drivers/devfreq/devfreq.c:	if (!delayed_work_pending(&devfreq->work) &&
drivers/devfreq/devfreq.c:			devfreq->profile->polling_ms)
drivers/devfreq/devfreq.c:		queue_delayed_work(devfreq_wq, &devfreq->work,
drivers/devfreq/devfreq.c:			msecs_to_jiffies(devfreq->profile->polling_ms));
drivers/devfreq/devfreq.c:	devfreq->stats.last_update = get_jiffies_64();
drivers/devfreq/devfreq.c:	devfreq->stop_polling = false;
drivers/devfreq/devfreq.c:	if (devfreq->profile->get_cur_freq &&
drivers/devfreq/devfreq.c:		!devfreq->profile->get_cur_freq(devfreq->dev.parent, &freq))
drivers/devfreq/devfreq.c:		devfreq->previous_freq = freq;
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	unsigned int cur_delay = devfreq->profile->polling_ms;
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->profile->polling_ms = new_delay;
drivers/devfreq/devfreq.c:	if (IS_SUPPORTED_FLAG(devfreq->governor->flags, IRQ_DRIVEN))
drivers/devfreq/devfreq.c:	if (devfreq->stop_polling)
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		cancel_delayed_work_sync(&devfreq->work);
drivers/devfreq/devfreq.c:		queue_delayed_work(devfreq_wq, &devfreq->work,
drivers/devfreq/devfreq.c:			msecs_to_jiffies(devfreq->profile->polling_ms));
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		cancel_delayed_work_sync(&devfreq->work);
drivers/devfreq/devfreq.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:		if (!devfreq->stop_polling)
drivers/devfreq/devfreq.c:			queue_delayed_work(devfreq_wq, &devfreq->work,
drivers/devfreq/devfreq.c:				msecs_to_jiffies(devfreq->profile->polling_ms));
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c: * @nb:		the notifier_block (supposed to be devfreq->nb)
drivers/devfreq/devfreq.c: * Called by a notifier that uses devfreq->nb.
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->scaling_min_freq = find_available_min_freq(devfreq);
drivers/devfreq/devfreq.c:	if (!devfreq->scaling_min_freq)
drivers/devfreq/devfreq.c:	devfreq->scaling_max_freq = find_available_max_freq(devfreq);
drivers/devfreq/devfreq.c:	if (!devfreq->scaling_max_freq) {
drivers/devfreq/devfreq.c:		devfreq->scaling_max_freq = ULONG_MAX;
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		dev_err(devfreq->dev.parent,
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		dev_err(devfreq->dev.parent,
drivers/devfreq/devfreq.c: * @nb:		Should be devfreq->nb_min
drivers/devfreq/devfreq.c: * @nb:		Should be devfreq->nb_max
drivers/devfreq/devfreq.c:	list_del(&devfreq->node);
drivers/devfreq/devfreq.c:	err = dev_pm_qos_remove_notifier(devfreq->dev.parent, &devfreq->nb_max,
drivers/devfreq/devfreq.c:	err = dev_pm_qos_remove_notifier(devfreq->dev.parent, &devfreq->nb_min,
drivers/devfreq/devfreq.c:	if (dev_pm_qos_request_active(&devfreq->user_max_freq_req)) {
drivers/devfreq/devfreq.c:		err = dev_pm_qos_remove_request(&devfreq->user_max_freq_req);
drivers/devfreq/devfreq.c:	if (dev_pm_qos_request_active(&devfreq->user_min_freq_req)) {
drivers/devfreq/devfreq.c:		err = dev_pm_qos_remove_request(&devfreq->user_min_freq_req);
drivers/devfreq/devfreq.c:	if (devfreq->profile->exit)
drivers/devfreq/devfreq.c:		devfreq->profile->exit(devfreq->dev.parent);
drivers/devfreq/devfreq.c:	if (devfreq->opp_table)
drivers/devfreq/devfreq.c:		dev_pm_opp_put_opp_table(devfreq->opp_table);
drivers/devfreq/devfreq.c:	mutex_destroy(&devfreq->lock);
drivers/devfreq/devfreq.c:	mutex_init(&devfreq->lock);
drivers/devfreq/devfreq.c:	mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->dev.parent = dev;
drivers/devfreq/devfreq.c:	devfreq->dev.class = devfreq_class;
drivers/devfreq/devfreq.c:	devfreq->dev.release = devfreq_dev_release;
drivers/devfreq/devfreq.c:	INIT_LIST_HEAD(&devfreq->node);
drivers/devfreq/devfreq.c:	devfreq->profile = profile;
drivers/devfreq/devfreq.c:	devfreq->previous_freq = profile->initial_freq;
drivers/devfreq/devfreq.c:	devfreq->last_status.current_frequency = profile->initial_freq;
drivers/devfreq/devfreq.c:	devfreq->data = data;
drivers/devfreq/devfreq.c:	devfreq->nb.notifier_call = devfreq_notifier_call;
drivers/devfreq/devfreq.c:	if (devfreq->profile->timer < 0
drivers/devfreq/devfreq.c:		|| devfreq->profile->timer >= DEVFREQ_TIMER_NUM) {
drivers/devfreq/devfreq.c:	if (!devfreq->profile->max_state && !devfreq->profile->freq_table) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->scaling_min_freq = find_available_min_freq(devfreq);
drivers/devfreq/devfreq.c:	if (!devfreq->scaling_min_freq) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->scaling_max_freq = find_available_max_freq(devfreq);
drivers/devfreq/devfreq.c:	if (!devfreq->scaling_max_freq) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->suspend_freq = dev_pm_opp_get_suspend_opp_freq(dev);
drivers/devfreq/devfreq.c:	devfreq->opp_table = dev_pm_opp_get_opp_table(dev);
drivers/devfreq/devfreq.c:	if (IS_ERR(devfreq->opp_table))
drivers/devfreq/devfreq.c:		devfreq->opp_table = NULL;
drivers/devfreq/devfreq.c:	atomic_set(&devfreq->suspend_count, 0);
drivers/devfreq/devfreq.c:	dev_set_name(&devfreq->dev, "%s", dev_name(dev));
drivers/devfreq/devfreq.c:	err = device_register(&devfreq->dev);
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:		put_device(&devfreq->dev);
drivers/devfreq/devfreq.c:	devfreq->stats.trans_table = devm_kzalloc(&devfreq->dev,
drivers/devfreq/devfreq.c:				    devfreq->profile->max_state,
drivers/devfreq/devfreq.c:				    devfreq->profile->max_state),
drivers/devfreq/devfreq.c:	if (!devfreq->stats.trans_table) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->stats.time_in_state = devm_kcalloc(&devfreq->dev,
drivers/devfreq/devfreq.c:			devfreq->profile->max_state,
drivers/devfreq/devfreq.c:			sizeof(*devfreq->stats.time_in_state),
drivers/devfreq/devfreq.c:	if (!devfreq->stats.time_in_state) {
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	devfreq->stats.total_trans = 0;
drivers/devfreq/devfreq.c:	devfreq->stats.last_update = get_jiffies_64();
drivers/devfreq/devfreq.c:	srcu_init_notifier_head(&devfreq->transition_notifier_list);
drivers/devfreq/devfreq.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	err = dev_pm_qos_add_request(dev, &devfreq->user_min_freq_req,
drivers/devfreq/devfreq.c:	err = dev_pm_qos_add_request(dev, &devfreq->user_max_freq_req,
drivers/devfreq/devfreq.c:	devfreq->nb_min.notifier_call = qos_min_notifier_call;
drivers/devfreq/devfreq.c:	err = dev_pm_qos_add_notifier(dev, &devfreq->nb_min,
drivers/devfreq/devfreq.c:	devfreq->nb_max.notifier_call = qos_max_notifier_call;
drivers/devfreq/devfreq.c:	err = dev_pm_qos_add_notifier(dev, &devfreq->nb_max,
drivers/devfreq/devfreq.c:	devfreq->governor = governor;
drivers/devfreq/devfreq.c:	err = devfreq->governor->event_handler(devfreq, DEVFREQ_GOV_START,
drivers/devfreq/devfreq.c:	create_sysfs_files(devfreq, devfreq->governor);
drivers/devfreq/devfreq.c:	list_add(&devfreq->node, &devfreq_list);
drivers/devfreq/devfreq.c:	if (devfreq->governor) {
drivers/devfreq/devfreq.c:		devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:		remove_sysfs_files(devfreq, devfreq->governor);
drivers/devfreq/devfreq.c:	device_unregister(&devfreq->dev);
drivers/devfreq/devfreq.c:		if (devfreq->dev.parent
drivers/devfreq/devfreq.c:			&& devfreq->dev.parent->of_node == node) {
drivers/devfreq/devfreq.c:	if (atomic_inc_return(&devfreq->suspend_count) > 1)
drivers/devfreq/devfreq.c:	if (devfreq->governor) {
drivers/devfreq/devfreq.c:		ret = devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:	if (devfreq->suspend_freq) {
drivers/devfreq/devfreq.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:		ret = devfreq_set_target(devfreq, devfreq->suspend_freq, 0);
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (atomic_dec_return(&devfreq->suspend_count) >= 1)
drivers/devfreq/devfreq.c:	if (devfreq->resume_freq) {
drivers/devfreq/devfreq.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:		ret = devfreq_set_target(devfreq, devfreq->resume_freq, 0);
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:	if (devfreq->governor) {
drivers/devfreq/devfreq.c:		ret = devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:			dev_err(&devfreq->dev,
drivers/devfreq/devfreq.c:			dev_warn(&devfreq->dev,
drivers/devfreq/devfreq.c:		struct device *dev = devfreq->dev.parent;
drivers/devfreq/devfreq.c:		if (!strncmp(devfreq->governor->name, governor->name,
drivers/devfreq/devfreq.c:			if (devfreq->governor) {
drivers/devfreq/devfreq.c:					 __func__, devfreq->governor->name);
drivers/devfreq/devfreq.c:				ret = devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:						 devfreq->governor->name, ret);
drivers/devfreq/devfreq.c:			devfreq->governor = governor;
drivers/devfreq/devfreq.c:			ret = devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:					 __func__, devfreq->governor->name,
drivers/devfreq/devfreq.c:		struct device *dev = devfreq->dev.parent;
drivers/devfreq/devfreq.c:		if (!strncmp(devfreq->governor->name, governor->name,
drivers/devfreq/devfreq.c:			if (!devfreq->governor) {
drivers/devfreq/devfreq.c:			ret = devfreq->governor->event_handler(devfreq,
drivers/devfreq/devfreq.c:					 __func__, devfreq->governor->name,
drivers/devfreq/devfreq.c:			devfreq->governor = NULL;
drivers/devfreq/devfreq.c:		sysfs_remove_file(&devfreq->dev.kobj,
drivers/devfreq/devfreq.c:		sysfs_remove_file(&devfreq->dev.kobj, &dev_attr_timer.attr);
drivers/devfreq/devfreq.c:		if (!strncmp(devfreq->governor->name, DEVFREQ_GOV_PASSIVE,
drivers/devfreq/devfreq.c:			struct devfreq_passive_data *data = devfreq->data;
drivers/devfreq/devfreq.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/devfreq.c:		cur_freq = devfreq->previous_freq;
drivers/devfreq/devfreq.c:		timer = devfreq->profile->timer;
drivers/devfreq/devfreq.c:		if (IS_SUPPORTED_ATTR(devfreq->governor->attrs, POLLING_INTERVAL))
drivers/devfreq/devfreq.c:			polling_ms = devfreq->profile->polling_ms;
drivers/devfreq/devfreq.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/devfreq.c:			dev_name(&devfreq->dev),
drivers/devfreq/devfreq.c:			p_devfreq ? dev_name(&p_devfreq->dev) : "null",
drivers/devfreq/devfreq.c:			devfreq->governor->name,
drivers/devfreq/devfreq.c:	return dev_pm_opp_register_notifier(dev, &devfreq->nb);
drivers/devfreq/devfreq.c:	return dev_pm_opp_unregister_notifier(dev, &devfreq->nb);
drivers/devfreq/devfreq.c:				&devfreq->transition_notifier_list, nb);
drivers/devfreq/devfreq.c:				&devfreq->transition_notifier_list, nb);
drivers/devfreq/tegra30-devfreq.c:	u32 band = avg_band_freq * tegra->devfreq->profile->polling_ms;
drivers/devfreq/tegra30-devfreq.c:	u32 val = tegra->cur_freq * tegra->devfreq->profile->polling_ms;
drivers/devfreq/tegra30-devfreq.c:	target_freq = dev->avg_count / tegra->devfreq->profile->polling_ms;
drivers/devfreq/tegra30-devfreq.c:	mutex_lock(&tegra->devfreq->lock);
drivers/devfreq/tegra30-devfreq.c:	mutex_unlock(&tegra->devfreq->lock);
drivers/devfreq/tegra30-devfreq.c:	mutex_lock(&tegra->devfreq->lock);
drivers/devfreq/tegra30-devfreq.c:	mutex_unlock(&tegra->devfreq->lock);
drivers/devfreq/tegra30-devfreq.c:	if (mutex_trylock(&tegra->devfreq->lock)) {
drivers/devfreq/tegra30-devfreq.c:		mutex_unlock(&tegra->devfreq->lock);
drivers/devfreq/tegra30-devfreq.c:	dev->avg_count = tegra->cur_freq * tegra->devfreq->profile->polling_ms;
drivers/devfreq/tegra30-devfreq.c:	if (!tegra->devfreq->profile->polling_ms || !tegra->started)
drivers/devfreq/tegra30-devfreq.c:	actmon_writel(tegra, tegra->devfreq->profile->polling_ms - 1,
drivers/devfreq/tegra30-devfreq.c:		dev_err(tegra->devfreq->dev.parent,
drivers/devfreq/tegra30-devfreq.c:		dev_err(tegra->devfreq->dev.parent,
drivers/devfreq/tegra30-devfreq.c:	if (!tegra->devfreq->profile->polling_ms || !tegra->started)
drivers/devfreq/tegra30-devfreq.c:	stat->total_time = tegra->devfreq->profile->polling_ms * cur_freq;
drivers/devfreq/tegra30-devfreq.c:	stat = &devfreq->last_status;
drivers/devfreq/tegra30-devfreq.c:	struct tegra_devfreq *tegra = dev_get_drvdata(devfreq->dev.parent);
drivers/devfreq/tegra30-devfreq.c:	 * Couple devfreq-device with the governor early because it is
drivers/devfreq/Makefile:obj-$(CONFIG_PM_DEVFREQ_EVENT)	+= devfreq-event.o
drivers/devfreq/devfreq-event.c: * devfreq-event: a framework to provide raw data and events of devfreq devices
drivers/devfreq/devfreq-event.c:#include <linux/devfreq-event.h>
drivers/devfreq/devfreq-event.c: * devfreq_event_enable_edev() - Enable the devfreq-event dev and increase
drivers/devfreq/devfreq-event.c: *				 the enable_count of devfreq-event dev.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * devfreq-event device. The devfreq-event device should be enabled before
drivers/devfreq/devfreq-event.c: * devfreq_event_disable_edev() - Disable the devfreq-event dev and decrease
drivers/devfreq/devfreq-event.c: *				  the enable_count of the devfreq-event dev.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * devfreq-event device. After the devfreq-event device is disabled,
drivers/devfreq/devfreq-event.c: * devfreq device can't use the devfreq-event device for get/set/reset
drivers/devfreq/devfreq-event.c: * devfreq_event_is_enabled() - Check whether devfreq-event dev is enabled or
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function check whether devfreq-event dev is enabled or not.
drivers/devfreq/devfreq-event.c: * If return true, the devfreq-event dev is enabeld. If return false, the
drivers/devfreq/devfreq-event.c: * devfreq-event dev is disabled.
drivers/devfreq/devfreq-event.c: * devfreq_event_set_event() - Set event to devfreq-event dev to start.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function set the event to the devfreq-event device to start
drivers/devfreq/devfreq-event.c: * devfreq_event_get_event() - Get {load|total}_count from devfreq-event dev.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * @edata	: the calculated data of devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function get the calculated event data from devfreq-event dev
drivers/devfreq/devfreq-event.c: * after stoping the progress of whole sequence of devfreq-event dev.
drivers/devfreq/devfreq-event.c: * devfreq_event_reset_event() - Reset all opeations of devfreq-event dev.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function stop all operations of devfreq-event dev and reset
drivers/devfreq/devfreq-event.c: * the current event data to make the devfreq-event device into initial state.
drivers/devfreq/devfreq-event.c: * devfreq_event_get_edev_by_phandle() - Get the devfreq-event dev from
drivers/devfreq/devfreq-event.c: * @index	: the index into list of devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function return the pointer of devfreq-event device.
drivers/devfreq/devfreq-event.c: * devfreq_event_get_edev_count() - Get the count of devfreq-event dev
drivers/devfreq/devfreq-event.c: * Note that this function return the count of devfreq-event devices.
drivers/devfreq/devfreq-event.c:			"failed to get the count of devfreq-event in %pOF node\n",
drivers/devfreq/devfreq-event.c: * devfreq_event_add_edev() - Add new devfreq-event device.
drivers/devfreq/devfreq-event.c: * @dev		: the device owning the devfreq-event device being created
drivers/devfreq/devfreq-event.c: * @desc	: the devfreq-event device's descriptor which include essential
drivers/devfreq/devfreq-event.c: *		  data for devfreq-event device.
drivers/devfreq/devfreq-event.c: * Note that this function add new devfreq-event device to devfreq-event class
drivers/devfreq/devfreq-event.c: * list and register the device of the devfreq-event device.
drivers/devfreq/devfreq-event.c: * devfreq_event_remove_edev() - Remove the devfreq-event device registered.
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function removes the registered devfreq-event device.
drivers/devfreq/devfreq-event.c: * @dev		: the device owning the devfreq-event device being created
drivers/devfreq/devfreq-event.c: * @desc	: the devfreq-event device's descriptor which include essential
drivers/devfreq/devfreq-event.c: *		  data for devfreq-event device.
drivers/devfreq/devfreq-event.c: * Note that this function manages automatically the memory of devfreq-event
drivers/devfreq/devfreq-event.c: * for memory of devfreq-event device.
drivers/devfreq/devfreq-event.c: * @dev		: the device owning the devfreq-event device being created
drivers/devfreq/devfreq-event.c: * @edev	: the devfreq-event device
drivers/devfreq/devfreq-event.c: * Note that this function manages automatically the memory of devfreq-event
drivers/devfreq/devfreq-event.c: * Device attributes for devfreq-event class.
drivers/devfreq/devfreq-event.c:	devfreq_event_class = class_create(THIS_MODULE, "devfreq-event");
drivers/devfreq/exynos-bus.c:#include <linux/devfreq-event.h>
drivers/devfreq/exynos-bus.c: * Control the devfreq-event device to get the current state of bus
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to get event from devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:	dev_dbg(dev, "Usage of devfreq-event : %lu/%lu\n", stat->busy_time,
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to set event to devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:		dev_warn(dev, "failed to disable the devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:	 * Get the devfreq-event devices to get the current utilization of
drivers/devfreq/exynos-bus.c:	count = devfreq_event_get_edev_count(dev, "devfreq-events");
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to get the count of devfreq-event dev\n");
drivers/devfreq/exynos-bus.c:							"devfreq-events", i);
drivers/devfreq/exynos-bus.c:	 * When measuring the utilization of each AXI bus with devfreq-event
drivers/devfreq/exynos-bus.c:	 * Enable devfreq-event to get raw data which is used to determine
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to enable devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to set event to devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:		dev_warn(dev, "failed to disable the devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:	max_state = bus->devfreq->profile->max_state;
drivers/devfreq/exynos-bus.c:	min_freq = (bus->devfreq->profile->freq_table[0] / 1000);
drivers/devfreq/exynos-bus.c:	max_freq = (bus->devfreq->profile->freq_table[max_state - 1] / 1000);
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to enable the devfreq-event devices\n");
drivers/devfreq/exynos-bus.c:		dev_err(dev, "failed to disable the devfreq-event devices\n");
drivers/devfreq/governor_simpleondemand.c:/* Default constants for DevFreq-Simple-Ondemand (DFSO) */
drivers/devfreq/imx8m-ddrc.c:		if (freq->rate == rate ||
drivers/devfreq/imx8m-ddrc.c:				freq->rate + 1 == rate ||
drivers/devfreq/imx8m-ddrc.c:				freq->rate - 1 == rate)
drivers/devfreq/imx8m-ddrc.c:			priv->dram_core, freq->dram_core_parent_index - 1);
drivers/devfreq/imx8m-ddrc.c:	if (freq->dram_alt_parent_index) {
drivers/devfreq/imx8m-ddrc.c:				freq->dram_alt_parent_index - 1);
drivers/devfreq/imx8m-ddrc.c:	if (freq->dram_apb_parent_index) {
drivers/devfreq/imx8m-ddrc.c:				freq->dram_apb_parent_index - 1);
drivers/devfreq/imx8m-ddrc.c:	imx8m_ddrc_smc_set_freq(freq->smcarg);
drivers/devfreq/imx8m-ddrc.c:		freq->rate = res.a0;
drivers/devfreq/imx8m-ddrc.c:		freq->smcarg = index;
drivers/devfreq/imx8m-ddrc.c:		freq->dram_core_parent_index = res.a1;
drivers/devfreq/imx8m-ddrc.c:		freq->dram_alt_parent_index = res.a2;
drivers/devfreq/imx8m-ddrc.c:		freq->dram_apb_parent_index = res.a3;
drivers/devfreq/imx8m-ddrc.c:		if (freq->dram_core_parent_index != 1 &&
drivers/devfreq/imx8m-ddrc.c:				freq->dram_core_parent_index != 2)
drivers/devfreq/imx8m-ddrc.c:		if (freq->dram_alt_parent_index > 8 ||
drivers/devfreq/imx8m-ddrc.c:				freq->dram_apb_parent_index > 8)
drivers/devfreq/imx8m-ddrc.c:		if (freq->dram_core_parent_index == 2 &&
drivers/devfreq/imx8m-ddrc.c:				freq->dram_alt_parent_index == 0)
drivers/devfreq/governor_passive.c:			= (struct devfreq_passive_data *)devfreq->data;
drivers/devfreq/governor_passive.c:	if (!devfreq->profile || !devfreq->profile->freq_table
drivers/devfreq/governor_passive.c:		|| devfreq->profile->max_state <= 0)
drivers/devfreq/governor_passive.c:	if (devfreq->opp_table && parent_devfreq->opp_table) {
drivers/devfreq/governor_passive.c:		p_opp = devfreq_recommended_opp(parent_devfreq->dev.parent,
drivers/devfreq/governor_passive.c:		opp = dev_pm_opp_xlate_required_opp(parent_devfreq->opp_table,
drivers/devfreq/governor_passive.c:						    devfreq->opp_table, p_opp);
drivers/devfreq/governor_passive.c:	for (i = 0; i < parent_devfreq->profile->max_state; i++)
drivers/devfreq/governor_passive.c:		if (parent_devfreq->profile->freq_table[i] == *freq)
drivers/devfreq/governor_passive.c:	if (i == parent_devfreq->profile->max_state)
drivers/devfreq/governor_passive.c:	if (i < devfreq->profile->max_state) {
drivers/devfreq/governor_passive.c:		child_freq = devfreq->profile->freq_table[i];
drivers/devfreq/governor_passive.c:		count = devfreq->profile->max_state;
drivers/devfreq/governor_passive.c:		child_freq = devfreq->profile->freq_table[count - 1];
drivers/devfreq/governor_passive.c:	mutex_lock_nested(&devfreq->lock, SINGLE_DEPTH_NESTING);
drivers/devfreq/governor_passive.c:	mutex_unlock(&devfreq->lock);
drivers/devfreq/governor_passive.c:		dev_warn(&devfreq->dev,
drivers/devfreq/governor_passive.c:			= (struct devfreq_passive_data *)devfreq->data;
drivers/devfreq/rk3399_dmc.c:#include <linux/devfreq-event.h>
drivers/devfreq/rk3399_dmc.c:	unsigned long old_clk_rate = dmcfreq->rate;
drivers/devfreq/rk3399_dmc.c:	if (dmcfreq->rate == target_rate)
drivers/devfreq/rk3399_dmc.c:	mutex_lock(&dmcfreq->lock);
drivers/devfreq/rk3399_dmc.c:	if (dmcfreq->regmap_pmu) {
drivers/devfreq/rk3399_dmc.c:		if (target_rate >= dmcfreq->odt_dis_freq)
drivers/devfreq/rk3399_dmc.c:		arm_smccc_smc(ROCKCHIP_SIP_DRAM_FREQ, dmcfreq->odt_pd_arg0,
drivers/devfreq/rk3399_dmc.c:			      dmcfreq->odt_pd_arg1,
drivers/devfreq/rk3399_dmc.c:		err = regulator_set_voltage(dmcfreq->vdd_center, target_volt,
drivers/devfreq/rk3399_dmc.c:	err = clk_set_rate(dmcfreq->dmc_clk, target_rate);
drivers/devfreq/rk3399_dmc.c:		regulator_set_voltage(dmcfreq->vdd_center, dmcfreq->volt,
drivers/devfreq/rk3399_dmc.c:				      dmcfreq->volt);
drivers/devfreq/rk3399_dmc.c:	dmcfreq->rate = clk_get_rate(dmcfreq->dmc_clk);
drivers/devfreq/rk3399_dmc.c:	if (dmcfreq->rate != target_rate) {
drivers/devfreq/rk3399_dmc.c:			target_rate, dmcfreq->rate);
drivers/devfreq/rk3399_dmc.c:		regulator_set_voltage(dmcfreq->vdd_center, dmcfreq->volt,
drivers/devfreq/rk3399_dmc.c:				      dmcfreq->volt);
drivers/devfreq/rk3399_dmc.c:		err = regulator_set_voltage(dmcfreq->vdd_center, target_volt,
drivers/devfreq/rk3399_dmc.c:	dmcfreq->rate = target_rate;
drivers/devfreq/rk3399_dmc.c:	dmcfreq->volt = target_volt;
drivers/devfreq/rk3399_dmc.c:	mutex_unlock(&dmcfreq->lock);
drivers/devfreq/rk3399_dmc.c:	ret = devfreq_event_get_event(dmcfreq->edev, &edata);
drivers/devfreq/rk3399_dmc.c:	stat->current_frequency = dmcfreq->rate;
drivers/devfreq/rk3399_dmc.c:	*freq = dmcfreq->rate;
drivers/devfreq/rk3399_dmc.c:	ret = devfreq_event_disable_edev(dmcfreq->edev);
drivers/devfreq/rk3399_dmc.c:		dev_err(dev, "failed to disable the devfreq-event devices\n");
drivers/devfreq/rk3399_dmc.c:	ret = devfreq_suspend_device(dmcfreq->devfreq);
drivers/devfreq/rk3399_dmc.c:	ret = devfreq_event_enable_edev(dmcfreq->edev);
drivers/devfreq/rk3399_dmc.c:		dev_err(dev, "failed to enable the devfreq-event devices\n");
drivers/devfreq/rk3399_dmc.c:	ret = devfreq_resume_device(dmcfreq->devfreq);
drivers/devfreq/rk3399_dmc.c:	data->edev = devfreq_event_get_edev_by_phandle(dev, "devfreq-events", 0);
drivers/devfreq/rk3399_dmc.c:		dev_err(dev, "failed to enable devfreq-event devices\n");
drivers/devfreq/rk3399_dmc.c:	devm_devfreq_unregister_opp_notifier(dmcfreq->dev, dmcfreq->devfreq);
drivers/devfreq/rk3399_dmc.c:	dev_pm_opp_of_remove_table(dmcfreq->dev);
drivers/devfreq/governor_performance.c:		mutex_lock(&devfreq->lock);
drivers/devfreq/governor_performance.c:		mutex_unlock(&devfreq->lock);
drivers/devfreq/governor.h: * Note that the callbacks are called with devfreq->lock locked by devfreq.
drivers/memory/emif.c:				"low-power-mode-freq-threshold",
drivers/memory/tegra/tegra20-emc.c:			min_rate = max(req->min_rate, min_rate);
drivers/memory/tegra/tegra20-emc.c:			max_rate = min(req->max_rate, max_rate);
drivers/memory/tegra/tegra20-emc.c:	ret = emc_request_rate(emc, rate, req->max_rate, type);
drivers/memory/tegra/tegra20-emc.c:	ret = emc_request_rate(emc, req->min_rate, rate, type);
drivers/memory/tegra/tegra124-emc.c:			min_rate = max(req->min_rate, min_rate);
drivers/memory/tegra/tegra124-emc.c:			max_rate = min(req->max_rate, max_rate);
drivers/memory/tegra/tegra124-emc.c:	ret = emc_request_rate(emc, rate, req->max_rate, type);
drivers/memory/tegra/tegra124-emc.c:	ret = emc_request_rate(emc, req->min_rate, rate, type);
drivers/memory/tegra/tegra30-emc.c:			min_rate = max(req->min_rate, min_rate);
drivers/memory/tegra/tegra30-emc.c:			max_rate = min(req->max_rate, max_rate);
drivers/memory/tegra/tegra30-emc.c:	ret = emc_request_rate(emc, rate, req->max_rate, type);
drivers/memory/tegra/tegra30-emc.c:	ret = emc_request_rate(emc, req->min_rate, rate, type);
drivers/memory/samsung/exynos5422-dmc.c:#include <linux/devfreq-event.h>
drivers/memory/samsung/exynos5422-dmc.c:	for (i = 0, freq = ULONG_MAX; i < dmc->opp_count; i++, freq--) {
drivers/memory/samsung/exynos5422-dmc.c:							"devfreq-events");
drivers/memory/samsung/exynos5422-dmc.c:		dev_err(dmc->dev, "could not get devfreq-event counters\n");
drivers/memory/samsung/exynos5422-dmc.c:						"devfreq-events", i);
drivers/message/fusion/mptscsih.c:		req_idx = le16_to_cpu(req->u.frame.hwhdr.msgctxu.fld.req_idx);
drivers/message/fusion/mptscsih.c:			if (req->u.scsireq.CDB[0] == INQUIRY)
drivers/message/fusion/mptsas.c:	req->Function = MPI_FUNCTION_SAS_IO_UNIT_CONTROL;
drivers/message/fusion/mptsas.c:	req->MsgContext = hdr->MsgContext;
drivers/message/fusion/mptsas.c:	req->Operation = hard_reset ?
drivers/message/fusion/mptsas.c:	req->PhyNum = phy->identify.phy_identifier;
drivers/message/fusion/mptsas.c:	smpreq->RequestDataLength =
drivers/message/fusion/mptsas.c:	smpreq->Function = MPI_FUNCTION_SMP_PASSTHROUGH;
drivers/message/fusion/mptsas.c:	*((u64 *)&smpreq->SASAddress) = cpu_to_le64(sas_address);
drivers/message/fusion/mptsas.c:	smpreq->Function = MPI_FUNCTION_SMP_PASSTHROUGH;
drivers/message/fusion/mptsas.c:	smpreq->PhysicalPort = 0xFF;
drivers/message/fusion/mptsas.c:	*((u64 *)&smpreq->SASAddress) = cpu_to_le64(sas_address);
drivers/message/fusion/mptsas.c:	smpreq->RequestDataLength = sizeof(struct rep_manu_request);
drivers/message/fusion/mptctl.c:	    "(0x%02X), req=%p, reply=%p\n", ioc->name,  req->u.hdr.Function,
drivers/message/fusion/mptctl.c:	if (ioc->ioctl_cmds.msg_context != req->u.hdr.MsgContext)
drivers/message/fusion/mptctl.c:	if ((req->u.hdr.Function == MPI_FUNCTION_SCSI_IO_REQUEST) ||
drivers/message/fusion/mptctl.c:		(req->u.hdr.Function ==
drivers/message/fusion/mptctl.c:			sz = req->u.scsireq.SenseBufferLength;
drivers/message/fusion/mptctl.c:			    le16_to_cpu(req->u.frame.hwhdr.msgctxu.fld.req_idx);
drivers/message/fusion/mptctl.c:		if (req->u.hdr.Function == MPI_FUNCTION_SCSI_TASK_MGMT) {
drivers/message/fusion/mptctl.c:				scsi_req->Bus, scsi_req->TargetID);
drivers/message/fusion/mptctl.c:				scsi_req->Bus, 0);
drivers/message/fusion/mptctl.c:				scsi_req->Bus, 0);
drivers/thunderbolt/xdomain.c:		const struct tb_xdp_header *req_hdr = req->request;
drivers/thunderbolt/xdomain.c:		if (pkg->frame.size < req->response_size / 4)
drivers/thunderbolt/xdomain.c:	memcpy(req->response, pkg->buffer, req->response_size);
drivers/thunderbolt/xdomain.c:	req->result.err = 0;
drivers/thunderbolt/xdomain.c:	req->match = tb_xdomain_match;
drivers/thunderbolt/xdomain.c:	req->copy = tb_xdomain_copy;
drivers/thunderbolt/xdomain.c:	req->request = response;
drivers/thunderbolt/xdomain.c:	req->request_size = size;
drivers/thunderbolt/xdomain.c:	req->request_type = type;
drivers/thunderbolt/xdomain.c:	req->match = tb_xdomain_match;
drivers/thunderbolt/xdomain.c:	req->copy = tb_xdomain_copy;
drivers/thunderbolt/xdomain.c:	req->request = request;
drivers/thunderbolt/xdomain.c:	req->request_size = request_size;
drivers/thunderbolt/xdomain.c:	req->request_type = request_type;
drivers/thunderbolt/xdomain.c:	req->response = response;
drivers/thunderbolt/xdomain.c:	req->response_size = response_size;
drivers/thunderbolt/xdomain.c:	req->response_type = response_type;
drivers/thunderbolt/xdomain.c:	if (!uuid_equal(src_uuid, &req->dst_uuid)) {
drivers/thunderbolt/xdomain.c:	if (req->offset >= xdomain_property_block_len) {
drivers/thunderbolt/xdomain.c:	len = xdomain_property_block_len - req->offset;
drivers/thunderbolt/xdomain.c:	res->offset = req->offset;
drivers/thunderbolt/xdomain.c:	uuid_copy(&res->dst_uuid, &req->src_uuid);
drivers/thunderbolt/xdomain.c:	memcpy(res->data, &xdomain_property_block[req->offset], len * 4);
drivers/thunderbolt/ctl.c:	kref_init(&req->kref);
drivers/thunderbolt/ctl.c:	kref_get(&req->kref);
drivers/thunderbolt/ctl.c:	kref_put(&req->kref, tb_cfg_request_destroy);
drivers/thunderbolt/ctl.c:	WARN_ON(test_bit(TB_CFG_REQUEST_ACTIVE, &req->flags));
drivers/thunderbolt/ctl.c:	WARN_ON(req->ctl);
drivers/thunderbolt/ctl.c:	req->ctl = ctl;
drivers/thunderbolt/ctl.c:	list_add_tail(&req->list, &ctl->request_queue);
drivers/thunderbolt/ctl.c:	set_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);
drivers/thunderbolt/ctl.c:	struct tb_ctl *ctl = req->ctl;
drivers/thunderbolt/ctl.c:	list_del(&req->list);
drivers/thunderbolt/ctl.c:	clear_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);
drivers/thunderbolt/ctl.c:	if (test_bit(TB_CFG_REQUEST_CANCELED, &req->flags))
drivers/thunderbolt/ctl.c:	return test_bit(TB_CFG_REQUEST_ACTIVE, &req->flags);
drivers/thunderbolt/ctl.c:		if (req->match(req, pkg)) {
drivers/thunderbolt/ctl.c:		if (req->copy(req, pkg))
drivers/thunderbolt/ctl.c:			schedule_work(&req->work);
drivers/thunderbolt/ctl.c:	if (!test_bit(TB_CFG_REQUEST_CANCELED, &req->flags))
drivers/thunderbolt/ctl.c:		req->callback(req->callback_data);
drivers/thunderbolt/ctl.c:	req->flags = 0;
drivers/thunderbolt/ctl.c:	req->callback = callback;
drivers/thunderbolt/ctl.c:	req->callback_data = callback_data;
drivers/thunderbolt/ctl.c:	INIT_WORK(&req->work, tb_cfg_request_work);
drivers/thunderbolt/ctl.c:	INIT_LIST_HEAD(&req->list);
drivers/thunderbolt/ctl.c:	ret = tb_ctl_tx(ctl, req->request, req->request_size,
drivers/thunderbolt/ctl.c:			req->request_type);
drivers/thunderbolt/ctl.c:	if (!req->response)
drivers/thunderbolt/ctl.c:		schedule_work(&req->work);
drivers/thunderbolt/ctl.c:	set_bit(TB_CFG_REQUEST_CANCELED, &req->flags);
drivers/thunderbolt/ctl.c:	schedule_work(&req->work);
drivers/thunderbolt/ctl.c:	req->result.err = err;
drivers/thunderbolt/ctl.c:	flush_work(&req->work);
drivers/thunderbolt/ctl.c:	return req->result;
drivers/thunderbolt/ctl.c:	if (pkg->frame.eof != req->response_type)
drivers/thunderbolt/ctl.c:	if (route != tb_cfg_get_route(req->request))
drivers/thunderbolt/ctl.c:	if (pkg->frame.size != req->response_size)
drivers/thunderbolt/ctl.c:		const struct cfg_read_pkg *req_hdr = req->request;
drivers/thunderbolt/ctl.c:	res = parse_header(pkg, req->response_size, req->response_type,
drivers/thunderbolt/ctl.c:			   tb_cfg_get_route(req->request));
drivers/thunderbolt/ctl.c:		memcpy(req->response, pkg->buffer, req->response_size);
drivers/thunderbolt/ctl.c:	req->result = res;
drivers/thunderbolt/ctl.c:	req->match = tb_cfg_match;
drivers/thunderbolt/ctl.c:	req->copy = tb_cfg_copy;
drivers/thunderbolt/ctl.c:	req->request = &request;
drivers/thunderbolt/ctl.c:	req->request_size = sizeof(request);
drivers/thunderbolt/ctl.c:	req->request_type = TB_CFG_PKG_RESET;
drivers/thunderbolt/ctl.c:	req->response = &reply;
drivers/thunderbolt/ctl.c:	req->response_size = sizeof(reply);
drivers/thunderbolt/ctl.c:	req->response_type = TB_CFG_PKG_RESET;
drivers/thunderbolt/ctl.c:		req->match = tb_cfg_match;
drivers/thunderbolt/ctl.c:		req->copy = tb_cfg_copy;
drivers/thunderbolt/ctl.c:		req->request = &request;
drivers/thunderbolt/ctl.c:		req->request_size = sizeof(request);
drivers/thunderbolt/ctl.c:		req->request_type = TB_CFG_PKG_READ;
drivers/thunderbolt/ctl.c:		req->response = &reply;
drivers/thunderbolt/ctl.c:		req->response_size = 12 + 4 * length;
drivers/thunderbolt/ctl.c:		req->response_type = TB_CFG_PKG_READ;
drivers/thunderbolt/ctl.c:		req->match = tb_cfg_match;
drivers/thunderbolt/ctl.c:		req->copy = tb_cfg_copy;
drivers/thunderbolt/ctl.c:		req->request = &request;
drivers/thunderbolt/ctl.c:		req->request_size = 12 + 4 * length;
drivers/thunderbolt/ctl.c:		req->request_type = TB_CFG_PKG_WRITE;
drivers/thunderbolt/ctl.c:		req->response = &reply;
drivers/thunderbolt/ctl.c:		req->response_size = sizeof(reply);
drivers/thunderbolt/ctl.c:		req->response_type = TB_CFG_PKG_WRITE;
drivers/thunderbolt/icm.c:	const struct icm_pkg_header *req_hdr = req->request;
drivers/thunderbolt/icm.c:	if (pkg->frame.eof != req->response_type)
drivers/thunderbolt/icm.c:	if (hdr->packet_id < req->npackets) {
drivers/thunderbolt/icm.c:		size_t offset = hdr->packet_id * req->response_size;
drivers/thunderbolt/icm.c:		memcpy(req->response + offset, pkg->buffer, req->response_size);
drivers/thunderbolt/icm.c:		req->match = icm_match;
drivers/thunderbolt/icm.c:		req->copy = icm_copy;
drivers/thunderbolt/icm.c:		req->request = request;
drivers/thunderbolt/icm.c:		req->request_size = request_size;
drivers/thunderbolt/icm.c:		req->request_type = TB_CFG_PKG_ICM_CMD;
drivers/thunderbolt/icm.c:		req->response = response;
drivers/thunderbolt/icm.c:		req->npackets = npackets;
drivers/thunderbolt/icm.c:		req->response_size = response_size;
drivers/thunderbolt/icm.c:		req->response_type = TB_CFG_PKG_ICM_RESP;
drivers/thunderbolt/icm.c:	req->match = icm_match;
drivers/thunderbolt/icm.c:	req->copy = icm_copy;
drivers/thunderbolt/icm.c:	req->request = &auth->request;
drivers/thunderbolt/icm.c:	req->request_size = sizeof(auth->request);
drivers/thunderbolt/icm.c:	req->request_type = TB_CFG_PKG_ICM_CMD;
drivers/thunderbolt/icm.c:	req->response = &auth->reply;
drivers/thunderbolt/icm.c:	req->npackets = 1;
drivers/thunderbolt/icm.c:	req->response_size = sizeof(auth->reply);
drivers/thunderbolt/icm.c:	req->response_type = TB_CFG_PKG_ICM_RESP;
drivers/thunderbolt/dma_port.c:	if (pkg->frame.eof != req->response_type)
drivers/thunderbolt/dma_port.c:	if (route != tb_cfg_get_route(req->request))
drivers/thunderbolt/dma_port.c:	if (pkg->frame.size != req->response_size)
drivers/thunderbolt/dma_port.c:	memcpy(req->response, pkg->buffer, req->response_size);
drivers/thunderbolt/dma_port.c:	req->match = dma_port_match;
drivers/thunderbolt/dma_port.c:	req->copy = dma_port_copy;
drivers/thunderbolt/dma_port.c:	req->request = &request;
drivers/thunderbolt/dma_port.c:	req->request_size = sizeof(request);
drivers/thunderbolt/dma_port.c:	req->request_type = TB_CFG_PKG_READ;
drivers/thunderbolt/dma_port.c:	req->response = &reply;
drivers/thunderbolt/dma_port.c:	req->response_size = 12 + 4 * length;
drivers/thunderbolt/dma_port.c:	req->response_type = TB_CFG_PKG_READ;
drivers/thunderbolt/dma_port.c:	req->match = dma_port_match;
drivers/thunderbolt/dma_port.c:	req->copy = dma_port_copy;
drivers/thunderbolt/dma_port.c:	req->request = &request;
drivers/thunderbolt/dma_port.c:	req->request_size = 12 + 4 * length;
drivers/thunderbolt/dma_port.c:	req->request_type = TB_CFG_PKG_WRITE;
drivers/thunderbolt/dma_port.c:	req->response = &reply;
drivers/thunderbolt/dma_port.c:	req->response_size = sizeof(reply);
drivers/thunderbolt/dma_port.c:	req->response_type = TB_CFG_PKG_WRITE;
drivers/macintosh/adb.c:        printk("adb reply (%d)", req->reply_len);
drivers/macintosh/adb.c:        for(i = 0; i < req->reply_len; i++)
drivers/macintosh/adb.c:                printk(" %x", req->reply[i]);
drivers/macintosh/adb.c:	struct completion *comp = req->arg;
drivers/macintosh/adb.c:	req->nbytes = nbytes+1;
drivers/macintosh/adb.c:	req->done = done;
drivers/macintosh/adb.c:	req->reply_expected = flags & ADBREQ_REPLY;
drivers/macintosh/adb.c:	req->data[0] = ADB_PACKET;
drivers/macintosh/adb.c:		req->data[i+1] = va_arg(list, int);
drivers/macintosh/adb.c:		req->done = adb_sync_req_done;
drivers/macintosh/adb.c:		req->arg = &comp;
drivers/macintosh/adb.c:	if ((flags & ADBREQ_SYNC) && !rc && !req->complete)
drivers/macintosh/adb.c:	struct adbdev_state *state = (struct adbdev_state *) req->arg;
drivers/macintosh/adb.c:	if (!req->complete) {
drivers/macintosh/adb.c:		req->reply_len = 0;
drivers/macintosh/adb.c:		req->complete = 1;
drivers/macintosh/adb.c:		req->next = NULL;
drivers/macintosh/adb.c:	switch(req->data[1]) {
drivers/macintosh/adb.c:		if (req->nbytes < 3)
drivers/macintosh/adb.c:		req->reply[0] = adb_handler[req->data[2]].original_address;
drivers/macintosh/adb.c:		req->reply[1] = adb_handler[req->data[2]].handler_id;
drivers/macintosh/adb.c:		req->complete = 1;
drivers/macintosh/adb.c:		req->reply_len = 2;
drivers/macintosh/adb.c:	if (count > sizeof(req->reply))
drivers/macintosh/adb.c:		count = sizeof(req->reply);
drivers/macintosh/adb.c:			state->completed = req->next;
drivers/macintosh/adb.c:	ret = req->reply_len;
drivers/macintosh/adb.c:	if (ret > 0 && copy_to_user(buf, req->reply, ret))
drivers/macintosh/adb.c:	if (count < 2 || count > sizeof(req->data))
drivers/macintosh/adb.c:	req->nbytes = count;
drivers/macintosh/adb.c:	req->done = adb_write_done;
drivers/macintosh/adb.c:	req->arg = (void *) state;
drivers/macintosh/adb.c:	req->complete = 0;
drivers/macintosh/adb.c:	if (copy_from_user(req->data, buf, count))
drivers/macintosh/adb.c:	if (req->data[0] == ADB_QUERY) {
drivers/macintosh/adb.c:	else if ((req->data[0] == ADB_PACKET) && (count > 1)
drivers/macintosh/adb.c:		&& (req->data[1] == ADB_BUSRESET)) {
drivers/macintosh/adb.c:		req->reply_expected = ((req->data[1] & 0xc) == 0xc);
drivers/macintosh/via-cuda.c:	req->complete = 1;
drivers/macintosh/via-cuda.c:    req->reply_expected = 1;
drivers/macintosh/via-cuda.c:	while (!req->complete)
drivers/macintosh/via-cuda.c:	req->complete = 1;
drivers/macintosh/via-cuda.c:    req->nbytes = nbytes;
drivers/macintosh/via-cuda.c:    req->done = done;
drivers/macintosh/via-cuda.c:	req->data[i] = va_arg(list, int);
drivers/macintosh/via-cuda.c:    req->reply_expected = 1;
drivers/macintosh/via-cuda.c:    if (req->nbytes < 2 || req->data[0] > CUDA_PACKET) {
drivers/macintosh/via-cuda.c:	req->complete = 1;
drivers/macintosh/via-cuda.c:    req->next = NULL;
drivers/macintosh/via-cuda.c:    req->sent = 0;
drivers/macintosh/via-cuda.c:    req->complete = 0;
drivers/macintosh/via-cuda.c:    req->reply_len = 0;
drivers/macintosh/via-cuda.c:	last_req->next = req;
drivers/macintosh/via-cuda.c:    out_8(&via[SR], current_req->data[data_index++]);
drivers/macintosh/via-cuda.c:	reply_ptr = current_req->reply;
drivers/macintosh/via-cuda.c:	    out_8(&via[SR], current_req->data[data_index++]);
drivers/macintosh/via-cuda.c:	if (data_index >= req->nbytes) {
drivers/macintosh/via-cuda.c:	    req->sent = 1;
drivers/macintosh/via-cuda.c:	    if (req->reply_expected) {
drivers/macintosh/via-cuda.c:		current_req = req->next;
drivers/macintosh/via-cuda.c:	    out_8(&via[SR], req->data[data_index++]);
drivers/macintosh/via-cuda.c:	full = reading_reply ? ARRAY_FULL(current_req->reply, reply_ptr)
drivers/macintosh/via-cuda.c:	    req->reply_len = reply_ptr - req->reply;
drivers/macintosh/via-cuda.c:	    if (req->data[0] == ADB_PACKET) {
drivers/macintosh/via-cuda.c:		if (req->reply_len <= 2 || (req->reply[1] & 2) != 0) {
drivers/macintosh/via-cuda.c:		    req->reply_len = 0;
drivers/macintosh/via-cuda.c:		    req->reply_len -= 2;
drivers/macintosh/via-cuda.c:		    memmove(req->reply, req->reply + 2, req->reply_len);
drivers/macintosh/via-cuda.c:	    current_req = req->next;
drivers/macintosh/via-cuda.c:    	void (*done)(struct adb_request *) = req->done;
drivers/macintosh/via-cuda.c:    	req->complete = 1;
drivers/macintosh/via-cuda.c:    	 * struct request will survive to setting req->complete to 1
drivers/macintosh/ams/ams-pmu.c:	complete((struct completion *)req->arg);
drivers/macintosh/macio-adb.c:	if (req->data[0] != ADB_PACKET)
drivers/macintosh/macio-adb.c:	for (i = 0; i < req->nbytes - 1; ++i)
drivers/macintosh/macio-adb.c:		req->data[i] = req->data[i+1];
drivers/macintosh/macio-adb.c:	--req->nbytes;
drivers/macintosh/macio-adb.c:	req->next = NULL;
drivers/macintosh/macio-adb.c:	req->sent = 0;
drivers/macintosh/macio-adb.c:	req->complete = 0;
drivers/macintosh/macio-adb.c:	req->reply_len = 0;
drivers/macintosh/macio-adb.c:		last_req->next = req;
drivers/macintosh/macio-adb.c:		while (!req->complete)
drivers/macintosh/macio-adb.c:			for (i = 0; i < req->nbytes; ++i)
drivers/macintosh/macio-adb.c:				out_8(&adb->data[i].r, req->data[i]);
drivers/macintosh/macio-adb.c:			out_8(&adb->dcount.r, req->nbytes & HMB);
drivers/macintosh/macio-adb.c:			req->sent = 1;
drivers/macintosh/macio-adb.c:			if (req->reply_expected) {
drivers/macintosh/macio-adb.c:				current_req = req->next;
drivers/macintosh/macio-adb.c:		if (current_req && current_req->sent) {
drivers/macintosh/macio-adb.c:				req->reply_len = in_8(&adb->dcount.r) & HMB;
drivers/macintosh/macio-adb.c:				for (i = 0; i < req->reply_len; ++i)
drivers/macintosh/macio-adb.c:					req->reply[i] = in_8(&adb->data[i].r);
drivers/macintosh/macio-adb.c:			current_req = req->next;
drivers/macintosh/macio-adb.c:	    void (*done)(struct adb_request *) = req->done;
drivers/macintosh/macio-adb.c:	    req->complete = 1;
drivers/macintosh/macio-adb.c:    	     * struct request will survive to setting req->complete to 1
drivers/macintosh/windfarm_cpufreq_clamp.c:	clamp->name = "cpufreq-clamp";
drivers/macintosh/windfarm_pm121.c: *   control        : cpufreq-clamp
drivers/macintosh/windfarm_pm121.c:	all = pm121_register_control(ct, "cpufreq-clamp", CPUFREQ) && all;
drivers/macintosh/windfarm_pm112.c:	if (cpufreq_clamp == NULL && !strcmp(ct->name, "cpufreq-clamp")) {
drivers/macintosh/windfarm_pm81.c:	if (cpufreq_clamp == NULL && !strcmp(ct->name, "cpufreq-clamp")) {
drivers/macintosh/windfarm_rm31.c:	else if (!strcmp(ct->name, "cpufreq-clamp"))
drivers/macintosh/via-pmu.c:	if (req->reply[0] & 0x01)
drivers/macintosh/via-pmu.c:	if (req->reply[0] & 0x04) {
drivers/macintosh/via-pmu.c:		if (req->reply[0] & 0x02)
drivers/macintosh/via-pmu.c:		vb = (req->reply[1] << 8) | req->reply[2];
drivers/macintosh/via-pmu.c:		amperage = req->reply[5];
drivers/macintosh/via-pmu.c:		if ((req->reply[0] & 0x01) == 0) {
drivers/macintosh/via-pmu.c:		} else if (req->reply[0] & 0x02) {
drivers/macintosh/via-pmu.c:		if (req->reply[0] & 0x40) {
drivers/macintosh/via-pmu.c:			pcharge = (req->reply[6] << 8) + req->reply[7];
drivers/macintosh/via-pmu.c:	if (req->reply[1] & 0x01)
drivers/macintosh/via-pmu.c:	if (req->reply[1] & 0x04) {
drivers/macintosh/via-pmu.c:		switch(req->reply[0]) {
drivers/macintosh/via-pmu.c:			case 4: capa = req->reply[2];
drivers/macintosh/via-pmu.c:				max = req->reply[3];
drivers/macintosh/via-pmu.c:				amperage = *((signed char *)&req->reply[4]);
drivers/macintosh/via-pmu.c:				voltage = req->reply[5];
drivers/macintosh/via-pmu.c:			case 5: capa = (req->reply[2] << 8) | req->reply[3];
drivers/macintosh/via-pmu.c:				max = (req->reply[4] << 8) | req->reply[5];
drivers/macintosh/via-pmu.c:				amperage = *((signed short *)&req->reply[6]);
drivers/macintosh/via-pmu.c:				voltage = (req->reply[8] << 8) | req->reply[9];
drivers/macintosh/via-pmu.c:					"len: %d, %4ph\n", req->reply_len,
drivers/macintosh/via-pmu.c:							   req->reply);
drivers/macintosh/via-pmu.c:	if ((req->reply[1] & 0x01) && (amperage > 0))
drivers/macintosh/via-pmu.c:		if ((req->reply[1] & 0x01) && (amperage > 0))
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:	switch (req->data[0]) {
drivers/macintosh/via-pmu.c:		for (i = 0; i < req->nbytes - 1; ++i)
drivers/macintosh/via-pmu.c:			req->data[i] = req->data[i+1];
drivers/macintosh/via-pmu.c:		--req->nbytes;
drivers/macintosh/via-pmu.c:		if (pmu_data_len[req->data[0]][1] != 0) {
drivers/macintosh/via-pmu.c:			req->reply[0] = ADB_RET_OK;
drivers/macintosh/via-pmu.c:			req->reply_len = 1;
drivers/macintosh/via-pmu.c:			req->reply_len = 0;
drivers/macintosh/via-pmu.c:		switch (req->data[1]) {
drivers/macintosh/via-pmu.c:			if (req->nbytes != 2)
drivers/macintosh/via-pmu.c:			req->data[0] = PMU_READ_RTC;
drivers/macintosh/via-pmu.c:			req->nbytes = 1;
drivers/macintosh/via-pmu.c:			req->reply_len = 3;
drivers/macintosh/via-pmu.c:			req->reply[0] = CUDA_PACKET;
drivers/macintosh/via-pmu.c:			req->reply[1] = 0;
drivers/macintosh/via-pmu.c:			req->reply[2] = CUDA_GET_TIME;
drivers/macintosh/via-pmu.c:			if (req->nbytes != 6)
drivers/macintosh/via-pmu.c:			req->data[0] = PMU_SET_RTC;
drivers/macintosh/via-pmu.c:			req->nbytes = 5;
drivers/macintosh/via-pmu.c:				req->data[i] = req->data[i+1];
drivers/macintosh/via-pmu.c:			req->reply_len = 3;
drivers/macintosh/via-pmu.c:			req->reply[0] = CUDA_PACKET;
drivers/macintosh/via-pmu.c:			req->reply[1] = 0;
drivers/macintosh/via-pmu.c:			req->reply[2] = CUDA_SET_TIME;
drivers/macintosh/via-pmu.c:		for (i = req->nbytes - 1; i > 1; --i)
drivers/macintosh/via-pmu.c:			req->data[i+2] = req->data[i];
drivers/macintosh/via-pmu.c:		req->data[3] = req->nbytes - 2;
drivers/macintosh/via-pmu.c:		req->data[2] = pmu_adb_flags;
drivers/macintosh/via-pmu.c:		/*req->data[1] = req->data[1];*/
drivers/macintosh/via-pmu.c:		req->data[0] = PMU_ADB_CMD;
drivers/macintosh/via-pmu.c:		req->nbytes += 2;
drivers/macintosh/via-pmu.c:		req->reply_expected = 1;
drivers/macintosh/via-pmu.c:		req->reply_len = 0;
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:		while (!req->complete)
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:	req->nbytes = nbytes;
drivers/macintosh/via-pmu.c:	req->done = done;
drivers/macintosh/via-pmu.c:		req->data[i] = va_arg(list, int);
drivers/macintosh/via-pmu.c:	req->reply_len = 0;
drivers/macintosh/via-pmu.c:	req->reply_expected = 0;
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:	if (req->nbytes <= 0) {
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:	nsend = pmu_data_len[req->data[0]][0];
drivers/macintosh/via-pmu.c:	if (nsend >= 0 && req->nbytes != nsend + 1) {
drivers/macintosh/via-pmu.c:		req->complete = 1;
drivers/macintosh/via-pmu.c:	req->next = NULL;
drivers/macintosh/via-pmu.c:	req->sent = 0;
drivers/macintosh/via-pmu.c:	req->complete = 0;
drivers/macintosh/via-pmu.c:		last_req->next = req;
drivers/macintosh/via-pmu.c:	void (*done)(struct adb_request *) = req->done;
drivers/macintosh/via-pmu.c:	req->complete = 1;
drivers/macintosh/via-pmu.c:    	 * struct request will survive to setting req->complete to 1
drivers/macintosh/via-pmu.c:	    || (/*req->reply_expected && */req_awaiting_reply))
drivers/macintosh/via-pmu.c:	data_len = pmu_data_len[req->data[0]][0];
drivers/macintosh/via-pmu.c:	send_byte(req->data[0]);
drivers/macintosh/via-pmu.c:	while((pmu_state != idle && pmu_state != locked) || !req->complete)
drivers/macintosh/via-pmu.c:				req->reply_len = 0;
drivers/macintosh/via-pmu.c:				memcpy(req->reply, data + 1, len - 1);
drivers/macintosh/via-pmu.c:				req->reply_len = len - 1;
drivers/macintosh/via-pmu.c:			data_len = req->nbytes - 1;
drivers/macintosh/via-pmu.c:			send_byte(req->data[data_index++]);
drivers/macintosh/via-pmu.c:		req->sent = 1;
drivers/macintosh/via-pmu.c:		data_len = pmu_data_len[req->data[0]][1];
drivers/macintosh/via-pmu.c:			current_req = req->next;
drivers/macintosh/via-pmu.c:			if (req->reply_expected)
drivers/macintosh/via-pmu.c:			reply_ptr = req->reply + req->reply_len;
drivers/macintosh/via-pmu.c:			current_req = req->next;
drivers/macintosh/via-pmu.c:			req->reply_len += data_index;
drivers/macintosh/via-pmu.c:			if (req->data[0] == PMU_SLEEP || req->data[0] == PMU_CPU_SPEED)
drivers/macintosh/via-pmu.c:	req->complete = 1;
drivers/macintosh/via-pmu.c:	c = req->data[0];
drivers/macintosh/via-pmu.c:	if (l >= 0 && req->nbytes != l + 1)
drivers/macintosh/via-pmu.c:		l = req->nbytes - 1;
drivers/macintosh/via-pmu.c:		polled_send_byte(req->data[i]);
drivers/macintosh/via-pmu.c:		req->reply[i + req->reply_len] = polled_recv_byte();
drivers/macintosh/via-pmu.c:	if (req->done)
drivers/macintosh/via-pmu.c:		(*req->done)(req);
drivers/macintosh/adb-iop.c:	req->complete = 1;
drivers/macintosh/adb-iop.c:	current_req = req->next;
drivers/macintosh/adb-iop.c:	if (req->done)
drivers/macintosh/adb-iop.c:		(*req->done)(req);
drivers/macintosh/adb-iop.c:			if (req->reply_expected) {
drivers/macintosh/adb-iop.c:				req->reply_len = amsg->count + 1;
drivers/macintosh/adb-iop.c:				memcpy(req->reply, &amsg->cmd, req->reply_len);
drivers/macintosh/adb-iop.c:	amsg.count = req->nbytes - 2;
drivers/macintosh/adb-iop.c:	memcpy(&amsg.cmd, req->data + 1, req->nbytes - 1);
drivers/macintosh/adb-iop.c:	req->sent = 1;
drivers/macintosh/adb-iop.c:		while (!req->complete)
drivers/macintosh/adb-iop.c:	if ((req->nbytes < 2) || (req->data[0] != ADB_PACKET)) {
drivers/macintosh/adb-iop.c:		req->complete = 1;
drivers/macintosh/adb-iop.c:	req->next = NULL;
drivers/macintosh/adb-iop.c:	req->sent = 0;
drivers/macintosh/adb-iop.c:	req->complete = 0;
drivers/macintosh/adb-iop.c:	req->reply_len = 0;
drivers/macintosh/adb-iop.c:		last_req->next = req;
drivers/macintosh/windfarm_pm91.c:	if (cpufreq_clamp == NULL && !strcmp(ct->name, "cpufreq-clamp")) {
drivers/macintosh/windfarm_pm72.c:	else if (!strcmp(ct->name, "cpufreq-clamp"))
drivers/macintosh/via-macii.c:static unsigned char *reply_ptr;     /* next byte in reply_buf or req->reply */
drivers/macintosh/via-macii.c:static bool reading_reply;       /* store reply in reply_buf else req->reply */
drivers/macintosh/via-macii.c:static int data_index;      /* index of the next byte to send from req->data */
drivers/macintosh/via-macii.c:static int reply_len; /* number of bytes received in reply_buf or req->reply */
drivers/macintosh/via-macii.c:		while (!req->complete)
drivers/macintosh/via-macii.c:	if (req->nbytes < 2 || req->data[0] != ADB_PACKET || req->nbytes > 15) {
drivers/macintosh/via-macii.c:		req->complete = 1;
drivers/macintosh/via-macii.c:	req->next = NULL;
drivers/macintosh/via-macii.c:	req->sent = 0;
drivers/macintosh/via-macii.c:	req->complete = 0;
drivers/macintosh/via-macii.c:	req->reply_len = 0;
drivers/macintosh/via-macii.c:		last_req->next = req;
drivers/macintosh/via-macii.c:	 * And req->nbytes is the number of bytes of real data plus one.
drivers/macintosh/via-macii.c:	via[SR] = req->data[1];
drivers/macintosh/via-macii.c:			last_cmd = req->data[1];
drivers/macintosh/via-macii.c:		} else if (data_index >= req->nbytes) {
drivers/macintosh/via-macii.c:			req->sent = 1;
drivers/macintosh/via-macii.c:			if (req->reply_expected) {
drivers/macintosh/via-macii.c:				reply_ptr = req->reply;
drivers/macintosh/via-macii.c:				*reply_ptr = req->data[1];
drivers/macintosh/via-macii.c:			} else if ((req->data[1] & OP_MASK) == TALK) {
drivers/macintosh/via-macii.c:				*reply_ptr = req->data[1];
drivers/macintosh/via-macii.c:				req->complete = 1;
drivers/macintosh/via-macii.c:				current_req = req->next;
drivers/macintosh/via-macii.c:				if (req->done)
drivers/macintosh/via-macii.c:					(*req->done)(req);
drivers/macintosh/via-macii.c:				req->complete = 1;
drivers/macintosh/via-macii.c:				current_req = req->next;
drivers/macintosh/via-macii.c:				if (req->done)
drivers/macintosh/via-macii.c:					(*req->done)(req);
drivers/macintosh/via-macii.c:			via[SR] = req->data[data_index++];
drivers/macintosh/via-macii.c:					req->reply_len = reply_len;
drivers/macintosh/via-macii.c:					req->complete = 1;
drivers/macintosh/via-macii.c:					current_req = req->next;
drivers/macintosh/via-macii.c:					if (req->done)
drivers/macintosh/via-macii.c:						(*req->done)(req);
drivers/md/dm-crypt.c:	*(__le32 *)iv = cpu_to_le32(dmreq->iv_sector & 0xffffffff);
drivers/md/dm-crypt.c:	*(__le64 *)iv = cpu_to_le64(dmreq->iv_sector);
drivers/md/dm-crypt.c:	*(__be64 *)&iv[cc->iv_size - sizeof(u64)] = cpu_to_be64(dmreq->iv_sector);
drivers/md/dm-crypt.c:	*(__le64 *)iv = cpu_to_le64(dmreq->iv_sector);
drivers/md/dm-crypt.c:	val = cpu_to_be64(((u64)dmreq->iv_sector << cc->iv_gen_private.benbi.shift) + 1);
drivers/md/dm-crypt.c:	buf[0] = cpu_to_le32(dmreq->iv_sector & 0xFFFFFFFF);
drivers/md/dm-crypt.c:	buf[1] = cpu_to_le32((((u64)dmreq->iv_sector >> 32) & 0x00FFFFFF) | 0x80000000);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE) {
drivers/md/dm-crypt.c:		sg = crypt_get_sg_data(cc, dmreq->sg_in);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE)
drivers/md/dm-crypt.c:	sg = crypt_get_sg_data(cc, dmreq->sg_out);
drivers/md/dm-crypt.c:	__le64 sector = cpu_to_le64(dmreq->iv_sector);
drivers/md/dm-crypt.c:	__le64 sector = cpu_to_le64(dmreq->iv_sector);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE) {
drivers/md/dm-crypt.c:		sg = crypt_get_sg_data(cc, dmreq->sg_in);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE)
drivers/md/dm-crypt.c:	sg = crypt_get_sg_data(cc, dmreq->sg_out);
drivers/md/dm-crypt.c:	*(__le64 *)buf = cpu_to_le64(dmreq->iv_sector * cc->sector_size);
drivers/md/dm-crypt.c:	*(__le64 *)es = cpu_to_le64(dmreq->iv_sector * cc->sector_size);
drivers/md/dm-crypt.c:	sg = crypt_get_sg_data(cc, dmreq->sg_out);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE) {
drivers/md/dm-crypt.c:		sg2 = crypt_get_sg_data(cc, dmreq->sg_in);
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE) {
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE) {
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) == WRITE) {
drivers/md/dm-crypt.c:	if (bio_data_dir(dmreq->ctx->bio_in) != WRITE)
drivers/md/dm-crypt.c:	struct convert_context *ctx = dmreq->ctx;
drivers/md/dm-crypt.c:	dmreq->iv_sector = ctx->cc_sector;
drivers/md/dm-crypt.c:		dmreq->iv_sector >>= cc->sector_shift;
drivers/md/dm-crypt.c:	dmreq->ctx = ctx;
drivers/md/dm-crypt.c:	sg_init_table(dmreq->sg_in, 4);
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_in[0], sector, sizeof(uint64_t));
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_in[1], org_iv, cc->iv_size);
drivers/md/dm-crypt.c:	sg_set_page(&dmreq->sg_in[2], bv_in.bv_page, cc->sector_size, bv_in.bv_offset);
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_in[3], tag, cc->integrity_tag_size);
drivers/md/dm-crypt.c:	sg_init_table(dmreq->sg_out, 4);
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_out[0], sector, sizeof(uint64_t));
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_out[1], org_iv, cc->iv_size);
drivers/md/dm-crypt.c:	sg_set_page(&dmreq->sg_out[2], bv_out.bv_page, cc->sector_size, bv_out.bv_offset);
drivers/md/dm-crypt.c:	sg_set_buf(&dmreq->sg_out[3], tag, cc->integrity_tag_size);
drivers/md/dm-crypt.c:		aead_request_set_crypt(req, dmreq->sg_in, dmreq->sg_out,
drivers/md/dm-crypt.c:		aead_request_set_crypt(req, dmreq->sg_in, dmreq->sg_out,
drivers/md/dm-crypt.c:	dmreq->iv_sector = ctx->cc_sector;
drivers/md/dm-crypt.c:		dmreq->iv_sector >>= cc->sector_shift;
drivers/md/dm-crypt.c:	dmreq->ctx = ctx;
drivers/md/dm-crypt.c:	sg_in  = &dmreq->sg_in[0];
drivers/md/dm-crypt.c:	sg_out = &dmreq->sg_out[0];
drivers/md/dm-crypt.c:	struct dm_crypt_request *dmreq = async_req->data;
drivers/md/dm-crypt.c:	struct convert_context *ctx = dmreq->ctx;
drivers/md/dm-integrity.c:	struct journal_completion *comp = req->data;
drivers/md/dm-integrity.c:		iv = req->iv;
drivers/md/dm-integrity.c:		req->src = source_sg[section];
drivers/md/dm-integrity.c:		req->dst = target_sg[section];
drivers/md/dm-integrity.c:	req->tfm = ic->internal_hash;
drivers/md/dm-integrity.c:				section_req->iv = kmalloc_array(ivsize, 2,
drivers/md/dm-integrity.c:				if (!section_req->iv) {
drivers/md/dm-integrity.c:				memcpy(section_req->iv + ivsize, crypt_data, ivsize);
drivers/md/dm-integrity.c:				section_req->cryptlen = (size_t)ic->journal_section_sectors << SECTOR_SHIFT;
drivers/md/dm-integrity.c:				kfree_sensitive(req->iv);
drivers/md/dm-snap-persistent.c:	req->result = dm_io(req->io_req, 1, req->where, NULL);
drivers/md/dm-io.c:	switch (io_req->mem.type) {
drivers/md/dm-io.c:		list_dp_init(dp, io_req->mem.ptr.pl, io_req->mem.offset);
drivers/md/dm-io.c:		bio_dp_init(dp, io_req->mem.ptr.bio);
drivers/md/dm-io.c:		flush_kernel_vmap_range(io_req->mem.ptr.vma, size);
drivers/md/dm-io.c:		if (io_req->bi_op == REQ_OP_READ) {
drivers/md/dm-io.c:			dp->vma_invalidate_address = io_req->mem.ptr.vma;
drivers/md/dm-io.c:		vm_dp_init(dp, io_req->mem.ptr.vma);
drivers/md/dm-io.c:		km_dp_init(dp, io_req->mem.ptr.addr);
drivers/md/dm-io.c: * io_req->bi_opf. If you fail to do one of these, the IO will be submitted to
drivers/md/dm-io.c:	if (!io_req->notify.fn)
drivers/md/dm-io.c:		return sync_io(io_req->client, num_regions, where,
drivers/md/dm-io.c:			       io_req->bi_op, io_req->bi_op_flags, &dp,
drivers/md/dm-io.c:	return async_io(io_req->client, num_regions, where, io_req->bi_op,
drivers/md/dm-io.c:			io_req->bi_op_flags, &dp, io_req->notify.fn,
drivers/md/dm-io.c:			io_req->notify.context);
drivers/gpio/gpiolib-cdev.c:				  line->req->label, line);
drivers/gpio/gpiolib-cdev.c:	if (eflags && !kfifo_initialized(&line->req->events)) {
drivers/gpio/gpiolib-cdev.c:		ret = kfifo_alloc(&line->req->events,
drivers/gpio/gpiolib-cdev.c:				  line->req->event_buffer_size, GFP_KERNEL);
drivers/gpio/gpiolib-cdev.c:				   irqflags, line->req->label, line);
drivers/android/binderfs.c:	req->name[BINDERFS_MAX_NAME] = '\0'; /* NUL-terminate */
drivers/android/binderfs.c:	name_len = strlen(req->name);
drivers/android/binderfs.c:	name = kmemdup(req->name, name_len + 1, GFP_KERNEL);
drivers/android/binderfs.c:	req->major = MAJOR(binderfs_dev);
drivers/android/binderfs.c:	req->minor = minor;
drivers/video/fbdev/omap/hwa742.c:	list_del(&req->entry);
drivers/video/fbdev/omap/hwa742.c:	INIT_LIST_HEAD(&req->entry);
drivers/video/fbdev/omap/hwa742.c:	req->flags = req_flags;
drivers/video/fbdev/omap/hwa742.c:	list_move(&req->entry, &hwa742.free_req_list);
drivers/video/fbdev/omap/hwa742.c:	if (!(req->flags & REQ_FROM_IRQ_POOL))
drivers/video/fbdev/omap/hwa742.c:		if (req->handler(req) == REQ_PENDING)
drivers/video/fbdev/omap/hwa742.c:		complete = req->complete;
drivers/video/fbdev/omap/hwa742.c:		complete_data = req->complete_data;
drivers/video/fbdev/omap/hwa742.c:	complete = req->complete;
drivers/video/fbdev/omap/hwa742.c:	complete_data = req->complete_data;
drivers/video/fbdev/omap/hwa742.c:	struct update_param *par = &req->par.update;
drivers/video/fbdev/omap/hwa742.c:	flags = req->par.update.flags;
drivers/video/fbdev/omap/hwa742.c:	req->handler	= send_frame_handler;	\
drivers/video/fbdev/omap/hwa742.c:	req->complete	= send_frame_complete;	\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.x = _x;			\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.y = _y;			\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.width  = _w;		\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.height = _h;		\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.color_mode = color_mode;\
drivers/video/fbdev/omap/hwa742.c:	req->par.update.flags	  = flags;	\
drivers/video/fbdev/omap/hwa742.c:	list_add_tail(&req->entry, req_head);	\
drivers/video/fbdev/omap/hwa742.c:	complete(req->par.sync);
drivers/video/fbdev/omap/hwa742.c:	req->handler = sync_handler;
drivers/video/fbdev/omap/hwa742.c:	req->complete = NULL;
drivers/video/fbdev/omap/hwa742.c:	req->par.sync = &comp;
drivers/video/fbdev/omap/hwa742.c:	list_add(&req->entry, &req_list);
drivers/video/fbdev/sis/sis_main.c:		poh = sisfb_poh_allocate(&ivideo->sisfb_heap, (u32)req->size);
drivers/video/fbdev/sis/sis_main.c:		req->offset = req->size = 0;
drivers/video/fbdev/sis/sis_main.c:		req->offset = poh->offset;
drivers/video/fbdev/sis/sis_main.c:		req->size = poh->size;
drivers/video/fbdev/sis/sis_main.c:		req->offset = req->size = 0;
drivers/block/sunvdc.c:	struct vdc_port *port = req->rq_disk->private_data;
drivers/block/sunvdc.c:	nsg = blk_rq_map_sg(req->q, req, sg);
drivers/block/xen-blkfront.c:	ring_req->operation = BLKIF_OP_DISCARD;
drivers/block/xen-blkfront.c:	ring_req->u.discard.nr_sectors = blk_rq_sectors(req);
drivers/block/xen-blkfront.c:	ring_req->u.discard.id = id;
drivers/block/xen-blkfront.c:	ring_req->u.discard.sector_number = (blkif_sector_t)blk_rq_pos(req);
drivers/block/xen-blkfront.c:		ring_req->u.discard.flag = BLKIF_DISCARD_SECURE;
drivers/block/xen-blkfront.c:		ring_req->u.discard.flag = 0;
drivers/block/xen-blkfront.c:	if ((ring_req->operation == BLKIF_OP_INDIRECT) &&
drivers/block/xen-blkfront.c:		ring_req->u.indirect.indirect_grefs[n] = gnt_list_entry->gref;
drivers/block/xen-blkfront.c:	if (ring_req->operation != BLKIF_OP_INDIRECT) {
drivers/block/xen-blkfront.c:		ring_req->u.rw.seg[grant_idx] =
drivers/block/xen-blkfront.c:	max_grefs = req->nr_phys_segments * GRANTS_PER_PSEG;
drivers/block/xen-blkfront.c:	num_sg = blk_rq_map_sg(req->q, req, rinfo->shadow[id].sg);
drivers/block/xen-blkfront.c:		BUG_ON(req_op(req) == REQ_OP_FLUSH || req->cmd_flags & REQ_FUA);
drivers/block/xen-blkfront.c:		ring_req->operation = BLKIF_OP_INDIRECT;
drivers/block/xen-blkfront.c:		ring_req->u.indirect.indirect_op = rq_data_dir(req) ?
drivers/block/xen-blkfront.c:		ring_req->u.indirect.sector_number = (blkif_sector_t)blk_rq_pos(req);
drivers/block/xen-blkfront.c:		ring_req->u.indirect.handle = info->handle;
drivers/block/xen-blkfront.c:		ring_req->u.indirect.nr_segments = num_grant;
drivers/block/xen-blkfront.c:		ring_req->u.rw.sector_number = (blkif_sector_t)blk_rq_pos(req);
drivers/block/xen-blkfront.c:		ring_req->u.rw.handle = info->handle;
drivers/block/xen-blkfront.c:		ring_req->operation = rq_data_dir(req) ?
drivers/block/xen-blkfront.c:		if (req_op(req) == REQ_OP_FLUSH || req->cmd_flags & REQ_FUA) {
drivers/block/xen-blkfront.c:				ring_req->operation =
drivers/block/xen-blkfront.c:				ring_req->operation =
drivers/block/xen-blkfront.c:				ring_req->operation = 0;
drivers/block/xen-blkfront.c:		ring_req->u.rw.nr_segments = num_grant;
drivers/block/xen-blkfront.c:		((req->cmd_flags & REQ_FUA) &&
drivers/block/xen-blkfront.c:		if (likely(!blk_should_fake_timeout(req->q)))
drivers/block/xen-blkfront.c:		list_del_init(&req->queuelist);
drivers/block/xen-blkfront.c:		BUG_ON(req->nr_phys_segments > segs);
drivers/block/drbd/drbd_receiver.c:		list_move(&peer_req->w.list, to_be_freed);
drivers/block/drbd/drbd_receiver.c:	INIT_LIST_HEAD(&peer_req->w.list);
drivers/block/drbd/drbd_receiver.c:	drbd_clear_interval(&peer_req->i);
drivers/block/drbd/drbd_receiver.c:	peer_req->i.size = request_size;
drivers/block/drbd/drbd_receiver.c:	peer_req->i.sector = sector;
drivers/block/drbd/drbd_receiver.c:	peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:	peer_req->peer_device = peer_device;
drivers/block/drbd/drbd_receiver.c:	peer_req->pages = page;
drivers/block/drbd/drbd_receiver.c:	peer_req->block_id = id;
drivers/block/drbd/drbd_receiver.c:	if (peer_req->flags & EE_HAS_DIGEST)
drivers/block/drbd/drbd_receiver.c:		kfree(peer_req->digest);
drivers/block/drbd/drbd_receiver.c:	drbd_free_pages(device, peer_req->pages, is_net);
drivers/block/drbd/drbd_receiver.c:	D_ASSERT(device, atomic_read(&peer_req->pending_bios) == 0);
drivers/block/drbd/drbd_receiver.c:	D_ASSERT(device, drbd_interval_empty(&peer_req->i));
drivers/block/drbd/drbd_receiver.c:	if (!expect(!(peer_req->flags & EE_CALL_AL_COMPLETE_IO))) {
drivers/block/drbd/drbd_receiver.c:		peer_req->flags &= ~EE_CALL_AL_COMPLETE_IO;
drivers/block/drbd/drbd_receiver.c:		drbd_al_complete_io(device, &peer_req->i);
drivers/block/drbd/drbd_receiver.c:		err2 = peer_req->w.cb(&peer_req->w, !!err);
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_ZEROOUT;
drivers/block/drbd/drbd_receiver.c:	if (drbd_issue_discard_or_zero_out(device, peer_req->i.sector,
drivers/block/drbd/drbd_receiver.c:	    peer_req->i.size >> 9, peer_req->flags & (EE_ZEROOUT|EE_TRIM)))
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_WAS_ERROR;
drivers/block/drbd/drbd_receiver.c:	sector_t s = peer_req->i.sector;
drivers/block/drbd/drbd_receiver.c:	sector_t nr = peer_req->i.size >> 9;
drivers/block/drbd/drbd_receiver.c:	if (blkdev_issue_write_same(bdev, s, nr, GFP_NOIO, peer_req->pages))
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_WAS_ERROR;
drivers/block/drbd/drbd_receiver.c:	struct page *page = peer_req->pages;
drivers/block/drbd/drbd_receiver.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_receiver.c:	unsigned data_size = peer_req->i.size;
drivers/block/drbd/drbd_receiver.c:	if (peer_req->flags & (EE_TRIM|EE_WRITE_SAME|EE_ZEROOUT)) {
drivers/block/drbd/drbd_receiver.c:		conn_wait_active_ee_empty(peer_req->peer_device->connection);
drivers/block/drbd/drbd_receiver.c:		peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_SUBMITTED;
drivers/block/drbd/drbd_receiver.c:		if (list_empty(&peer_req->w.list)) {
drivers/block/drbd/drbd_receiver.c:			list_add_tail(&peer_req->w.list, &device->active_ee);
drivers/block/drbd/drbd_receiver.c:		if (peer_req->flags & (EE_TRIM|EE_ZEROOUT))
drivers/block/drbd/drbd_receiver.c:	/* > peer_req->i.sector, unless this is the first bio */
drivers/block/drbd/drbd_receiver.c:	atomic_set(&peer_req->pending_bios, n_bios);
drivers/block/drbd/drbd_receiver.c:	peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:	peer_req->flags |= EE_SUBMITTED;
drivers/block/drbd/drbd_receiver.c:	struct drbd_interval *i = &peer_req->i;
drivers/block/drbd/drbd_receiver.c:	peer_req->flags |= EE_WRITE;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_TRIM;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_ZEROOUT;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_WRITE_SAME;
drivers/block/drbd/drbd_receiver.c:	page = peer_req->pages;
drivers/block/drbd/drbd_receiver.c:	bio = req->master_bio;
drivers/block/drbd/drbd_receiver.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_receiver.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_receiver.c:	D_ASSERT(device, drbd_interval_empty(&peer_req->i));
drivers/block/drbd/drbd_receiver.c:	if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_receiver.c:		drbd_set_in_sync(device, sector, peer_req->i.size);
drivers/block/drbd/drbd_receiver.c:		drbd_rs_failed_io(device, sector, peer_req->i.size);
drivers/block/drbd/drbd_receiver.c:	peer_req->w.cb = e_end_resync_block;
drivers/block/drbd/drbd_receiver.c:	peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:	list_add_tail(&peer_req->w.list, &device->sync_ee);
drivers/block/drbd/drbd_receiver.c:	list_del(&peer_req->w.list);
drivers/block/drbd/drbd_receiver.c:	if (drbd_contains_interval(root, sector, &req->i) && req->i.local)
drivers/block/drbd/drbd_receiver.c:	/* hlist_del(&req->collision) is done in _req_may_be_done, to avoid
drivers/block/drbd/drbd_receiver.c:		if (req->rq_state & RQ_LOCAL_PENDING ||
drivers/block/drbd/drbd_receiver.c:		    !(req->rq_state & RQ_POSTPONED))
drivers/block/drbd/drbd_receiver.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_receiver.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_receiver.c:	if (peer_req->flags & EE_SEND_WRITE_ACK) {
drivers/block/drbd/drbd_receiver.c:		if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_receiver.c:				peer_req->flags & EE_MAY_SET_IN_SYNC) ?
drivers/block/drbd/drbd_receiver.c:				drbd_set_in_sync(device, sector, peer_req->i.size);
drivers/block/drbd/drbd_receiver.c:	if (peer_req->flags & EE_IN_INTERVAL_TREE) {
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(device, !drbd_interval_empty(&peer_req->i));
drivers/block/drbd/drbd_receiver.c:		if (peer_req->flags & EE_RESTART_REQUESTS)
drivers/block/drbd/drbd_receiver.c:			restart_conflicting_writes(device, sector, peer_req->i.size);
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(device, drbd_interval_empty(&peer_req->i));
drivers/block/drbd/drbd_receiver.c:	drbd_may_finish_epoch(peer_device->connection, peer_req->epoch, EV_PUT + (cancel ? EV_CLEANUP : 0));
drivers/block/drbd/drbd_receiver.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_receiver.c:	struct drbd_connection *connection = peer_req->peer_device->connection;
drivers/block/drbd/drbd_receiver.c:		if (overlaps(peer_req->i.sector, peer_req->i.size,
drivers/block/drbd/drbd_receiver.c:			     rs_req->i.sector, rs_req->i.size)) {
drivers/block/drbd/drbd_receiver.c:		if (!(req->rq_state & RQ_POSTPONED))
drivers/block/drbd/drbd_receiver.c:		req->rq_state &= ~RQ_POSTPONED;
drivers/block/drbd/drbd_receiver.c:	struct drbd_connection *connection = peer_req->peer_device->connection;
drivers/block/drbd/drbd_receiver.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_receiver.c:	const unsigned int size = peer_req->i.size;
drivers/block/drbd/drbd_receiver.c:	drbd_insert_interval(&device->write_requests, &peer_req->i);
drivers/block/drbd/drbd_receiver.c:		if (i == &peer_req->i)
drivers/block/drbd/drbd_receiver.c:			peer_req->w.cb = superseded ? e_send_superseded :
drivers/block/drbd/drbd_receiver.c:			list_add_tail(&peer_req->w.list, &device->done_ee);
drivers/block/drbd/drbd_receiver.c:			queue_work(connection->ack_sender, &peer_req->peer_device->send_acks_work);
drivers/block/drbd/drbd_receiver.c:			if (req->rq_state & RQ_LOCAL_PENDING ||
drivers/block/drbd/drbd_receiver.c:			    !(req->rq_state & RQ_POSTPONED)) {
drivers/block/drbd/drbd_receiver.c:				err = drbd_wait_misc(device, &req->i);
drivers/block/drbd/drbd_receiver.c:			peer_req->flags |= EE_RESTART_REQUESTS;
drivers/block/drbd/drbd_receiver.c:	peer_req->w.cb = e_end_block;
drivers/block/drbd/drbd_receiver.c:	peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:	peer_req->flags |= EE_APPLICATION;
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(peer_device, peer_req->i.size > 0);
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(peer_device, peer_req->pages == NULL);
drivers/block/drbd/drbd_receiver.c:			peer_req->flags |= EE_ZEROOUT;
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(peer_device, peer_req->i.size > 0);
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(peer_device, peer_req->pages == NULL);
drivers/block/drbd/drbd_receiver.c:			peer_req->flags |= EE_TRIM;
drivers/block/drbd/drbd_receiver.c:	} else if (peer_req->pages == NULL) {
drivers/block/drbd/drbd_receiver.c:		D_ASSERT(device, peer_req->i.size == 0);
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_MAY_SET_IN_SYNC;
drivers/block/drbd/drbd_receiver.c:	peer_req->epoch = connection->current_epoch;
drivers/block/drbd/drbd_receiver.c:	atomic_inc(&peer_req->epoch->epoch_size);
drivers/block/drbd/drbd_receiver.c:	atomic_inc(&peer_req->epoch->active);
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_SEND_WRITE_ACK;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_IN_INTERVAL_TREE;
drivers/block/drbd/drbd_receiver.c:	if ((peer_req->flags & (EE_TRIM|EE_WRITE_SAME|EE_ZEROOUT)) == 0)
drivers/block/drbd/drbd_receiver.c:		list_add_tail(&peer_req->w.list, &device->active_ee);
drivers/block/drbd/drbd_receiver.c:		drbd_set_out_of_sync(device, peer_req->i.sector, peer_req->i.size);
drivers/block/drbd/drbd_receiver.c:		peer_req->flags &= ~EE_MAY_SET_IN_SYNC;
drivers/block/drbd/drbd_receiver.c:		drbd_al_begin_io(device, &peer_req->i);
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_CALL_AL_COMPLETE_IO;
drivers/block/drbd/drbd_receiver.c:	list_del(&peer_req->w.list);
drivers/block/drbd/drbd_receiver.c:	if (peer_req->flags & EE_CALL_AL_COMPLETE_IO) {
drivers/block/drbd/drbd_receiver.c:		peer_req->flags &= ~EE_CALL_AL_COMPLETE_IO;
drivers/block/drbd/drbd_receiver.c:		drbd_al_complete_io(device, &peer_req->i);
drivers/block/drbd/drbd_receiver.c:	drbd_may_finish_epoch(connection, peer_req->epoch, EV_PUT | EV_CLEANUP);
drivers/block/drbd/drbd_receiver.c:		peer_req->w.cb = w_e_end_data_req;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_APPLICATION;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_RS_THIN_REQ;
drivers/block/drbd/drbd_receiver.c:		peer_req->w.cb = w_e_end_rsdata_req;
drivers/block/drbd/drbd_receiver.c:		peer_req->digest = di;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_HAS_DIGEST;
drivers/block/drbd/drbd_receiver.c:			peer_req->w.cb = w_e_end_csum_rs_req;
drivers/block/drbd/drbd_receiver.c:			peer_req->w.cb = w_e_end_ov_reply;
drivers/block/drbd/drbd_receiver.c:		peer_req->w.cb = w_e_end_ov_req;
drivers/block/drbd/drbd_receiver.c:	list_add_tail(&peer_req->w.list, &device->read_ee);
drivers/block/drbd/drbd_receiver.c:	list_del(&peer_req->w.list);
drivers/block/drbd/drbd_receiver.c:		peer_req->w.cb = e_end_resync_block;
drivers/block/drbd/drbd_receiver.c:		peer_req->submit_jif = jiffies;
drivers/block/drbd/drbd_receiver.c:		peer_req->flags |= EE_TRIM;
drivers/block/drbd/drbd_receiver.c:		list_add_tail(&peer_req->w.list, &device->sync_ee);
drivers/block/drbd/drbd_receiver.c:			list_del(&peer_req->w.list);
drivers/block/drbd/drbd_req.h:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.h:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_debugfs.c:/* pretty print enum drbd_req_state_bits req->rq_state */
drivers/block/drbd/drbd_debugfs.c:	unsigned int s = req->rq_state;
drivers/block/drbd/drbd_debugfs.c:	seq_printf(m, "\tmaster: %s", req->master_bio ? "pending" : "completed");
drivers/block/drbd/drbd_debugfs.c:	unsigned int s = req->rq_state;
drivers/block/drbd/drbd_debugfs.c:		req->epoch,
drivers/block/drbd/drbd_debugfs.c:		(unsigned long long)req->i.sector, req->i.size >> 9,
drivers/block/drbd/drbd_debugfs.c:	seq_printf(m, "\t%d", jiffies_to_msecs(now - req->start_jif));
drivers/block/drbd/drbd_debugfs.c:	seq_print_age_or_dash(m, s & RQ_IN_ACT_LOG, now - req->in_actlog_jif);
drivers/block/drbd/drbd_debugfs.c:	seq_print_age_or_dash(m, s & RQ_LOCAL_PENDING, now - req->pre_submit_jif);
drivers/block/drbd/drbd_debugfs.c:	seq_print_age_or_dash(m, s & RQ_NET_SENT, now - req->pre_send_jif);
drivers/block/drbd/drbd_debugfs.c:	seq_print_age_or_dash(m, (s & RQ_NET_SENT) && !(s & RQ_NET_PENDING), now - req->acked_jif);
drivers/block/drbd/drbd_debugfs.c:	seq_print_age_or_dash(m, s & RQ_NET_DONE, now - req->net_done_jif);
drivers/block/drbd/drbd_debugfs.c:	seq_printf(m, "%u\t%u\t", req->device->minor, req->device->vnr);
drivers/block/drbd/drbd_debugfs.c:			if (req && !(req->rq_state & RQ_IN_ACT_LOG))
drivers/block/drbd/drbd_debugfs.c:				jif = req->start_jif;
drivers/block/drbd/drbd_debugfs.c:/* pretty print enum peer_req->flags */
drivers/block/drbd/drbd_debugfs.c:	unsigned long f = peer_req->flags;
drivers/block/drbd/drbd_debugfs.c:		if (reported_preparing && !(peer_req->flags & EE_SUBMITTED))
drivers/block/drbd/drbd_debugfs.c:			(unsigned long long)peer_req->i.sector, peer_req->i.size >> 9,
drivers/block/drbd/drbd_debugfs.c:			(peer_req->flags & EE_WRITE) ? 'W' : 'R',
drivers/block/drbd/drbd_debugfs.c:			jiffies_to_msecs(now - peer_req->submit_jif));
drivers/block/drbd/drbd_debugfs.c:		if (peer_req->flags & EE_SUBMITTED)
drivers/block/drbd/drbd_debugfs.c:			kref_get(&req->kref);
drivers/block/drbd/drbd_debugfs.c:			if (kref_put(&req->kref, drbd_req_destroy))
drivers/block/drbd/drbd_debugfs.c:			if (&req->tl_requests == &connection->transfer_log)
drivers/block/drbd/drbd_debugfs.c:		s = req->rq_state;
drivers/block/drbd/drbd_debugfs.c:		if (req->master_bio == NULL)
drivers/block/drbd/drbd_int.h:		 * with req->epoch == current_epoch_nr.
drivers/block/drbd/drbd_int.h:	struct page *page = peer_req->pages;
drivers/block/drbd/drbd_main.c:			expect_epoch = req->epoch;
drivers/block/drbd/drbd_main.c:		if (req->epoch == expect_epoch)
drivers/block/drbd/drbd_main.c:		if (req->epoch != expect_epoch)
drivers/block/drbd/drbd_main.c:		if (!(req->rq_state & RQ_LOCAL_PENDING))
drivers/block/drbd/drbd_main.c:		if (req->device != device)
drivers/block/drbd/drbd_main.c:			      cpu_to_be64(peer_req->i.sector),
drivers/block/drbd/drbd_main.c:			      cpu_to_be32(peer_req->i.size),
drivers/block/drbd/drbd_main.c:			      peer_req->block_id);
drivers/block/drbd/drbd_main.c:	p->sector = cpu_to_be64(peer_req->i.sector);
drivers/block/drbd/drbd_main.c:	p->blksize = cpu_to_be32(peer_req->i.size);
drivers/block/drbd/drbd_main.c:	struct page *page = peer_req->pages;
drivers/block/drbd/drbd_main.c:	unsigned len = peer_req->i.size;
drivers/block/drbd/drbd_main.c:	p->sector = cpu_to_be64(req->i.sector);
drivers/block/drbd/drbd_main.c:	dp_flags = bio_flags_to_wire(peer_device->connection, req->master_bio);
drivers/block/drbd/drbd_main.c:		if (req->rq_state & RQ_EXP_RECEIVE_ACK)
drivers/block/drbd/drbd_main.c:		if (req->rq_state & RQ_EXP_WRITE_ACK
drivers/block/drbd/drbd_main.c:		t->size = cpu_to_be32(req->i.size);
drivers/block/drbd/drbd_main.c:		wsame->size = cpu_to_be32(req->i.size);
drivers/block/drbd/drbd_main.c:		drbd_csum_bio(peer_device->connection->integrity_tfm, req->master_bio, digest_out);
drivers/block/drbd/drbd_main.c:				   bio_iovec(req->master_bio).bv_len);
drivers/block/drbd/drbd_main.c:				   sizeof(*p) + digest_size, NULL, req->i.size);
drivers/block/drbd/drbd_main.c:		if (!(req->rq_state & (RQ_EXP_RECEIVE_ACK | RQ_EXP_WRITE_ACK)) || digest_size)
drivers/block/drbd/drbd_main.c:			err = _drbd_send_bio(peer_device, req->master_bio);
drivers/block/drbd/drbd_main.c:			err = _drbd_send_zc_bio(peer_device, req->master_bio);
drivers/block/drbd/drbd_main.c:			drbd_csum_bio(peer_device->connection->integrity_tfm, req->master_bio, digest);
drivers/block/drbd/drbd_main.c:					(unsigned long long)req->i.sector, req->i.size);
drivers/block/drbd/drbd_main.c:	p->sector = cpu_to_be64(peer_req->i.sector);
drivers/block/drbd/drbd_main.c:	p->block_id = peer_req->block_id;
drivers/block/drbd/drbd_main.c:	err = __send_command(peer_device->connection, device->vnr, sock, cmd, sizeof(*p) + digest_size, NULL, peer_req->i.size);
drivers/block/drbd/drbd_main.c:	p->sector = cpu_to_be64(req->i.sector);
drivers/block/drbd/drbd_main.c:	p->blksize = cpu_to_be32(req->i.size);
drivers/block/drbd/drbd_main.c:		struct drbd_device *device = req->device;
drivers/block/drbd/drbd_main.c:		struct bio *bio = req->master_bio;
drivers/block/drbd/drbd_main.c:			expect(atomic_read(&req->completion_ref) == 0) &&
drivers/block/drbd/drbd_main.c:			expect(req->rq_state & RQ_POSTPONED) &&
drivers/block/drbd/drbd_main.c:			expect((req->rq_state & RQ_LOCAL_PENDING) == 0 ||
drivers/block/drbd/drbd_main.c:				(req->rq_state & RQ_LOCAL_ABORTED) != 0);
drivers/block/drbd/drbd_main.c:				req, atomic_read(&req->completion_ref),
drivers/block/drbd/drbd_main.c:				req->rq_state);
drivers/block/drbd/drbd_main.c:		 * frozen local req->private_bio, in case we force-detached.
drivers/block/drbd/drbd_main.c:		kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_main.c:	list_move_tail(&req->tl_requests, &retry.writes);
drivers/block/drbd/drbd_main.c:	dec_ap_bio(req->device);
drivers/block/drbd/drbd_req.c:	req->private_bio = bio_clone_fast(bio_src, GFP_NOIO, &drbd_io_bio_set);
drivers/block/drbd/drbd_req.c:	req->private_bio->bi_private = req;
drivers/block/drbd/drbd_req.c:	req->private_bio->bi_end_io = drbd_request_endio;
drivers/block/drbd/drbd_req.c:	req->rq_state = (bio_data_dir(bio_src) == WRITE ? RQ_WRITE : 0)
drivers/block/drbd/drbd_req.c:	req->device = device;
drivers/block/drbd/drbd_req.c:	req->master_bio = bio_src;
drivers/block/drbd/drbd_req.c:	req->epoch = 0;
drivers/block/drbd/drbd_req.c:	drbd_clear_interval(&req->i);
drivers/block/drbd/drbd_req.c:	req->i.sector     = bio_src->bi_iter.bi_sector;
drivers/block/drbd/drbd_req.c:	req->i.size      = bio_src->bi_iter.bi_size;
drivers/block/drbd/drbd_req.c:	req->i.local = true;
drivers/block/drbd/drbd_req.c:	req->i.waiting = false;
drivers/block/drbd/drbd_req.c:	INIT_LIST_HEAD(&req->tl_requests);
drivers/block/drbd/drbd_req.c:	INIT_LIST_HEAD(&req->w.list);
drivers/block/drbd/drbd_req.c:	INIT_LIST_HEAD(&req->req_pending_master_completion);
drivers/block/drbd/drbd_req.c:	INIT_LIST_HEAD(&req->req_pending_local);
drivers/block/drbd/drbd_req.c:	atomic_set(&req->completion_ref, 1);
drivers/block/drbd/drbd_req.c:	kref_init(&req->kref);
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	struct drbd_interval *i = &req->i;
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	const unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	if ((req->master_bio && !(s & RQ_POSTPONED)) ||
drivers/block/drbd/drbd_req.c:		atomic_read(&req->completion_ref) ||
drivers/block/drbd/drbd_req.c:				s, atomic_read(&req->completion_ref));
drivers/block/drbd/drbd_req.c:	 * req_lock, and req->tl_requests will typicaly be on ->transfer_log,
drivers/block/drbd/drbd_req.c:	 * still allowed to unconditionally list_del(&req->tl_requests),
drivers/block/drbd/drbd_req.c:	list_del_init(&req->tl_requests);
drivers/block/drbd/drbd_req.c:	if (!drbd_interval_empty(&req->i)) {
drivers/block/drbd/drbd_req.c:	} else if (s & (RQ_NET_MASK & ~RQ_NET_DONE) && req->i.size != 0)
drivers/block/drbd/drbd_req.c:			s, (unsigned long long)req->i.sector, req->i.size);
drivers/block/drbd/drbd_req.c:				drbd_set_out_of_sync(device, req->i.sector, req->i.size);
drivers/block/drbd/drbd_req.c:				drbd_set_in_sync(device, req->i.sector, req->i.size);
drivers/block/drbd/drbd_req.c:				drbd_al_complete_io(device, &req->i);
drivers/block/drbd/drbd_req.c:					 (unsigned long long) req->i.sector, req->i.size);
drivers/block/drbd/drbd_req.c:	const unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	if (!req->master_bio) {
drivers/block/drbd/drbd_req.c:	error = PTR_ERR(req->private_bio);
drivers/block/drbd/drbd_req.c:	if (op_is_write(bio_op(req->master_bio)) &&
drivers/block/drbd/drbd_req.c:	    req->epoch == atomic_read(&first_peer_device(device)->connection->current_tle_nr))
drivers/block/drbd/drbd_req.c:	bio_end_io_acct(req->master_bio, req->start_jif);
drivers/block/drbd/drbd_req.c:	    bio_op(req->master_bio) == REQ_OP_READ &&
drivers/block/drbd/drbd_req.c:	    !(req->master_bio->bi_opf & REQ_RAHEAD) &&
drivers/block/drbd/drbd_req.c:	    !list_empty(&req->tl_requests))
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_POSTPONED;
drivers/block/drbd/drbd_req.c:	if (!(req->rq_state & RQ_POSTPONED)) {
drivers/block/drbd/drbd_req.c:		m->bio = req->master_bio;
drivers/block/drbd/drbd_req.c:		req->master_bio = NULL;
drivers/block/drbd/drbd_req.c:		req->i.completed = true;
drivers/block/drbd/drbd_req.c:	if (req->i.waiting)
drivers/block/drbd/drbd_req.c:	list_del_init(&req->req_pending_master_completion);
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	D_ASSERT(device, m || (req->rq_state & RQ_POSTPONED));
drivers/block/drbd/drbd_req.c:	if (!atomic_sub_and_test(put, &req->completion_ref))
drivers/block/drbd/drbd_req.c:	if (req->rq_state & RQ_LOCAL_ABORTED)
drivers/block/drbd/drbd_req.c:	if (req->rq_state & RQ_POSTPONED) {
drivers/block/drbd/drbd_req.c:	kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_req.c:		const unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	if (&req->tl_requests == &connection->transfer_log)
drivers/block/drbd/drbd_req.c:		const unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	if (&req->tl_requests == &connection->transfer_log)
drivers/block/drbd/drbd_req.c:		const unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	if (&req->tl_requests == &connection->transfer_log)
drivers/block/drbd/drbd_req.c: * req->completion_ref and req->kref. */
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	unsigned s = req->rq_state;
drivers/block/drbd/drbd_req.c:	req->rq_state &= ~clear;
drivers/block/drbd/drbd_req.c:	req->rq_state |= set;
drivers/block/drbd/drbd_req.c:	if (req->rq_state == s)
drivers/block/drbd/drbd_req.c:	kref_get(&req->kref);
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		kref_get(&req->kref); /* wait for the DONE */
drivers/block/drbd/drbd_req.c:			atomic_add(req->i.size >> 9, &device->ap_in_flight);
drivers/block/drbd/drbd_req.c:		if (req->rq_state & RQ_NET_PENDING)
drivers/block/drbd/drbd_req.c:		atomic_inc(&req->completion_ref);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_LOCAL_PENDING);
drivers/block/drbd/drbd_req.c:		if (req->rq_state & RQ_LOCAL_ABORTED)
drivers/block/drbd/drbd_req.c:			kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_req.c:		list_del_init(&req->req_pending_local);
drivers/block/drbd/drbd_req.c:		req->acked_jif = jiffies;
drivers/block/drbd/drbd_req.c:			atomic_sub(req->i.size >> 9, &device->ap_in_flight);
drivers/block/drbd/drbd_req.c:			kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_req.c:		req->net_done_jif = jiffies;
drivers/block/drbd/drbd_req.c:	if (req->i.waiting)
drivers/block/drbd/drbd_req.c:	kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_req.c:			(req->rq_state & RQ_WRITE) ? "WRITE" : "READ",
drivers/block/drbd/drbd_req.c:			(unsigned long long)req->i.sector,
drivers/block/drbd/drbd_req.c:			req->i.size >> 9,
drivers/block/drbd/drbd_req.c:	return (req->rq_state &
drivers/block/drbd/drbd_req.c:	struct drbd_device *const device = req->device;
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, !(req->rq_state & RQ_NET_MASK));
drivers/block/drbd/drbd_req.c:		req->rq_state |=
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, !(req->rq_state & RQ_LOCAL_MASK));
drivers/block/drbd/drbd_req.c:		if (req->rq_state & RQ_WRITE)
drivers/block/drbd/drbd_req.c:			device->writ_cnt += req->i.size >> 9;
drivers/block/drbd/drbd_req.c:			device->read_cnt += req->i.size >> 9;
drivers/block/drbd/drbd_req.c:		drbd_set_out_of_sync(device, req->i.sector, req->i.size);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, drbd_interval_empty(&req->i));
drivers/block/drbd/drbd_req.c:		drbd_insert_interval(&device->read_requests, &req->i);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, (req->rq_state & RQ_LOCAL_MASK) == 0);
drivers/block/drbd/drbd_req.c:		req->w.cb = w_send_read_req;
drivers/block/drbd/drbd_req.c:				&req->w);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, drbd_interval_empty(&req->i));
drivers/block/drbd/drbd_req.c:		drbd_insert_interval(&device->write_requests, &req->i);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:		req->w.cb =  w_send_dblock;
drivers/block/drbd/drbd_req.c:				&req->w);
drivers/block/drbd/drbd_req.c:		req->w.cb =  w_send_out_of_sync;
drivers/block/drbd/drbd_req.c:				&req->w);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_EXP_WRITE_ACK);
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_NET_SIS;
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_EXP_RECEIVE_ACK);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_EXP_WRITE_ACK);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_POSTPONED;
drivers/block/drbd/drbd_req.c:		if (req->i.waiting)
drivers/block/drbd/drbd_req.c:		if (!(req->rq_state & RQ_LOCAL_COMPLETED))
drivers/block/drbd/drbd_req.c:		if (!(req->rq_state & RQ_LOCAL_COMPLETED))
drivers/block/drbd/drbd_req.c:		if (bio_data_dir(req->master_bio) == WRITE)
drivers/block/drbd/drbd_req.c:		req->w.cb = w_restart_disk_io;
drivers/block/drbd/drbd_req.c:				&req->w);
drivers/block/drbd/drbd_req.c:		if (!(req->rq_state & RQ_WRITE) && !req->w.cb) {
drivers/block/drbd/drbd_req.c:		if (!(req->rq_state & RQ_NET_OK)) {
drivers/block/drbd/drbd_req.c:			/* FIXME could this possibly be a req->dw.cb == w_send_out_of_sync?
drivers/block/drbd/drbd_req.c:			if (req->w.cb) {
drivers/block/drbd/drbd_req.c:						&req->w);
drivers/block/drbd/drbd_req.c:				rv = req->rq_state & RQ_WRITE ? MR_WRITE : MR_READ;
drivers/block/drbd/drbd_req.c:		if (!(req->rq_state & RQ_WRITE))
drivers/block/drbd/drbd_req.c:		if (req->rq_state & RQ_NET_PENDING) {
drivers/block/drbd/drbd_req.c:				(req->rq_state & RQ_NET_MASK) ? RQ_NET_DONE : 0);
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->rq_state & RQ_NET_PENDING);
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	sector_t sector = req->i.sector;
drivers/block/drbd/drbd_req.c:	int size = req->i.size;
drivers/block/drbd/drbd_req.c:/* If this returns false, and req->private_bio is still set,
drivers/block/drbd/drbd_req.c: * If it returns false, but req->private_bio is not set,
drivers/block/drbd/drbd_req.c: * Otherwise, this destroys req->private_bio, if any,
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	if (req->private_bio) {
drivers/block/drbd/drbd_req.c:					req->i.sector, req->i.size)) {
drivers/block/drbd/drbd_req.c:			bio_put(req->private_bio);
drivers/block/drbd/drbd_req.c:			req->private_bio = NULL;
drivers/block/drbd/drbd_req.c:	if (req->private_bio == NULL)
drivers/block/drbd/drbd_req.c:	if (rbm == RB_PREFER_LOCAL && req->private_bio)
drivers/block/drbd/drbd_req.c:	if (remote_due_to_read_balancing(device, req->i.sector, rbm)) {
drivers/block/drbd/drbd_req.c:		if (req->private_bio) {
drivers/block/drbd/drbd_req.c:			bio_put(req->private_bio);
drivers/block/drbd/drbd_req.c:			req->private_bio = NULL;
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	if (unlikely(req->i.size == 0)) {
drivers/block/drbd/drbd_req.c:		D_ASSERT(device, req->master_bio->bi_opf & REQ_PREFLUSH);
drivers/block/drbd/drbd_req.c:	} else if (drbd_set_out_of_sync(device, req->i.sector, req->i.size))
drivers/block/drbd/drbd_req.c:	int err = drbd_issue_discard_or_zero_out(req->device,
drivers/block/drbd/drbd_req.c:				req->i.sector, req->i.size >> 9, flags);
drivers/block/drbd/drbd_req.c:		req->private_bio->bi_status = BLK_STS_IOERR;
drivers/block/drbd/drbd_req.c:	bio_endio(req->private_bio);
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_req.c:	struct bio *bio = req->private_bio;
drivers/block/drbd/drbd_req.c:	list_add_tail(&req->tl_requests, &device->submit.writes);
drivers/block/drbd/drbd_req.c:	list_add_tail(&req->req_pending_master_completion,
drivers/block/drbd/drbd_req.c:	req->start_jif = bio_start_io_acct(req->master_bio);
drivers/block/drbd/drbd_req.c:		bio_put(req->private_bio);
drivers/block/drbd/drbd_req.c:		req->private_bio = NULL;
drivers/block/drbd/drbd_req.c:	if (rw == WRITE && req->private_bio && req->i.size
drivers/block/drbd/drbd_req.c:		if (!drbd_al_begin_io_fastpath(device, &req->i))
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_IN_ACT_LOG;
drivers/block/drbd/drbd_req.c:		req->in_actlog_jif = jiffies;
drivers/block/drbd/drbd_req.c:	req->rq_state |= RQ_UNPLUG;
drivers/block/drbd/drbd_req.c:	drbd_queue_unplug(req->device);
drivers/block/drbd/drbd_req.c:	kref_put(&req->kref, drbd_req_destroy);
drivers/block/drbd/drbd_req.c:	kref_get(&req->kref);
drivers/block/drbd/drbd_req.c:	const int rw = bio_data_dir(req->master_bio);
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_POSTPONED;
drivers/block/drbd/drbd_req.c:		if (req->private_bio) {
drivers/block/drbd/drbd_req.c:			bio_put(req->private_bio);
drivers/block/drbd/drbd_req.c:			req->private_bio = NULL;
drivers/block/drbd/drbd_req.c:		if (!do_remote_read(req) && !req->private_bio)
drivers/block/drbd/drbd_req.c:	req->epoch = atomic_read(&first_peer_device(device)->connection->current_tle_nr);
drivers/block/drbd/drbd_req.c:	if (likely(req->i.size!=0)) {
drivers/block/drbd/drbd_req.c:		list_add_tail(&req->tl_requests, &first_peer_device(device)->connection->transfer_log);
drivers/block/drbd/drbd_req.c:		if (req->private_bio && !may_do_writes(device)) {
drivers/block/drbd/drbd_req.c:			bio_put(req->private_bio);
drivers/block/drbd/drbd_req.c:			req->private_bio = NULL;
drivers/block/drbd/drbd_req.c:		if (req->private_bio == NULL) {
drivers/block/drbd/drbd_req.c:	if (list_empty(&req->req_pending_master_completion))
drivers/block/drbd/drbd_req.c:		list_add_tail(&req->req_pending_master_completion,
drivers/block/drbd/drbd_req.c:	if (req->private_bio) {
drivers/block/drbd/drbd_req.c:		req->pre_submit_jif = jiffies;
drivers/block/drbd/drbd_req.c:		list_add_tail(&req->req_pending_local,
drivers/block/drbd/drbd_req.c:					(unsigned long long)req->i.sector, req->i.size >> 9);
drivers/block/drbd/drbd_req.c:	 * That's why we cannot check on req->private_bio. */
drivers/block/drbd/drbd_req.c:		const int rw = bio_data_dir(req->master_bio);
drivers/block/drbd/drbd_req.c:		&& req->private_bio && req->i.size
drivers/block/drbd/drbd_req.c:			if (!drbd_al_begin_io_fastpath(device, &req->i))
drivers/block/drbd/drbd_req.c:			req->rq_state |= RQ_IN_ACT_LOG;
drivers/block/drbd/drbd_req.c:			req->in_actlog_jif = jiffies;
drivers/block/drbd/drbd_req.c:		list_del_init(&req->tl_requests);
drivers/block/drbd/drbd_req.c:		err = drbd_al_begin_io_nonblock(device, &req->i);
drivers/block/drbd/drbd_req.c:			list_move_tail(&req->tl_requests, later);
drivers/block/drbd/drbd_req.c:			list_move_tail(&req->tl_requests, pending);
drivers/block/drbd/drbd_req.c:		req->rq_state |= RQ_IN_ACT_LOG;
drivers/block/drbd/drbd_req.c:		req->in_actlog_jif = jiffies;
drivers/block/drbd/drbd_req.c:		list_del_init(&req->tl_requests);
drivers/block/drbd/drbd_req.c:	struct drbd_device *device = net_req->device;
drivers/block/drbd/drbd_req.c:	if (!time_after(now, net_req->pre_send_jif + ent))
drivers/block/drbd/drbd_req.c:	if (net_req->rq_state & RQ_NET_PENDING) {
drivers/block/drbd/drbd_req.c:			jiffies_to_msecs(now - net_req->pre_send_jif), ko_count, timeout);
drivers/block/drbd/drbd_req.c:	if (net_req->epoch == connection->send.current_epoch_nr) {
drivers/block/drbd/drbd_req.c:			jiffies_to_msecs(now - net_req->pre_send_jif), ko_count, timeout);
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	device->read_cnt += peer_req->i.size >> 9;
drivers/block/drbd/drbd_worker.c:	list_del(&peer_req->w.list);
drivers/block/drbd/drbd_worker.c:	if (test_bit(__EE_WAS_ERROR, &peer_req->flags))
drivers/block/drbd/drbd_worker.c:	drbd_queue_work(&peer_device->connection->sender_work, &peer_req->w);
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	i = peer_req->i;
drivers/block/drbd/drbd_worker.c:	do_al_complete_io = peer_req->flags & EE_CALL_AL_COMPLETE_IO;
drivers/block/drbd/drbd_worker.c:	block_id = peer_req->block_id;
drivers/block/drbd/drbd_worker.c:	peer_req->flags &= ~EE_CALL_AL_COMPLETE_IO;
drivers/block/drbd/drbd_worker.c:	if (peer_req->flags & EE_WAS_ERROR) {
drivers/block/drbd/drbd_worker.c:		if (!__test_and_set_bit(__EE_SEND_WRITE_ACK, &peer_req->flags))
drivers/block/drbd/drbd_worker.c:		drbd_set_out_of_sync(device, peer_req->i.sector, peer_req->i.size);
drivers/block/drbd/drbd_worker.c:	device->writ_cnt += peer_req->i.size >> 9;
drivers/block/drbd/drbd_worker.c:	list_move_tail(&peer_req->w.list, &device->done_ee);
drivers/block/drbd/drbd_worker.c:	 * ((peer_req->flags & (EE_WAS_ERROR|EE_TRIM)) == EE_WAS_ERROR) */
drivers/block/drbd/drbd_worker.c:	if (peer_req->flags & EE_WAS_ERROR)
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = peer_req->peer_device->device;
drivers/block/drbd/drbd_worker.c:				(unsigned long long)peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:		set_bit(__EE_WAS_ERROR, &peer_req->flags);
drivers/block/drbd/drbd_worker.c:	if (atomic_dec_and_test(&peer_req->pending_bios)) {
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_worker.c:	if (unlikely(req->rq_state & RQ_LOCAL_ABORTED)) {
drivers/block/drbd/drbd_worker.c:	req->private_bio = ERR_PTR(blk_status_to_errno(bio->bi_status));
drivers/block/drbd/drbd_worker.c:	struct page *page = peer_req->pages;
drivers/block/drbd/drbd_worker.c:	len = peer_req->i.size & (PAGE_SIZE - 1);
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	if (unlikely((peer_req->flags & EE_WAS_ERROR) != 0))
drivers/block/drbd/drbd_worker.c:		sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_worker.c:		unsigned int size = peer_req->i.size;
drivers/block/drbd/drbd_worker.c:	peer_req->w.cb = w_e_send_csum;
drivers/block/drbd/drbd_worker.c:	list_add_tail(&peer_req->w.list, &device->read_ee);
drivers/block/drbd/drbd_worker.c:	list_del(&peer_req->w.list);
drivers/block/drbd/drbd_worker.c:		int i = (peer_req->i.size + PAGE_SIZE -1) >> PAGE_SHIFT;
drivers/block/drbd/drbd_worker.c:		list_add_tail(&peer_req->w.list, &device->net_ee);
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_worker.c:			    (unsigned long long)peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:	struct page *page = peer_req->pages;
drivers/block/drbd/drbd_worker.c:	unsigned int len = peer_req->i.size;
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:		drbd_rs_complete_io(device, peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:	} else if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_worker.c:			if (peer_req->flags & EE_RS_THIN_REQ && all_zero(peer_req))
drivers/block/drbd/drbd_worker.c:			    (unsigned long long)peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:		drbd_rs_failed_io(device, peer_req->i.sector, peer_req->i.size);
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:		drbd_rs_complete_io(device, peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:	di = peer_req->digest;
drivers/block/drbd/drbd_worker.c:	if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_worker.c:			drbd_set_in_sync(device, peer_req->i.sector, peer_req->i.size);
drivers/block/drbd/drbd_worker.c:			device->rs_same_csum += peer_req->i.size >> BM_BLOCK_SHIFT;
drivers/block/drbd/drbd_worker.c:			peer_req->block_id = ID_SYNCER; /* By setting block_id, digest pointer becomes invalid! */
drivers/block/drbd/drbd_worker.c:			peer_req->flags &= ~EE_HAS_DIGEST; /* This peer request no longer has a digest pointer */
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_worker.c:	unsigned int size = peer_req->i.size;
drivers/block/drbd/drbd_worker.c:	if (likely(!(peer_req->flags & EE_WAS_ERROR)))
drivers/block/drbd/drbd_worker.c:	struct drbd_peer_device *peer_device = peer_req->peer_device;
drivers/block/drbd/drbd_worker.c:	sector_t sector = peer_req->i.sector;
drivers/block/drbd/drbd_worker.c:	unsigned int size = peer_req->i.size;
drivers/block/drbd/drbd_worker.c:		drbd_rs_complete_io(device, peer_req->i.sector);
drivers/block/drbd/drbd_worker.c:	di = peer_req->digest;
drivers/block/drbd/drbd_worker.c:	if (likely((peer_req->flags & EE_WAS_ERROR) == 0)) {
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_worker.c:	req->pre_send_jif = jiffies;
drivers/block/drbd/drbd_worker.c:	maybe_send_barrier(connection, req->epoch);
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_worker.c:	bool do_send_unplug = req->rq_state & RQ_UNPLUG;
drivers/block/drbd/drbd_worker.c:	req->pre_send_jif = jiffies;
drivers/block/drbd/drbd_worker.c:	re_init_if_first_write(connection, req->epoch);
drivers/block/drbd/drbd_worker.c:	maybe_send_barrier(connection, req->epoch);
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_worker.c:	bool do_send_unplug = req->rq_state & RQ_UNPLUG;
drivers/block/drbd/drbd_worker.c:	req->pre_send_jif = jiffies;
drivers/block/drbd/drbd_worker.c:	maybe_send_barrier(connection, req->epoch);
drivers/block/drbd/drbd_worker.c:	err = drbd_send_drequest(peer_device, P_DATA_REQUEST, req->i.sector, req->i.size,
drivers/block/drbd/drbd_worker.c:	struct drbd_device *device = req->device;
drivers/block/drbd/drbd_worker.c:	if (bio_data_dir(req->master_bio) == WRITE && req->rq_state & RQ_IN_ACT_LOG)
drivers/block/drbd/drbd_worker.c:		drbd_al_begin_io(device, &req->i);
drivers/block/drbd/drbd_worker.c:	req->private_bio = bio_clone_fast(req->master_bio, GFP_NOIO,
drivers/block/drbd/drbd_worker.c:	bio_set_dev(req->private_bio, device->ldev->backing_bdev);
drivers/block/drbd/drbd_worker.c:	req->private_bio->bi_private = req;
drivers/block/drbd/drbd_worker.c:	req->private_bio->bi_end_io = drbd_request_endio;
drivers/block/drbd/drbd_worker.c:	submit_bio_noacct(req->private_bio);
drivers/block/swim3.c:		init_dma(cp, OUTPUT_MORE, bio_data(req->bio), 512);
drivers/block/swim3.c:		init_dma(cp, INPUT_LAST, bio_data(req->bio), n * 512);
drivers/block/swim.c:					  bio_data(req->bio));
drivers/block/rbd.c:	switch (obj_req->img_request->data_type) {
drivers/block/rbd.c:		zero_bios(&obj_req->bio_pos, off, bytes);
drivers/block/rbd.c:		zero_bvecs(&obj_req->bvec_pos, off, bytes);
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	     __func__, osd_req, obj_req, obj_req->ex.oe_objno,
drivers/block/rbd.c:	     obj_req->ex.oe_off, obj_req->ex.oe_len);
drivers/block/rbd.c:	ceph_osdc_start_request(osd_req->r_osdc, osd_req, false);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	return !obj_req->ex.oe_off &&
drivers/block/rbd.c:	       obj_req->ex.oe_len == rbd_dev->layout.object_size;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	return obj_req->ex.oe_off + obj_req->ex.oe_len ==
drivers/block/rbd.c:	if (!obj_req->num_img_extents ||
drivers/block/rbd.c:	     !obj_req->img_request->snapc->num_snaps))
drivers/block/rbd.c:	return ceph_file_extents_bytes(obj_req->img_extents,
drivers/block/rbd.c:				       obj_req->num_img_extents);
drivers/block/rbd.c:	switch (img_req->op_type) {
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	     osd_req->r_result, obj_req);
drivers/block/rbd.c:	if (osd_req->r_result > 0 && rbd_img_is_write(obj_req->img_request))
drivers/block/rbd.c:		result = osd_req->r_result;
drivers/block/rbd.c:	struct rbd_obj_request *obj_request = osd_req->r_priv;
drivers/block/rbd.c:	osd_req->r_flags = CEPH_OSD_FLAG_READ | opt->read_from_replica;
drivers/block/rbd.c:	osd_req->r_snapid = obj_request->img_request->snap_id;
drivers/block/rbd.c:	struct rbd_obj_request *obj_request = osd_req->r_priv;
drivers/block/rbd.c:	osd_req->r_flags = CEPH_OSD_FLAG_WRITE;
drivers/block/rbd.c:	ktime_get_real_ts64(&osd_req->r_mtime);
drivers/block/rbd.c:	osd_req->r_data_offset = obj_request->ex.oe_off;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	list_add_tail(&req->r_private_item, &obj_req->osd_reqs);
drivers/block/rbd.c:	req->r_callback = rbd_osd_req_callback;
drivers/block/rbd.c:	req->r_priv = obj_req;
drivers/block/rbd.c:	ceph_oloc_copy(&req->r_base_oloc, &rbd_dev->header_oloc);
drivers/block/rbd.c:	req->r_base_oloc.pool = rbd_dev->layout.pool_id;
drivers/block/rbd.c:	ret = ceph_oid_aprintf(&req->r_base_oid, GFP_NOIO, name_format,
drivers/block/rbd.c:			       obj_req->ex.oe_objno);
drivers/block/rbd.c:	return __rbd_obj_add_osd_request(obj_req, obj_req->img_request->snapc,
drivers/block/rbd.c:		list_del_init(&osd_req->r_private_item);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:		img_req->snapc = ceph_get_snap_context(rbd_dev->header.snapc);
drivers/block/rbd.c:		img_req->snap_id = rbd_dev->spec->snap_id;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	if (osd_req->r_result)
drivers/block/rbd.c:		return osd_req->r_result;
drivers/block/rbd.c:	if (osd_req->r_num_ops == 1)
drivers/block/rbd.c:	rbd_assert(osd_req->r_num_ops == 2);
drivers/block/rbd.c:	rbd_assert(objno == obj_req->ex.oe_objno);
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	     osd_req->r_result, obj_req);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:		if (!update_needed(rbd_dev, obj_req->ex.oe_objno, new_state))
drivers/block/rbd.c:	list_add_tail(&req->r_private_item, &obj_req->osd_reqs);
drivers/block/rbd.c:	req->r_callback = rbd_object_map_callback;
drivers/block/rbd.c:	req->r_priv = obj_req;
drivers/block/rbd.c:	rbd_object_map_name(rbd_dev, snap_id, &req->r_base_oid);
drivers/block/rbd.c:	ceph_oloc_copy(&req->r_base_oloc, &rbd_dev->header_oloc);
drivers/block/rbd.c:	req->r_flags = CEPH_OSD_FLAG_WRITE;
drivers/block/rbd.c:	ktime_get_real_ts64(&req->r_mtime);
drivers/block/rbd.c:	ret = rbd_cls_object_map_update(req, which, obj_req->ex.oe_objno,
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	ret = ceph_extent_to_file(&rbd_dev->layout, obj_req->ex.oe_objno,
drivers/block/rbd.c:				  entire ? 0 : obj_req->ex.oe_off,
drivers/block/rbd.c:							obj_req->ex.oe_len,
drivers/block/rbd.c:				  &obj_req->img_extents,
drivers/block/rbd.c:				  &obj_req->num_img_extents);
drivers/block/rbd.c:	prune_extents(obj_req->img_extents, &obj_req->num_img_extents,
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	switch (obj_req->img_request->data_type) {
drivers/block/rbd.c:					       &obj_req->bio_pos,
drivers/block/rbd.c:					       obj_req->ex.oe_len);
drivers/block/rbd.c:		rbd_assert(obj_req->bvec_pos.iter.bi_size ==
drivers/block/rbd.c:							obj_req->ex.oe_len);
drivers/block/rbd.c:		rbd_assert(obj_req->bvec_idx == obj_req->bvec_count);
drivers/block/rbd.c:						    &obj_req->bvec_pos);
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	osd_req_op_cls_request_data_bvecs(osd_req, which, obj_req->copyup_bvecs,
drivers/block/rbd.c:					  obj_req->copyup_bvec_count, bytes);
drivers/block/rbd.c:	obj_req->read_state = RBD_OBJ_READ_START;
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	    !(obj_req->flags & RBD_OBJ_FLAG_MAY_EXIST)) {
drivers/block/rbd.c:			       obj_req->ex.oe_off, obj_req->ex.oe_len, 0, 0);
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_COPYUP_ENABLED;
drivers/block/rbd.c:	obj_req->write_state = RBD_OBJ_WRITE_START;
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	if (rbd_obj_is_entire(obj_req) && !obj_req->num_img_extents) {
drivers/block/rbd.c:		rbd_assert(obj_req->flags & RBD_OBJ_FLAG_DELETION);
drivers/block/rbd.c:				       obj_req->ex.oe_off, obj_req->ex.oe_len,
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:		off = round_up(obj_req->ex.oe_off, rbd_dev->opts->alloc_size);
drivers/block/rbd.c:		next_off = round_down(obj_req->ex.oe_off + obj_req->ex.oe_len,
drivers/block/rbd.c:		     obj_req, obj_req->ex.oe_off, obj_req->ex.oe_len,
drivers/block/rbd.c:		obj_req->ex.oe_off = off;
drivers/block/rbd.c:		obj_req->ex.oe_len = next_off - off;
drivers/block/rbd.c:	obj_req->flags |= RBD_OBJ_FLAG_NOOP_FOR_NONEXISTENT;
drivers/block/rbd.c:	if (rbd_obj_is_entire(obj_req) && !obj_req->num_img_extents)
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_DELETION;
drivers/block/rbd.c:	obj_req->write_state = RBD_OBJ_WRITE_START;
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:		if (obj_req->num_img_extents) {
drivers/block/rbd.c:			if (!(obj_req->flags & RBD_OBJ_FLAG_COPYUP_ENABLED))
drivers/block/rbd.c:			rbd_assert(obj_req->flags & RBD_OBJ_FLAG_DELETION);
drivers/block/rbd.c:				       obj_req->ex.oe_off, obj_req->ex.oe_len,
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_COPYUP_ENABLED;
drivers/block/rbd.c:	if (!obj_req->num_img_extents) {
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_NOOP_FOR_NONEXISTENT;
drivers/block/rbd.c:			obj_req->flags |= RBD_OBJ_FLAG_DELETION;
drivers/block/rbd.c:	obj_req->write_state = RBD_OBJ_WRITE_START;
drivers/block/rbd.c:	struct rbd_img_request *img_req = obj_req->img_request;
drivers/block/rbd.c:	switch (img_req->op_type) {
drivers/block/rbd.c:		if (!use_object_map(img_req->rbd_dev) ||
drivers/block/rbd.c:		    !(obj_req->flags & RBD_OBJ_FLAG_MAY_EXIST))
drivers/block/rbd.c:		if (rbd_obj_is_entire(obj_req) && obj_req->num_img_extents &&
drivers/block/rbd.c:		    !(obj_req->flags & RBD_OBJ_FLAG_COPYUP_ENABLED))
drivers/block/rbd.c:	struct rbd_obj_request *obj_req = osd_req->r_priv;
drivers/block/rbd.c:	switch (obj_req->img_request->op_type) {
drivers/block/rbd.c:		switch (img_req->op_type) {
drivers/block/rbd.c:	img_req->state = RBD_IMG_START;
drivers/block/rbd.c:	return &obj_req->ex;
drivers/block/rbd.c:	img_req->data_type = fctx->pos_type;
drivers/block/rbd.c:		ret = ceph_file_to_extents(&img_req->rbd_dev->layout,
drivers/block/rbd.c:					   &img_req->object_extents,
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	img_req->data_type = OBJ_REQUEST_OWN_BVECS;
drivers/block/rbd.c:					   &img_req->object_extents,
drivers/block/rbd.c:		obj_req->bvec_pos.bvecs = kmalloc_array(obj_req->bvec_count,
drivers/block/rbd.c:					      sizeof(*obj_req->bvec_pos.bvecs),
drivers/block/rbd.c:		if (!obj_req->bvec_pos.bvecs)
drivers/block/rbd.c:					   &img_req->object_extents,
drivers/block/rbd.c:	obj_req->bio_pos = *it;
drivers/block/rbd.c:		obj_req->bvec_count++;
drivers/block/rbd.c:		obj_req->bvec_pos.bvecs[obj_req->bvec_idx++] = bv;
drivers/block/rbd.c:		obj_req->bvec_pos.iter.bi_size += bv.bv_len;
drivers/block/rbd.c:	obj_req->bvec_pos = *it;
drivers/block/rbd.c:	ceph_bvec_iter_shorten(&obj_req->bvec_pos, bytes);
drivers/block/rbd.c:		obj_req->bvec_count++;
drivers/block/rbd.c:		obj_req->bvec_pos.bvecs[obj_req->bvec_idx++] = bv;
drivers/block/rbd.c:		obj_req->bvec_pos.iter.bi_size += bv.bv_len;
drivers/block/rbd.c:	rbd_img_handle_request(img_req, img_req->work_result);
drivers/block/rbd.c:	INIT_WORK(&img_req->work, rbd_img_handle_request_work);
drivers/block/rbd.c:	img_req->work_result = result;
drivers/block/rbd.c:	queue_work(rbd_wq, &img_req->work);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	if (rbd_object_map_may_exist(rbd_dev, obj_req->ex.oe_objno)) {
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_MAY_EXIST;
drivers/block/rbd.c:	     obj_req->ex.oe_objno);
drivers/block/rbd.c:			       obj_req->ex.oe_off, obj_req->ex.oe_len, 0, 0);
drivers/block/rbd.c:	struct rbd_img_request *img_req = obj_req->img_request;
drivers/block/rbd.c:	struct rbd_device *parent = img_req->rbd_dev->parent;
drivers/block/rbd.c:	__set_bit(IMG_REQ_CHILD, &child_img_req->flags);
drivers/block/rbd.c:	child_img_req->obj_request = obj_req;
drivers/block/rbd.c:		switch (img_req->data_type) {
drivers/block/rbd.c:						      obj_req->img_extents,
drivers/block/rbd.c:						      obj_req->num_img_extents,
drivers/block/rbd.c:						      &obj_req->bio_pos);
drivers/block/rbd.c:						      obj_req->img_extents,
drivers/block/rbd.c:						      obj_req->num_img_extents,
drivers/block/rbd.c:						      &obj_req->bvec_pos);
drivers/block/rbd.c:					      obj_req->img_extents,
drivers/block/rbd.c:					      obj_req->num_img_extents,
drivers/block/rbd.c:					      obj_req->copyup_bvecs);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	switch (obj_req->read_state) {
drivers/block/rbd.c:			obj_req->read_state = RBD_OBJ_READ_OBJECT;
drivers/block/rbd.c:		obj_req->read_state = RBD_OBJ_READ_OBJECT;
drivers/block/rbd.c:			if (obj_req->num_img_extents) {
drivers/block/rbd.c:				obj_req->read_state = RBD_OBJ_READ_PARENT;
drivers/block/rbd.c:			rbd_obj_zero_range(obj_req, 0, obj_req->ex.oe_len);
drivers/block/rbd.c:			if (*result < obj_req->ex.oe_len)
drivers/block/rbd.c:						obj_req->ex.oe_len - *result);
drivers/block/rbd.c:				rbd_assert(*result == obj_req->ex.oe_len);
drivers/block/rbd.c:			if (obj_overlap < obj_req->ex.oe_len)
drivers/block/rbd.c:					    obj_req->ex.oe_len - obj_overlap);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	if (rbd_object_map_may_exist(rbd_dev, obj_req->ex.oe_objno))
drivers/block/rbd.c:		obj_req->flags |= RBD_OBJ_FLAG_MAY_EXIST;
drivers/block/rbd.c:	if (!(obj_req->flags & RBD_OBJ_FLAG_MAY_EXIST) &&
drivers/block/rbd.c:	    (obj_req->flags & RBD_OBJ_FLAG_NOOP_FOR_NONEXISTENT)) {
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	if (obj_req->flags & RBD_OBJ_FLAG_DELETION)
drivers/block/rbd.c:	if (obj_req->flags & RBD_OBJ_FLAG_COPYUP_ENABLED)
drivers/block/rbd.c:	if (obj_req->flags & RBD_OBJ_FLAG_COPYUP_ENABLED) {
drivers/block/rbd.c:	rbd_assert(!obj_req->copyup_bvecs);
drivers/block/rbd.c:	obj_req->copyup_bvec_count = calc_pages_for(0, obj_overlap);
drivers/block/rbd.c:	obj_req->copyup_bvecs = kcalloc(obj_req->copyup_bvec_count,
drivers/block/rbd.c:					sizeof(*obj_req->copyup_bvecs),
drivers/block/rbd.c:	if (!obj_req->copyup_bvecs)
drivers/block/rbd.c:	for (i = 0; i < obj_req->copyup_bvec_count; i++) {
drivers/block/rbd.c:		obj_req->copyup_bvecs[i].bv_page = alloc_page(GFP_NOIO);
drivers/block/rbd.c:		if (!obj_req->copyup_bvecs[i].bv_page)
drivers/block/rbd.c:		obj_req->copyup_bvecs[i].bv_offset = 0;
drivers/block/rbd.c:		obj_req->copyup_bvecs[i].bv_len = len;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	rbd_assert(obj_req->num_img_extents);
drivers/block/rbd.c:	prune_extents(obj_req->img_extents, &obj_req->num_img_extents,
drivers/block/rbd.c:	if (!obj_req->num_img_extents) {
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	struct ceph_snap_context *snapc = obj_req->img_request->snapc;
drivers/block/rbd.c:	rbd_assert(!obj_req->pending.result && !obj_req->pending.num_pending);
drivers/block/rbd.c:	if (obj_req->flags & RBD_OBJ_FLAG_COPYUP_ZEROS)
drivers/block/rbd.c:			obj_req->pending.result = ret;
drivers/block/rbd.c:		obj_req->pending.num_pending++;
drivers/block/rbd.c:	rbd_assert(!obj_req->pending.result && !obj_req->pending.num_pending);
drivers/block/rbd.c:	if (obj_req->flags & RBD_OBJ_FLAG_COPYUP_ZEROS)
drivers/block/rbd.c:	if (obj_req->img_request->snapc->num_snaps && bytes > 0) {
drivers/block/rbd.c:			obj_req->pending.result = ret;
drivers/block/rbd.c:		obj_req->pending.num_pending++;
drivers/block/rbd.c:		obj_req->pending.result = ret;
drivers/block/rbd.c:	obj_req->pending.num_pending++;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	switch (obj_req->copyup_state) {
drivers/block/rbd.c:		if (obj_req->num_img_extents)
drivers/block/rbd.c:			obj_req->copyup_state = RBD_OBJ_COPYUP_READ_PARENT;
drivers/block/rbd.c:			obj_req->copyup_state = RBD_OBJ_COPYUP_WRITE_OBJECT;
drivers/block/rbd.c:		if (is_zero_bvecs(obj_req->copyup_bvecs,
drivers/block/rbd.c:			obj_req->flags |= RBD_OBJ_FLAG_COPYUP_ZEROS;
drivers/block/rbd.c:		if (!obj_req->pending.num_pending) {
drivers/block/rbd.c:			*result = obj_req->pending.result;
drivers/block/rbd.c:			obj_req->copyup_state = RBD_OBJ_COPYUP_OBJECT_MAPS;
drivers/block/rbd.c:		obj_req->copyup_state = __RBD_OBJ_COPYUP_OBJECT_MAPS;
drivers/block/rbd.c:		if (!pending_result_dec(&obj_req->pending, result))
drivers/block/rbd.c:		if (!obj_req->pending.num_pending) {
drivers/block/rbd.c:			*result = obj_req->pending.result;
drivers/block/rbd.c:			obj_req->copyup_state = RBD_OBJ_COPYUP_WRITE_OBJECT;
drivers/block/rbd.c:		obj_req->copyup_state = __RBD_OBJ_COPYUP_WRITE_OBJECT;
drivers/block/rbd.c:		if (!pending_result_dec(&obj_req->pending, result))
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	if (!(obj_req->flags & RBD_OBJ_FLAG_DELETION))
drivers/block/rbd.c:	struct rbd_device *rbd_dev = obj_req->img_request->rbd_dev;
drivers/block/rbd.c:	switch (obj_req->write_state) {
drivers/block/rbd.c:		obj_req->write_state = RBD_OBJ_WRITE_PRE_OBJECT_MAP;
drivers/block/rbd.c:		obj_req->write_state = RBD_OBJ_WRITE_OBJECT;
drivers/block/rbd.c:			if (obj_req->flags & RBD_OBJ_FLAG_COPYUP_ENABLED) {
drivers/block/rbd.c:				obj_req->copyup_state = RBD_OBJ_COPYUP_START;
drivers/block/rbd.c:				obj_req->write_state = __RBD_OBJ_WRITE_COPYUP;
drivers/block/rbd.c:			if (obj_req->flags & RBD_OBJ_FLAG_DELETION)
drivers/block/rbd.c:		obj_req->write_state = RBD_OBJ_WRITE_COPYUP;
drivers/block/rbd.c:		obj_req->write_state = RBD_OBJ_WRITE_POST_OBJECT_MAP;
drivers/block/rbd.c:	struct rbd_img_request *img_req = obj_req->img_request;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	mutex_lock(&obj_req->state_mutex);
drivers/block/rbd.c:	mutex_unlock(&obj_req->state_mutex);
drivers/block/rbd.c:			 obj_op_name(img_req->op_type), obj_req->ex.oe_objno,
drivers/block/rbd.c:			 obj_req->ex.oe_off, obj_req->ex.oe_len, *result);
drivers/block/rbd.c:		rbd_img_handle_request(obj_req->img_request, result);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	rbd_assert(!test_bit(IMG_REQ_CHILD, &img_req->flags));
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	rbd_assert(list_empty(&img_req->lock_item));
drivers/block/rbd.c:		list_add_tail(&img_req->lock_item, &rbd_dev->acquiring_list);
drivers/block/rbd.c:		list_add_tail(&img_req->lock_item, &rbd_dev->running_list);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	rbd_assert(!list_empty(&img_req->lock_item));
drivers/block/rbd.c:	list_del_init(&img_req->lock_item);
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	rbd_assert(!img_req->pending.result && !img_req->pending.num_pending);
drivers/block/rbd.c:				img_req->pending.result = result;
drivers/block/rbd.c:			img_req->pending.num_pending++;
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:	switch (img_req->state) {
drivers/block/rbd.c:		img_req->state = RBD_IMG_EXCLUSIVE_LOCK;
drivers/block/rbd.c:		if (!img_req->pending.num_pending) {
drivers/block/rbd.c:			*result = img_req->pending.result;
drivers/block/rbd.c:			img_req->state = RBD_IMG_OBJECT_REQUESTS;
drivers/block/rbd.c:		img_req->state = __RBD_IMG_OBJECT_REQUESTS;
drivers/block/rbd.c:		if (!pending_result_dec(&img_req->pending, result))
drivers/block/rbd.c:	struct rbd_device *rbd_dev = img_req->rbd_dev;
drivers/block/rbd.c:		mutex_lock(&img_req->state_mutex);
drivers/block/rbd.c:		mutex_unlock(&img_req->state_mutex);
drivers/block/rbd.c:		mutex_lock(&img_req->state_mutex);
drivers/block/rbd.c:		mutex_unlock(&img_req->state_mutex);
drivers/block/rbd.c:		      test_bit(IMG_REQ_CHILD, &img_req->flags) ? "child " : "",
drivers/block/rbd.c:		      obj_op_name(img_req->op_type), *result);
drivers/block/rbd.c:	if (test_bit(IMG_REQ_CHILD, &img_req->flags)) {
drivers/block/rbd.c:		struct rbd_obj_request *obj_req = img_req->obj_request;
drivers/block/rbd.c:			img_req = obj_req->img_request;
drivers/block/rbd.c:		mutex_lock(&img_req->state_mutex);
drivers/block/rbd.c:		rbd_assert(img_req->state == RBD_IMG_EXCLUSIVE_LOCK);
drivers/block/rbd.c:		mutex_unlock(&img_req->state_mutex);
drivers/block/rbd.c:				 obj_op_name(img_req->op_type));
drivers/block/rbd.c:	INIT_WORK(&img_req->work, rbd_queue_workfn);
drivers/block/rbd.c:	queue_work(rbd_wq, &img_req->work);
drivers/block/rbd.c:	ceph_oid_copy(&req->r_base_oid, oid);
drivers/block/rbd.c:	ceph_oloc_copy(&req->r_base_oloc, oloc);
drivers/block/rbd.c:	req->r_flags = CEPH_OSD_FLAG_READ;
drivers/block/paride/pf.c:			list_del_init(&pf_req->queuelist);
drivers/block/paride/pf.c:	pf_current = pf_req->rq_disk->private_data;
drivers/block/paride/pf.c:	if (pf_block + pf_count > get_capacity(pf_req->rq_disk)) {
drivers/block/paride/pf.c:	pf_buf = bio_data(pf_req->bio);
drivers/block/paride/pf.c:		pf_buf = bio_data(pf_req->bio);
drivers/block/paride/pd.c:			list_del_init(&pd_req->queuelist);
drivers/block/paride/pd.c:			pd_current = pd_req->rq_disk->private_data;
drivers/block/paride/pd.c:		if (pd_block + pd_count > get_capacity(pd_req->rq_disk))
drivers/block/paride/pd.c:		pd_buf = bio_data(pd_req->bio);
drivers/block/paride/pd.c:	return req->func(pd_current);
drivers/block/paride/pd.c:		pd_buf = bio_data(pd_req->bio);
drivers/block/paride/pd.c:	req->func = func;
drivers/block/paride/pcd.c:			list_del_init(&pcd_req->queuelist);
drivers/block/paride/pcd.c:	cd = pcd_req->rq_disk->private_data;
drivers/block/paride/pcd.c:	pcd_buf = bio_data(pcd_req->bio);
drivers/block/mtip32xx/mtip32xx.c:	if (likely(!blk_should_fake_timeout(req->q)))
drivers/block/mtip32xx/mtip32xx.c:	dbg_printk(MTIP_DRV_NAME " Aborting request, tag = %d\n", req->tag);
drivers/block/mtip32xx/mtip32xx.c:	clear_bit(req->tag, dd->port->cmds_to_issue);
drivers/block/mtip32xx/mtip32xx.c:	set_bit(req->tag, dd->port->cmds_to_issue);
drivers/block/mtip32xx/mtip32xx.c:	struct driver_data *dd = req->q->queuedata;
drivers/block/mtip32xx/mtip32xx.c:	if (test_bit(req->tag, dd->port->cmds_to_issue))
drivers/block/floppy.c:	    tmp_format_req->track >= _floppy->track ||
drivers/block/floppy.c:	    tmp_format_req->head >= _floppy->head ||
drivers/block/floppy.c:	unsigned int drive = (unsigned long)req->rq_disk->private_data;
drivers/block/floppy.c:	    raw_cmd->kernel_data == bio_data(current_req->bio)) {
drivers/block/floppy.c:	base = bio_data(current_req->bio);
drivers/block/floppy.c:		pr_info("current_req->nr_sectors=%u\n",
drivers/block/floppy.c:		pr_info("current_req->current_nr_sectors=%u\n",
drivers/block/floppy.c:	set_fdc((long)current_req->rq_disk->private_data);
drivers/block/floppy.c:	} else if ((unsigned long)bio_data(current_req->bio) < MAX_DMA_ADDRESS) {
drivers/block/floppy.c:			     ((unsigned long)bio_data(current_req->bio))) >> 9;
drivers/block/floppy.c:		if (CROSS_64KB(bio_data(current_req->bio), max_size << 9))
drivers/block/floppy.c:				    ((unsigned long)bio_data(current_req->bio)) %
drivers/block/floppy.c:			raw_cmd->kernel_data = bio_data(current_req->bio);
drivers/block/floppy.c:	    (raw_cmd->kernel_data != bio_data(current_req->bio) &&
drivers/block/floppy.c:		if (raw_cmd->kernel_data != bio_data(current_req->bio))
drivers/block/floppy.c:	if (raw_cmd->kernel_data != bio_data(current_req->bio)) {
drivers/block/floppy.c:		current_req->error_count = 0;
drivers/block/floppy.c:		list_del_init(&current_req->queuelist);
drivers/block/floppy.c:	drive = (long)current_req->rq_disk->private_data;
drivers/block/floppy.c:	errors = &(current_req->error_count);
drivers/block/floppy.c:		 (unsigned long long) current_req->cmd_flags))
drivers/block/nbd.c:			blk_rq_bytes(req), (req->timeout / HZ) * cmd->retries);
drivers/block/nbd.c:	if (req->cmd_flags & REQ_FUA)
drivers/block/nbd.c:	bio = req->bio;
drivers/block/aoe/aoecmd.c:		req->nr_bios = 0;
drivers/block/aoe/aoecmd.c:			req->nr_bios++;
drivers/block/aoe/aoecmd.c:	if (--req->nr_bios == 0)
drivers/block/aoe/aoedev.c:		req->nr_bios--;
drivers/block/aoe/aoedev.c:	if (!req->nr_bios)
drivers/block/z2ram.c:		void *buffer = bio_data(req->bio);
drivers/block/xen-blkback/blkback.c:		list_del(&req->free_list);
drivers/block/xen-blkback/blkback.c:	list_add(&req->free_list, &ring->pending_free);
drivers/block/xen-blkback/blkback.c:	if (likely(req->nr_sects)) {
drivers/block/xen-blkback/blkback.c:		blkif_sector_t end = req->sector_number + req->nr_sects;
drivers/block/xen-blkback/blkback.c:		if (unlikely(end < req->sector_number))
drivers/block/xen-blkback/blkback.c:	req->dev  = vbd->pdevice;
drivers/block/xen-blkback/blkback.c:	req->bdev = vbd->bdev;
drivers/block/xen-blkback/blkback.c:	struct xen_blkif_ring *ring = pending_req->ring;
drivers/block/xen-blkback/blkback.c:	make_response(ring, pending_req->id,
drivers/block/xen-blkback/blkback.c:		      pending_req->operation, pending_req->status);
drivers/block/xen-blkback/blkback.c:	struct gntab_unmap_queue_data* work = &req->gnttab_unmap_data;
drivers/block/xen-blkback/blkback.c:	struct xen_blkif_ring *ring = req->ring;
drivers/block/xen-blkback/blkback.c:	struct grant_page **pages = req->segments;
drivers/block/xen-blkback/blkback.c:	invcount = xen_blkbk_unmap_prepare(ring, pages, req->nr_segs,
drivers/block/xen-blkback/blkback.c:					   req->unmap, req->unmap_pages);
drivers/block/xen-blkback/blkback.c:	work->unmap_ops = req->unmap;
drivers/block/xen-blkback/blkback.c:	work->pages = req->unmap_pages;
drivers/block/xen-blkback/blkback.c:	gnttab_unmap_refs_async(&req->gnttab_unmap_data);
drivers/block/xen-blkback/blkback.c:	rc = xen_blkbk_map(pending_req->ring, pending_req->segments,
drivers/block/xen-blkback/blkback.c:			   pending_req->nr_segs,
drivers/block/xen-blkback/blkback.c:	                   (pending_req->operation != BLKIF_OP_READ));
drivers/block/xen-blkback/blkback.c:	struct grant_page **pages = pending_req->indirect_pages;
drivers/block/xen-blkback/blkback.c:	struct xen_blkif_ring *ring = pending_req->ring;
drivers/block/xen-blkback/blkback.c:	nseg = pending_req->nr_segs;
drivers/block/xen-blkback/blkback.c:		pages[i]->gref = req->u.indirect.indirect_grefs[i];
drivers/block/xen-blkback/blkback.c:		pending_req->segments[n]->gref = segments[i].gref;
drivers/block/xen-blkback/blkback.c:		preq->nr_sects += seg[n].nsec;
drivers/block/xen-blkback/blkback.c:	preq.sector_number = req->u.discard.sector_number;
drivers/block/xen-blkback/blkback.c:	preq.nr_sects      = req->u.discard.nr_sectors;
drivers/block/xen-blkback/blkback.c:		 (req->u.discard.flag & BLKIF_DISCARD_SECURE)) ?
drivers/block/xen-blkback/blkback.c:	err = blkdev_issue_discard(bdev, req->u.discard.sector_number,
drivers/block/xen-blkback/blkback.c:				   req->u.discard.nr_sectors,
drivers/block/xen-blkback/blkback.c:	make_response(ring, req->u.discard.id, req->operation, status);
drivers/block/xen-blkback/blkback.c:	make_response(ring, req->u.other.id, req->operation,
drivers/block/xen-blkback/blkback.c:	if (pending_req->operation == BLKIF_OP_FLUSH_DISKCACHE &&
drivers/block/xen-blkback/blkback.c:		xen_blkbk_flush_diskcache(XBT_NIL, pending_req->ring->blkif->be, 0);
drivers/block/xen-blkback/blkback.c:		pending_req->status = BLKIF_RSP_EOPNOTSUPP;
drivers/block/xen-blkback/blkback.c:	} else if (pending_req->operation == BLKIF_OP_WRITE_BARRIER &&
drivers/block/xen-blkback/blkback.c:		xen_blkbk_barrier(XBT_NIL, pending_req->ring->blkif->be, 0);
drivers/block/xen-blkback/blkback.c:		pending_req->status = BLKIF_RSP_EOPNOTSUPP;
drivers/block/xen-blkback/blkback.c:		pending_req->status = BLKIF_RSP_ERROR;
drivers/block/xen-blkback/blkback.c:	if (atomic_dec_and_test(&pending_req->pendcnt))
drivers/block/xen-blkback/blkback.c:	struct seg_buf *seg = pending_req->seg;
drivers/block/xen-blkback/blkback.c:	struct bio **biolist = pending_req->biolist;
drivers/block/xen-blkback/blkback.c:	struct grant_page **pages = pending_req->segments;
drivers/block/xen-blkback/blkback.c:	req_operation = req->operation == BLKIF_OP_INDIRECT ?
drivers/block/xen-blkback/blkback.c:			req->u.indirect.indirect_op : req->operation;
drivers/block/xen-blkback/blkback.c:	if ((req->operation == BLKIF_OP_INDIRECT) &&
drivers/block/xen-blkback/blkback.c:	nseg = req->operation == BLKIF_OP_INDIRECT ?
drivers/block/xen-blkback/blkback.c:	       req->u.indirect.nr_segments : req->u.rw.nr_segments;
drivers/block/xen-blkback/blkback.c:	    unlikely((req->operation != BLKIF_OP_INDIRECT) &&
drivers/block/xen-blkback/blkback.c:	    unlikely((req->operation == BLKIF_OP_INDIRECT) &&
drivers/block/xen-blkback/blkback.c:	pending_req->ring      = ring;
drivers/block/xen-blkback/blkback.c:	pending_req->id        = req->u.rw.id;
drivers/block/xen-blkback/blkback.c:	pending_req->operation = req_operation;
drivers/block/xen-blkback/blkback.c:	pending_req->status    = BLKIF_RSP_OKAY;
drivers/block/xen-blkback/blkback.c:	pending_req->nr_segs   = nseg;
drivers/block/xen-blkback/blkback.c:	if (req->operation != BLKIF_OP_INDIRECT) {
drivers/block/xen-blkback/blkback.c:		preq.dev               = req->u.rw.handle;
drivers/block/xen-blkback/blkback.c:		preq.sector_number     = req->u.rw.sector_number;
drivers/block/xen-blkback/blkback.c:			pages[i]->gref = req->u.rw.seg[i].gref;
drivers/block/xen-blkback/blkback.c:			seg[i].nsec = req->u.rw.seg[i].last_sect -
drivers/block/xen-blkback/blkback.c:				req->u.rw.seg[i].first_sect + 1;
drivers/block/xen-blkback/blkback.c:			seg[i].offset = (req->u.rw.seg[i].first_sect << 9);
drivers/block/xen-blkback/blkback.c:			if ((req->u.rw.seg[i].last_sect >= (XEN_PAGE_SIZE >> 9)) ||
drivers/block/xen-blkback/blkback.c:			    (req->u.rw.seg[i].last_sect <
drivers/block/xen-blkback/blkback.c:			     req->u.rw.seg[i].first_sect))
drivers/block/xen-blkback/blkback.c:		preq.dev               = req->u.indirect.handle;
drivers/block/xen-blkback/blkback.c:		preq.sector_number     = req->u.indirect.sector_number;
drivers/block/xen-blkback/blkback.c:		xen_blk_drain_io(pending_req->ring);
drivers/block/xen-blkback/blkback.c:	atomic_set(&pending_req->pendcnt, nbio);
drivers/block/xen-blkback/blkback.c:	xen_blkbk_unmap(ring, pending_req->segments,
drivers/block/xen-blkback/blkback.c:	                pending_req->nr_segs);
drivers/block/xen-blkback/blkback.c:	make_response(ring, req->u.rw.id, req_operation, BLKIF_RSP_ERROR);
drivers/block/xen-blkback/blkback.c:	atomic_set(&pending_req->pendcnt, 1);
drivers/block/xen-blkback/xenbus.c:			list_del(&req->free_list);
drivers/block/xen-blkback/xenbus.c:				kfree(req->segments[j]);
drivers/block/xen-blkback/xenbus.c:				kfree(req->indirect_pages[j]);
drivers/block/xen-blkback/xenbus.c:		list_add_tail(&req->free_list, &ring->pending_free);
drivers/block/xen-blkback/xenbus.c:			req->segments[j] = kzalloc(sizeof(*req->segments[0]), GFP_KERNEL);
drivers/block/xen-blkback/xenbus.c:			if (!req->segments[j])
drivers/block/xen-blkback/xenbus.c:			req->indirect_pages[j] = kzalloc(sizeof(*req->indirect_pages[0]),
drivers/block/xen-blkback/xenbus.c:			if (!req->indirect_pages[j])
drivers/block/xen-blkback/xenbus.c:		list_del(&req->free_list);
drivers/block/xen-blkback/xenbus.c:			if (!req->segments[j])
drivers/block/xen-blkback/xenbus.c:			kfree(req->segments[j]);
drivers/block/xen-blkback/xenbus.c:			if (!req->indirect_pages[j])
drivers/block/xen-blkback/xenbus.c:			kfree(req->indirect_pages[j]);
drivers/block/virtio_blk.c:	if (queue_max_discard_segments(req->q) == 1) {
drivers/block/virtio_blk.c:	req->special_vec.bv_page = virt_to_page(range);
drivers/block/virtio_blk.c:	req->special_vec.bv_offset = offset_in_page(range);
drivers/block/virtio_blk.c:	req->special_vec.bv_len = sizeof(*range) * segments;
drivers/block/virtio_blk.c:	req->rq_flags |= RQF_SPECIAL_PAYLOAD;
drivers/block/virtio_blk.c:	if (req->rq_flags & RQF_SPECIAL_PAYLOAD) {
drivers/block/virtio_blk.c:		kfree(page_address(req->special_vec.bv_page) +
drivers/block/virtio_blk.c:		      req->special_vec.bv_offset);
drivers/block/virtio_blk.c:			if (likely(!blk_should_fake_timeout(req->q)))
drivers/block/virtio_blk.c:	BUG_ON(req->nr_phys_segments + 2 > vblk->sg_elems);
drivers/block/virtio_blk.c:		unmap = !(req->cmd_flags & REQ_NOUNMAP);
drivers/block/xsysace.c:		ace->data_ptr = bio_data(req->bio);
drivers/block/xsysace.c:			ace->data_ptr = bio_data(ace->req->bio);
drivers/block/xsysace.c:	list_add_tail(&req->queuelist, &ace->rq_list);
drivers/iommu/virtio-iommu.c:	if (req->type == VIRTIO_IOMMU_T_PROBE)
drivers/iommu/virtio-iommu.c:			viommu_set_req_status(req->buf, req->len,
drivers/iommu/virtio-iommu.c:		write_len = req->len - req->write_offset;
drivers/iommu/virtio-iommu.c:		if (req->writeback && len == write_len)
drivers/iommu/virtio-iommu.c:			memcpy(req->writeback, req->buf + req->write_offset,
drivers/iommu/virtio-iommu.c:		list_del(&req->list);
drivers/iommu/virtio-iommu.c:	req->len = len;
drivers/iommu/virtio-iommu.c:		req->writeback = buf + write_offset;
drivers/iommu/virtio-iommu.c:		req->write_offset = write_offset;
drivers/iommu/virtio-iommu.c:	memcpy(&req->buf, buf, write_offset);
drivers/iommu/virtio-iommu.c:	sg_init_one(&top_sg, req->buf, write_offset);
drivers/iommu/virtio-iommu.c:	sg_init_one(&bottom_sg, req->buf + write_offset, len - write_offset);
drivers/iommu/virtio-iommu.c:	list_add_tail(&req->list, &viommu->requests);
drivers/iommu/intel/svm.c:	if (req->exe_req)
drivers/iommu/intel/svm.c:	if (req->rd_req)
drivers/iommu/intel/svm.c:	if (req->wr_req)
drivers/iommu/intel/svm.c:		if (!req->pasid_present || req->pasid != pasid) {
drivers/iommu/intel/svm.c:	if (req->rd_req)
drivers/iommu/intel/svm.c:	if (req->wr_req)
drivers/iommu/intel/svm.c:	if (req->exe_req)
drivers/iommu/intel/svm.c:	if (req->pm_req)
drivers/iommu/intel/svm.c:		address = (u64)req->addr << VTD_PAGE_SHIFT;
drivers/iommu/intel/svm.c:		if (!req->pasid_present) {
drivers/iommu/intel/svm.c:		if (!svm || svm->pasid != req->pasid) {
drivers/iommu/intel/svm.c:			svm = ioasid_find(NULL, req->pasid, NULL);
drivers/iommu/intel/svm.c:				       iommu->name, req->pasid, ((unsigned long long *)req)[0],
drivers/iommu/intel/svm.c:		if (!sdev || sdev->sid != req->rid) {
drivers/iommu/intel/svm.c:				if (t->sid == req->rid) {
drivers/iommu/intel/svm.c:				      req->wr_req ? FAULT_FLAG_WRITE : 0,
drivers/iommu/intel/svm.c:			int rwxp = (req->rd_req << 3) | (req->wr_req << 2) |
drivers/iommu/intel/svm.c:				(req->exe_req << 1) | (req->pm_req);
drivers/iommu/intel/svm.c:			sdev->ops->fault_cb(sdev->dev, req->pasid, req->addr,
drivers/iommu/intel/svm.c:					    req->priv_data, rwxp, result);
drivers/iommu/intel/svm.c:		if (req->lpig || req->priv_data_present) {
drivers/iommu/intel/svm.c:			resp.qw0 = QI_PGRP_PASID(req->pasid) |
drivers/iommu/intel/svm.c:				QI_PGRP_DID(req->rid) |
drivers/iommu/intel/svm.c:				QI_PGRP_PASID_P(req->pasid_present) |
drivers/iommu/intel/svm.c:				QI_PGRP_PDP(req->priv_data_present) |
drivers/iommu/intel/svm.c:			resp.qw1 = QI_PGRP_IDX(req->prg_index) |
drivers/iommu/intel/svm.c:				QI_PGRP_LPIG(req->lpig);
drivers/iommu/intel/svm.c:			if (req->priv_data_present)
drivers/iommu/intel/svm.c:				memcpy(&resp.qw2, req->priv_data,
drivers/iommu/intel/svm.c:				       sizeof(req->priv_data));
drivers/nvme/host/tcp.c:	return req == &req->queue->ctrl->async_req;
drivers/nvme/host/tcp.c:	return rq_data_dir(rq) == WRITE && req->data_len &&
drivers/nvme/host/tcp.c:		req->data_len <= nvme_tcp_inline_data_size(req->queue);
drivers/nvme/host/tcp.c:	return req->iter.bvec->bv_page;
drivers/nvme/host/tcp.c:	return req->iter.bvec->bv_offset + req->iter.iov_offset;
drivers/nvme/host/tcp.c:	return min_t(size_t, iov_iter_single_seg_count(&req->iter),
drivers/nvme/host/tcp.c:			req->pdu_len - req->pdu_sent);
drivers/nvme/host/tcp.c:			req->pdu_len - req->pdu_sent : 0;
drivers/nvme/host/tcp.c:		struct bio *bio = req->curr_bio;
drivers/nvme/host/tcp.c:	iov_iter_bvec(&req->iter, dir, vec, nr_bvec, size);
drivers/nvme/host/tcp.c:	req->iter.iov_offset = offset;
drivers/nvme/host/tcp.c:	req->data_sent += len;
drivers/nvme/host/tcp.c:	req->pdu_sent += len;
drivers/nvme/host/tcp.c:	iov_iter_advance(&req->iter, len);
drivers/nvme/host/tcp.c:	if (!iov_iter_count(&req->iter) &&
drivers/nvme/host/tcp.c:	    req->data_sent < req->data_len) {
drivers/nvme/host/tcp.c:		req->curr_bio = req->curr_bio->bi_next;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:	empty = llist_add(&req->lentry, &queue->req_list) &&
drivers/nvme/host/tcp.c:		list_add(&req->entry, &queue->send_list);
drivers/nvme/host/tcp.c:	list_del(&req->entry);
drivers/nvme/host/tcp.c:	page_frag_free(req->pdu);
drivers/nvme/host/tcp.c:	req->pdu = page_frag_alloc(&queue->pf_cache,
drivers/nvme/host/tcp.c:	if (!req->pdu)
drivers/nvme/host/tcp.c:	req->queue = queue;
drivers/nvme/host/tcp.c:	struct nvme_tcp_data_pdu *data = req->pdu;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:	req->pdu_len = le32_to_cpu(pdu->r2t_length);
drivers/nvme/host/tcp.c:	req->pdu_sent = 0;
drivers/nvme/host/tcp.c:	if (unlikely(!req->pdu_len)) {
drivers/nvme/host/tcp.c:			rq->tag, req->pdu_len);
drivers/nvme/host/tcp.c:	if (unlikely(req->data_sent + req->pdu_len > req->data_len)) {
drivers/nvme/host/tcp.c:			rq->tag, req->pdu_len, req->data_len,
drivers/nvme/host/tcp.c:			req->data_sent);
drivers/nvme/host/tcp.c:	if (unlikely(le32_to_cpu(pdu->r2t_offset) < req->data_sent)) {
drivers/nvme/host/tcp.c:			req->data_sent);
drivers/nvme/host/tcp.c:		cpu_to_le32(data->hdr.hlen + hdgst + req->pdu_len + ddgst);
drivers/nvme/host/tcp.c:	data->data_offset = cpu_to_le32(req->data_sent);
drivers/nvme/host/tcp.c:	data->data_length = cpu_to_le32(req->pdu_len);
drivers/nvme/host/tcp.c:	req->state = NVME_TCP_SEND_H2C_PDU;
drivers/nvme/host/tcp.c:	req->offset = 0;
drivers/nvme/host/tcp.c:		if (!iov_iter_count(&req->iter)) {
drivers/nvme/host/tcp.c:			req->curr_bio = req->curr_bio->bi_next;
drivers/nvme/host/tcp.c:			if (!req->curr_bio) {
drivers/nvme/host/tcp.c:				iov_iter_count(&req->iter));
drivers/nvme/host/tcp.c:				&req->iter, recv_len, queue->rcv_hash);
drivers/nvme/host/tcp.c:					&req->iter, recv_len);
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:					&req->ddgst);
drivers/nvme/host/tcp.c:				req->state = NVME_TCP_SEND_DDGST;
drivers/nvme/host/tcp.c:				req->offset = 0;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/tcp.c:	int len = sizeof(*pdu) + hdgst - req->offset;
drivers/nvme/host/tcp.c:	if (queue->hdr_digest && !req->offset)
drivers/nvme/host/tcp.c:			offset_in_page(pdu) + req->offset, len,  flags);
drivers/nvme/host/tcp.c:			req->state = NVME_TCP_SEND_DATA;
drivers/nvme/host/tcp.c:	req->offset += ret;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:	struct nvme_tcp_data_pdu *pdu = req->pdu;
drivers/nvme/host/tcp.c:	int len = sizeof(*pdu) - req->offset + hdgst;
drivers/nvme/host/tcp.c:	if (queue->hdr_digest && !req->offset)
drivers/nvme/host/tcp.c:			offset_in_page(pdu) + req->offset, len,
drivers/nvme/host/tcp.c:		req->state = NVME_TCP_SEND_DATA;
drivers/nvme/host/tcp.c:	req->offset += ret;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:		.iov_base = &req->ddgst + req->offset,
drivers/nvme/host/tcp.c:		.iov_len = NVME_TCP_DIGEST_LENGTH - req->offset
drivers/nvme/host/tcp.c:	if (req->offset + ret == NVME_TCP_DIGEST_LENGTH) {
drivers/nvme/host/tcp.c:	req->offset += ret;
drivers/nvme/host/tcp.c:	if (req->state == NVME_TCP_SEND_CMD_PDU) {
drivers/nvme/host/tcp.c:	if (req->state == NVME_TCP_SEND_H2C_PDU) {
drivers/nvme/host/tcp.c:	if (req->state == NVME_TCP_SEND_DATA) {
drivers/nvme/host/tcp.c:	if (req->state == NVME_TCP_SEND_DDGST)
drivers/nvme/host/tcp.c:	icreq->hdr.type = nvme_tcp_icreq;
drivers/nvme/host/tcp.c:	icreq->hdr.hlen = sizeof(*icreq);
drivers/nvme/host/tcp.c:	icreq->hdr.pdo = 0;
drivers/nvme/host/tcp.c:	icreq->hdr.plen = cpu_to_le32(icreq->hdr.hlen);
drivers/nvme/host/tcp.c:	icreq->pfv = cpu_to_le16(NVME_TCP_PFV_1_0);
drivers/nvme/host/tcp.c:	icreq->maxr2t = 0; /* single inflight r2t supported */
drivers/nvme/host/tcp.c:	icreq->hpda = 0; /* no alignment constraint */
drivers/nvme/host/tcp.c:		icreq->digest |= NVME_TCP_HDR_DIGEST_ENABLE;
drivers/nvme/host/tcp.c:		icreq->digest |= NVME_TCP_DATA_DIGEST_ENABLE;
drivers/nvme/host/tcp.c:	struct nvme_ctrl *ctrl = &req->queue->ctrl->ctrl;
drivers/nvme/host/tcp.c:	nvme_tcp_stop_queue(ctrl, nvme_tcp_queue_id(req->queue));
drivers/nvme/host/tcp.c:	struct nvme_ctrl *ctrl = &req->queue->ctrl->ctrl;
drivers/nvme/host/tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/tcp.c:		nvme_tcp_queue_id(req->queue), rq->tag, pdu->hdr.type);
drivers/nvme/host/tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/tcp.c:	    req->data_len <= nvme_tcp_inline_data_size(queue))
drivers/nvme/host/tcp.c:		nvme_tcp_set_sg_inline(queue, c, req->data_len);
drivers/nvme/host/tcp.c:		nvme_tcp_set_sg_host_data(c, req->data_len);
drivers/nvme/host/tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/tcp.c:	req->state = NVME_TCP_SEND_CMD_PDU;
drivers/nvme/host/tcp.c:	req->offset = 0;
drivers/nvme/host/tcp.c:	req->data_sent = 0;
drivers/nvme/host/tcp.c:	req->pdu_len = 0;
drivers/nvme/host/tcp.c:	req->pdu_sent = 0;
drivers/nvme/host/tcp.c:	req->data_len = blk_rq_nr_phys_segments(rq) ?
drivers/nvme/host/tcp.c:	req->curr_bio = rq->bio;
drivers/nvme/host/tcp.c:	if (req->curr_bio && req->data_len)
drivers/nvme/host/tcp.c:	    req->data_len <= nvme_tcp_inline_data_size(queue))
drivers/nvme/host/tcp.c:		req->pdu_len = req->data_len;
drivers/nvme/host/tcp.c:	if (queue->data_digest && req->pdu_len) {
drivers/nvme/host/tcp.c:	pdu->hdr.pdo = req->pdu_len ? pdu->hdr.hlen + hdgst : 0;
drivers/nvme/host/tcp.c:		cpu_to_le32(pdu->hdr.hlen + hdgst + req->pdu_len + ddgst);
drivers/nvme/host/nvme.h:	if (!req->q->queuedata)
drivers/nvme/host/nvme.h:	return req->mq_hctx->queue_num + 1;
drivers/nvme/host/nvme.h:	if (req->xrp_command) {
drivers/nvme/host/nvme.h:		kfree(req->xrp_command);
drivers/nvme/host/nvme.h:		req->xrp_command = NULL;
drivers/nvme/host/nvme.h:	if (unlikely(blk_should_fake_timeout(req->q)))
drivers/nvme/host/nvme.h:	struct nvme_ns *ns = req->q->queuedata;
drivers/nvme/host/nvme.h:	if (req->cmd_flags & REQ_NVME_MPATH)
drivers/nvme/host/nvme.h:		trace_block_bio_complete(ns->head->disk->queue, req->bio);
drivers/nvme/host/pci.c:	iod->nents = blk_rq_map_sg(req->q, req, iod->sg);
drivers/nvme/host/pci.c:	if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/pci.c:			req->xrp_command = NULL;
drivers/nvme/host/pci.c:			req->xrp_command = cmndp;
drivers/nvme/host/pci.c:		req->xrp_command = NULL;
drivers/nvme/host/pci.c:	if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/pci.c:    req->status = 1;
drivers/nvme/host/pci.c:    req->cpu_arival = 0;
drivers/nvme/host/pci.c:    req->prev_cpu_arival = 0;
drivers/nvme/host/pci.c:        req->cpu_arival = ktime_get_ns();
drivers/nvme/host/pci.c:        req->prev_cpu_arival = 0;
drivers/nvme/host/pci.c:        while (req->prev_cpu_arival == 0) { msleep(1); }
drivers/nvme/host/pci.c:	if (!req->bio || !req->bio->xrp_enabled) {
drivers/nvme/host/pci.c:        phys_addr_t phys = req->xrp_command->rw.rsvd2;
drivers/nvme/host/pci.c:		struct resubmit_data *data = req->on_meta;
drivers/nvme/host/pci.c:            if (!xrp_check_tree(req->bio->xrp_inode, data->extents, data->num_extents)) {
drivers/nvme/host/pci.c:                req->xrp_command->rw.slba = first_slba;
drivers/nvme/host/pci.c:                req->xrp_command->rw.rsvd2 = (u64)phys;
drivers/nvme/host/pci.c:		        nvme_submit_cmd(nvmeq, req->xrp_command, true);
drivers/nvme/host/pci.c:        ebpf_context.data = page_address(bio_page(req->bio));
drivers/nvme/host/pci.c:		ebpf_context.scratch = page_address(req->bio->xrp_scratch_page);
drivers/nvme/host/pci.c:		ebpf_prog = req->bio->xrp_bpf_prog;
drivers/nvme/host/pci.c:            if (!xrp_check_tree(req->bio->xrp_inode, data->extents, data->num_extents)) {
drivers/nvme/host/pci.c:                req->xrp_command->rw.slba = first_slba;
drivers/nvme/host/pci.c:                req->xrp_command->rw.rsvd2 = (u64)phys;
drivers/nvme/host/pci.c:		        nvme_submit_cmd(nvmeq, req->xrp_command, true);
drivers/nvme/host/pci.c:		if (req->bio->xrp_inode->i_op == &ext4_file_inode_operations) {
drivers/nvme/host/pci.c:			//xrp_retrieve_mapping(req->bio->xrp_inode, file_offset, data_len, &mapping);
drivers/nvme/host/pci.c:				//req->bio->xrp_extent_version = mapping.version;
drivers/nvme/host/pci.c:		nvme_req(req)->cmd = req->xrp_command;
drivers/nvme/host/pci.c:		req->bio->bi_iter.bi_sector = (disk_offset >> 9) + req->bio->xrp_partition_start_sector;
drivers/nvme/host/pci.c:		req->__sector = req->bio->bi_iter.bi_sector;
drivers/nvme/host/pci.c:		req->xrp_command->rw.slba = cpu_to_le64(nvme_sect_to_lba(req->q->queuedata, blk_rq_pos(req)));
drivers/nvme/host/pci.c:        atomic64_set(&data->slba, cpu_to_le64(nvme_sect_to_lba(req->q->queuedata, blk_rq_pos(req))));
drivers/nvme/host/pci.c:		nvme_submit_cmd(nvmeq, req->xrp_command, true);
drivers/nvme/host/pci.c:        if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/pci.c:            nvme_poll(req->mq_hctx);
drivers/nvme/host/pci.c:                 req->tag, nvmeq->qid);
drivers/nvme/host/pci.c:                 req->tag, nvmeq->qid);
drivers/nvme/host/pci.c:                 req->tag, nvmeq->qid);
drivers/nvme/host/pci.c:        cmd.abort.cid = req->tag;
drivers/nvme/host/pci.c:             req->tag, nvmeq->qid);
drivers/nvme/host/pci.c:        abort_req->end_io_data = NULL;
drivers/nvme/host/pci.c:        struct nvme_queue *nvmeq = req->end_io_data;
drivers/nvme/host/pci.c:        struct nvme_queue *nvmeq = req->end_io_data;
drivers/nvme/host/pci.c:        req->end_io_data = nvmeq;
drivers/nvme/host/fault_inject.c:	struct gendisk *disk = req->rq_disk;
drivers/nvme/host/rdma.c:	kfree(req->sqe.data);
drivers/nvme/host/rdma.c:	req->sqe.data = kzalloc(sizeof(struct nvme_command), GFP_KERNEL);
drivers/nvme/host/rdma.c:	if (!req->sqe.data)
drivers/nvme/host/rdma.c:		req->metadata_sgl = (void *)nvme_req(rq) +
drivers/nvme/host/rdma.c:	req->queue = queue;
drivers/nvme/host/rdma.c:	if (!refcount_dec_and_test(&req->ref))
drivers/nvme/host/rdma.c:	if (!nvme_try_complete_req(rq, req->status, req->result))
drivers/nvme/host/rdma.c:		.ex.invalidate_rkey = req->mr->rkey,
drivers/nvme/host/rdma.c:	req->reg_cqe.done = nvme_rdma_inv_rkey_done;
drivers/nvme/host/rdma.c:	wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/rdma.c:		ib_dma_unmap_sg(ibdev, req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/rdma.c:				req->metadata_sgl->nents, rq_dma_dir(rq));
drivers/nvme/host/rdma.c:		sg_free_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/rdma.c:	if (req->use_sig_mr)
drivers/nvme/host/rdma.c:	if (req->mr) {
drivers/nvme/host/rdma.c:		ib_mr_pool_put(queue->qp, pool, req->mr);
drivers/nvme/host/rdma.c:		req->mr = NULL;
drivers/nvme/host/rdma.c:	ib_dma_unmap_sg(ibdev, req->data_sgl.sg_table.sgl, req->data_sgl.nents,
drivers/nvme/host/rdma.c:	sg_free_table_chained(&req->data_sgl.sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/rdma.c:	struct scatterlist *sgl = req->data_sgl.sg_table.sgl;
drivers/nvme/host/rdma.c:	struct ib_sge *sge = &req->sge[1];
drivers/nvme/host/rdma.c:	req->num_sge += count;
drivers/nvme/host/rdma.c:	sg->addr = cpu_to_le64(sg_dma_address(req->data_sgl.sg_table.sgl));
drivers/nvme/host/rdma.c:	put_unaligned_le24(sg_dma_len(req->data_sgl.sg_table.sgl), sg->length);
drivers/nvme/host/rdma.c:	req->mr = ib_mr_pool_get(queue->qp, &queue->qp->rdma_mrs);
drivers/nvme/host/rdma.c:	if (WARN_ON_ONCE(!req->mr))
drivers/nvme/host/rdma.c:	nr = ib_map_mr_sg(req->mr, req->data_sgl.sg_table.sgl, count, NULL,
drivers/nvme/host/rdma.c:		ib_mr_pool_put(queue->qp, &queue->qp->rdma_mrs, req->mr);
drivers/nvme/host/rdma.c:		req->mr = NULL;
drivers/nvme/host/rdma.c:	ib_update_fast_reg_key(req->mr, ib_inc_rkey(req->mr->rkey));
drivers/nvme/host/rdma.c:	req->reg_cqe.done = nvme_rdma_memreg_done;
drivers/nvme/host/rdma.c:	memset(&req->reg_wr, 0, sizeof(req->reg_wr));
drivers/nvme/host/rdma.c:	req->reg_wr.wr.opcode = IB_WR_REG_MR;
drivers/nvme/host/rdma.c:	req->reg_wr.wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/rdma.c:	req->reg_wr.wr.num_sge = 0;
drivers/nvme/host/rdma.c:	req->reg_wr.mr = req->mr;
drivers/nvme/host/rdma.c:	req->reg_wr.key = req->mr->rkey;
drivers/nvme/host/rdma.c:	req->reg_wr.access = IB_ACCESS_LOCAL_WRITE |
drivers/nvme/host/rdma.c:	sg->addr = cpu_to_le64(req->mr->iova);
drivers/nvme/host/rdma.c:	put_unaligned_le24(req->mr->length, sg->length);
drivers/nvme/host/rdma.c:	put_unaligned_le32(req->mr->rkey, sg->key);
drivers/nvme/host/rdma.c:	struct nvme_rdma_sgl *sgl = &req->data_sgl;
drivers/nvme/host/rdma.c:	struct ib_reg_wr *wr = &req->reg_wr;
drivers/nvme/host/rdma.c:	req->mr = ib_mr_pool_get(queue->qp, &queue->qp->sig_mrs);
drivers/nvme/host/rdma.c:	if (WARN_ON_ONCE(!req->mr))
drivers/nvme/host/rdma.c:	nr = ib_map_mr_sg_pi(req->mr, sgl->sg_table.sgl, count, NULL,
drivers/nvme/host/rdma.c:			     req->metadata_sgl->sg_table.sgl, pi_count, NULL,
drivers/nvme/host/rdma.c:				req->mr->sig_attrs, ns->pi_type);
drivers/nvme/host/rdma.c:	nvme_rdma_set_prot_checks(c, &req->mr->sig_attrs->check_mask);
drivers/nvme/host/rdma.c:	ib_update_fast_reg_key(req->mr, ib_inc_rkey(req->mr->rkey));
drivers/nvme/host/rdma.c:	req->reg_cqe.done = nvme_rdma_sig_done;
drivers/nvme/host/rdma.c:	wr->wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/rdma.c:	wr->mr = req->mr;
drivers/nvme/host/rdma.c:	wr->key = req->mr->rkey;
drivers/nvme/host/rdma.c:	sg->addr = cpu_to_le64(req->mr->iova);
drivers/nvme/host/rdma.c:	put_unaligned_le24(req->mr->length, sg->length);
drivers/nvme/host/rdma.c:	put_unaligned_le32(req->mr->rkey, sg->key);
drivers/nvme/host/rdma.c:	ib_mr_pool_put(queue->qp, &queue->qp->sig_mrs, req->mr);
drivers/nvme/host/rdma.c:	req->mr = NULL;
drivers/nvme/host/rdma.c:	req->num_sge = 1;
drivers/nvme/host/rdma.c:	refcount_set(&req->ref, 2); /* send and recv completions */
drivers/nvme/host/rdma.c:	req->data_sgl.sg_table.sgl = (struct scatterlist *)(req + 1);
drivers/nvme/host/rdma.c:	ret = sg_alloc_table_chained(&req->data_sgl.sg_table,
drivers/nvme/host/rdma.c:			blk_rq_nr_phys_segments(rq), req->data_sgl.sg_table.sgl,
drivers/nvme/host/rdma.c:	req->data_sgl.nents = blk_rq_map_sg(rq->q, rq,
drivers/nvme/host/rdma.c:					    req->data_sgl.sg_table.sgl);
drivers/nvme/host/rdma.c:	count = ib_dma_map_sg(ibdev, req->data_sgl.sg_table.sgl,
drivers/nvme/host/rdma.c:			      req->data_sgl.nents, rq_dma_dir(rq));
drivers/nvme/host/rdma.c:		req->metadata_sgl->sg_table.sgl =
drivers/nvme/host/rdma.c:			(struct scatterlist *)(req->metadata_sgl + 1);
drivers/nvme/host/rdma.c:		ret = sg_alloc_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/rdma.c:				req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/rdma.c:		req->metadata_sgl->nents = blk_rq_map_integrity_sg(rq->q,
drivers/nvme/host/rdma.c:				rq->bio, req->metadata_sgl->sg_table.sgl);
drivers/nvme/host/rdma.c:					 req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/rdma.c:					 req->metadata_sgl->nents,
drivers/nvme/host/rdma.c:	if (req->use_sig_mr) {
drivers/nvme/host/rdma.c:		ib_dma_unmap_sg(ibdev, req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/rdma.c:				req->metadata_sgl->nents, rq_dma_dir(rq));
drivers/nvme/host/rdma.c:		sg_free_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/rdma.c:	ib_dma_unmap_sg(ibdev, req->data_sgl.sg_table.sgl, req->data_sgl.nents,
drivers/nvme/host/rdma.c:	sg_free_table_chained(&req->data_sgl.sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/rdma.c:	req->status = cqe->status;
drivers/nvme/host/rdma.c:	req->result = cqe->result;
drivers/nvme/host/rdma.c:		if (unlikely(!req->mr ||
drivers/nvme/host/rdma.c:			     wc->ex.invalidate_rkey != req->mr->rkey)) {
drivers/nvme/host/rdma.c:				req->mr ? req->mr->rkey : 0);
drivers/nvme/host/rdma.c:	} else if (req->mr) {
drivers/nvme/host/rdma.c:				req->mr->rkey, ret);
drivers/nvme/host/rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/rdma.c:	struct nvme_rdma_qe *sqe = &req->sqe;
drivers/nvme/host/rdma.c:	req->sqe.dma = ib_dma_map_single(dev, req->sqe.data,
drivers/nvme/host/rdma.c:	err = ib_dma_mapping_error(dev, req->sqe.dma);
drivers/nvme/host/rdma.c:		req->use_sig_mr = true;
drivers/nvme/host/rdma.c:		req->use_sig_mr = false;
drivers/nvme/host/rdma.c:	err = nvme_rdma_post_send(queue, sqe, req->sge, req->num_sge,
drivers/nvme/host/rdma.c:			req->mr ? &req->reg_wr.wr : NULL);
drivers/nvme/host/rdma.c:	ib_dma_unmap_single(dev, req->sqe.dma, sizeof(struct nvme_command),
drivers/nvme/host/rdma.c:	ret = ib_check_mr_status(req->mr, IB_MR_CHECK_SIG_STATUS, &mr_status);
drivers/nvme/host/rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/rdma.c:	if (req->use_sig_mr)
drivers/nvme/host/rdma.c:	ib_dma_unmap_single(ibdev, req->sqe.dma, sizeof(struct nvme_command),
drivers/nvme/host/fabrics.c:	if (rq->q == ctrl->admin_q && (req->flags & NVME_REQ_USERCMD))
drivers/nvme/host/fabrics.c:		if (blk_rq_is_passthrough(rq) && nvme_is_fabrics(req->cmd) &&
drivers/nvme/host/fabrics.c:		    req->cmd->fabrics.fctype == nvme_fabrics_type_connect)
drivers/nvme/host/fc.h:	lsreq->rqstaddr = discon_rqst;
drivers/nvme/host/fc.h:	lsreq->rqstlen = sizeof(*discon_rqst);
drivers/nvme/host/fc.h:	lsreq->rspaddr = discon_acc;
drivers/nvme/host/fc.h:	lsreq->rsplen = sizeof(*discon_acc);
drivers/nvme/host/fc.h:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/multipath.c:	struct nvme_ns *ns = req->q->queuedata;
drivers/nvme/host/fc.c:	fc_dma_unmap_single(rport->dev, lsreq->rqstdma,
drivers/nvme/host/fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/host/fc.c:	lsreq->done = done;
drivers/nvme/host/fc.c:	lsreq->rqstdma = fc_dma_map_single(rport->dev, lsreq->rqstaddr,
drivers/nvme/host/fc.c:				  lsreq->rqstlen + lsreq->rsplen,
drivers/nvme/host/fc.c:	if (fc_dma_mapping_error(rport->dev, lsreq->rqstdma)) {
drivers/nvme/host/fc.c:	lsreq->rspdma = lsreq->rqstdma + lsreq->rqstlen;
drivers/nvme/host/fc.c:	fc_dma_unmap_single(rport->dev, lsreq->rqstdma,
drivers/nvme/host/fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/host/fc.c:	struct fcnvme_ls_rjt *rjt = lsreq->rspaddr;
drivers/nvme/host/fc.c:		lsreq->private = &assoc_acc[1];
drivers/nvme/host/fc.c:		lsreq->private = NULL;
drivers/nvme/host/fc.c:	lsreq->rqstaddr = assoc_rqst;
drivers/nvme/host/fc.c:	lsreq->rqstlen = sizeof(*assoc_rqst);
drivers/nvme/host/fc.c:	lsreq->rspaddr = assoc_acc;
drivers/nvme/host/fc.c:	lsreq->rsplen = sizeof(*assoc_acc);
drivers/nvme/host/fc.c:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/fc.c:		lsreq->private = (void *)&conn_acc[1];
drivers/nvme/host/fc.c:		lsreq->private = NULL;
drivers/nvme/host/fc.c:	lsreq->rqstaddr = conn_rqst;
drivers/nvme/host/fc.c:	lsreq->rqstlen = sizeof(*conn_rqst);
drivers/nvme/host/fc.c:	lsreq->rspaddr = conn_acc;
drivers/nvme/host/fc.c:	lsreq->rsplen = sizeof(*conn_acc);
drivers/nvme/host/fc.c:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/fc.c:		lsreq->private = (void *)&discon_acc[1];
drivers/nvme/host/fc.c:		lsreq->private = NULL;
drivers/nvme/host/fc.c:	else if (freq->status) {
drivers/nvme/host/fc.c:			ctrl->cnum, freq->status);
drivers/nvme/host/fc.c:	switch (freq->rcv_rsplen) {
drivers/nvme/host/fc.c:		if (freq->transferred_length !=
drivers/nvme/host/fc.c:				ctrl->cnum, freq->transferred_length,
drivers/nvme/host/fc.c:					(freq->rcv_rsplen / 4) ||
drivers/nvme/host/fc.c:					freq->transferred_length ||
drivers/nvme/host/fc.c:				freq->transferred_length,
drivers/nvme/host/fc.c:			ctrl->cnum, freq->rcv_rsplen);
drivers/nvme/host/fc.c:	freq->sg_cnt = 0;
drivers/nvme/host/fc.c:	freq->sg_table.sgl = freq->first_sgl;
drivers/nvme/host/fc.c:	ret = sg_alloc_table_chained(&freq->sg_table,
drivers/nvme/host/fc.c:			blk_rq_nr_phys_segments(rq), freq->sg_table.sgl,
drivers/nvme/host/fc.c:	op->nents = blk_rq_map_sg(rq->q, rq, freq->sg_table.sgl);
drivers/nvme/host/fc.c:	freq->sg_cnt = fc_dma_map_sg(ctrl->lport->dev, freq->sg_table.sgl,
drivers/nvme/host/fc.c:	if (unlikely(freq->sg_cnt <= 0)) {
drivers/nvme/host/fc.c:		sg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/fc.c:		freq->sg_cnt = 0;
drivers/nvme/host/fc.c:	if (!freq->sg_cnt)
drivers/nvme/host/fc.c:	fc_dma_unmap_sg(ctrl->lport->dev, freq->sg_table.sgl, op->nents,
drivers/nvme/host/fc.c:	sg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/fc.c:	freq->sg_cnt = 0;
drivers/nvme/host/status:trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/status:trace.h:		__entry->cid = req->tag;
drivers/nvme/host/status:trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/status:trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/status:tcp.c:	return req == &req->queue->ctrl->async_req;
drivers/nvme/host/status:tcp.c:	return rq_data_dir(rq) == WRITE && req->data_len &&
drivers/nvme/host/status:tcp.c:		req->data_len <= nvme_tcp_inline_data_size(req->queue);
drivers/nvme/host/status:tcp.c:	return req->iter.bvec->bv_page;
drivers/nvme/host/status:tcp.c:	return req->iter.bvec->bv_offset + req->iter.iov_offset;
drivers/nvme/host/status:tcp.c:	return min_t(size_t, iov_iter_single_seg_count(&req->iter),
drivers/nvme/host/status:tcp.c:			req->pdu_len - req->pdu_sent);
drivers/nvme/host/status:tcp.c:			req->pdu_len - req->pdu_sent : 0;
drivers/nvme/host/status:tcp.c:		struct bio *bio = req->curr_bio;
drivers/nvme/host/status:tcp.c:	iov_iter_bvec(&req->iter, dir, vec, nr_bvec, size);
drivers/nvme/host/status:tcp.c:	req->iter.iov_offset = offset;
drivers/nvme/host/status:tcp.c:	req->data_sent += len;
drivers/nvme/host/status:tcp.c:	req->pdu_sent += len;
drivers/nvme/host/status:tcp.c:	iov_iter_advance(&req->iter, len);
drivers/nvme/host/status:tcp.c:	if (!iov_iter_count(&req->iter) &&
drivers/nvme/host/status:tcp.c:	    req->data_sent < req->data_len) {
drivers/nvme/host/status:tcp.c:		req->curr_bio = req->curr_bio->bi_next;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:	empty = llist_add(&req->lentry, &queue->req_list) &&
drivers/nvme/host/status:tcp.c:		list_add(&req->entry, &queue->send_list);
drivers/nvme/host/status:tcp.c:	list_del(&req->entry);
drivers/nvme/host/status:tcp.c:	page_frag_free(req->pdu);
drivers/nvme/host/status:tcp.c:	req->pdu = page_frag_alloc(&queue->pf_cache,
drivers/nvme/host/status:tcp.c:	if (!req->pdu)
drivers/nvme/host/status:tcp.c:	req->queue = queue;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_data_pdu *data = req->pdu;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:	req->pdu_len = le32_to_cpu(pdu->r2t_length);
drivers/nvme/host/status:tcp.c:	req->pdu_sent = 0;
drivers/nvme/host/status:tcp.c:	if (unlikely(!req->pdu_len)) {
drivers/nvme/host/status:tcp.c:			rq->tag, req->pdu_len);
drivers/nvme/host/status:tcp.c:	if (unlikely(req->data_sent + req->pdu_len > req->data_len)) {
drivers/nvme/host/status:tcp.c:			rq->tag, req->pdu_len, req->data_len,
drivers/nvme/host/status:tcp.c:			req->data_sent);
drivers/nvme/host/status:tcp.c:	if (unlikely(le32_to_cpu(pdu->r2t_offset) < req->data_sent)) {
drivers/nvme/host/status:tcp.c:			req->data_sent);
drivers/nvme/host/status:tcp.c:		cpu_to_le32(data->hdr.hlen + hdgst + req->pdu_len + ddgst);
drivers/nvme/host/status:tcp.c:	data->data_offset = cpu_to_le32(req->data_sent);
drivers/nvme/host/status:tcp.c:	data->data_length = cpu_to_le32(req->pdu_len);
drivers/nvme/host/status:tcp.c:	req->state = NVME_TCP_SEND_H2C_PDU;
drivers/nvme/host/status:tcp.c:	req->offset = 0;
drivers/nvme/host/status:tcp.c:		if (!iov_iter_count(&req->iter)) {
drivers/nvme/host/status:tcp.c:			req->curr_bio = req->curr_bio->bi_next;
drivers/nvme/host/status:tcp.c:			if (!req->curr_bio) {
drivers/nvme/host/status:tcp.c:				iov_iter_count(&req->iter));
drivers/nvme/host/status:tcp.c:				&req->iter, recv_len, queue->rcv_hash);
drivers/nvme/host/status:tcp.c:					&req->iter, recv_len);
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:					&req->ddgst);
drivers/nvme/host/status:tcp.c:				req->state = NVME_TCP_SEND_DDGST;
drivers/nvme/host/status:tcp.c:				req->offset = 0;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/status:tcp.c:	int len = sizeof(*pdu) + hdgst - req->offset;
drivers/nvme/host/status:tcp.c:	if (queue->hdr_digest && !req->offset)
drivers/nvme/host/status:tcp.c:			offset_in_page(pdu) + req->offset, len,  flags);
drivers/nvme/host/status:tcp.c:			req->state = NVME_TCP_SEND_DATA;
drivers/nvme/host/status:tcp.c:	req->offset += ret;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_data_pdu *pdu = req->pdu;
drivers/nvme/host/status:tcp.c:	int len = sizeof(*pdu) - req->offset + hdgst;
drivers/nvme/host/status:tcp.c:	if (queue->hdr_digest && !req->offset)
drivers/nvme/host/status:tcp.c:			offset_in_page(pdu) + req->offset, len,
drivers/nvme/host/status:tcp.c:		req->state = NVME_TCP_SEND_DATA;
drivers/nvme/host/status:tcp.c:	req->offset += ret;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:		.iov_base = &req->ddgst + req->offset,
drivers/nvme/host/status:tcp.c:		.iov_len = NVME_TCP_DIGEST_LENGTH - req->offset
drivers/nvme/host/status:tcp.c:	if (req->offset + ret == NVME_TCP_DIGEST_LENGTH) {
drivers/nvme/host/status:tcp.c:	req->offset += ret;
drivers/nvme/host/status:tcp.c:	if (req->state == NVME_TCP_SEND_CMD_PDU) {
drivers/nvme/host/status:tcp.c:	if (req->state == NVME_TCP_SEND_H2C_PDU) {
drivers/nvme/host/status:tcp.c:	if (req->state == NVME_TCP_SEND_DATA) {
drivers/nvme/host/status:tcp.c:	if (req->state == NVME_TCP_SEND_DDGST)
drivers/nvme/host/status:tcp.c:	icreq->hdr.type = nvme_tcp_icreq;
drivers/nvme/host/status:tcp.c:	icreq->hdr.hlen = sizeof(*icreq);
drivers/nvme/host/status:tcp.c:	icreq->hdr.pdo = 0;
drivers/nvme/host/status:tcp.c:	icreq->hdr.plen = cpu_to_le32(icreq->hdr.hlen);
drivers/nvme/host/status:tcp.c:	icreq->pfv = cpu_to_le16(NVME_TCP_PFV_1_0);
drivers/nvme/host/status:tcp.c:	icreq->maxr2t = 0; /* single inflight r2t supported */
drivers/nvme/host/status:tcp.c:	icreq->hpda = 0; /* no alignment constraint */
drivers/nvme/host/status:tcp.c:		icreq->digest |= NVME_TCP_HDR_DIGEST_ENABLE;
drivers/nvme/host/status:tcp.c:		icreq->digest |= NVME_TCP_DATA_DIGEST_ENABLE;
drivers/nvme/host/status:tcp.c:	struct nvme_ctrl *ctrl = &req->queue->ctrl->ctrl;
drivers/nvme/host/status:tcp.c:	nvme_tcp_stop_queue(ctrl, nvme_tcp_queue_id(req->queue));
drivers/nvme/host/status:tcp.c:	struct nvme_ctrl *ctrl = &req->queue->ctrl->ctrl;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/status:tcp.c:		nvme_tcp_queue_id(req->queue), rq->tag, pdu->hdr.type);
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/status:tcp.c:	    req->data_len <= nvme_tcp_inline_data_size(queue))
drivers/nvme/host/status:tcp.c:		nvme_tcp_set_sg_inline(queue, c, req->data_len);
drivers/nvme/host/status:tcp.c:		nvme_tcp_set_sg_host_data(c, req->data_len);
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_cmd_pdu *pdu = req->pdu;
drivers/nvme/host/status:tcp.c:	struct nvme_tcp_queue *queue = req->queue;
drivers/nvme/host/status:tcp.c:	req->state = NVME_TCP_SEND_CMD_PDU;
drivers/nvme/host/status:tcp.c:	req->offset = 0;
drivers/nvme/host/status:tcp.c:	req->data_sent = 0;
drivers/nvme/host/status:tcp.c:	req->pdu_len = 0;
drivers/nvme/host/status:tcp.c:	req->pdu_sent = 0;
drivers/nvme/host/status:tcp.c:	req->data_len = blk_rq_nr_phys_segments(rq) ?
drivers/nvme/host/status:tcp.c:	req->curr_bio = rq->bio;
drivers/nvme/host/status:tcp.c:	if (req->curr_bio && req->data_len)
drivers/nvme/host/status:tcp.c:	    req->data_len <= nvme_tcp_inline_data_size(queue))
drivers/nvme/host/status:tcp.c:		req->pdu_len = req->data_len;
drivers/nvme/host/status:tcp.c:	if (queue->data_digest && req->pdu_len) {
drivers/nvme/host/status:tcp.c:	pdu->hdr.pdo = req->pdu_len ? pdu->hdr.hlen + hdgst : 0;
drivers/nvme/host/status:tcp.c:		cpu_to_le32(pdu->hdr.hlen + hdgst + req->pdu_len + ddgst);
drivers/nvme/host/status:fc.h:	lsreq->rqstaddr = discon_rqst;
drivers/nvme/host/status:fc.h:	lsreq->rqstlen = sizeof(*discon_rqst);
drivers/nvme/host/status:fc.h:	lsreq->rspaddr = discon_acc;
drivers/nvme/host/status:fc.h:	lsreq->rsplen = sizeof(*discon_acc);
drivers/nvme/host/status:fc.h:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/status:fault_inject.c:	struct gendisk *disk = req->rq_disk;
drivers/nvme/host/status:core.c:	blk_mq_delay_kick_requeue_list(req->q, delay);
drivers/nvme/host/status:core.c:	if (req->cmd_flags & REQ_NVME_MPATH) {
drivers/nvme/host/status:core.c:		    blk_queue_dying(req->q))
drivers/nvme/host/status:core.c:		if (blk_queue_dying(req->q))
drivers/nvme/host/status:core.c:		req->__sector = nvme_lba_to_sect(req->q->queuedata,
drivers/nvme/host/status:core.c:				"Cancelling I/O %d", req->tag);
drivers/nvme/host/status:core.c:	if (!(req->rq_flags & RQF_DONTPREP)) {
drivers/nvme/host/status:core.c:		req->rq_flags |= RQF_DONTPREP;
drivers/nvme/host/status:core.c:	if (req->q->queuedata)
drivers/nvme/host/status:core.c:		req->timeout = NVME_IO_TIMEOUT;
drivers/nvme/host/status:core.c:		req->timeout = NVME_ADMIN_TIMEOUT;
drivers/nvme/host/status:core.c:	req->cmd_flags |= REQ_FAILFAST_DRIVER;
drivers/nvme/host/status:core.c:	enum rw_hint streamid = req->write_hint;
drivers/nvme/host/status:core.c:	if (streamid < ARRAY_SIZE(req->q->write_hints))
drivers/nvme/host/status:core.c:		req->q->write_hints[streamid] += blk_rq_bytes(req) >> 9;
drivers/nvme/host/status:core.c:	req->special_vec.bv_page = virt_to_page(range);
drivers/nvme/host/status:core.c:	req->special_vec.bv_offset = offset_in_page(range);
drivers/nvme/host/status:core.c:	req->special_vec.bv_len = alloc_size;
drivers/nvme/host/status:core.c:	req->rq_flags |= RQF_SPECIAL_PAYLOAD;
drivers/nvme/host/status:core.c:	if (req->cmd_flags & REQ_FUA)
drivers/nvme/host/status:core.c:	if (req->cmd_flags & (REQ_FAILFAST_DEV | REQ_RAHEAD))
drivers/nvme/host/status:core.c:	if (req->cmd_flags & REQ_RAHEAD)
drivers/nvme/host/status:core.c:	if (req->rq_flags & RQF_SPECIAL_PAYLOAD) {
drivers/nvme/host/status:core.c:		struct page *page = req->special_vec.bv_page;
drivers/nvme/host/status:core.c:			kfree(page_address(page) + req->special_vec.bv_offset);
drivers/nvme/host/status:core.c:	new->inode = req->bio->xrp_inode;
drivers/nvme/host/status:core.c:	new->xrp_bpf_prog = req->bio->xrp_bpf_prog;
drivers/nvme/host/status:core.c:	new->queuedata = req->q->queuedata;
drivers/nvme/host/status:core.c:	new->xrp_partition_start_sector = req->bio->xrp_partition_start_sector;
drivers/nvme/host/status:core.c:	new->xrp_extent_version = req->bio->xrp_extent_version;
drivers/nvme/host/status:core.c:	new->i_op = req->bio->xrp_inode->i_op;
drivers/nvme/host/status:core.c:	new->xrp_data_page = page_address(bio_page(req->bio));
drivers/nvme/host/status:core.c:	new->xrp_scratch_page = page_address(req->bio->xrp_scratch_page);
drivers/nvme/host/status:core.c:	//memcpy(page_address(bio_page(req->bio)), data->xrp_data_page, 0x1000);
drivers/nvme/host/status:core.c:	//memcpy(page_address(req->bio->xrp_scratch_page), data->xrp_scratch_page, 0x1000);
drivers/nvme/host/status:core.c:	cmd->common.command_id = req->tag;
drivers/nvme/host/status:core.c:		req->timeout = timeout;
drivers/nvme/host/status:core.c:		nvme_execute_rq_polled(req->q, NULL, req, at_head);
drivers/nvme/host/status:core.c:		req->timeout = timeout;
drivers/nvme/host/status:core.c:		bio = req->bio;
drivers/nvme/host/status:core.c:			req->cmd_flags |= REQ_INTEGRITY;
drivers/nvme/host/status:multipath.c:	struct nvme_ns *ns = req->q->queuedata;
drivers/nvme/host/status:fc.c:	fc_dma_unmap_single(rport->dev, lsreq->rqstdma,
drivers/nvme/host/status:fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/host/status:fc.c:	lsreq->done = done;
drivers/nvme/host/status:fc.c:	lsreq->rqstdma = fc_dma_map_single(rport->dev, lsreq->rqstaddr,
drivers/nvme/host/status:fc.c:				  lsreq->rqstlen + lsreq->rsplen,
drivers/nvme/host/status:fc.c:	if (fc_dma_mapping_error(rport->dev, lsreq->rqstdma)) {
drivers/nvme/host/status:fc.c:	lsreq->rspdma = lsreq->rqstdma + lsreq->rqstlen;
drivers/nvme/host/status:fc.c:	fc_dma_unmap_single(rport->dev, lsreq->rqstdma,
drivers/nvme/host/status:fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/host/status:fc.c:	struct fcnvme_ls_rjt *rjt = lsreq->rspaddr;
drivers/nvme/host/status:fc.c:		lsreq->private = &assoc_acc[1];
drivers/nvme/host/status:fc.c:		lsreq->private = NULL;
drivers/nvme/host/status:fc.c:	lsreq->rqstaddr = assoc_rqst;
drivers/nvme/host/status:fc.c:	lsreq->rqstlen = sizeof(*assoc_rqst);
drivers/nvme/host/status:fc.c:	lsreq->rspaddr = assoc_acc;
drivers/nvme/host/status:fc.c:	lsreq->rsplen = sizeof(*assoc_acc);
drivers/nvme/host/status:fc.c:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/status:fc.c:		lsreq->private = (void *)&conn_acc[1];
drivers/nvme/host/status:fc.c:		lsreq->private = NULL;
drivers/nvme/host/status:fc.c:	lsreq->rqstaddr = conn_rqst;
drivers/nvme/host/status:fc.c:	lsreq->rqstlen = sizeof(*conn_rqst);
drivers/nvme/host/status:fc.c:	lsreq->rspaddr = conn_acc;
drivers/nvme/host/status:fc.c:	lsreq->rsplen = sizeof(*conn_acc);
drivers/nvme/host/status:fc.c:	lsreq->timeout = NVME_FC_LS_TIMEOUT_SEC;
drivers/nvme/host/status:fc.c:		lsreq->private = (void *)&discon_acc[1];
drivers/nvme/host/status:fc.c:		lsreq->private = NULL;
drivers/nvme/host/status:fc.c:	else if (freq->status) {
drivers/nvme/host/status:fc.c:			ctrl->cnum, freq->status);
drivers/nvme/host/status:fc.c:	switch (freq->rcv_rsplen) {
drivers/nvme/host/status:fc.c:		if (freq->transferred_length !=
drivers/nvme/host/status:fc.c:				ctrl->cnum, freq->transferred_length,
drivers/nvme/host/status:fc.c:					(freq->rcv_rsplen / 4) ||
drivers/nvme/host/status:fc.c:					freq->transferred_length ||
drivers/nvme/host/status:fc.c:				freq->transferred_length,
drivers/nvme/host/status:fc.c:			ctrl->cnum, freq->rcv_rsplen);
drivers/nvme/host/status:fc.c:	freq->sg_cnt = 0;
drivers/nvme/host/status:fc.c:	freq->sg_table.sgl = freq->first_sgl;
drivers/nvme/host/status:fc.c:	ret = sg_alloc_table_chained(&freq->sg_table,
drivers/nvme/host/status:fc.c:			blk_rq_nr_phys_segments(rq), freq->sg_table.sgl,
drivers/nvme/host/status:fc.c:	op->nents = blk_rq_map_sg(rq->q, rq, freq->sg_table.sgl);
drivers/nvme/host/status:fc.c:	freq->sg_cnt = fc_dma_map_sg(ctrl->lport->dev, freq->sg_table.sgl,
drivers/nvme/host/status:fc.c:	if (unlikely(freq->sg_cnt <= 0)) {
drivers/nvme/host/status:fc.c:		sg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/status:fc.c:		freq->sg_cnt = 0;
drivers/nvme/host/status:fc.c:	if (!freq->sg_cnt)
drivers/nvme/host/status:fc.c:	fc_dma_unmap_sg(ctrl->lport->dev, freq->sg_table.sgl, op->nents,
drivers/nvme/host/status:fc.c:	sg_free_table_chained(&freq->sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/status:fc.c:	freq->sg_cnt = 0;
drivers/nvme/host/status:fabrics.c:	if (rq->q == ctrl->admin_q && (req->flags & NVME_REQ_USERCMD))
drivers/nvme/host/status:fabrics.c:		if (blk_rq_is_passthrough(rq) && nvme_is_fabrics(req->cmd) &&
drivers/nvme/host/status:fabrics.c:		    req->cmd->fabrics.fctype == nvme_fabrics_type_connect)
drivers/nvme/host/status:pci.c:	iod->nents = blk_rq_map_sg(req->q, req, iod->sg);
drivers/nvme/host/status:pci.c:	if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/status:pci.c:			req->xrp_command = NULL;
drivers/nvme/host/status:pci.c:			req->xrp_command = cmndp;
drivers/nvme/host/status:pci.c:		req->xrp_command = NULL;
drivers/nvme/host/status:pci.c:	if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/status:pci.c:	if (!req->bio || !req->bio->xrp_enabled) {
drivers/nvme/host/status:pci.c:		struct resubmit_data *data = (struct resubmit_data *)(req->xrp_command->rw.rsvd2);
drivers/nvme/host/status:pci.c:		if (req->bio->xrp_count > 1
drivers/nvme/host/status:pci.c:		    && req->bio->xrp_inode->i_op == &ext4_file_inode_operations) {
drivers/nvme/host/status:pci.c:			file_offset = req->bio->xrp_file_offset;
drivers/nvme/host/status:pci.c:			xrp_retrieve_mapping(req->bio->xrp_inode, file_offset, data_len, &mapping);
drivers/nvme/host/status:pci.c:			} else if (mapping.version != req->bio->xrp_extent_version) {
drivers/nvme/host/status:pci.c:				       file_offset, req->bio->xrp_extent_version, mapping.version);
drivers/nvme/host/status:pci.c:			atomic_long_add(req->bio->xrp_count, &xrp_resubmit_level_nr);
drivers/nvme/host/status:pci.c:		req->bio->xrp_file_offset = file_offset;
drivers/nvme/host/status:pci.c:		if (req->bio->xrp_inode->i_op == &ext4_file_inode_operations) {
drivers/nvme/host/status:pci.c:			xrp_retrieve_mapping(req->bio->xrp_inode, file_offset, data_len, &mapping);
drivers/nvme/host/status:pci.c:				req->bio->xrp_extent_version = mapping.version;
drivers/nvme/host/status:pci.c:		nvme_req(req)->cmd = req->xrp_command;
drivers/nvme/host/status:pci.c:		req->bio->xrp_count += 1;
drivers/nvme/host/status:pci.c:		req->bio->bi_iter.bi_sector = (disk_offset >> 9) + req->bio->xrp_partition_start_sector;
drivers/nvme/host/status:pci.c:		req->__sector = req->bio->bi_iter.bi_sector;
drivers/nvme/host/status:pci.c:		req->xrp_command->rw.slba = cpu_to_le64(nvme_sect_to_lba(req->q->queuedata, blk_rq_pos(req)));
drivers/nvme/host/status:pci.c:		nvme_submit_cmd(nvmeq, req->xrp_command, true);
drivers/nvme/host/status:pci.c:    if (req->bio && req->bio->xrp_enabled) {
drivers/nvme/host/status:pci.c:		nvme_poll(req->mq_hctx);
drivers/nvme/host/status:pci.c:			 req->tag, nvmeq->qid);
drivers/nvme/host/status:pci.c:			 req->tag, nvmeq->qid);
drivers/nvme/host/status:pci.c:			 req->tag, nvmeq->qid);
drivers/nvme/host/status:pci.c:	cmd.abort.cid = req->tag;
drivers/nvme/host/status:pci.c:		 req->tag, nvmeq->qid);
drivers/nvme/host/status:pci.c:	abort_req->end_io_data = NULL;
drivers/nvme/host/status:pci.c:	struct nvme_queue *nvmeq = req->end_io_data;
drivers/nvme/host/status:pci.c:	struct nvme_queue *nvmeq = req->end_io_data;
drivers/nvme/host/status:pci.c:	req->end_io_data = nvmeq;
drivers/nvme/host/status:nvme.h:	if (!req->q->queuedata)
drivers/nvme/host/status:nvme.h:	return req->mq_hctx->queue_num + 1;
drivers/nvme/host/status:nvme.h:	if (req->xrp_command) {
drivers/nvme/host/status:nvme.h:		kfree(req->xrp_command);
drivers/nvme/host/status:nvme.h:		req->xrp_command = NULL;
drivers/nvme/host/status:nvme.h:	if (unlikely(blk_should_fake_timeout(req->q)))
drivers/nvme/host/status:nvme.h:	struct nvme_ns *ns = req->q->queuedata;
drivers/nvme/host/status:nvme.h:	if (req->cmd_flags & REQ_NVME_MPATH)
drivers/nvme/host/status:nvme.h:		trace_block_bio_complete(ns->head->disk->queue, req->bio);
drivers/nvme/host/status:rdma.c:	kfree(req->sqe.data);
drivers/nvme/host/status:rdma.c:	req->sqe.data = kzalloc(sizeof(struct nvme_command), GFP_KERNEL);
drivers/nvme/host/status:rdma.c:	if (!req->sqe.data)
drivers/nvme/host/status:rdma.c:		req->metadata_sgl = (void *)nvme_req(rq) +
drivers/nvme/host/status:rdma.c:	req->queue = queue;
drivers/nvme/host/status:rdma.c:	if (!refcount_dec_and_test(&req->ref))
drivers/nvme/host/status:rdma.c:	if (!nvme_try_complete_req(rq, req->status, req->result))
drivers/nvme/host/status:rdma.c:		.ex.invalidate_rkey = req->mr->rkey,
drivers/nvme/host/status:rdma.c:	req->reg_cqe.done = nvme_rdma_inv_rkey_done;
drivers/nvme/host/status:rdma.c:	wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/status:rdma.c:		ib_dma_unmap_sg(ibdev, req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/status:rdma.c:				req->metadata_sgl->nents, rq_dma_dir(rq));
drivers/nvme/host/status:rdma.c:		sg_free_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/status:rdma.c:	if (req->use_sig_mr)
drivers/nvme/host/status:rdma.c:	if (req->mr) {
drivers/nvme/host/status:rdma.c:		ib_mr_pool_put(queue->qp, pool, req->mr);
drivers/nvme/host/status:rdma.c:		req->mr = NULL;
drivers/nvme/host/status:rdma.c:	ib_dma_unmap_sg(ibdev, req->data_sgl.sg_table.sgl, req->data_sgl.nents,
drivers/nvme/host/status:rdma.c:	sg_free_table_chained(&req->data_sgl.sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/status:rdma.c:	struct scatterlist *sgl = req->data_sgl.sg_table.sgl;
drivers/nvme/host/status:rdma.c:	struct ib_sge *sge = &req->sge[1];
drivers/nvme/host/status:rdma.c:	req->num_sge += count;
drivers/nvme/host/status:rdma.c:	sg->addr = cpu_to_le64(sg_dma_address(req->data_sgl.sg_table.sgl));
drivers/nvme/host/status:rdma.c:	put_unaligned_le24(sg_dma_len(req->data_sgl.sg_table.sgl), sg->length);
drivers/nvme/host/status:rdma.c:	req->mr = ib_mr_pool_get(queue->qp, &queue->qp->rdma_mrs);
drivers/nvme/host/status:rdma.c:	if (WARN_ON_ONCE(!req->mr))
drivers/nvme/host/status:rdma.c:	nr = ib_map_mr_sg(req->mr, req->data_sgl.sg_table.sgl, count, NULL,
drivers/nvme/host/status:rdma.c:		ib_mr_pool_put(queue->qp, &queue->qp->rdma_mrs, req->mr);
drivers/nvme/host/status:rdma.c:		req->mr = NULL;
drivers/nvme/host/status:rdma.c:	ib_update_fast_reg_key(req->mr, ib_inc_rkey(req->mr->rkey));
drivers/nvme/host/status:rdma.c:	req->reg_cqe.done = nvme_rdma_memreg_done;
drivers/nvme/host/status:rdma.c:	memset(&req->reg_wr, 0, sizeof(req->reg_wr));
drivers/nvme/host/status:rdma.c:	req->reg_wr.wr.opcode = IB_WR_REG_MR;
drivers/nvme/host/status:rdma.c:	req->reg_wr.wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/status:rdma.c:	req->reg_wr.wr.num_sge = 0;
drivers/nvme/host/status:rdma.c:	req->reg_wr.mr = req->mr;
drivers/nvme/host/status:rdma.c:	req->reg_wr.key = req->mr->rkey;
drivers/nvme/host/status:rdma.c:	req->reg_wr.access = IB_ACCESS_LOCAL_WRITE |
drivers/nvme/host/status:rdma.c:	sg->addr = cpu_to_le64(req->mr->iova);
drivers/nvme/host/status:rdma.c:	put_unaligned_le24(req->mr->length, sg->length);
drivers/nvme/host/status:rdma.c:	put_unaligned_le32(req->mr->rkey, sg->key);
drivers/nvme/host/status:rdma.c:	struct nvme_rdma_sgl *sgl = &req->data_sgl;
drivers/nvme/host/status:rdma.c:	struct ib_reg_wr *wr = &req->reg_wr;
drivers/nvme/host/status:rdma.c:	req->mr = ib_mr_pool_get(queue->qp, &queue->qp->sig_mrs);
drivers/nvme/host/status:rdma.c:	if (WARN_ON_ONCE(!req->mr))
drivers/nvme/host/status:rdma.c:	nr = ib_map_mr_sg_pi(req->mr, sgl->sg_table.sgl, count, NULL,
drivers/nvme/host/status:rdma.c:			     req->metadata_sgl->sg_table.sgl, pi_count, NULL,
drivers/nvme/host/status:rdma.c:				req->mr->sig_attrs, ns->pi_type);
drivers/nvme/host/status:rdma.c:	nvme_rdma_set_prot_checks(c, &req->mr->sig_attrs->check_mask);
drivers/nvme/host/status:rdma.c:	ib_update_fast_reg_key(req->mr, ib_inc_rkey(req->mr->rkey));
drivers/nvme/host/status:rdma.c:	req->reg_cqe.done = nvme_rdma_sig_done;
drivers/nvme/host/status:rdma.c:	wr->wr.wr_cqe = &req->reg_cqe;
drivers/nvme/host/status:rdma.c:	wr->mr = req->mr;
drivers/nvme/host/status:rdma.c:	wr->key = req->mr->rkey;
drivers/nvme/host/status:rdma.c:	sg->addr = cpu_to_le64(req->mr->iova);
drivers/nvme/host/status:rdma.c:	put_unaligned_le24(req->mr->length, sg->length);
drivers/nvme/host/status:rdma.c:	put_unaligned_le32(req->mr->rkey, sg->key);
drivers/nvme/host/status:rdma.c:	ib_mr_pool_put(queue->qp, &queue->qp->sig_mrs, req->mr);
drivers/nvme/host/status:rdma.c:	req->mr = NULL;
drivers/nvme/host/status:rdma.c:	req->num_sge = 1;
drivers/nvme/host/status:rdma.c:	refcount_set(&req->ref, 2); /* send and recv completions */
drivers/nvme/host/status:rdma.c:	req->data_sgl.sg_table.sgl = (struct scatterlist *)(req + 1);
drivers/nvme/host/status:rdma.c:	ret = sg_alloc_table_chained(&req->data_sgl.sg_table,
drivers/nvme/host/status:rdma.c:			blk_rq_nr_phys_segments(rq), req->data_sgl.sg_table.sgl,
drivers/nvme/host/status:rdma.c:	req->data_sgl.nents = blk_rq_map_sg(rq->q, rq,
drivers/nvme/host/status:rdma.c:					    req->data_sgl.sg_table.sgl);
drivers/nvme/host/status:rdma.c:	count = ib_dma_map_sg(ibdev, req->data_sgl.sg_table.sgl,
drivers/nvme/host/status:rdma.c:			      req->data_sgl.nents, rq_dma_dir(rq));
drivers/nvme/host/status:rdma.c:		req->metadata_sgl->sg_table.sgl =
drivers/nvme/host/status:rdma.c:			(struct scatterlist *)(req->metadata_sgl + 1);
drivers/nvme/host/status:rdma.c:		ret = sg_alloc_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/status:rdma.c:				req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/status:rdma.c:		req->metadata_sgl->nents = blk_rq_map_integrity_sg(rq->q,
drivers/nvme/host/status:rdma.c:				rq->bio, req->metadata_sgl->sg_table.sgl);
drivers/nvme/host/status:rdma.c:					 req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/status:rdma.c:					 req->metadata_sgl->nents,
drivers/nvme/host/status:rdma.c:	if (req->use_sig_mr) {
drivers/nvme/host/status:rdma.c:		ib_dma_unmap_sg(ibdev, req->metadata_sgl->sg_table.sgl,
drivers/nvme/host/status:rdma.c:				req->metadata_sgl->nents, rq_dma_dir(rq));
drivers/nvme/host/status:rdma.c:		sg_free_table_chained(&req->metadata_sgl->sg_table,
drivers/nvme/host/status:rdma.c:	ib_dma_unmap_sg(ibdev, req->data_sgl.sg_table.sgl, req->data_sgl.nents,
drivers/nvme/host/status:rdma.c:	sg_free_table_chained(&req->data_sgl.sg_table, NVME_INLINE_SG_CNT);
drivers/nvme/host/status:rdma.c:	req->status = cqe->status;
drivers/nvme/host/status:rdma.c:	req->result = cqe->result;
drivers/nvme/host/status:rdma.c:		if (unlikely(!req->mr ||
drivers/nvme/host/status:rdma.c:			     wc->ex.invalidate_rkey != req->mr->rkey)) {
drivers/nvme/host/status:rdma.c:				req->mr ? req->mr->rkey : 0);
drivers/nvme/host/status:rdma.c:	} else if (req->mr) {
drivers/nvme/host/status:rdma.c:				req->mr->rkey, ret);
drivers/nvme/host/status:rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/status:rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/status:rdma.c:	struct nvme_rdma_qe *sqe = &req->sqe;
drivers/nvme/host/status:rdma.c:	req->sqe.dma = ib_dma_map_single(dev, req->sqe.data,
drivers/nvme/host/status:rdma.c:	err = ib_dma_mapping_error(dev, req->sqe.dma);
drivers/nvme/host/status:rdma.c:		req->use_sig_mr = true;
drivers/nvme/host/status:rdma.c:		req->use_sig_mr = false;
drivers/nvme/host/status:rdma.c:	err = nvme_rdma_post_send(queue, sqe, req->sge, req->num_sge,
drivers/nvme/host/status:rdma.c:			req->mr ? &req->reg_wr.wr : NULL);
drivers/nvme/host/status:rdma.c:	ib_dma_unmap_single(dev, req->sqe.dma, sizeof(struct nvme_command),
drivers/nvme/host/status:rdma.c:	ret = ib_check_mr_status(req->mr, IB_MR_CHECK_SIG_STATUS, &mr_status);
drivers/nvme/host/status:rdma.c:	struct nvme_rdma_queue *queue = req->queue;
drivers/nvme/host/status:rdma.c:	if (req->use_sig_mr)
drivers/nvme/host/status:rdma.c:	ib_dma_unmap_single(ibdev, req->sqe.dma, sizeof(struct nvme_command),
drivers/nvme/host/trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/trace.h:		__entry->cid = req->tag;
drivers/nvme/host/trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/trace.h:		__assign_disk_name(__entry->disk, req->rq_disk);
drivers/nvme/host/core.c:	blk_mq_delay_kick_requeue_list(req->q, delay);
drivers/nvme/host/core.c:	if (req->cmd_flags & REQ_NVME_MPATH) {
drivers/nvme/host/core.c:		    blk_queue_dying(req->q))
drivers/nvme/host/core.c:		if (blk_queue_dying(req->q))
drivers/nvme/host/core.c:		req->__sector = nvme_lba_to_sect(req->q->queuedata,
drivers/nvme/host/core.c:				"Cancelling I/O %d", req->tag);
drivers/nvme/host/core.c:	if (!(req->rq_flags & RQF_DONTPREP)) {
drivers/nvme/host/core.c:		req->rq_flags |= RQF_DONTPREP;
drivers/nvme/host/core.c:	if (req->q->queuedata)
drivers/nvme/host/core.c:		req->timeout = NVME_IO_TIMEOUT;
drivers/nvme/host/core.c:		req->timeout = NVME_ADMIN_TIMEOUT;
drivers/nvme/host/core.c:	req->cmd_flags |= REQ_FAILFAST_DRIVER;
drivers/nvme/host/core.c:	enum rw_hint streamid = req->write_hint;
drivers/nvme/host/core.c:	if (streamid < ARRAY_SIZE(req->q->write_hints))
drivers/nvme/host/core.c:		req->q->write_hints[streamid] += blk_rq_bytes(req) >> 9;
drivers/nvme/host/core.c:	req->special_vec.bv_page = virt_to_page(range);
drivers/nvme/host/core.c:	req->special_vec.bv_offset = offset_in_page(range);
drivers/nvme/host/core.c:	req->special_vec.bv_len = alloc_size;
drivers/nvme/host/core.c:	req->rq_flags |= RQF_SPECIAL_PAYLOAD;
drivers/nvme/host/core.c:	if (req->cmd_flags & REQ_FUA)
drivers/nvme/host/core.c:	if (req->cmd_flags & (REQ_FAILFAST_DEV | REQ_RAHEAD))
drivers/nvme/host/core.c:	if (req->cmd_flags & REQ_RAHEAD)
drivers/nvme/host/core.c:	if (req->rq_flags & RQF_SPECIAL_PAYLOAD) {
drivers/nvme/host/core.c:		struct page *page = req->special_vec.bv_page;
drivers/nvme/host/core.c:			kfree(page_address(page) + req->special_vec.bv_offset);
drivers/nvme/host/core.c:    int num_extents = xrp_count_tree(req->bio->xrp_inode);
drivers/nvme/host/core.c:	new->xrp_bpf_prog = req->bio->xrp_bpf_prog;
drivers/nvme/host/core.c:	new->queuedata = req->q->queuedata;
drivers/nvme/host/core.c:	new->xrp_partition_start_sector = req->bio->xrp_partition_start_sector;
drivers/nvme/host/core.c:	new->i_op = req->bio->xrp_inode->i_op;
drivers/nvme/host/core.c:	new->xrp_data_page = page_address(bio_page(req->bio));
drivers/nvme/host/core.c:	new->xrp_scratch_page = page_address(req->bio->xrp_scratch_page);
drivers/nvme/host/core.c:	new->num_extents = xrp_count_tree(req->bio->xrp_inode);
drivers/nvme/host/core.c:	xrp_copy_tree(req->bio->xrp_inode, new->extents);
drivers/nvme/host/core.c:    req->on_meta = new;
drivers/nvme/host/core.c:    new->xrp_command = req->xrp_command;
drivers/nvme/host/core.c:    atomic64_set(&new->slba, req->xrp_command->rw.slba);
drivers/nvme/host/core.c:    new->first_slba = req->xrp_command->rw.slba;
drivers/nvme/host/core.c:	//memcpy(page_address(bio_page(req->bio)), data->xrp_data_page, 0x1000);
drivers/nvme/host/core.c:	//memcpy(page_address(req->bio->xrp_scratch_page), data->xrp_scratch_page, 0x1000);
drivers/nvme/host/core.c:	cmd->common.command_id = req->tag;
drivers/nvme/host/core.c:		req->timeout = timeout;
drivers/nvme/host/core.c:		nvme_execute_rq_polled(req->q, NULL, req, at_head);
drivers/nvme/host/core.c:		req->timeout = timeout;
drivers/nvme/host/core.c:		bio = req->bio;
drivers/nvme/host/core.c:			req->cmd_flags |= REQ_INTEGRITY;
drivers/nvme/target/tcp.c:	if (le32_to_cpu(icreq->hdr.plen) != sizeof(struct nvme_tcp_icreq_pdu)) {
drivers/nvme/target/tcp.c:			le32_to_cpu(icreq->hdr.plen));
drivers/nvme/target/tcp.c:	if (icreq->pfv != NVME_TCP_PFV_1_0) {
drivers/nvme/target/tcp.c:		pr_err("queue %d: bad pfv %d\n", queue->idx, icreq->pfv);
drivers/nvme/target/tcp.c:	if (icreq->hpda != 0) {
drivers/nvme/target/tcp.c:			icreq->hpda);
drivers/nvme/target/tcp.c:	queue->hdr_digest = !!(icreq->digest & NVME_TCP_HDR_DIGEST_ENABLE);
drivers/nvme/target/tcp.c:	queue->data_digest = !!(icreq->digest & NVME_TCP_DATA_DIGEST_ENABLE);
drivers/nvme/target/tcp.c:	size_t data_len = le32_to_cpu(req->cmd->common.dptr.sgl.length);
drivers/nvme/target/tcp.c:	memcpy(req->cmd, nvme_cmd, sizeof(*nvme_cmd));
drivers/nvme/target/tcp.c:			req->cmd, req->cmd->common.command_id,
drivers/nvme/target/tcp.c:			req->cmd->common.opcode,
drivers/nvme/target/tcp.c:			le32_to_cpu(req->cmd->common.dptr.sgl.length));
drivers/nvme/target/fabrics-cmd.c:	u64 val = le64_to_cpu(req->cmd->prop_set.value);
drivers/nvme/target/fabrics-cmd.c:	if (req->cmd->prop_set.attrib & 1) {
drivers/nvme/target/fabrics-cmd.c:		req->error_loc =
drivers/nvme/target/fabrics-cmd.c:	switch (le32_to_cpu(req->cmd->prop_set.offset)) {
drivers/nvme/target/fabrics-cmd.c:		nvmet_update_cc(req->sq->ctrl, val);
drivers/nvme/target/fabrics-cmd.c:		req->error_loc =
drivers/nvme/target/fabrics-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/fabrics-cmd.c:	if (req->cmd->prop_get.attrib & 1) {
drivers/nvme/target/fabrics-cmd.c:		switch (le32_to_cpu(req->cmd->prop_get.offset)) {
drivers/nvme/target/fabrics-cmd.c:		switch (le32_to_cpu(req->cmd->prop_get.offset)) {
drivers/nvme/target/fabrics-cmd.c:	if (status && req->cmd->prop_get.attrib & 1) {
drivers/nvme/target/fabrics-cmd.c:		req->error_loc =
drivers/nvme/target/fabrics-cmd.c:		req->error_loc =
drivers/nvme/target/fabrics-cmd.c:	req->cqe->result.u64 = cpu_to_le64(val);
drivers/nvme/target/fabrics-cmd.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/fabrics-cmd.c:		req->execute = nvmet_execute_prop_set;
drivers/nvme/target/fabrics-cmd.c:		req->execute = nvmet_execute_prop_get;
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvmf_common_command, fctype);
drivers/nvme/target/fabrics-cmd.c:	struct nvmf_connect_command *c = &req->cmd->connect;
drivers/nvme/target/fabrics-cmd.c:	old = cmpxchg(&req->sq->ctrl, NULL, ctrl);
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvmf_connect_command, opcode);
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvmf_connect_command, sqsize);
drivers/nvme/target/fabrics-cmd.c:	nvmet_cq_setup(ctrl, req->cq, qid, sqsize + 1);
drivers/nvme/target/fabrics-cmd.c:	nvmet_sq_setup(ctrl, req->sq, qid, sqsize + 1);
drivers/nvme/target/fabrics-cmd.c:		req->sq->sqhd_disabled = true;
drivers/nvme/target/fabrics-cmd.c:		req->cqe->sq_head = cpu_to_le16(0xffff);
drivers/nvme/target/fabrics-cmd.c:		ret = ctrl->ops->install_queue(req->sq);
drivers/nvme/target/fabrics-cmd.c:	req->sq->ctrl = NULL;
drivers/nvme/target/fabrics-cmd.c:	struct nvmf_connect_command *c = &req->cmd->connect;
drivers/nvme/target/fabrics-cmd.c:	req->cqe->result.u32 = 0;
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvmf_connect_command, recfmt);
drivers/nvme/target/fabrics-cmd.c:		req->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);
drivers/nvme/target/fabrics-cmd.c:			req->error_loc =
drivers/nvme/target/fabrics-cmd.c:	req->cqe->result.u16 = cpu_to_le16(ctrl->cntlid);
drivers/nvme/target/fabrics-cmd.c:	struct nvmf_connect_command *c = &req->cmd->connect;
drivers/nvme/target/fabrics-cmd.c:	req->cqe->result.u32 = 0;
drivers/nvme/target/fabrics-cmd.c:		req->cqe->result.u32 = IPO_IATTR_CONNECT_SQE(qid);
drivers/nvme/target/fabrics-cmd.c:		req->cqe->result.u16 = cpu_to_le16(ctrl->cntlid);
drivers/nvme/target/fabrics-cmd.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/fabrics-cmd.c:		req->error_loc = offsetof(struct nvmf_common_command, fctype);
drivers/nvme/target/fabrics-cmd.c:		req->execute = nvmet_execute_admin_connect;
drivers/nvme/target/fabrics-cmd.c:		req->execute = nvmet_execute_io_connect;
drivers/nvme/target/nvmet.h:	req->cqe->result.u32 = cpu_to_le32(result);
drivers/nvme/target/nvmet.h:	return nvme_is_write(req->cmd) ? DMA_FROM_DEVICE : DMA_TO_DEVICE;
drivers/nvme/target/nvmet.h:	int rae = le32_to_cpu(req->cmd->common.cdw10) & 1 << 15;
drivers/nvme/target/nvmet.h:		clear_bit(bn, &req->sq->ctrl->aen_masked);
drivers/nvme/target/nvmet.h:	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) <<
drivers/nvme/target/nvmet.h:			req->ns->blksize_shift;
drivers/nvme/target/nvmet.h:	return ((u32)le16_to_cpu(req->cmd->rw.length) + 1) *
drivers/nvme/target/nvmet.h:			req->ns->metadata_size;
drivers/nvme/target/nvmet.h:	return (le32_to_cpu(req->cmd->dsm.nr) + 1) *
drivers/nvme/target/nvmet.h:	return req->sq->ctrl->subsys;
drivers/nvme/target/admin-cmd.c:		return sizeof(req->sq->ctrl->hostid);
drivers/nvme/target/admin-cmd.c:	nvmet_req_complete(req, nvmet_zero_sgl(req, 0, req->transfer_len));
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	if (!req->ns->bdev)
drivers/nvme/target/admin-cmd.c:	host_reads = part_stat_read(req->ns->bdev, ios[READ]);
drivers/nvme/target/admin-cmd.c:		DIV_ROUND_UP(part_stat_read(req->ns->bdev, sectors[READ]), 1000);
drivers/nvme/target/admin-cmd.c:	host_writes = part_stat_read(req->ns->bdev, ios[WRITE]);
drivers/nvme/target/admin-cmd.c:		DIV_ROUND_UP(part_stat_read(req->ns->bdev, sectors[WRITE]), 1000);
drivers/nvme/target/admin-cmd.c:	ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	if (req->transfer_len != sizeof(*log))
drivers/nvme/target/admin-cmd.c:	if (req->cmd->get_log_page.nsid == cpu_to_le32(NVME_NSID_ALL))
drivers/nvme/target/admin-cmd.c:	spin_lock_irqsave(&req->sq->ctrl->error_lock, flags);
drivers/nvme/target/admin-cmd.c:	put_unaligned_le64(req->sq->ctrl->err_counter,
drivers/nvme/target/admin-cmd.c:	spin_unlock_irqrestore(&req->sq->ctrl->error_lock, flags);
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	if (req->transfer_len != NVME_MAX_CHANGED_NAMESPACES * sizeof(__le32))
drivers/nvme/target/admin-cmd.c:		status = nvmet_zero_sgl(req, len, req->transfer_len - len);
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	if (!(req->cmd->get_log_page.lsp & NVME_ANA_LOG_RGO)) {
drivers/nvme/target/admin-cmd.c:	desc->state = req->port->ana_state[grpid];
drivers/nvme/target/admin-cmd.c:	if (!nvmet_check_transfer_len(req, nvmet_get_log_page_len(req->cmd)))
drivers/nvme/target/admin-cmd.c:	switch (req->cmd->get_log_page.lid) {
drivers/nvme/target/admin-cmd.c:	       req->cmd->get_log_page.lid, req->sq->qid);
drivers/nvme/target/admin-cmd.c:	req->error_loc = offsetof(struct nvme_get_log_page_command, lid);
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	if (req->port->inline_data_size)
drivers/nvme/target/admin-cmd.c:		cmd_capsule_size += req->port->inline_data_size;
drivers/nvme/target/admin-cmd.c:	if (le32_to_cpu(req->cmd->identify.nsid) == NVME_NSID_ALL) {
drivers/nvme/target/admin-cmd.c:		req->error_loc = offsetof(struct nvme_identify, nsid);
drivers/nvme/target/admin-cmd.c:	nvmet_ns_revalidate(req->ns);
drivers/nvme/target/admin-cmd.c:		cpu_to_le64(req->ns->size >> req->ns->blksize_shift);
drivers/nvme/target/admin-cmd.c:	switch (req->port->ana_state[req->ns->anagrpid]) {
drivers/nvme/target/admin-cmd.c:	if (req->ns->bdev)
drivers/nvme/target/admin-cmd.c:		nvmet_bdev_set_limits(req->ns->bdev, id);
drivers/nvme/target/admin-cmd.c:	id->anagrpid = cpu_to_le32(req->ns->anagrpid);
drivers/nvme/target/admin-cmd.c:	memcpy(&id->nguid, &req->ns->nguid, sizeof(id->nguid));
drivers/nvme/target/admin-cmd.c:	id->lbaf[0].ds = req->ns->blksize_shift;
drivers/nvme/target/admin-cmd.c:	if (req->sq->ctrl->pi_support && nvmet_ns_has_pi(req->ns)) {
drivers/nvme/target/admin-cmd.c:		id->dps = req->ns->pi_type;
drivers/nvme/target/admin-cmd.c:		id->lbaf[0].ms = cpu_to_le16(req->ns->metadata_size);
drivers/nvme/target/admin-cmd.c:	if (req->ns->readonly)
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	u32 min_nsid = le32_to_cpu(req->cmd->identify.nsid);
drivers/nvme/target/admin-cmd.c:	if (memchr_inv(&req->ns->uuid, 0, sizeof(req->ns->uuid))) {
drivers/nvme/target/admin-cmd.c:						  &req->ns->uuid, &off);
drivers/nvme/target/admin-cmd.c:	if (memchr_inv(req->ns->nguid, 0, sizeof(req->ns->nguid))) {
drivers/nvme/target/admin-cmd.c:						  &req->ns->nguid, &off);
drivers/nvme/target/admin-cmd.c:	if (sg_zero_buffer(req->sg, req->sg_cnt, NVME_IDENTIFY_DATA_SIZE - off,
drivers/nvme/target/admin-cmd.c:	switch (req->cmd->identify.cns) {
drivers/nvme/target/admin-cmd.c:	       req->cmd->identify.cns, req->sq->qid);
drivers/nvme/target/admin-cmd.c:	req->error_loc = offsetof(struct nvme_identify, cns);
drivers/nvme/target/admin-cmd.c:	if (req->ns->file)
drivers/nvme/target/admin-cmd.c:		pr_err("write protect flush failed nsid: %u\n", req->ns->nsid);
drivers/nvme/target/admin-cmd.c:	u32 write_protect = le32_to_cpu(req->cmd->common.cdw11);
drivers/nvme/target/admin-cmd.c:		req->ns->readonly = true;
drivers/nvme/target/admin-cmd.c:			req->ns->readonly = false;
drivers/nvme/target/admin-cmd.c:		req->ns->readonly = false;
drivers/nvme/target/admin-cmd.c:		nvmet_ns_changed(subsys, req->ns->nsid);
drivers/nvme/target/admin-cmd.c:	u32 val32 = le32_to_cpu(req->cmd->common.cdw11);
drivers/nvme/target/admin-cmd.c:	nvmet_stop_keep_alive_timer(req->sq->ctrl);
drivers/nvme/target/admin-cmd.c:	req->sq->ctrl->kato = DIV_ROUND_UP(val32, 1000);
drivers/nvme/target/admin-cmd.c:	nvmet_start_keep_alive_timer(req->sq->ctrl);
drivers/nvme/target/admin-cmd.c:	nvmet_set_result(req, req->sq->ctrl->kato);
drivers/nvme/target/admin-cmd.c:	u32 val32 = le32_to_cpu(req->cmd->common.cdw11);
drivers/nvme/target/admin-cmd.c:		req->error_loc = offsetof(struct nvme_common_command, cdw11);
drivers/nvme/target/admin-cmd.c:	WRITE_ONCE(req->sq->ctrl->aen_enabled, val32);
drivers/nvme/target/admin-cmd.c:	u32 cdw10 = le32_to_cpu(req->cmd->common.cdw10);
drivers/nvme/target/admin-cmd.c:	u32 cdw11 = le32_to_cpu(req->cmd->common.cdw11);
drivers/nvme/target/admin-cmd.c:		req->error_loc = offsetof(struct nvme_common_command, cdw10);
drivers/nvme/target/admin-cmd.c:	if (req->ns->readonly == true)
drivers/nvme/target/admin-cmd.c:	nvmet_set_result(req, req->sq->ctrl->kato * 1000);
drivers/nvme/target/admin-cmd.c:	nvmet_set_result(req, READ_ONCE(req->sq->ctrl->aen_enabled));
drivers/nvme/target/admin-cmd.c:	u32 cdw10 = le32_to_cpu(req->cmd->common.cdw10);
drivers/nvme/target/admin-cmd.c:		if (!(req->cmd->common.cdw11 & cpu_to_le32(1 << 0))) {
drivers/nvme/target/admin-cmd.c:			req->error_loc =
drivers/nvme/target/admin-cmd.c:		status = nvmet_copy_to_sgl(req, 0, &req->sq->ctrl->hostid,
drivers/nvme/target/admin-cmd.c:				sizeof(req->sq->ctrl->hostid));
drivers/nvme/target/admin-cmd.c:		req->error_loc =
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/admin-cmd.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_get_log_page;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_identify;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_abort;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_set_features;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_get_features;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_async_event;
drivers/nvme/target/admin-cmd.c:		req->execute = nvmet_execute_keep_alive;
drivers/nvme/target/admin-cmd.c:	       req->sq->qid);
drivers/nvme/target/admin-cmd.c:	req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/rdma.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/rdma.c:	u8 pi_type = req->ns->pi_type;
drivers/nvme/target/rdma.c:	bi = bdev_get_integrity(req->ns->bdev);
drivers/nvme/target/rdma.c:		req->transfer_len += req->metadata_len;
drivers/nvme/target/rdma.c:	if (req->metadata_len)
drivers/nvme/target/rdma.c:			cm_id->port_num, req->sg, req->sg_cnt,
drivers/nvme/target/rdma.c:			req->metadata_sg, req->metadata_sg_cnt, sig_attrs,
drivers/nvme/target/rdma.c:				       req->sg, req->sg_cnt, 0, addr, key,
drivers/nvme/target/rdma.c:	if (req->metadata_len)
drivers/nvme/target/rdma.c:			cm_id->port_num, req->sg, req->sg_cnt,
drivers/nvme/target/rdma.c:			req->metadata_sg, req->metadata_sg_cnt,
drivers/nvme/target/rdma.c:				    req->sg, req->sg_cnt, nvmet_data_dir(req));
drivers/nvme/target/rdma.c:	if (le16_to_cpu(req->recfmt) != NVME_RDMA_CM_FMT_1_0)
drivers/nvme/target/rdma.c:	queue->host_qid = le16_to_cpu(req->qid);
drivers/nvme/target/rdma.c:	 * req->hsqsize corresponds to our recv queue size plus 1
drivers/nvme/target/rdma.c:	 * req->hrqsize corresponds to our send queue size
drivers/nvme/target/rdma.c:	queue->recv_queue_size = le16_to_cpu(req->hsqsize) + 1;
drivers/nvme/target/rdma.c:	queue->send_queue_size = le16_to_cpu(req->hrqsize);
drivers/nvme/target/loop.c:		container_of(req->sq, struct nvme_loop_queue, nvme_sq);
drivers/nvme/target/loop.c:	struct nvme_completion *cqe = req->cqe;
drivers/nvme/target/loop.c:		iod->req.sg_cnt = blk_rq_map_sg(req->q, req, iod->sg_table.sgl);
drivers/nvme/target/fcloop.c:		list_del(&tls_req->ls_list);
drivers/nvme/target/fcloop.c:		tls_req->lsreq->done(tls_req->lsreq, tls_req->status);
drivers/nvme/target/fcloop.c:	struct fcloop_lsreq *tls_req = lsreq->private;
drivers/nvme/target/fcloop.c:	tls_req->lsreq = lsreq;
drivers/nvme/target/fcloop.c:	INIT_LIST_HEAD(&tls_req->ls_list);
drivers/nvme/target/fcloop.c:		tls_req->status = -ECONNREFUSED;
drivers/nvme/target/fcloop.c:		list_add_tail(&rport->ls_list, &tls_req->ls_list);
drivers/nvme/target/fcloop.c:	tls_req->status = 0;
drivers/nvme/target/fcloop.c:				  &tls_req->ls_rsp,
drivers/nvme/target/fcloop.c:				  lsreq->rqstaddr, lsreq->rqstlen);
drivers/nvme/target/fcloop.c:	struct nvmefc_ls_req *lsreq = tls_req->lsreq;
drivers/nvme/target/fcloop.c:	memcpy(lsreq->rspaddr, lsrsp->rspbuf,
drivers/nvme/target/fcloop.c:		((lsreq->rsplen < lsrsp->rsplen) ?
drivers/nvme/target/fcloop.c:				lsreq->rsplen : lsrsp->rsplen));
drivers/nvme/target/fcloop.c:		list_add_tail(&rport->ls_list, &tls_req->ls_list);
drivers/nvme/target/fcloop.c:		list_del(&tls_req->ls_list);
drivers/nvme/target/fcloop.c:		tls_req->lsreq->done(tls_req->lsreq, tls_req->status);
drivers/nvme/target/fcloop.c:	struct fcloop_lsreq *tls_req = lsreq->private;
drivers/nvme/target/fcloop.c:	tls_req->lsreq = lsreq;
drivers/nvme/target/fcloop.c:	INIT_LIST_HEAD(&tls_req->ls_list);
drivers/nvme/target/fcloop.c:		tls_req->status = -ECONNREFUSED;
drivers/nvme/target/fcloop.c:		list_add_tail(&tport->ls_list, &tls_req->ls_list);
drivers/nvme/target/fcloop.c:	tls_req->status = 0;
drivers/nvme/target/fcloop.c:	ret = nvme_fc_rcv_ls_req(tport->remoteport, &tls_req->ls_rsp,
drivers/nvme/target/fcloop.c:				 lsreq->rqstaddr, lsreq->rqstlen);
drivers/nvme/target/fcloop.c:	struct nvmefc_ls_req *lsreq = tls_req->lsreq;
drivers/nvme/target/fcloop.c:	memcpy(lsreq->rspaddr, lsrsp->rspbuf,
drivers/nvme/target/fcloop.c:		((lsreq->rsplen < lsrsp->rsplen) ?
drivers/nvme/target/fcloop.c:				lsreq->rsplen : lsrsp->rsplen));
drivers/nvme/target/fcloop.c:		list_add_tail(&tport->ls_list, &tls_req->ls_list);
drivers/nvme/target/fcloop.c:	kref_put(&tfcp_req->ref, fcloop_tfcp_req_free);
drivers/nvme/target/fcloop.c:	return kref_get_unless_zero(&tfcp_req->ref);
drivers/nvme/target/fcloop.c:		inireq = fcpreq->private;
drivers/nvme/target/fcloop.c:		spin_lock(&inireq->inilock);
drivers/nvme/target/fcloop.c:		inireq->tfcp_req = NULL;
drivers/nvme/target/fcloop.c:		spin_unlock(&inireq->inilock);
drivers/nvme/target/fcloop.c:		fcpreq->status = status;
drivers/nvme/target/fcloop.c:		fcpreq->done(fcpreq);
drivers/nvme/target/fcloop.c:	struct nvmefc_fcp_req *fcpreq = tfcp_req->fcpreq;
drivers/nvme/target/fcloop.c:	struct nvme_fc_cmd_iu *cmdiu = fcpreq->cmdaddr;
drivers/nvme/target/fcloop.c:	struct nvmefc_fcp_req *fcpreq = tfcp_req->fcpreq;
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	switch (tfcp_req->inistate) {
drivers/nvme/target/fcloop.c:		tfcp_req->inistate = INI_IO_ACTIVE;
drivers/nvme/target/fcloop.c:		spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:			ret = nvmet_fc_rcv_fcp_req(tfcp_req->tport->targetport,
drivers/nvme/target/fcloop.c:				&tfcp_req->tgt_fcp_req,
drivers/nvme/target/fcloop.c:				fcpreq->cmdaddr, fcpreq->cmdlen);
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	fcpreq = tfcp_req->fcpreq;
drivers/nvme/target/fcloop.c:	switch (tfcp_req->inistate) {
drivers/nvme/target/fcloop.c:		spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	if (tfcp_req->tport->targetport)
drivers/nvme/target/fcloop.c:		nvmet_fc_rcv_fcp_abort(tfcp_req->tport->targetport,
drivers/nvme/target/fcloop.c:					&tfcp_req->tgt_fcp_req);
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	tfcp_req->fcpreq = NULL;
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	fcpreq = tfcp_req->fcpreq;
drivers/nvme/target/fcloop.c:	tfcp_req->inistate = INI_IO_COMPLETED;
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	fcloop_call_host_done(fcpreq, tfcp_req, tfcp_req->status);
drivers/nvme/target/fcloop.c:	struct fcloop_ini_fcpreq *inireq = fcpreq->private;
drivers/nvme/target/fcloop.c:	inireq->fcpreq = fcpreq;
drivers/nvme/target/fcloop.c:	inireq->tfcp_req = tfcp_req;
drivers/nvme/target/fcloop.c:	spin_lock_init(&inireq->inilock);
drivers/nvme/target/fcloop.c:	tfcp_req->fcpreq = fcpreq;
drivers/nvme/target/fcloop.c:	tfcp_req->tport = rport->targetport->private;
drivers/nvme/target/fcloop.c:	tfcp_req->inistate = INI_IO_START;
drivers/nvme/target/fcloop.c:	spin_lock_init(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	INIT_WORK(&tfcp_req->fcp_rcv_work, fcloop_fcp_recv_work);
drivers/nvme/target/fcloop.c:	INIT_WORK(&tfcp_req->abort_rcv_work, fcloop_fcp_abort_recv_work);
drivers/nvme/target/fcloop.c:	INIT_WORK(&tfcp_req->tio_done_work, fcloop_tgt_fcprqst_done_work);
drivers/nvme/target/fcloop.c:	kref_init(&tfcp_req->ref);
drivers/nvme/target/fcloop.c:	schedule_work(&tfcp_req->fcp_rcv_work);
drivers/nvme/target/fcloop.c:	u8 op = tgt_fcpreq->op;
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	fcpreq = tfcp_req->fcpreq;
drivers/nvme/target/fcloop.c:	active = tfcp_req->active;
drivers/nvme/target/fcloop.c:	aborted = tfcp_req->aborted;
drivers/nvme/target/fcloop.c:	tfcp_req->active = true;
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:		spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:		tfcp_req->active = false;
drivers/nvme/target/fcloop.c:		spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:		tgt_fcpreq->transferred_length = 0;
drivers/nvme/target/fcloop.c:		tgt_fcpreq->fcp_error = -ECANCELED;
drivers/nvme/target/fcloop.c:		tgt_fcpreq->done(tgt_fcpreq);
drivers/nvme/target/fcloop.c:		xfrlen = tgt_fcpreq->transfer_length;
drivers/nvme/target/fcloop.c:			fcloop_fcp_copy_data(op, tgt_fcpreq->sg,
drivers/nvme/target/fcloop.c:					fcpreq->first_sgl, tgt_fcpreq->offset,
drivers/nvme/target/fcloop.c:			fcpreq->transferred_length += xfrlen;
drivers/nvme/target/fcloop.c:		xfrlen = tgt_fcpreq->transfer_length;
drivers/nvme/target/fcloop.c:			fcloop_fcp_copy_data(op, tgt_fcpreq->sg,
drivers/nvme/target/fcloop.c:					fcpreq->first_sgl, tgt_fcpreq->offset,
drivers/nvme/target/fcloop.c:			fcpreq->transferred_length += xfrlen;
drivers/nvme/target/fcloop.c:			rsplen = ((fcpreq->rsplen < tgt_fcpreq->rsplen) ?
drivers/nvme/target/fcloop.c:					fcpreq->rsplen : tgt_fcpreq->rsplen);
drivers/nvme/target/fcloop.c:			memcpy(fcpreq->rspaddr, tgt_fcpreq->rspaddr, rsplen);
drivers/nvme/target/fcloop.c:			if (rsplen < tgt_fcpreq->rsplen)
drivers/nvme/target/fcloop.c:			fcpreq->rcv_rsplen = rsplen;
drivers/nvme/target/fcloop.c:			fcpreq->status = 0;
drivers/nvme/target/fcloop.c:		tfcp_req->status = 0;
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	tfcp_req->active = false;
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	tgt_fcpreq->transferred_length = xfrlen;
drivers/nvme/target/fcloop.c:	tgt_fcpreq->fcp_error = fcp_err;
drivers/nvme/target/fcloop.c:	tgt_fcpreq->done(tgt_fcpreq);
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	tfcp_req->aborted = true;
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	tfcp_req->status = NVME_SC_INTERNAL;
drivers/nvme/target/fcloop.c:	schedule_work(&tfcp_req->tio_done_work);
drivers/nvme/target/fcloop.c:	struct fcloop_ini_fcpreq *inireq = fcpreq->private;
drivers/nvme/target/fcloop.c:	spin_lock(&inireq->inilock);
drivers/nvme/target/fcloop.c:	tfcp_req = inireq->tfcp_req;
drivers/nvme/target/fcloop.c:	spin_unlock(&inireq->inilock);
drivers/nvme/target/fcloop.c:	spin_lock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	switch (tfcp_req->inistate) {
drivers/nvme/target/fcloop.c:		tfcp_req->inistate = INI_IO_ABORTED;
drivers/nvme/target/fcloop.c:		spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:	spin_unlock_irq(&tfcp_req->reqlock);
drivers/nvme/target/fcloop.c:		WARN_ON(!schedule_work(&tfcp_req->abort_rcv_work));
drivers/nvme/target/io-cmd-file.c:	struct kiocb *iocb = &req->f.iocb;
drivers/nvme/target/io-cmd-file.c:	if (req->cmd->rw.opcode == nvme_cmd_write) {
drivers/nvme/target/io-cmd-file.c:		if (req->cmd->rw.control & cpu_to_le16(NVME_RW_FUA))
drivers/nvme/target/io-cmd-file.c:		call_iter = req->ns->file->f_op->write_iter;
drivers/nvme/target/io-cmd-file.c:		call_iter = req->ns->file->f_op->read_iter;
drivers/nvme/target/io-cmd-file.c:	iov_iter_bvec(&iter, rw, req->f.bvec, nr_segs, count);
drivers/nvme/target/io-cmd-file.c:	iocb->ki_filp = req->ns->file;
drivers/nvme/target/io-cmd-file.c:	iocb->ki_flags = ki_flags | iocb_flags(req->ns->file);
drivers/nvme/target/io-cmd-file.c:	if (req->f.bvec != req->inline_bvec) {
drivers/nvme/target/io-cmd-file.c:		if (likely(req->f.mpool_alloc == false))
drivers/nvme/target/io-cmd-file.c:			kfree(req->f.bvec);
drivers/nvme/target/io-cmd-file.c:			mempool_free(req->f.bvec, req->ns->bvec_pool);
drivers/nvme/target/io-cmd-file.c:	if (unlikely(ret != req->transfer_len))
drivers/nvme/target/io-cmd-file.c:	ssize_t nr_bvec = req->sg_cnt;
drivers/nvme/target/io-cmd-file.c:	if (req->f.mpool_alloc && nr_bvec > NVMET_MAX_MPOOL_BVEC)
drivers/nvme/target/io-cmd-file.c:	pos = le64_to_cpu(req->cmd->rw.slba) << req->ns->blksize_shift;
drivers/nvme/target/io-cmd-file.c:	if (unlikely(pos + req->transfer_len > req->ns->size)) {
drivers/nvme/target/io-cmd-file.c:	memset(&req->f.iocb, 0, sizeof(struct kiocb));
drivers/nvme/target/io-cmd-file.c:	for_each_sg(req->sg, sg, req->sg_cnt, i) {
drivers/nvme/target/io-cmd-file.c:		nvmet_file_init_bvec(&req->f.bvec[bv_cnt], sg);
drivers/nvme/target/io-cmd-file.c:		len += req->f.bvec[bv_cnt].bv_len;
drivers/nvme/target/io-cmd-file.c:		total_len += req->f.bvec[bv_cnt].bv_len;
drivers/nvme/target/io-cmd-file.c:	if (WARN_ON_ONCE(total_len != req->transfer_len)) {
drivers/nvme/target/io-cmd-file.c:		req->f.iocb.ki_complete = nvmet_file_io_done;
drivers/nvme/target/io-cmd-file.c:	nvmet_file_io_done(&req->f.iocb, ret, 0);
drivers/nvme/target/io-cmd-file.c:	INIT_WORK(&req->f.work, nvmet_file_buffered_io_work);
drivers/nvme/target/io-cmd-file.c:	queue_work(buffered_io_wq, &req->f.work);
drivers/nvme/target/io-cmd-file.c:	ssize_t nr_bvec = req->sg_cnt;
drivers/nvme/target/io-cmd-file.c:	if (!req->sg_cnt || !nr_bvec) {
drivers/nvme/target/io-cmd-file.c:		req->f.bvec = kmalloc_array(nr_bvec, sizeof(struct bio_vec),
drivers/nvme/target/io-cmd-file.c:		req->f.bvec = req->inline_bvec;
drivers/nvme/target/io-cmd-file.c:	if (unlikely(!req->f.bvec)) {
drivers/nvme/target/io-cmd-file.c:		req->f.bvec = mempool_alloc(req->ns->bvec_pool, GFP_KERNEL);
drivers/nvme/target/io-cmd-file.c:		req->f.mpool_alloc = true;
drivers/nvme/target/io-cmd-file.c:		req->f.mpool_alloc = false;
drivers/nvme/target/io-cmd-file.c:	if (req->ns->buffered_io) {
drivers/nvme/target/io-cmd-file.c:		if (likely(!req->f.mpool_alloc) &&
drivers/nvme/target/io-cmd-file.c:	return errno_to_nvme_status(req, vfs_fsync(req->ns->file, 1));
drivers/nvme/target/io-cmd-file.c:	INIT_WORK(&req->f.work, nvmet_file_flush_work);
drivers/nvme/target/io-cmd-file.c:	schedule_work(&req->f.work);
drivers/nvme/target/io-cmd-file.c:	for (i = 0; i <= le32_to_cpu(req->cmd->dsm.nr); i++) {
drivers/nvme/target/io-cmd-file.c:		offset = le64_to_cpu(range.slba) << req->ns->blksize_shift;
drivers/nvme/target/io-cmd-file.c:		len <<= req->ns->blksize_shift;
drivers/nvme/target/io-cmd-file.c:		if (offset + len > req->ns->size) {
drivers/nvme/target/io-cmd-file.c:			req->error_slba = le64_to_cpu(range.slba);
drivers/nvme/target/io-cmd-file.c:		ret = vfs_fallocate(req->ns->file, mode, offset, len);
drivers/nvme/target/io-cmd-file.c:			req->error_slba = le64_to_cpu(range.slba);
drivers/nvme/target/io-cmd-file.c:	switch (le32_to_cpu(req->cmd->dsm.attributes)) {
drivers/nvme/target/io-cmd-file.c:	INIT_WORK(&req->f.work, nvmet_file_dsm_work);
drivers/nvme/target/io-cmd-file.c:	schedule_work(&req->f.work);
drivers/nvme/target/io-cmd-file.c:	struct nvme_write_zeroes_cmd *write_zeroes = &req->cmd->write_zeroes;
drivers/nvme/target/io-cmd-file.c:	offset = le64_to_cpu(write_zeroes->slba) << req->ns->blksize_shift;
drivers/nvme/target/io-cmd-file.c:			req->ns->blksize_shift);
drivers/nvme/target/io-cmd-file.c:	if (unlikely(offset + len > req->ns->size)) {
drivers/nvme/target/io-cmd-file.c:	ret = vfs_fallocate(req->ns->file, mode, offset, len);
drivers/nvme/target/io-cmd-file.c:	INIT_WORK(&req->f.work, nvmet_file_write_zeroes_work);
drivers/nvme/target/io-cmd-file.c:	schedule_work(&req->f.work);
drivers/nvme/target/io-cmd-file.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/io-cmd-file.c:		req->execute = nvmet_file_execute_rw;
drivers/nvme/target/io-cmd-file.c:		req->execute = nvmet_file_execute_flush;
drivers/nvme/target/io-cmd-file.c:		req->execute = nvmet_file_execute_dsm;
drivers/nvme/target/io-cmd-file.c:		req->execute = nvmet_file_execute_write_zeroes;
drivers/nvme/target/passthru.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/passthru.c:	if (req->port->inline_data_size)
drivers/nvme/target/passthru.c:				req->port->inline_data_size) / 16);
drivers/nvme/target/passthru.c:	struct request *rq = req->p.rq;
drivers/nvme/target/passthru.c:	    req->cmd->common.opcode == nvme_admin_identify) {
drivers/nvme/target/passthru.c:		switch (req->cmd->identify.cns) {
drivers/nvme/target/passthru.c:	req->cqe->result = nvme_req(rq)->result;
drivers/nvme/target/passthru.c:	req->cqe->result = nvme_req(rq)->result;
drivers/nvme/target/passthru.c:	if (req->sg_cnt > BIO_MAX_VECS)
drivers/nvme/target/passthru.c:	if (req->transfer_len <= NVMET_MAX_INLINE_DATA_LEN) {
drivers/nvme/target/passthru.c:		bio = &req->p.inline_bio;
drivers/nvme/target/passthru.c:		bio_init(bio, req->inline_bvec, ARRAY_SIZE(req->inline_bvec));
drivers/nvme/target/passthru.c:		bio = bio_alloc(GFP_KERNEL, bio_max_segs(req->sg_cnt));
drivers/nvme/target/passthru.c:	for_each_sg(req->sg, sg, req->sg_cnt, i) {
drivers/nvme/target/passthru.c:			if (bio != &req->p.inline_bio)
drivers/nvme/target/passthru.c:	blk_rq_bio_prep(rq, bio, req->sg_cnt);
drivers/nvme/target/passthru.c:	if (likely(req->sq->qid != 0)) {
drivers/nvme/target/passthru.c:		u32 nsid = le32_to_cpu(req->cmd->common.nsid);
drivers/nvme/target/passthru.c:	rq = nvme_alloc_request(q, req->cmd, 0);
drivers/nvme/target/passthru.c:	if (req->sg_cnt) {
drivers/nvme/target/passthru.c:	effects = nvme_command_effects(ctrl, ns, req->cmd->common.opcode);
drivers/nvme/target/passthru.c:	if (req->p.use_workqueue || effects) {
drivers/nvme/target/passthru.c:		INIT_WORK(&req->p.work, nvmet_passthru_execute_cmd_work);
drivers/nvme/target/passthru.c:		req->p.rq = rq;
drivers/nvme/target/passthru.c:		schedule_work(&req->p.work);
drivers/nvme/target/passthru.c:	req->p.use_workqueue = false;
drivers/nvme/target/passthru.c:	req->execute = nvmet_passthru_execute_cmd;
drivers/nvme/target/passthru.c:	if (req->cmd->common.flags & ~NVME_CMD_SGL_ALL)
drivers/nvme/target/passthru.c:	switch (req->cmd->common.opcode) {
drivers/nvme/target/passthru.c:	switch (le32_to_cpu(req->cmd->features.fid)) {
drivers/nvme/target/passthru.c:	if (req->cmd->common.flags & ~NVME_CMD_SGL_ALL)
drivers/nvme/target/passthru.c:	if (req->cmd->common.opcode >= nvme_admin_vendor_start)
drivers/nvme/target/passthru.c:	switch (req->cmd->common.opcode) {
drivers/nvme/target/passthru.c:		req->execute = nvmet_execute_async_event;
drivers/nvme/target/passthru.c:		req->execute = nvmet_execute_keep_alive;
drivers/nvme/target/passthru.c:		switch (le32_to_cpu(req->cmd->features.fid)) {
drivers/nvme/target/passthru.c:			req->execute = nvmet_execute_set_features;
drivers/nvme/target/passthru.c:			req->execute = nvmet_passthru_set_host_behaviour;
drivers/nvme/target/passthru.c:		switch (le32_to_cpu(req->cmd->features.fid)) {
drivers/nvme/target/passthru.c:			req->execute = nvmet_execute_get_features;
drivers/nvme/target/passthru.c:		switch (req->cmd->identify.cns) {
drivers/nvme/target/passthru.c:			req->execute = nvmet_passthru_execute_cmd;
drivers/nvme/target/passthru.c:			req->p.use_workqueue = true;
drivers/nvme/target/passthru.c:			switch (req->cmd->identify.csi) {
drivers/nvme/target/passthru.c:				req->execute = nvmet_passthru_execute_cmd;
drivers/nvme/target/passthru.c:				req->p.use_workqueue = true;
drivers/nvme/target/passthru.c:			req->execute = nvmet_passthru_execute_cmd;
drivers/nvme/target/passthru.c:			req->p.use_workqueue = true;
drivers/nvme/target/passthru.c:			switch (req->cmd->identify.csi) {
drivers/nvme/target/passthru.c:				req->execute = nvmet_passthru_execute_cmd;
drivers/nvme/target/passthru.c:				req->p.use_workqueue = true;
drivers/nvme/target/io-cmd-bdev.c:		req->error_loc = offsetof(struct nvme_rw_command, length);
drivers/nvme/target/io-cmd-bdev.c:		req->error_loc = offsetof(struct nvme_rw_command, slba);
drivers/nvme/target/io-cmd-bdev.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/io-cmd-bdev.c:		switch (req->cmd->common.opcode) {
drivers/nvme/target/io-cmd-bdev.c:		req->error_loc = offsetof(struct nvme_rw_command, nsid);
drivers/nvme/target/io-cmd-bdev.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/io-cmd-bdev.c:	switch (req->cmd->common.opcode) {
drivers/nvme/target/io-cmd-bdev.c:		req->error_slba = le64_to_cpu(req->cmd->rw.slba);
drivers/nvme/target/io-cmd-bdev.c:		req->error_slba =
drivers/nvme/target/io-cmd-bdev.c:			le64_to_cpu(req->cmd->write_zeroes.slba);
drivers/nvme/target/io-cmd-bdev.c:		req->error_slba = 0;
drivers/nvme/target/io-cmd-bdev.c:	if (bio != &req->b.inline_bio)
drivers/nvme/target/io-cmd-bdev.c:	struct block_device *bdev = req->ns->bdev;
drivers/nvme/target/io-cmd-bdev.c:					bio_max_segs(req->metadata_sg_cnt));
drivers/nvme/target/io-cmd-bdev.c:	unsigned int sg_cnt = req->sg_cnt;
drivers/nvme/target/io-cmd-bdev.c:	unsigned int total_len = nvmet_rw_data_len(req) + req->metadata_len;
drivers/nvme/target/io-cmd-bdev.c:	if (!req->sg_cnt) {
drivers/nvme/target/io-cmd-bdev.c:	if (req->cmd->rw.opcode == nvme_cmd_write) {
drivers/nvme/target/io-cmd-bdev.c:		if (req->cmd->rw.control & cpu_to_le16(NVME_RW_FUA))
drivers/nvme/target/io-cmd-bdev.c:	if (is_pci_p2pdma_page(sg_page(req->sg)))
drivers/nvme/target/io-cmd-bdev.c:	sector = nvmet_lba_to_sect(req->ns, req->cmd->rw.slba);
drivers/nvme/target/io-cmd-bdev.c:	if (req->transfer_len <= NVMET_MAX_INLINE_DATA_LEN) {
drivers/nvme/target/io-cmd-bdev.c:		bio = &req->b.inline_bio;
drivers/nvme/target/io-cmd-bdev.c:		bio_init(bio, req->inline_bvec, ARRAY_SIZE(req->inline_bvec));
drivers/nvme/target/io-cmd-bdev.c:	bio_set_dev(bio, req->ns->bdev);
drivers/nvme/target/io-cmd-bdev.c:	if (req->metadata_len)
drivers/nvme/target/io-cmd-bdev.c:		sg_miter_start(&prot_miter, req->metadata_sg,
drivers/nvme/target/io-cmd-bdev.c:			       req->metadata_sg_cnt, iter_flags);
drivers/nvme/target/io-cmd-bdev.c:	for_each_sg(req->sg, sg, req->sg_cnt, i) {
drivers/nvme/target/io-cmd-bdev.c:			if (req->metadata_len) {
drivers/nvme/target/io-cmd-bdev.c:			bio_set_dev(bio, req->ns->bdev);
drivers/nvme/target/io-cmd-bdev.c:	if (req->metadata_len) {
drivers/nvme/target/io-cmd-bdev.c:	struct bio *bio = &req->b.inline_bio;
drivers/nvme/target/io-cmd-bdev.c:	bio_init(bio, req->inline_bvec, ARRAY_SIZE(req->inline_bvec));
drivers/nvme/target/io-cmd-bdev.c:	bio_set_dev(bio, req->ns->bdev);
drivers/nvme/target/io-cmd-bdev.c:	if (blkdev_issue_flush(req->ns->bdev))
drivers/nvme/target/io-cmd-bdev.c:	struct nvmet_ns *ns = req->ns;
drivers/nvme/target/io-cmd-bdev.c:		req->error_slba = le64_to_cpu(range->slba);
drivers/nvme/target/io-cmd-bdev.c:	for (i = 0; i <= le32_to_cpu(req->cmd->dsm.nr); i++) {
drivers/nvme/target/io-cmd-bdev.c:	switch (le32_to_cpu(req->cmd->dsm.attributes)) {
drivers/nvme/target/io-cmd-bdev.c:	struct nvme_write_zeroes_cmd *write_zeroes = &req->cmd->write_zeroes;
drivers/nvme/target/io-cmd-bdev.c:	sector = nvmet_lba_to_sect(req->ns, write_zeroes->slba);
drivers/nvme/target/io-cmd-bdev.c:		(req->ns->blksize_shift - 9));
drivers/nvme/target/io-cmd-bdev.c:	ret = __blkdev_issue_zeroout(req->ns->bdev, sector, nr_sector,
drivers/nvme/target/io-cmd-bdev.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/io-cmd-bdev.c:		req->execute = nvmet_bdev_execute_rw;
drivers/nvme/target/io-cmd-bdev.c:		if (req->sq->ctrl->pi_support && nvmet_ns_has_pi(req->ns))
drivers/nvme/target/io-cmd-bdev.c:			req->metadata_len = nvmet_rw_metadata_len(req);
drivers/nvme/target/io-cmd-bdev.c:		req->execute = nvmet_bdev_execute_flush;
drivers/nvme/target/io-cmd-bdev.c:		req->execute = nvmet_bdev_execute_dsm;
drivers/nvme/target/io-cmd-bdev.c:		req->execute = nvmet_bdev_execute_write_zeroes;
drivers/nvme/target/fc.c:	fc_dma_unmap_single(tgtport->dev, lsreq->rqstdma,
drivers/nvme/target/fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/target/fc.c:	lsreq->done = done;
drivers/nvme/target/fc.c:	lsreq->rqstdma = fc_dma_map_single(tgtport->dev, lsreq->rqstaddr,
drivers/nvme/target/fc.c:				  lsreq->rqstlen + lsreq->rsplen,
drivers/nvme/target/fc.c:	if (fc_dma_mapping_error(tgtport->dev, lsreq->rqstdma)) {
drivers/nvme/target/fc.c:	lsreq->rspdma = lsreq->rqstdma + lsreq->rqstlen;
drivers/nvme/target/fc.c:	fc_dma_unmap_single(tgtport->dev, lsreq->rqstdma,
drivers/nvme/target/fc.c:				  (lsreq->rqstlen + lsreq->rsplen),
drivers/nvme/target/fc.c:		lsreq->private = (void *)&discon_acc[1];
drivers/nvme/target/fc.c:		lsreq->private = NULL;
drivers/nvme/target/fc.c:	struct nvmet_fc_fcp_iod *fod = fcpreq->nvmet_fc_private;
drivers/nvme/target/fc.c:	fcpreq->hwqid = queue->qid ?
drivers/nvme/target/fc.c:	fcpreq->nvmet_fc_private = NULL;
drivers/nvme/target/fc.c:	memcpy(&fod->cmdiubuf, fcpreq->rspaddr, fcpreq->rsplen);
drivers/nvme/target/fc.c:	fcpreq->rspaddr = NULL;
drivers/nvme/target/fc.c:	fcpreq->rsplen  = 0;
drivers/nvme/target/fc.c:	fcpreq->nvmet_fc_private = fod;
drivers/nvme/target/fc.c:	if (fod->fcpreq->op == NVMET_FCOP_READDATA_RSP)
drivers/nvme/target/fc.c:	fod->fcpreq->rspaddr = ersp;
drivers/nvme/target/fc.c:	fod->fcpreq->rspdma = fod->rspdma;
drivers/nvme/target/fc.c:		fod->fcpreq->rsplen = NVME_FC_SIZEOF_ZEROS_RSP;
drivers/nvme/target/fc.c:		fod->fcpreq->rsplen = sizeof(*ersp);
drivers/nvme/target/fc.c:	fod->fcpreq->op = NVMET_FCOP_RSP;
drivers/nvme/target/fc.c:	fod->fcpreq->timeout = 0;
drivers/nvme/target/fc.c:	fcpreq->op = op;
drivers/nvme/target/fc.c:	fcpreq->offset = fod->offset;
drivers/nvme/target/fc.c:	fcpreq->timeout = NVME_FC_TGTOP_TIMEOUT_SEC;
drivers/nvme/target/fc.c:	fcpreq->sg = sg;
drivers/nvme/target/fc.c:	fcpreq->sg_cnt = 0;
drivers/nvme/target/fc.c:	       fcpreq->sg_cnt < tgtport->max_sg_cnt &&
drivers/nvme/target/fc.c:		fcpreq->sg_cnt++;
drivers/nvme/target/fc.c:	if (tlen < remaininglen && fcpreq->sg_cnt == 0) {
drivers/nvme/target/fc.c:		fcpreq->sg_cnt++;
drivers/nvme/target/fc.c:	fcpreq->transfer_length = tlen;
drivers/nvme/target/fc.c:	fcpreq->transferred_length = 0;
drivers/nvme/target/fc.c:	fcpreq->fcp_error = 0;
drivers/nvme/target/fc.c:	fcpreq->rsplen = 0;
drivers/nvme/target/fc.c:	    ((fod->offset + fcpreq->transfer_length) == fod->req.transfer_len) &&
drivers/nvme/target/fc.c:		fcpreq->op = NVMET_FCOP_READDATA_RSP;
drivers/nvme/target/fc.c:			fcpreq->fcp_error = ret;
drivers/nvme/target/fc.c:			fcpreq->transferred_length = 0;
drivers/nvme/target/fc.c:		if (fcpreq->op == NVMET_FCOP_WRITEDATA) {
drivers/nvme/target/fc.c:	switch (fcpreq->op) {
drivers/nvme/target/fc.c:		if (fcpreq->fcp_error ||
drivers/nvme/target/fc.c:		    fcpreq->transferred_length != fcpreq->transfer_length) {
drivers/nvme/target/fc.c:		fod->offset += fcpreq->transferred_length;
drivers/nvme/target/fc.c:		if (fcpreq->fcp_error ||
drivers/nvme/target/fc.c:		    fcpreq->transferred_length != fcpreq->transfer_length) {
drivers/nvme/target/fc.c:		if (fcpreq->op == NVMET_FCOP_READDATA_RSP) {
drivers/nvme/target/fc.c:		fod->offset += fcpreq->transferred_length;
drivers/nvme/target/fc.c:	struct nvmet_fc_fcp_iod *fod = fcpreq->nvmet_fc_private;
drivers/nvme/target/fc.c:	fod->fcpreq->done = nvmet_fc_xmt_fcp_op_done;
drivers/nvme/target/fc.c:		fcpreq->nvmet_fc_private = fod;
drivers/nvme/target/fc.c:	fcpreq->rspaddr = cmdiubuf;
drivers/nvme/target/fc.c:	fcpreq->rsplen  = cmdiubuf_len;
drivers/nvme/target/fc.c:	struct nvmet_fc_fcp_iod *fod = fcpreq->nvmet_fc_private;
drivers/nvme/target/trace.h:	return req->sq->ctrl;
drivers/nvme/target/trace.h:	if (!req->ns) {
drivers/nvme/target/trace.h:	strncpy(name, req->ns->device_path,
drivers/nvme/target/trace.h:		min_t(size_t, DISK_NAME_LEN, strlen(req->ns->device_path)));
drivers/nvme/target/trace.h:		__entry->qid = req->sq->qid;
drivers/nvme/target/trace.h:		__entry->qid = req->cq->qid;
drivers/nvme/target/trace.h:		__entry->cid = req->cqe->command_id;
drivers/nvme/target/trace.h:		__entry->result = le64_to_cpu(req->cqe->result.u64);
drivers/nvme/target/trace.h:		__entry->status = le16_to_cpu(req->cqe->status) >> 1;
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_rw_command, length);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_rw_command, slba);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/core.c:		switch (req->cmd->common.opcode) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_rw_command, nsid);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/core.c:	pr_debug("unhandled cmd %d on qid %d\n", req->cmd->common.opcode,
drivers/nvme/target/core.c:		 req->sq->qid);
drivers/nvme/target/core.c:	req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/nvme/target/core.c:	if (sg_pcopy_from_buffer(req->sg, req->sg_cnt, buf, len, off) != len) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, dptr);
drivers/nvme/target/core.c:	if (sg_pcopy_to_buffer(req->sg, req->sg_cnt, buf, len, off) != len) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, dptr);
drivers/nvme/target/core.c:	if (sg_zero_buffer(req->sg, req->sg_cnt, len, off) != len) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, dptr);
drivers/nvme/target/core.c:		trace_nvmet_async_event(ctrl, req->cqe->result.u32);
drivers/nvme/target/core.c:	u32 nsid = le32_to_cpu(req->cmd->common.nsid);
drivers/nvme/target/core.c:	req->ns = xa_load(&nvmet_req_subsys(req)->namespaces, nsid);
drivers/nvme/target/core.c:	if (unlikely(!req->ns)) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, nsid);
drivers/nvme/target/core.c:	percpu_ref_get(&req->ns->ref);
drivers/nvme/target/core.c:	if (req->sq->size) {
drivers/nvme/target/core.c:			old_sqhd = req->sq->sqhd;
drivers/nvme/target/core.c:			new_sqhd = (old_sqhd + 1) % req->sq->size;
drivers/nvme/target/core.c:		} while (cmpxchg(&req->sq->sqhd, old_sqhd, new_sqhd) !=
drivers/nvme/target/core.c:	req->cqe->sq_head = cpu_to_le16(req->sq->sqhd & 0x0000FFFF);
drivers/nvme/target/core.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/core.c:	req->cqe->status = cpu_to_le16(status << 1);
drivers/nvme/target/core.c:	if (!ctrl || req->error_loc == NVMET_NO_ERROR_LOC)
drivers/nvme/target/core.c:	new_error_slot->sqid = cpu_to_le16(req->sq->qid);
drivers/nvme/target/core.c:	new_error_slot->cmdid = cpu_to_le16(req->cmd->common.command_id);
drivers/nvme/target/core.c:	new_error_slot->param_error_location = cpu_to_le16(req->error_loc);
drivers/nvme/target/core.c:	new_error_slot->lba = cpu_to_le64(req->error_slba);
drivers/nvme/target/core.c:	new_error_slot->nsid = req->cmd->common.nsid;
drivers/nvme/target/core.c:	req->cqe->status |= cpu_to_le16(1 << 14);
drivers/nvme/target/core.c:	if (!req->sq->sqhd_disabled)
drivers/nvme/target/core.c:	req->cqe->sq_id = cpu_to_le16(req->sq->qid);
drivers/nvme/target/core.c:	req->cqe->command_id = req->cmd->common.command_id;
drivers/nvme/target/core.c:	if (req->ns)
drivers/nvme/target/core.c:		nvmet_put_namespace(req->ns);
drivers/nvme/target/core.c:	req->ops->queue_response(req);
drivers/nvme/target/core.c:	percpu_ref_put(&req->sq->ref);
drivers/nvme/target/core.c:	if (unlikely(req->ns->readonly)) {
drivers/nvme/target/core.c:		switch (req->cmd->common.opcode) {
drivers/nvme/target/core.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/core.c:	ret = nvmet_check_ana_state(req->port, req->ns);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, nsid);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, nsid);
drivers/nvme/target/core.c:	if (req->ns->file)
drivers/nvme/target/core.c:	u8 flags = req->cmd->common.flags;
drivers/nvme/target/core.c:	req->cq = cq;
drivers/nvme/target/core.c:	req->sq = sq;
drivers/nvme/target/core.c:	req->ops = ops;
drivers/nvme/target/core.c:	req->sg = NULL;
drivers/nvme/target/core.c:	req->metadata_sg = NULL;
drivers/nvme/target/core.c:	req->sg_cnt = 0;
drivers/nvme/target/core.c:	req->metadata_sg_cnt = 0;
drivers/nvme/target/core.c:	req->transfer_len = 0;
drivers/nvme/target/core.c:	req->metadata_len = 0;
drivers/nvme/target/core.c:	req->cqe->status = 0;
drivers/nvme/target/core.c:	req->cqe->sq_head = 0;
drivers/nvme/target/core.c:	req->ns = NULL;
drivers/nvme/target/core.c:	req->error_loc = NVMET_NO_ERROR_LOC;
drivers/nvme/target/core.c:	req->error_slba = 0;
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, flags);
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, flags);
drivers/nvme/target/core.c:	if (unlikely(!req->sq->ctrl))
drivers/nvme/target/core.c:	else if (likely(req->sq->qid != 0))
drivers/nvme/target/core.c:	trace_nvmet_req_init(req, req->cmd);
drivers/nvme/target/core.c:	percpu_ref_put(&req->sq->ref);
drivers/nvme/target/core.c:	if (req->ns)
drivers/nvme/target/core.c:		nvmet_put_namespace(req->ns);
drivers/nvme/target/core.c:	if (unlikely(len != req->transfer_len)) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, dptr);
drivers/nvme/target/core.c:	if (unlikely(data_len > req->transfer_len)) {
drivers/nvme/target/core.c:		req->error_loc = offsetof(struct nvme_common_command, dptr);
drivers/nvme/target/core.c:	return req->transfer_len - req->metadata_len;
drivers/nvme/target/core.c:	req->sg = pci_p2pmem_alloc_sgl(req->p2p_dev, &req->sg_cnt,
drivers/nvme/target/core.c:	if (!req->sg)
drivers/nvme/target/core.c:	if (req->metadata_len) {
drivers/nvme/target/core.c:		req->metadata_sg = pci_p2pmem_alloc_sgl(req->p2p_dev,
drivers/nvme/target/core.c:				&req->metadata_sg_cnt, req->metadata_len);
drivers/nvme/target/core.c:		if (!req->metadata_sg)
drivers/nvme/target/core.c:	pci_p2pmem_free_sgl(req->p2p_dev, req->sg);
drivers/nvme/target/core.c:	if (req->sq->ctrl && req->sq->qid && req->ns) {
drivers/nvme/target/core.c:		req->p2p_dev = radix_tree_lookup(&req->sq->ctrl->p2p_ns_map,
drivers/nvme/target/core.c:						 req->ns->nsid);
drivers/nvme/target/core.c:		if (req->p2p_dev)
drivers/nvme/target/core.c:	req->p2p_dev = NULL;
drivers/nvme/target/core.c:	req->sg = sgl_alloc(nvmet_data_transfer_len(req), GFP_KERNEL,
drivers/nvme/target/core.c:			    &req->sg_cnt);
drivers/nvme/target/core.c:	if (unlikely(!req->sg))
drivers/nvme/target/core.c:	if (req->metadata_len) {
drivers/nvme/target/core.c:		req->metadata_sg = sgl_alloc(req->metadata_len, GFP_KERNEL,
drivers/nvme/target/core.c:					     &req->metadata_sg_cnt);
drivers/nvme/target/core.c:		if (unlikely(!req->metadata_sg))
drivers/nvme/target/core.c:	sgl_free(req->sg);
drivers/nvme/target/core.c:	if (req->p2p_dev) {
drivers/nvme/target/core.c:		pci_p2pmem_free_sgl(req->p2p_dev, req->sg);
drivers/nvme/target/core.c:		if (req->metadata_sg)
drivers/nvme/target/core.c:			pci_p2pmem_free_sgl(req->p2p_dev, req->metadata_sg);
drivers/nvme/target/core.c:		sgl_free(req->sg);
drivers/nvme/target/core.c:		if (req->metadata_sg)
drivers/nvme/target/core.c:			sgl_free(req->metadata_sg);
drivers/nvme/target/core.c:	req->sg = NULL;
drivers/nvme/target/core.c:	req->metadata_sg = NULL;
drivers/nvme/target/core.c:	req->sg_cnt = 0;
drivers/nvme/target/core.c:	req->metadata_sg_cnt = 0;
drivers/nvme/target/core.c:	subsys = nvmet_find_get_subsys(req->port, subsysnqn);
drivers/nvme/target/core.c:		req->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(subsysnqn);
drivers/nvme/target/core.c:	req->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(cntlid);
drivers/nvme/target/core.c:	if (unlikely(!(req->sq->ctrl->cc & NVME_CC_ENABLE))) {
drivers/nvme/target/core.c:		       cmd->common.opcode, req->sq->qid);
drivers/nvme/target/core.c:	if (unlikely(!(req->sq->ctrl->csts & NVME_CSTS_RDY))) {
drivers/nvme/target/core.c:		       cmd->common.opcode, req->sq->qid);
drivers/nvme/target/core.c:	if (!req->p2p_client)
drivers/nvme/target/core.c:	ctrl->p2p_client = get_device(req->p2p_client);
drivers/nvme/target/core.c:	subsys = nvmet_find_get_subsys(req->port, subsysnqn);
drivers/nvme/target/core.c:		req->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(subsysnqn);
drivers/nvme/target/core.c:		req->cqe->result.u32 = IPO_IATTR_CONNECT_DATA(hostnqn);
drivers/nvme/target/core.c:	ctrl->port = req->port;
drivers/nvme/target/core.c:	ctrl->ops = req->ops;
drivers/nvme/target/discovery.c: * from the req->port address in case the port in question listens
drivers/nvme/target/discovery.c:	if (req->ops->disc_traddr)
drivers/nvme/target/discovery.c:		req->ops->disc_traddr(req, port, traddr);
drivers/nvme/target/discovery.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/discovery.c:	list_for_each_entry(p, &req->port->subsystems, entry) {
drivers/nvme/target/discovery.c:	list_for_each_entry(r, &req->port->referrals, entry)
drivers/nvme/target/discovery.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/discovery.c:	u64 offset = nvmet_get_log_page_offset(req->cmd);
drivers/nvme/target/discovery.c:	size_t data_len = nvmet_get_log_page_len(req->cmd);
drivers/nvme/target/discovery.c:	if (req->cmd->get_log_page.lid != NVME_LOG_DISC) {
drivers/nvme/target/discovery.c:		req->error_loc =
drivers/nvme/target/discovery.c:	list_for_each_entry(p, &req->port->subsystems, entry) {
drivers/nvme/target/discovery.c:		nvmet_set_disc_traddr(req, req->port, traddr);
drivers/nvme/target/discovery.c:		nvmet_format_discovery_entry(hdr, req->port,
drivers/nvme/target/discovery.c:	list_for_each_entry(r, &req->port->referrals, entry) {
drivers/nvme/target/discovery.c:	struct nvmet_ctrl *ctrl = req->sq->ctrl;
drivers/nvme/target/discovery.c:	if (req->cmd->identify.cns != NVME_ID_CNS_CTRL) {
drivers/nvme/target/discovery.c:		req->error_loc = offsetof(struct nvme_identify, cns);
drivers/nvme/target/discovery.c:	if (req->port->inline_data_size)
drivers/nvme/target/discovery.c:	u32 cdw10 = le32_to_cpu(req->cmd->common.cdw10);
drivers/nvme/target/discovery.c:		req->error_loc =
drivers/nvme/target/discovery.c:	u32 cdw10 = le32_to_cpu(req->cmd->common.cdw10);
drivers/nvme/target/discovery.c:		req->error_loc =
drivers/nvme/target/discovery.c:	struct nvme_command *cmd = req->cmd;
drivers/nvme/target/discovery.c:	if (unlikely(!(req->sq->ctrl->csts & NVME_CSTS_RDY))) {
drivers/nvme/target/discovery.c:		req->error_loc =
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_disc_set_features;
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_disc_get_features;
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_async_event;
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_keep_alive;
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_disc_get_log_page;
drivers/nvme/target/discovery.c:		req->execute = nvmet_execute_disc_identify;
drivers/nvme/target/discovery.c:		req->error_loc = offsetof(struct nvme_common_command, opcode);
drivers/cpufreq/spear-cpufreq.c:	.name		= "cpufreq-spear",
drivers/cpufreq/s3c24xx-cpufreq.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
drivers/cpufreq/qcom-cpufreq-nvmem.c: * The qcom-cpufreq-nvmem driver reads the msm-id and efuse value from the SoC
drivers/cpufreq/qcom-cpufreq-nvmem.c:	cpufreq_dt_pdev = platform_device_register_simple("cpufreq-dt", -1,
drivers/cpufreq/qcom-cpufreq-nvmem.c:		.name = "qcom-cpufreq-nvmem",
drivers/cpufreq/qcom-cpufreq-nvmem.c:	cpufreq_pdev = platform_device_register_data(NULL, "qcom-cpufreq-nvmem",
drivers/cpufreq/armada-8k-cpufreq.c:	armada_8k_pdev = platform_device_register_simple("cpufreq-dt", -1,
drivers/cpufreq/sun50i-cpufreq-nvmem.c: * The sun50i-cpufreq-nvmem driver reads the efuse value from the SoC to
drivers/cpufreq/sun50i-cpufreq-nvmem.c:	cpufreq_dt_pdev = platform_device_register_simple("cpufreq-dt", -1,
drivers/cpufreq/sun50i-cpufreq-nvmem.c:		.name = "sun50i-cpufreq-nvmem",
drivers/cpufreq/sun50i-cpufreq-nvmem.c:		platform_device_register_simple("sun50i-cpufreq-nvmem",
drivers/cpufreq/Makefile:obj-$(CONFIG_CPUFREQ_DT)		+= cpufreq-dt.o
drivers/cpufreq/Makefile:obj-$(CONFIG_CPUFREQ_DT_PLATDEV)	+= cpufreq-dt-platdev.o
drivers/cpufreq/Makefile:obj-$(CONFIG_X86_CPUFREQ_NFORCE2)	+= cpufreq-nforce2.o
drivers/cpufreq/Makefile:obj-$(CONFIG_ARM_IMX_CPUFREQ_DT)	+= imx-cpufreq-dt.o
drivers/cpufreq/Makefile:obj-$(CONFIG_ARM_QCOM_CPUFREQ_HW)	+= qcom-cpufreq-hw.o
drivers/cpufreq/Makefile:obj-$(CONFIG_ARM_QCOM_CPUFREQ_NVMEM)	+= qcom-cpufreq-nvmem.o
drivers/cpufreq/Makefile:obj-$(CONFIG_ARM_S3C24XX_CPUFREQ_DEBUGFS) += s3c24xx-cpufreq-debugfs.o
drivers/cpufreq/Makefile:obj-$(CONFIG_ARM_ALLWINNER_SUN50I_CPUFREQ_NVMEM) += sun50i-cpufreq-nvmem.o
drivers/cpufreq/Makefile:ppc-cbe-cpufreq-y			+= ppc_cbe_cpufreq_pervasive.o ppc_cbe_cpufreq.o
drivers/cpufreq/s3c64xx-cpufreq.c:		dvfs = &s3c64xx_dvfs_table[freq->driver_data];
drivers/cpufreq/s3c64xx-cpufreq.c:				 freq->frequency);
drivers/cpufreq/s3c64xx-cpufreq.c:			freq->frequency = CPUFREQ_ENTRY_INVALID;
drivers/cpufreq/s3c64xx-cpufreq.c:		r = clk_round_rate(policy->clk, freq->frequency * 1000);
drivers/cpufreq/s3c64xx-cpufreq.c:		if (r != freq->frequency) {
drivers/cpufreq/s3c64xx-cpufreq.c:				 freq->frequency);
drivers/cpufreq/s3c64xx-cpufreq.c:			freq->frequency = CPUFREQ_ENTRY_INVALID;
drivers/cpufreq/s3c64xx-cpufreq.c:		if (!vddarm && freq->frequency > clk_get_rate(policy->clk) / 1000)
drivers/cpufreq/s3c64xx-cpufreq.c:			freq->frequency = CPUFREQ_ENTRY_INVALID;
drivers/cpufreq/davinci-cpufreq.c:		.name	 = "cpufreq-davinci",
drivers/cpufreq/raspberrypi-cpufreq.c:	cpufreq_dt = platform_device_register_simple("cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/highbank-cpufreq.c: * the cpufreq-dt driver changes to frequency to alert the highbank
drivers/cpufreq/highbank-cpufreq.c:	struct platform_device_info devinfo = { .name = "cpufreq-dt", };
drivers/cpufreq/highbank-cpufreq.c:	/* Instantiate cpufreq-dt */
drivers/cpufreq/cpufreq.c:	 * freq-table. This also makes cpufreq stats inconsistent as
drivers/cpufreq/cpufreq.c:	 * cpufreq-stats would fail to register because current frequency of CPU
drivers/cpufreq/cpufreq.c:	 * isn't found in freq-table.
drivers/cpufreq/freq_table.c:			pr_warn("Duplicate freq-table entries: %u\n",
drivers/cpufreq/imx-cpufreq-dt.c:#include "cpufreq-dt.h"
drivers/cpufreq/imx-cpufreq-dt.c:/* cpufreq-dt device registered by imx-cpufreq-dt */
drivers/cpufreq/imx-cpufreq-dt.c:		dt_pdev = platform_device_register_data(NULL, "cpufreq-dt",
drivers/cpufreq/imx-cpufreq-dt.c:			dev_err(&pdev->dev, "Failed to register cpufreq-dt: %d\n", ret);
drivers/cpufreq/imx-cpufreq-dt.c:			&pdev->dev, "cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/imx-cpufreq-dt.c:		dev_err(&pdev->dev, "Failed to register cpufreq-dt: %d\n", ret);
drivers/cpufreq/imx-cpufreq-dt.c:		.name = "imx-cpufreq-dt",
drivers/cpufreq/imx-cpufreq-dt.c:MODULE_ALIAS("platform:imx-cpufreq-dt");
drivers/cpufreq/ia64-acpi-cpufreq.c:	unsigned int		cpu = req->cpu;
drivers/cpufreq/ia64-acpi-cpufreq.c:	unsigned int		cpu = req->cpu;
drivers/cpufreq/ia64-acpi-cpufreq.c:	int			ret, state = req->state;
drivers/cpufreq/omap-cpufreq.c:	dev_dbg(mpu_dev, "cpufreq-omap: %u MHz, %ld mV --> %u MHz, %ld mV\n", 
drivers/cpufreq/s3c2440-cpufreq.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
drivers/cpufreq/pxa2xx-cpufreq.c:	vmin = pxa_freq->vmin;
drivers/cpufreq/pxa2xx-cpufreq.c:	vmax = pxa_freq->vmax;
drivers/cpufreq/mvebu-cpufreq.c:	platform_device_register_simple("cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/s3c24xx-cpufreq-debugfs.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
drivers/cpufreq/Kconfig.arm:	  module will be called sun50i-cpufreq-nvmem.
drivers/cpufreq/Kconfig.arm:	  based on cpufreq-dt.
drivers/cpufreq/Kconfig.arm:	  use the cpufreq-dt driver on all Texas Instruments platforms that
drivers/cpufreq/cpufreq-dt-platdev.c:#include "cpufreq-dt.h"
drivers/cpufreq/cpufreq-dt-platdev.c:	return PTR_ERR_OR_ZERO(platform_device_register_data(NULL, "cpufreq-dt",
drivers/cpufreq/Kconfig:	  management.  This creates a 'cpufreq-dt' platform device, on the
drivers/cpufreq/s5pv210-cpufreq.c:	 * cpufreq-dt driver.
drivers/cpufreq/tegra20-cpufreq.c:	cpufreq_dt = platform_device_register_simple("cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/tegra20-cpufreq.c:			"failed to create cpufreq-dt device: %d\n", err);
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->is_dvs)
drivers/cpufreq/s3c2416-cpufreq.c:	return clk_get_rate(s3c_freq->armclk) / 1000;
drivers/cpufreq/s3c2416-cpufreq.c:	if (clk_get_rate(s3c_freq->armdiv) / 1000 != freq) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = clk_set_rate(s3c_freq->armdiv, freq * 1000);
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->is_dvs) {
drivers/cpufreq/s3c2416-cpufreq.c:		 clk_get_rate(s3c_freq->hclk) / 1000);
drivers/cpufreq/s3c2416-cpufreq.c:	ret = clk_set_parent(s3c_freq->armclk, s3c_freq->hclk);
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->vddarm) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = regulator_set_voltage(s3c_freq->vddarm,
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->is_dvs = 1;
drivers/cpufreq/s3c2416-cpufreq.c:	if (!s3c_freq->is_dvs) {
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->vddarm) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = regulator_set_voltage(s3c_freq->vddarm,
drivers/cpufreq/s3c2416-cpufreq.c:	if (clk_get_rate(s3c_freq->armdiv) > clk_get_rate(s3c_freq->hclk)) {
drivers/cpufreq/s3c2416-cpufreq.c:			 clk_get_rate(s3c_freq->hclk) / 1000);
drivers/cpufreq/s3c2416-cpufreq.c:					clk_get_rate(s3c_freq->hclk) / 1000);
drivers/cpufreq/s3c2416-cpufreq.c:			       clk_get_rate(s3c_freq->hclk) / 1000, ret);
drivers/cpufreq/s3c2416-cpufreq.c:			clk_get_rate(s3c_freq->armdiv) / 1000);
drivers/cpufreq/s3c2416-cpufreq.c:	ret = clk_set_parent(s3c_freq->armclk, s3c_freq->armdiv);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->is_dvs = 0;
drivers/cpufreq/s3c2416-cpufreq.c:	idx = s3c_freq->freq_table[index].driver_data;
drivers/cpufreq/s3c2416-cpufreq.c:	if (to_dvs && s3c_freq->disable_dvs) {
drivers/cpufreq/s3c2416-cpufreq.c:	new_freq = (s3c_freq->is_dvs && !to_dvs)
drivers/cpufreq/s3c2416-cpufreq.c:				? clk_get_rate(s3c_freq->hclk) / 1000
drivers/cpufreq/s3c2416-cpufreq.c:				: s3c_freq->freq_table[index].frequency;
drivers/cpufreq/s3c2416-cpufreq.c:	} else if (s3c_freq->is_dvs) {
drivers/cpufreq/s3c2416-cpufreq.c:	count = regulator_count_voltages(s3c_freq->vddarm);
drivers/cpufreq/s3c2416-cpufreq.c:	cpufreq_for_each_valid_entry(pos, s3c_freq->freq_table) {
drivers/cpufreq/s3c2416-cpufreq.c:			v = regulator_list_voltage(s3c_freq->vddarm, i);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->regulator_latency = 1 * 1000 * 1000;
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->disable_dvs = 1;
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->is_dvs) {
drivers/cpufreq/s3c2416-cpufreq.c:		s3c_freq->freq_table = s3c2416_freq_table;
drivers/cpufreq/s3c2416-cpufreq.c:		s3c_freq->freq_table = s3c2450_freq_table;
drivers/cpufreq/s3c2416-cpufreq.c:	if (s3c_freq->freq_table == NULL) {
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->is_dvs = 0;
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->armdiv = clk_get(NULL, "armdiv");
drivers/cpufreq/s3c2416-cpufreq.c:	if (IS_ERR(s3c_freq->armdiv)) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = PTR_ERR(s3c_freq->armdiv);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->hclk = clk_get(NULL, "hclk");
drivers/cpufreq/s3c2416-cpufreq.c:	if (IS_ERR(s3c_freq->hclk)) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = PTR_ERR(s3c_freq->hclk);
drivers/cpufreq/s3c2416-cpufreq.c:	rate = clk_get_rate(s3c_freq->hclk);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->armclk = clk_get(NULL, "armclk");
drivers/cpufreq/s3c2416-cpufreq.c:	if (IS_ERR(s3c_freq->armclk)) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = PTR_ERR(s3c_freq->armclk);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->vddarm = regulator_get(NULL, "vddarm");
drivers/cpufreq/s3c2416-cpufreq.c:	if (IS_ERR(s3c_freq->vddarm)) {
drivers/cpufreq/s3c2416-cpufreq.c:		ret = PTR_ERR(s3c_freq->vddarm);
drivers/cpufreq/s3c2416-cpufreq.c:	s3c_freq->regulator_latency = 0;
drivers/cpufreq/s3c2416-cpufreq.c:	cpufreq_for_each_entry(pos, s3c_freq->freq_table) {
drivers/cpufreq/s3c2416-cpufreq.c:			if (!s3c_freq->hclk) {
drivers/cpufreq/s3c2416-cpufreq.c:		rate = clk_round_rate(s3c_freq->armdiv,
drivers/cpufreq/s3c2416-cpufreq.c:	cpufreq_generic_init(policy, s3c_freq->freq_table,
drivers/cpufreq/s3c2416-cpufreq.c:			(500 * 1000) + s3c_freq->regulator_latency);
drivers/cpufreq/s3c2416-cpufreq.c:	clk_put(s3c_freq->armclk);
drivers/cpufreq/s3c2416-cpufreq.c:	clk_put(s3c_freq->hclk);
drivers/cpufreq/s3c2416-cpufreq.c:	clk_put(s3c_freq->armdiv);
drivers/cpufreq/sti-cpufreq.c:	platform_device_register_simple("cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/loongson1-cpufreq.c:	clk_set_parent(policy->clk, cpufreq->osc_clk);
drivers/cpufreq/loongson1-cpufreq.c:	clk_set_rate(cpufreq->mux_clk, new_freq * 1000);
drivers/cpufreq/loongson1-cpufreq.c:	clk_set_parent(policy->clk, cpufreq->mux_clk);
drivers/cpufreq/loongson1-cpufreq.c:	pll_freq = clk_get_rate(cpufreq->pll_clk) / 1000;
drivers/cpufreq/loongson1-cpufreq.c:		if ((freq < cpufreq->min_freq) || (freq > cpufreq->max_freq))
drivers/cpufreq/loongson1-cpufreq.c:	policy->clk = cpufreq->clk;
drivers/cpufreq/loongson1-cpufreq.c:	.name		= "cpufreq-ls1x",
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->dev = &pdev->dev;
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->clk = clk;
drivers/cpufreq/loongson1-cpufreq.c:			__clk_get_name(cpufreq->clk));
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->mux_clk = clk;
drivers/cpufreq/loongson1-cpufreq.c:			__clk_get_name(cpufreq->mux_clk));
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->pll_clk = clk;
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->osc_clk = clk;
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->max_freq = pdata->max_freq;
drivers/cpufreq/loongson1-cpufreq.c:	cpufreq->min_freq = pdata->min_freq;
drivers/cpufreq/s3c2410-cpufreq.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
drivers/cpufreq/qcom-cpufreq-hw.c:		ret = of_parse_phandle_with_args(cpu_np, "qcom,freq-domain",
drivers/cpufreq/qcom-cpufreq-hw.c:						 "#freq-domain-cells", 0,
drivers/cpufreq/qcom-cpufreq-hw.c:	{ .compatible = "qcom,cpufreq-hw", .data = &qcom_soc_data },
drivers/cpufreq/qcom-cpufreq-hw.c:	{ .compatible = "qcom,cpufreq-epss", .data = &epss_soc_data },
drivers/cpufreq/qcom-cpufreq-hw.c:	ret = of_parse_phandle_with_args(cpu_np, "qcom,freq-domain",
drivers/cpufreq/qcom-cpufreq-hw.c:					 "#freq-domain-cells", 0, &args);
drivers/cpufreq/qcom-cpufreq-hw.c:	.name		= "qcom-cpufreq-hw",
drivers/cpufreq/qcom-cpufreq-hw.c:		.name = "qcom-cpufreq-hw",
drivers/cpufreq/cpufreq-dt.c:#include "cpufreq-dt.h"
drivers/cpufreq/cpufreq-dt.c:	.name = "cpufreq-dt",
drivers/cpufreq/cpufreq-dt.c:		.name	= "cpufreq-dt",
drivers/cpufreq/cpufreq-dt.c:MODULE_ALIAS("platform:cpufreq-dt");
drivers/cpufreq/tegra124-cpufreq.c:	cpufreq_dt_devinfo.name = "cpufreq-dt";
drivers/cpufreq/tegra124-cpufreq.c:	.driver.name	= "cpufreq-tegra124",
drivers/cpufreq/tegra124-cpufreq.c:	pdev = platform_device_register_simple("cpufreq-tegra124", -1, NULL, 0);
drivers/cpufreq/armada-37xx-cpufreq.c:#include "cpufreq-dt.h"
drivers/cpufreq/armada-37xx-cpufreq.c:	pdev = platform_device_register_data(NULL, "cpufreq-dt", -1, &pdata,
drivers/cpufreq/ti-cpufreq.c:			 "OPP-v2 not supported, cpufreq-dt will attempt to use legacy tables.\n");
drivers/cpufreq/ti-cpufreq.c:	platform_device_register_simple("cpufreq-dt", -1, NULL, 0);
drivers/cpufreq/s3c2412-cpufreq.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
drivers/cpufreq/imx6q-cpufreq.c:	 * voltage like <freq-kHz vol-uV>.
drivers/s390/char/sclp_ftp.c:		 req->sccb, 24, req->sccb);
drivers/s390/char/sclp_ftp.c:	req->command = SCLP_CMDW_WRITE_EVENT_DATA;
drivers/s390/char/sclp_ftp.c:	req->sccb = sccb;
drivers/s390/char/sclp_ftp.c:	req->status = SCLP_REQ_FILLED;
drivers/s390/char/sclp_ftp.c:	req->callback = sclp_ftp_txcb;
drivers/s390/char/sclp_ftp.c:	req->callback_data = &completion;
drivers/s390/char/sclp_ftp.c:	if (req->status != SCLP_REQ_DONE ||
drivers/s390/char/tape_core.c:		rc = scnprintf(buf,PAGE_SIZE, "%s\n", tape_op_verbose[req->op]);
drivers/s390/char/tape_core.c:		if (req->status == TAPE_REQUEST_LONG_BUSY) {
drivers/s390/char/con3215.c:	raw3215_freelist = req->next;
drivers/s390/char/con3215.c:	if (req->type == RAW3215_FREE)
drivers/s390/char/con3215.c:	req->type = RAW3215_FREE;
drivers/s390/char/con3215.c:	req->next = raw3215_freelist;
drivers/s390/char/con3215.c:		req->type = RAW3215_READ;
drivers/s390/char/con3215.c:		req->info = raw;
drivers/s390/char/con3215.c:	ccw = req->ccws;
drivers/s390/char/con3215.c:		req->type = RAW3215_WRITE;
drivers/s390/char/con3215.c:		req->info = raw;
drivers/s390/char/con3215.c:		raw->written -= req->len;
drivers/s390/char/con3215.c:	ccw = req->ccws;
drivers/s390/char/con3215.c:	req->start = (raw->head - raw->count + raw->written) &
drivers/s390/char/con3215.c:	ix = req->start;
drivers/s390/char/con3215.c:	len = ((ix - 1 - req->start) & (RAW3215_BUFFER_SIZE - 1)) + 1;
drivers/s390/char/con3215.c:	req->len = len;
drivers/s390/char/con3215.c:	req->delayable = (ix == raw->head) && (len < RAW3215_MIN_WRITE);
drivers/s390/char/con3215.c:	ix = req->start;
drivers/s390/char/con3215.c:		if (ccw > req->ccws)
drivers/s390/char/con3215.c:	if (ccw > req->ccws)
drivers/s390/char/con3215.c:		res = ccw_device_start(raw->cdev, req->ccws,
drivers/s390/char/con3215.c:		res = ccw_device_start(raw->cdev, req->ccws,
drivers/s390/char/con3215.c:		if ((raw = req->info) == NULL)
drivers/s390/char/con3215.c:		if (req->type == RAW3215_READ) {
drivers/s390/char/con3215.c:			req->residual = irb->scsw.cmd.count;
drivers/s390/char/con3215.c:		if ((raw = req->info) == NULL)
drivers/s390/char/con3215.c:		if (req->type == RAW3215_READ && tty != NULL) {
drivers/s390/char/con3215.c:			count = 160 - req->residual;
drivers/s390/char/con3215.c:		} else if (req->type == RAW3215_WRITE) {
drivers/s390/char/con3215.c:			raw->count -= req->len;
drivers/s390/char/con3215.c:			raw->written -= req->len;
drivers/s390/char/con3215.c:		if (req != NULL && req->type != RAW3215_FREE) {
drivers/s390/char/con3215.c:			if (req->type == RAW3215_WRITE) {
drivers/s390/char/con3215.c:				raw->count -= req->len;
drivers/s390/char/con3215.c:				raw->written -= req->len;
drivers/s390/char/con3215.c:		req->next = raw3215_freelist;
drivers/s390/char/sclp.c:		if (!req->queue_expires)
drivers/s390/char/sclp.c:		   (time_before(req->queue_expires, expires_next)))
drivers/s390/char/sclp.c:				expires_next = req->queue_expires;
drivers/s390/char/sclp.c:		if (!req->queue_expires)
drivers/s390/char/sclp.c:		if (time_before_eq(req->queue_expires, now)) {
drivers/s390/char/sclp.c:			if (req->status == SCLP_REQ_QUEUED) {
drivers/s390/char/sclp.c:				req->status = SCLP_REQ_QUEUED_TIMEOUT;
drivers/s390/char/sclp.c:				list_del(&req->list);
drivers/s390/char/sclp.c:		if (req && req->callback)
drivers/s390/char/sclp.c:			req->callback(req, req->callback_data);
drivers/s390/char/sclp.c:	rc = sclp_service_call(req->command, req->sccb);
drivers/s390/char/sclp.c:	req->start_count++;
drivers/s390/char/sclp.c:		req->status = SCLP_REQ_RUNNING;
drivers/s390/char/sclp.c:	req->status = SCLP_REQ_FAILED;
drivers/s390/char/sclp.c:		if (!req->sccb)
drivers/s390/char/sclp.c:		if (req->start_count > 1) {
drivers/s390/char/sclp.c:		list_del(&req->list);
drivers/s390/char/sclp.c:		if (req->callback) {
drivers/s390/char/sclp.c:			req->callback(req, req->callback_data);
drivers/s390/char/sclp.c:	req->status = SCLP_REQ_QUEUED;
drivers/s390/char/sclp.c:	req->start_count = 0;
drivers/s390/char/sclp.c:	list_add_tail(&req->list, &sclp_req_queue);
drivers/s390/char/sclp.c:	if (req->queue_timeout) {
drivers/s390/char/sclp.c:		req->queue_expires = jiffies + req->queue_timeout * HZ;
drivers/s390/char/sclp.c:		    time_after(sclp_queue_timer.expires, req->queue_expires))
drivers/s390/char/sclp.c:			mod_timer(&sclp_queue_timer, req->queue_expires);
drivers/s390/char/sclp.c:		req->queue_expires = 0;
drivers/s390/char/sclp.c:	    req->list.prev == &sclp_req_queue) {
drivers/s390/char/sclp.c:		if (!req->sccb) {
drivers/s390/char/sclp.c:			list_del(&req->list);
drivers/s390/char/sclp.c:			list_del(&req->list);
drivers/s390/char/sclp.c:	sccb = (struct sccb_header *) req->sccb;
drivers/s390/char/sclp.c:	if (req->status == SCLP_REQ_DONE && (sccb->response_code == 0x20 ||
drivers/s390/char/sclp.c:		if (sccb == (u32) (addr_t) req->sccb)
drivers/s390/char/sclp.c:			list_del(&req->list);
drivers/s390/char/sclp.c:			req->status = SCLP_REQ_DONE;
drivers/s390/char/sclp.c:			if (req->callback) {
drivers/s390/char/sclp.c:				req->callback(req, req->callback_data);
drivers/s390/char/sclp_cpi_sys.c:	req->command = SCLP_CMDW_WRITE_EVENT_DATA;
drivers/s390/char/sclp_cpi_sys.c:	req->sccb = sccb;
drivers/s390/char/sclp_cpi_sys.c:	req->status = SCLP_REQ_FILLED;
drivers/s390/char/sclp_cpi_sys.c:	req->callback = cpi_callback;
drivers/s390/char/sclp_cpi_sys.c:	free_page((unsigned long) req->sccb);
drivers/s390/char/sclp_cpi_sys.c:	req->callback_data = &completion;
drivers/s390/char/sclp_cpi_sys.c:	if (req->status != SCLP_REQ_DONE) {
drivers/s390/char/sclp_cpi_sys.c:		pr_warn("request failed (status=0x%02x)\n", req->status);
drivers/s390/char/sclp_cpi_sys.c:	response = ((struct cpi_sccb *) req->sccb)->header.response_code;
drivers/s390/char/sclp_sdias.c:		if (req->status == SCLP_REQ_FAILED) {
drivers/s390/cio/ccwreq.c:	if (!req->singlepath) {
drivers/s390/cio/ccwreq.c:		req->mask = 0;
drivers/s390/cio/ccwreq.c:	req->retries	= req->maxretries;
drivers/s390/cio/ccwreq.c:	req->mask	= lpm_adjust(req->mask >> 1, req->lpm);
drivers/s390/cio/ccwreq.c:	return req->mask;
drivers/s390/cio/ccwreq.c:	if (req->done)
drivers/s390/cio/ccwreq.c:	req->done = 1;
drivers/s390/cio/ccwreq.c:	if (rc && rc != -ENODEV && req->drc)
drivers/s390/cio/ccwreq.c:		rc = req->drc;
drivers/s390/cio/ccwreq.c:	req->callback(cdev, req->data, rc);
drivers/s390/cio/ccwreq.c:	struct ccw1 *cp = req->cp;
drivers/s390/cio/ccwreq.c:	while (req->mask) {
drivers/s390/cio/ccwreq.c:		if (req->retries-- == 0) {
drivers/s390/cio/ccwreq.c:		rc = cio_start(sch, cp, (u8) req->mask);
drivers/s390/cio/ccwreq.c:			ccw_device_set_timeout(cdev, req->timeout);
drivers/s390/cio/ccwreq.c:	if (req->singlepath) {
drivers/s390/cio/ccwreq.c:		req->mask = 0x8080;
drivers/s390/cio/ccwreq.c:		req->mask = req->lpm;
drivers/s390/cio/ccwreq.c:	req->retries	= req->maxretries;
drivers/s390/cio/ccwreq.c:	req->mask	= lpm_adjust(req->mask, req->lpm);
drivers/s390/cio/ccwreq.c:	req->drc	= 0;
drivers/s390/cio/ccwreq.c:	req->done	= 0;
drivers/s390/cio/ccwreq.c:	req->cancel	= 0;
drivers/s390/cio/ccwreq.c:	if (!req->mask)
drivers/s390/cio/ccwreq.c:	if (req->done)
drivers/s390/cio/ccwreq.c:	req->cancel = 1;
drivers/s390/cio/ccwreq.c:	data.retries	= req->retries;
drivers/s390/cio/ccwreq.c:	data.lpm	= (u8) req->mask;
drivers/s390/cio/ccwreq.c:	if (req->filter)
drivers/s390/cio/ccwreq.c:		status = req->filter(cdev, req->data, irb, status);
drivers/s390/cio/ccwreq.c:		if (req->cancel) {
drivers/s390/cio/ccwreq.c:	if (!req->check)
drivers/s390/cio/ccwreq.c:	switch (req->check(cdev, req->data)) {
drivers/s390/cio/ccwreq.c:				dev_name(&cdev->dev), req->timeout / HZ,
drivers/s390/cio/ccwreq.c:		req->drc = -ETIME;
drivers/s390/cio/device_pgid.c:	req->cp		= cp;
drivers/s390/cio/device_pgid.c:	req->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam & sch->opm &
drivers/s390/cio/device_pgid.c:	if (!req->lpm)
drivers/s390/cio/device_pgid.c:		sch->vpm |= req->lpm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_noirq_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_notoper_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:	req->lpm >>= 1;
drivers/s390/cio/device_pgid.c:	int i = pathmask_to_pos(req->lpm);
drivers/s390/cio/device_pgid.c:	req->cp		= cp;
drivers/s390/cio/device_pgid.c:	req->timeout	= PGID_TIMEOUT;
drivers/s390/cio/device_pgid.c:	req->maxretries	= PGID_RETRIES;
drivers/s390/cio/device_pgid.c:	req->lpm	= sch->schib.pmcw.pam;
drivers/s390/cio/device_pgid.c:	req->callback	= pgid_wipeout_callback;
drivers/s390/cio/device_pgid.c:	req->lpm = lpm_adjust(req->lpm, cdev->private->pgid_todo_mask);
drivers/s390/cio/device_pgid.c:	if (!req->lpm)
drivers/s390/cio/device_pgid.c:	if (req->lpm & sch->opm)
drivers/s390/cio/device_pgid.c:		sch->vpm |= req->lpm & sch->opm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_noirq_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_notoper_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:	req->lpm >>= 1;
drivers/s390/cio/device_pgid.c:	req->timeout	= PGID_TIMEOUT;
drivers/s390/cio/device_pgid.c:	req->maxretries	= PGID_RETRIES;
drivers/s390/cio/device_pgid.c:	req->lpm	= 0x80;
drivers/s390/cio/device_pgid.c:	req->singlepath	= 1;
drivers/s390/cio/device_pgid.c:	req->callback	= spid_callback;
drivers/s390/cio/device_pgid.c:	int i = pathmask_to_pos(req->lpm);
drivers/s390/cio/device_pgid.c:	req->cp		= cp;
drivers/s390/cio/device_pgid.c:	req->lpm = lpm_adjust(req->lpm, sch->schib.pmcw.pam &
drivers/s390/cio/device_pgid.c:	if (!req->lpm)
drivers/s390/cio/device_pgid.c:		cdev->private->pgid_valid_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_noirq_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:		cdev->private->path_notoper_mask |= req->lpm;
drivers/s390/cio/device_pgid.c:	req->lpm >>= 1;
drivers/s390/cio/device_pgid.c:	req->timeout	= PGID_TIMEOUT;
drivers/s390/cio/device_pgid.c:	req->maxretries	= PGID_RETRIES;
drivers/s390/cio/device_pgid.c:	req->lpm	= 0x80;
drivers/s390/cio/device_pgid.c:	req->singlepath	= 1;
drivers/s390/cio/device_pgid.c:		req->callback	= snid_callback;
drivers/s390/cio/device_pgid.c:		req->filter	= nop_filter;
drivers/s390/cio/device_pgid.c:		req->callback	= nop_callback;
drivers/s390/cio/device_pgid.c:	req->timeout	= PGID_TIMEOUT;
drivers/s390/cio/device_pgid.c:	req->maxretries	= PGID_RETRIES;
drivers/s390/cio/device_pgid.c:	req->lpm	= sch->schib.pmcw.pam & sch->opm;
drivers/s390/cio/device_pgid.c:	req->singlepath	= 1;
drivers/s390/cio/device_pgid.c:	req->callback	= disband_callback;
drivers/s390/cio/device_pgid.c:	req->cp = cp;
drivers/s390/cio/device_pgid.c:	req->timeout	= PGID_TIMEOUT;
drivers/s390/cio/device_pgid.c:	req->maxretries	= PGID_RETRIES;
drivers/s390/cio/device_pgid.c:	req->lpm	= sch->schib.pmcw.pam & sch->opm;
drivers/s390/cio/device_pgid.c:	req->data	= data;
drivers/s390/cio/device_pgid.c:	req->callback	= stlck_callback;
drivers/s390/cio/device_id.c:	req->cp		= cp;
drivers/s390/cio/device_id.c:	req->timeout	= SENSE_ID_TIMEOUT;
drivers/s390/cio/device_id.c:	req->maxretries	= SENSE_ID_RETRIES;
drivers/s390/cio/device_id.c:	req->lpm	= sch->schib.pmcw.pam & sch->opm;
drivers/s390/cio/device_id.c:	req->check	= snsid_check;
drivers/s390/cio/device_id.c:	req->callback	= snsid_callback;
drivers/s390/crypto/zcrypt_ep11misc.c:		req->flags |= 0x20; /* CPACF_WRAP needs special bit */
drivers/s390/net/qeth_core_main.c:				 access_ctrl_req->subcmd_code, CARD_DEVID(card),
drivers/s390/net/qeth_core_main.c:		if (access_ctrl_req->subcmd_code == ISOLATION_MODE_NONE)
drivers/s390/net/qeth_core_main.c:	access_ctrl_req->subcmd_code = mode;
drivers/s390/net/qeth_core_main.c:	if (get_user(qinfo.udata_len, &ureq->hdr.data_len) ||
drivers/s390/net/qeth_core_main.c:	    get_user(req_len, &ureq->hdr.req_len))
drivers/s390/net/qeth_core_main.c:			   &ureq->cmd, req_len)) {
drivers/s390/net/qeth_core_main.c:	oat_req->subcmd_code = oat_data.command;
drivers/s390/net/qeth_core_main.c:			oat_req->subcmd_code = QETH_QOAT_SCOPE_INTERFACE;
drivers/s390/net/ism_drv.c:	__ism_write_cmd(ism, req + 1, sizeof(*req), req->len - sizeof(*req));
drivers/s390/scsi/zfcp_dbf.h:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_dbf.h:	if (debug_level_enabled(req->adapter->dbf->hba, level))
drivers/s390/scsi/zfcp_dbf.h:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_dbf.h:	if (unlikely(req->status & (ZFCP_STATUS_FSFREQ_DISMISSED |
drivers/s390/scsi/zfcp_def.h:	return req->qtcb == NULL;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = fsf_req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	fsf_req->timer.function = zfcp_fsf_request_timeout_handler;
drivers/s390/scsi/zfcp_fsf.c:	fsf_req->timer.expires = jiffies + timeout;
drivers/s390/scsi/zfcp_fsf.c:	add_timer(&fsf_req->timer);
drivers/s390/scsi/zfcp_fsf.c:	BUG_ON(!fsf_req->erp_action);
drivers/s390/scsi/zfcp_fsf.c:	fsf_req->timer.function = zfcp_erp_timeout_handler;
drivers/s390/scsi/zfcp_fsf.c:	fsf_req->timer.expires = jiffies + 30 * HZ;
drivers/s390/scsi/zfcp_fsf.c:	add_timer(&fsf_req->timer);
drivers/s390/scsi/zfcp_fsf.c:	dev_err(&req->adapter->ccw_device->dev, "FCP device not "
drivers/s390/scsi/zfcp_fsf.c:	zfcp_erp_adapter_shutdown(req->adapter, 0, "fscns_1");
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	if (likely(req->pool)) {
drivers/s390/scsi/zfcp_fsf.c:			mempool_free(req->qtcb, req->adapter->pool.qtcb_pool);
drivers/s390/scsi/zfcp_fsf.c:		mempool_free(req, req->pool);
drivers/s390/scsi/zfcp_fsf.c:		kmem_cache_free(zfcp_fsf_qtcb_cache, req->qtcb);
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_status_read_buffer *sr_buf = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_status_read_buffer *sr_buf = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_status_read_buffer *sr_buf = req->data;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_DISMISSED) {
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status_qual.word[0]) {
drivers/s390/scsi/zfcp_fsf.c:		dev_err(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_siosl(req->adapter);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_erp_adapter_shutdown(req->adapter, 0, "fsfsqe1");
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	if (unlikely(req->status & ZFCP_STATUS_FSFREQ_ERROR))
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status) {
drivers/s390/scsi/zfcp_fsf.c:		dev_err(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:			req->qtcb->header.fsf_command);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_erp_adapter_shutdown(req->adapter, 0, "fsfse_1");
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_DISMISSED) {
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	del_timer_sync(&req->timer);
drivers/s390/scsi/zfcp_fsf.c:	req->handler(req);
drivers/s390/scsi/zfcp_fsf.c:	erp_action = req->erp_action;
drivers/s390/scsi/zfcp_fsf.c:	if (likely(req->status & ZFCP_STATUS_FSFREQ_CLEANUP))
drivers/s390/scsi/zfcp_fsf.c:		complete(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:		list_del(&req->list);
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_DISMISSED;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_bottom_config *bottom = &req->qtcb->bottom.config;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	if (req->data)
drivers/s390/scsi/zfcp_fsf.c:		memcpy(req->data, bottom, sizeof(*bottom));
drivers/s390/scsi/zfcp_fsf.c:	if (req->qtcb->header.fsf_status == FSF_EXCHANGE_CONFIG_DATA_INCOMPLETE)
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_XDATAINCOMPLETE;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_bottom_port *bottom = &req->qtcb->bottom.port;
drivers/s390/scsi/zfcp_fsf.c:	if (req->data)
drivers/s390/scsi/zfcp_fsf.c:		memcpy(req->data, bottom, sizeof(*bottom));
drivers/s390/scsi/zfcp_fsf.c:		&req->adapter->diagnostics->port_data.header;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:		zfcp_scsi_shost_update_port_data(req->adapter, bottom);
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_XDATAINCOMPLETE;
drivers/s390/scsi/zfcp_fsf.c:		zfcp_scsi_shost_update_port_data(req->adapter, bottom);
drivers/s390/scsi/zfcp_fsf.c:	req->pool = pool;
drivers/s390/scsi/zfcp_fsf.c:	INIT_LIST_HEAD(&req->list);
drivers/s390/scsi/zfcp_fsf.c:	timer_setup(&req->timer, NULL, 0);
drivers/s390/scsi/zfcp_fsf.c:	init_completion(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:	req->adapter = adapter;
drivers/s390/scsi/zfcp_fsf.c:	req->req_id = adapter->req_no;
drivers/s390/scsi/zfcp_fsf.c:			req->qtcb = zfcp_fsf_qtcb_alloc(
drivers/s390/scsi/zfcp_fsf.c:			req->qtcb = zfcp_fsf_qtcb_alloc(NULL);
drivers/s390/scsi/zfcp_fsf.c:		if (unlikely(!req->qtcb)) {
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->prefix.req_seq_no = adapter->fsf_req_seq_no;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->prefix.req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->prefix.ulp_info = 26;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->prefix.qtcb_type = fsf_qtcb_type[fsf_cmd];
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->prefix.qtcb_version = FSF_QTCB_CURRENT_VERSION;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->header.req_handle = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->header.fsf_command = fsf_cmd;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_req_init(adapter->qdio, &req->qdio_req, req->req_id, sbtype,
drivers/s390/scsi/zfcp_fsf.c:			   req->qtcb, sizeof(struct fsf_qtcb));
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	int req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	req->qdio_req.qdio_outb_usage = atomic_read(&qdio->req_q_free);
drivers/s390/scsi/zfcp_fsf.c:	req->issued = get_tod_clock();
drivers/s390/scsi/zfcp_fsf.c:	if (zfcp_qdio_send(qdio, &req->qdio_req)) {
drivers/s390/scsi/zfcp_fsf.c:		del_timer_sync(&req->timer);
drivers/s390/scsi/zfcp_fsf.c:	 *	 ONLY TOUCH SYNC req AGAIN ON req->completion.
drivers/s390/scsi/zfcp_fsf.c:	 * when it is completed via req->completion, is it safe to use req
drivers/s390/scsi/zfcp_fsf.c:	req->data = sr_buf;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_fill_next(qdio, &req->qdio_req, sr_buf, sizeof(*sr_buf));
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->data = NULL;
drivers/s390/scsi/zfcp_fsf.c:	struct scsi_device *sdev = req->data;
drivers/s390/scsi/zfcp_fsf.c:	union fsf_status_qual *fsq = &req->qtcb->header.fsf_status_qual;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status) {
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ABORTNOTNEEDED;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ABORTSUCCEEDED;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->data = sdev;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_abort_fcp_command_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.lun_handle = zfcp_sdev->lun_handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = zfcp_sdev->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.support.req_handle = (u64) old_req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_fsf_ct_els *ct = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_fill_next(qdio, q_req, sg_virt(sg_req), sg_req->length);
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb *qtcb = req->qtcb;
drivers/s390/scsi/zfcp_fsf.c:		if (zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req, sg_req))
drivers/s390/scsi/zfcp_fsf.c:		if (zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req, sg_resp))
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_set_data_div(qdio, &req->qdio_req, sg_nents(sg_req));
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_set_scount(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_fsf_setup_ct_els_unchained(qdio, &req->qdio_req,
drivers/s390/scsi/zfcp_fsf.c:	if (zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req, sg_req))
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_skip_to_last_sbale(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	if (zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req, sg_resp))
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.support.service_class = FSF_CLASS_3;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.support.timeout = timeout;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_send_ct_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = wka_port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->data = ct;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_fsf_ct_els *send_els = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_sbal_limit(qdio, &req->qdio_req, 2);
drivers/s390/scsi/zfcp_fsf.c:	hton24(req->qtcb->bottom.support.d_id, d_id);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_send_els_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->data = els;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.config.feature_selection =
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_exchange_config_data_handler;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_exchange_config_data_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.config.feature_selection =
drivers/s390/scsi/zfcp_fsf.c:		req->data = data;
drivers/s390/scsi/zfcp_fsf.c:		/* NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */
drivers/s390/scsi/zfcp_fsf.c:		wait_for_completion(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:		if (req->status &
drivers/s390/scsi/zfcp_fsf.c:		else if (req->status & ZFCP_STATUS_FSFREQ_XDATAINCOMPLETE)
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_exchange_port_data_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:		req->data = data;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_exchange_port_data_handler;
drivers/s390/scsi/zfcp_fsf.c:		/* NOTE: ONLY TOUCH SYNC req AGAIN ON req->completion. */
drivers/s390/scsi/zfcp_fsf.c:		wait_for_completion(&req->completion);
drivers/s390/scsi/zfcp_fsf.c:		if (req->status &
drivers/s390/scsi/zfcp_fsf.c:		else if (req->status & ZFCP_STATUS_FSFREQ_XDATAINCOMPLETE)
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_port *port = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_bottom_support *bottom = &req->qtcb->bottom.support;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		zfcp_fsf_log_security_error(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_open_port_handler;
drivers/s390/scsi/zfcp_fsf.c:	hton24(req->qtcb->bottom.support.d_id, port->d_id);
drivers/s390/scsi/zfcp_fsf.c:	req->data = port;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_port *port = req->data;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status) {
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_close_port_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->data = erp_action->port;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = erp_action->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_fc_wka_port *wka_port = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR) {
drivers/s390/scsi/zfcp_fsf.c:		dev_warn(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_open_wka_port_handler;
drivers/s390/scsi/zfcp_fsf.c:	hton24(req->qtcb->bottom.support.d_id, wka_port->d_id);
drivers/s390/scsi/zfcp_fsf.c:	req->data = wka_port;
drivers/s390/scsi/zfcp_fsf.c:	req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_fc_wka_port *wka_port = req->data;
drivers/s390/scsi/zfcp_fsf.c:	if (req->qtcb->header.fsf_status == FSF_PORT_HANDLE_NOT_VALID) {
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_close_wka_port_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->data = wka_port;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = wka_port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_port *port = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->data = erp_action->port;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = erp_action->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_close_physical_port_handler;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fsf.c:	struct scsi_device *sdev = req->data;
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = erp_action->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.support.fcp_lun = zfcp_scsi_dev_lun(erp_action->sdev);
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_open_lun_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->data = erp_action->sdev;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:		req->qtcb->bottom.support.option = FSF_OPEN_LUN_SUPPRESS_BOXING;
drivers/s390/scsi/zfcp_fsf.c:	struct scsi_device *sdev = req->data;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status) {
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		switch (req->qtcb->header.fsf_status_qual.word[0]) {
drivers/s390/scsi/zfcp_fsf.c:			req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = erp_action->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.lun_handle = zfcp_sdev->lun_handle;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_close_lun_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->data = erp_action->sdev;
drivers/s390/scsi/zfcp_fsf.c:	req->erp_action = erp_action;
drivers/s390/scsi/zfcp_fsf.c:	erp_action->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	int ticks = req->adapter->timer_ticks;
drivers/s390/scsi/zfcp_fsf.c:	lat_in = &req->qtcb->prefix.prot_status_qual.latency_info;
drivers/s390/scsi/zfcp_fsf.c:	if (req->status & ZFCP_STATUS_FSFREQ_ERROR)
drivers/s390/scsi/zfcp_fsf.c:	blktrc.outb_usage = req->qdio_req.qdio_outb_usage;
drivers/s390/scsi/zfcp_fsf.c:	if (req->adapter->adapter_features & FSF_FEATURE_MEASUREMENT_DATA &&
drivers/s390/scsi/zfcp_fsf.c:	    !(req->status & ZFCP_STATUS_FSFREQ_ERROR)) {
drivers/s390/scsi/zfcp_fsf.c:		switch (req->qtcb->bottom.io.data_direction) {
drivers/s390/scsi/zfcp_fsf.c:	struct fsf_qtcb_header *header = &req->qtcb->header;
drivers/s390/scsi/zfcp_fsf.c:	if (unlikely(req->status & ZFCP_STATUS_FSFREQ_ERROR))
drivers/s390/scsi/zfcp_fsf.c:		zfcp_erp_adapter_reopen(req->adapter, 0, "fssfch1");
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		dev_err(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:			req->qtcb->bottom.io.data_direction,
drivers/s390/scsi/zfcp_fsf.c:		zfcp_erp_adapter_shutdown(req->adapter, 0, "fssfch3");
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		dev_err(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:			req->qtcb->bottom.io.fcp_cmnd_length);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_erp_adapter_shutdown(req->adapter, 0, "fssfch4");
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:		zfcp_fsf_log_security_error(&req->adapter->ccw_device->dev,
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_ERROR;
drivers/s390/scsi/zfcp_fsf.c:	read_lock_irqsave(&req->adapter->abort_lock, flags);
drivers/s390/scsi/zfcp_fsf.c:	scpnt = req->data;
drivers/s390/scsi/zfcp_fsf.c:		read_unlock_irqrestore(&req->adapter->abort_lock, flags);
drivers/s390/scsi/zfcp_fsf.c:	if (unlikely(req->status & ZFCP_STATUS_FSFREQ_ERROR)) {
drivers/s390/scsi/zfcp_fsf.c:	switch (req->qtcb->header.fsf_status) {
drivers/s390/scsi/zfcp_fsf.c:	fcp_rsp = &req->qtcb->bottom.io.fcp_rsp.iu;
drivers/s390/scsi/zfcp_fsf.c:	read_unlock_irqrestore(&req->adapter->abort_lock, flags);
drivers/s390/scsi/zfcp_fsf.c:	scsi_cmnd->host_scribble = (unsigned char *) req->req_id;
drivers/s390/scsi/zfcp_fsf.c:	io = &req->qtcb->bottom.io;
drivers/s390/scsi/zfcp_fsf.c:	req->status |= ZFCP_STATUS_FSFREQ_CLEANUP;
drivers/s390/scsi/zfcp_fsf.c:	req->data = scsi_cmnd;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_fcp_cmnd_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.lun_handle = zfcp_sdev->lun_handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = zfcp_sdev->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	fcp_cmnd = &req->qtcb->bottom.io.fcp_cmnd.iu;
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_set_data_div(qdio, &req->qdio_req,
drivers/s390/scsi/zfcp_fsf.c:		retval = zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req,
drivers/s390/scsi/zfcp_fsf.c:	retval = zfcp_qdio_sbals_from_sg(qdio, &req->qdio_req,
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(adapter->qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:		zfcp_qdio_set_scount(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	struct scsi_device *sdev = req->data;
drivers/s390/scsi/zfcp_fsf.c:	fcp_rsp = &req->qtcb->bottom.io.fcp_rsp.iu;
drivers/s390/scsi/zfcp_fsf.c:	     (req->status & ZFCP_STATUS_FSFREQ_ERROR))
drivers/s390/scsi/zfcp_fsf.c:		req->status |= ZFCP_STATUS_FSFREQ_TMFUNCFAILED;
drivers/s390/scsi/zfcp_fsf.c:	req->data = sdev;
drivers/s390/scsi/zfcp_fsf.c:	req->handler = zfcp_fsf_fcp_task_mgmt_handler;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.lun_handle = zfcp_sdev->lun_handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->header.port_handle = zfcp_sdev->port->handle;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.io.data_direction = FSF_DATADIR_CMND;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.io.service_class = FSF_CLASS_3;
drivers/s390/scsi/zfcp_fsf.c:	req->qtcb->bottom.io.fcp_cmnd_length = FCP_CMND_LEN;
drivers/s390/scsi/zfcp_fsf.c:	zfcp_qdio_set_sbale_last(qdio, &req->qdio_req);
drivers/s390/scsi/zfcp_fsf.c:	fcp_cmnd = &req->qtcb->bottom.io.fcp_cmnd.iu;
drivers/s390/scsi/zfcp_qdio.h:	return &qdio->req_q[q_req->sbal_last]->element[0];
drivers/s390/scsi/zfcp_qdio.h:	return &qdio->req_q[q_req->sbal_last]->element[q_req->sbale_curr];
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbal_first = q_req->sbal_last = qdio->req_q_idx;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbal_number = 1;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbtype = sbtype;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbale_curr = 1;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbal_limit = (q_req->sbal_first + count - 1)
drivers/s390/scsi/zfcp_qdio.h:	BUG_ON(q_req->sbale_curr == qdio->max_sbale_per_sbal - 1);
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbale_curr++;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbale_curr = qdio->max_sbale_per_sbal - 1;
drivers/s390/scsi/zfcp_qdio.h:	q_req->sbal_limit = (q_req->sbal_first + count - 1) %
drivers/s390/scsi/zfcp_qdio.h:	sbale = qdio->req_q[q_req->sbal_first]->element;
drivers/s390/scsi/zfcp_qdio.h:	sbale = qdio->req_q[q_req->sbal_first]->element;
drivers/s390/scsi/zfcp_qdio.h:	sbale->scount = q_req->sbal_number - 1;
drivers/s390/scsi/zfcp_reqlist.h:		if (req->req_id == req_id)
drivers/s390/scsi/zfcp_reqlist.h:		list_del(&req->list);
drivers/s390/scsi/zfcp_reqlist.h:	i = zfcp_reqlist_hash(req->req_id);
drivers/s390/scsi/zfcp_reqlist.h:	list_add_tail(&req->list, &rl->buckets[i]);
drivers/s390/scsi/zfcp_qdio.c:	if (q_req->sbal_last == q_req->sbal_limit)
drivers/s390/scsi/zfcp_qdio.c:	q_req->sbal_last++;
drivers/s390/scsi/zfcp_qdio.c:	q_req->sbal_last %= QDIO_MAX_BUFFERS_PER_Q;
drivers/s390/scsi/zfcp_qdio.c:	q_req->sbal_number++;
drivers/s390/scsi/zfcp_qdio.c:	BUG_ON(q_req->sbal_number > ZFCP_QDIO_MAX_SBALS_PER_REQ);
drivers/s390/scsi/zfcp_qdio.c:	q_req->sbale_curr = 0;
drivers/s390/scsi/zfcp_qdio.c:	sbale->sflags |= q_req->sbtype;
drivers/s390/scsi/zfcp_qdio.c:	if (q_req->sbale_curr == qdio->max_sbale_per_sbal - 1)
drivers/s390/scsi/zfcp_qdio.c:	q_req->sbale_curr++;
drivers/s390/scsi/zfcp_qdio.c:	sbale->sflags |= q_req->sbtype;
drivers/s390/scsi/zfcp_qdio.c:			zfcp_qdio_zero_sbals(qdio->req_q, q_req->sbal_first,
drivers/s390/scsi/zfcp_qdio.c:					     q_req->sbal_number);
drivers/s390/scsi/zfcp_qdio.c:	u8 sbal_number = q_req->sbal_number;
drivers/s390/scsi/zfcp_qdio.c:			 q_req->sbal_first, sbal_number);
drivers/s390/scsi/zfcp_qdio.c:		zfcp_qdio_zero_sbals(qdio->req_q, q_req->sbal_first,
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_adapter *adapter = fsf_req->adapter;
drivers/s390/scsi/zfcp_fc.c:	struct fsf_status_read_buffer *status_buffer = (void *)fsf_req->data;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_adapter *adapter = fsf_req->adapter;
drivers/s390/scsi/zfcp_fc.c:		zfcp_fc_enqueue_event(fsf_req->adapter, FCH_EVT_RSCN,
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_conditional_port_scan(fsf_req->adapter);
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_adapter *adapter = req->adapter;
drivers/s390/scsi/zfcp_fc.c:	status_buffer = (struct fsf_status_read_buffer *) req->data;
drivers/s390/scsi/zfcp_fc.c:		(struct fsf_status_read_buffer *)req->data;
drivers/s390/scsi/zfcp_fc.c:		(struct fsf_status_read_buffer *) fsf_req->data;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fsf_ct_els *ct_els = &fc_req->ct_els;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gid_pn_rsp *gid_pn_rsp = &fc_req->u.gid_pn.rsp;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gid_pn_req *gid_pn_req = &fc_req->u.gid_pn.req;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gid_pn_rsp *gid_pn_rsp = &fc_req->u.gid_pn.rsp;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.port = port;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.handler = zfcp_fc_complete;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.handler_data = &completion;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.req = &fc_req->sg_req;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.resp = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_req, gid_pn_req, sizeof(*gid_pn_req));
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_rsp, gid_pn_rsp, sizeof(*gid_pn_rsp));
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_ct_ns_init(&gid_pn_req->ct_hdr,
drivers/s390/scsi/zfcp_fc.c:	gid_pn_req->gid_pn.fn_wwpn = cpu_to_be64(port->wwpn);
drivers/s390/scsi/zfcp_fc.c:	ret = zfcp_fsf_send_ct(&adapter->gs->ds, &fc_req->ct_els,
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_port *port = fc_req->ct_els.port;
drivers/s390/scsi/zfcp_fc.c:	struct fc_els_adisc *adisc_resp = &fc_req->u.adisc.rsp;
drivers/s390/scsi/zfcp_fc.c:	if (fc_req->ct_els.status) {
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.port = port;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.req = &fc_req->sg_req;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.resp = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_req, &fc_req->u.adisc.req,
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_rsp, &fc_req->u.adisc.rsp,
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.handler = zfcp_fc_adisc_handler;
drivers/s390/scsi/zfcp_fc.c:	fc_req->ct_els.handler_data = fc_req;
drivers/s390/scsi/zfcp_fc.c:	fc_req->u.adisc.req.adisc_wwpn = cpu_to_be64(fc_host_port_name(shost));
drivers/s390/scsi/zfcp_fc.c:	fc_req->u.adisc.req.adisc_wwnn = cpu_to_be64(fc_host_node_name(shost));
drivers/s390/scsi/zfcp_fc.c:	fc_req->u.adisc.req.adisc_cmd = ELS_ADISC;
drivers/s390/scsi/zfcp_fc.c:	hton24(fc_req->u.adisc.req.adisc_port_id, fc_host_port_id(shost));
drivers/s390/scsi/zfcp_fc.c:	ret = zfcp_fsf_send_els(adapter, port->d_id, &fc_req->ct_els,
drivers/s390/scsi/zfcp_fc.c:	if (zfcp_fc_sg_setup_table(&fc_req->sg_rsp, buf_num)) {
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_req, &fc_req->u.gpn_ft.req,
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fsf_ct_els *ct_els = &fc_req->ct_els;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gpn_ft_req *req = &fc_req->u.gpn_ft.req;
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_ct_ns_init(&req->ct_hdr, FC_NS_GPN_FT, max_bytes);
drivers/s390/scsi/zfcp_fc.c:	req->gpn_ft.fn_fc4_type = FC_TYPE_FCP;
drivers/s390/scsi/zfcp_fc.c:	ct_els->req = &fc_req->sg_req;
drivers/s390/scsi/zfcp_fc.c:	ct_els->resp = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fsf_ct_els *ct_els = &fc_req->ct_els;
drivers/s390/scsi/zfcp_fc.c:	struct scatterlist *sg = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_sg_free_table(&fc_req->sg_rsp, buf_num);
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fsf_ct_els *ct_els = &fc_req->ct_els;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gspn_req *gspn_req = &fc_req->u.gspn.req;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_gspn_rsp *gspn_rsp = &fc_req->u.gspn.rsp;
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_ct_ns_init(&gspn_req->ct_hdr, FC_NS_GSPN_ID,
drivers/s390/scsi/zfcp_fc.c:	hton24(gspn_req->gspn.fp_fid, fc_host_port_id(adapter->scsi_host));
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_req, gspn_req, sizeof(*gspn_req));
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_rsp, gspn_rsp, sizeof(*gspn_rsp));
drivers/s390/scsi/zfcp_fc.c:	ct_els->req = &fc_req->sg_req;
drivers/s390/scsi/zfcp_fc.c:	ct_els->resp = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fsf_ct_els *ct_els = &fc_req->ct_els;
drivers/s390/scsi/zfcp_fc.c:	struct zfcp_fc_rspn_req *rspn_req = &fc_req->u.rspn.req;
drivers/s390/scsi/zfcp_fc.c:	struct fc_ct_hdr *rspn_rsp = &fc_req->u.rspn.rsp;
drivers/s390/scsi/zfcp_fc.c:	zfcp_fc_ct_ns_init(&rspn_req->ct_hdr, FC_NS_RSPN_ID,
drivers/s390/scsi/zfcp_fc.c:	hton24(rspn_req->rspn.fr_fid.fp_fid, fc_host_port_id(shost));
drivers/s390/scsi/zfcp_fc.c:	len = strlcpy(rspn_req->rspn.fr_name, fc_host_symbolic_name(shost),
drivers/s390/scsi/zfcp_fc.c:	rspn_req->rspn.fr_name_len = len;
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_req, rspn_req, sizeof(*rspn_req));
drivers/s390/scsi/zfcp_fc.c:	sg_init_one(&fc_req->sg_rsp, rspn_rsp, sizeof(*rspn_rsp));
drivers/s390/scsi/zfcp_fc.c:	ct_els->req = &fc_req->sg_req;
drivers/s390/scsi/zfcp_fc.c:	ct_els->resp = &fc_req->sg_rsp;
drivers/s390/scsi/zfcp_scsi.c:	old_req->data = NULL;
drivers/s390/scsi/zfcp_scsi.c:	wait_for_completion(&abrt_req->completion);
drivers/s390/scsi/zfcp_scsi.c:	if (abrt_req->status & ZFCP_STATUS_FSFREQ_ABORTSUCCEEDED)
drivers/s390/scsi/zfcp_scsi.c:	else if (abrt_req->status & ZFCP_STATUS_FSFREQ_ABORTNOTNEEDED)
drivers/s390/scsi/zfcp_scsi.c:	if (old_req->data == NULL ||
drivers/s390/scsi/zfcp_scsi.c:	    old_req->qtcb->header.fsf_command != FSF_QTCB_FCP_CMND)
drivers/s390/scsi/zfcp_scsi.c:	if (old_req->qtcb->header.port_handle != filter->port_handle)
drivers/s390/scsi/zfcp_scsi.c:	    old_req->qtcb->header.lun_handle != filter->lun_handle)
drivers/s390/scsi/zfcp_scsi.c:	zfcp_dbf_scsi_nullcmnd((struct scsi_cmnd *)old_req->data, old_req);
drivers/s390/scsi/zfcp_scsi.c:	old_req->data = NULL;
drivers/s390/scsi/zfcp_scsi.c:	wait_for_completion(&fsf_req->completion);
drivers/s390/scsi/zfcp_scsi.c:	if (fsf_req->status & ZFCP_STATUS_FSFREQ_TMFUNCFAILED) {
drivers/s390/scsi/zfcp_dbf.c:	struct zfcp_dbf *dbf = req->adapter->dbf;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_qtcb_prefix *q_pref = &req->qtcb->prefix;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_qtcb_header *q_head = &req->qtcb->header;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_status = req->status;
drivers/s390/scsi/zfcp_dbf.c:	rec->u.res.req_issued = req->issued;
drivers/s390/scsi/zfcp_dbf.c:			  rec->pl_len, "fsf_res", req->req_id);
drivers/s390/scsi/zfcp_dbf.c:	struct zfcp_dbf *dbf = req->adapter->dbf;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_qtcb_prefix *q_pref = &req->qtcb->prefix;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_qtcb_header *q_head = &req->qtcb->header;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_status = req->status;
drivers/s390/scsi/zfcp_dbf.c:	rec->u.fces.req_issued = req->issued;
drivers/s390/scsi/zfcp_dbf.c:	struct zfcp_dbf *dbf = req->adapter->dbf;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_status_read_buffer *srb = req->data;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_status = req->status;
drivers/s390/scsi/zfcp_dbf.c:				  "fsf_uss", req->req_id);
drivers/s390/scsi/zfcp_dbf.c:	struct zfcp_dbf *dbf = req->adapter->dbf;
drivers/s390/scsi/zfcp_dbf.c:	struct fsf_status_read_buffer *sr_buf = req->data;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_id = req->req_id;
drivers/s390/scsi/zfcp_dbf.c:	rec->fsf_req_status = req->status;
drivers/s390/scsi/zfcp_erp.c:	if (req && req->erp_action == act) {
drivers/s390/scsi/zfcp_erp.c:			req->status |= ZFCP_STATUS_FSFREQ_DISMISSED;
drivers/s390/scsi/zfcp_erp.c:			WRITE_ONCE(req->erp_action, NULL);
drivers/s390/scsi/zfcp_erp.c:		if (req->status & ZFCP_STATUS_FSFREQ_DISMISSED)
drivers/s390/scsi/zfcp_erp.c:	if (fsf_req->status & ZFCP_STATUS_FSFREQ_DISMISSED)
drivers/s390/scsi/zfcp_erp.c:	act = READ_ONCE(fsf_req->erp_action);
drivers/s390/block/dasd_diag.c:	private->iob.block_count = dreq->block_count;
drivers/s390/block/dasd_diag.c:	private->iob.bio_list = dreq->bio;
drivers/s390/block/dasd_diag.c:	dreq->block_count = count;
drivers/s390/block/dasd_diag.c:	dbio = dreq->bio;
drivers/s390/block/dasd.c:		blk_mq_run_hw_queues(req->q, true);
drivers/s390/block/dasd.c:		} else if (likely(!blk_should_fake_timeout(req->q))) {
drivers/s390/block/dasd.c:	struct dasd_block *block = req->q->queuedata;
drivers/s390/block/dasd.c:	blk_mq_run_hw_queues(req->q, true);
drivers/s390/block/dasd_eckd.c:		cqr = &dasd_vol_info_req->cqr;
drivers/s390/block/dasd_eckd.c:		cqr->cpaddr = &dasd_vol_info_req->ccw;
drivers/s390/block/dasd_eckd.c:		cqr->data = &dasd_vol_info_req->data;
drivers/s390/block/dasd_eckd.c:		cqr = &dasd_reserve_req->cqr;
drivers/s390/block/dasd_eckd.c:		memset(&dasd_reserve_req->ccw, 0,
drivers/s390/block/dasd_eckd.c:		       sizeof(dasd_reserve_req->ccw));
drivers/s390/block/dasd_eckd.c:		cqr->cpaddr = &dasd_reserve_req->ccw;
drivers/s390/block/dasd_eckd.c:		cqr->data = &dasd_reserve_req->data;
drivers/s390/block/dasd_eckd.c:		cqr = &dasd_reserve_req->cqr;
drivers/s390/block/dasd_eckd.c:		memset(&dasd_reserve_req->ccw, 0,
drivers/s390/block/dasd_eckd.c:		       sizeof(dasd_reserve_req->ccw));
drivers/s390/block/dasd_eckd.c:		cqr->cpaddr = &dasd_reserve_req->ccw;
drivers/s390/block/dasd_eckd.c:		cqr->data = &dasd_reserve_req->data;
drivers/s390/block/dasd_eckd.c:		cqr = &dasd_reserve_req->cqr;
drivers/s390/block/dasd_eckd.c:		memset(&dasd_reserve_req->ccw, 0,
drivers/s390/block/dasd_eckd.c:		       sizeof(dasd_reserve_req->ccw));
drivers/s390/block/dasd_eckd.c:		cqr->cpaddr = &dasd_reserve_req->ccw;
drivers/s390/block/dasd_eckd.c:		cqr->data = &dasd_reserve_req->data;
drivers/s390/block/dasd_eckd.c:		cqr = &dasd_reserve_req->cqr;
drivers/s390/block/dasd_eckd.c:		memset(&dasd_reserve_req->ccw, 0,
drivers/s390/block/dasd_eckd.c:		       sizeof(dasd_reserve_req->ccw));
drivers/s390/block/dasd_eckd.c:		cqr->cpaddr = &dasd_reserve_req->ccw;
drivers/s390/block/dasd_eckd.c:		cqr->data = &dasd_reserve_req->data;
drivers/s390/block/dasd_eckd.c:		       req ? req->intrc : 0);
drivers/s390/block/dasd_eckd.c:		first = req->cpaddr;
drivers/s390/block/dasd_eckd.c:		       req ? req->intrc : 0);
drivers/s390/block/dasd_eckd.c:		    test_bit(DASD_CQR_SUPPRESS_FP, &req->flags))
drivers/s390/block/dasd_eckd.c:		    test_bit(DASD_CQR_SUPPRESS_IL, &req->flags))
drivers/s390/block/dasd_eckd.c:		    test_bit(DASD_CQR_SUPPRESS_CR, &req->flags))
drivers/s390/block/dasd_eckd.c:		    test_bit(DASD_CQR_SUPPRESS_NRF, &req->flags))
drivers/s390/block/dasd_fba.c:	act = req->cpaddr;
drivers/cdrom/gdrom.c:	__raw_writel(virt_to_phys(bio_data(req->bio)), GDROM_DMA_STARTADDR_REG);
drivers/cdrom/cdrom.c:		req->cmd[0] = GPCMD_READ_CD;
drivers/cdrom/cdrom.c:		req->cmd[1] = 1 << 2;
drivers/cdrom/cdrom.c:		req->cmd[2] = (lba >> 24) & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[3] = (lba >> 16) & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[4] = (lba >>  8) & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[5] = lba & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[6] = (nr >> 16) & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[7] = (nr >>  8) & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[8] = nr & 0xff;
drivers/cdrom/cdrom.c:		req->cmd[9] = 0xf8;
drivers/cdrom/cdrom.c:		req->cmd_len = 12;
drivers/cdrom/cdrom.c:			scsi_normalize_sense(req->sense, req->sense_len,
drivers/hwmon/occ/common.c:		val = get_unaligned_be16(&freq->sensor_id);
drivers/hwmon/occ/common.c:		val = get_unaligned_be16(&freq->value);
drivers/hwmon/occ/common.c:		val = get_unaligned_be32(&freq->sensor_id);
drivers/hwmon/occ/common.c:		val = get_unaligned_be16(&freq->value);
mm/zswap.c:		dlen = acomp_ctx->req->dlen;
mm/zswap.c:	dlen = acomp_ctx->req->dlen;
mm/cma.c:		pr_err("%s: %s: alloc failed, req-size: %zu pages, ret: %d\n",
security/smack/smack_lsm.c:	req->peer_secid = skp->smk_secid;
security/smack/smack_lsm.c:	if (req->peer_secid != 0) {
security/smack/smack_lsm.c:		skp = smack_from_secid(req->peer_secid);
security/keys/dh.c:	struct dh_completion *compl = req->data;
security/keys/dh.c:		if (copy_from_user(outbuf + req->dst_len, kdfcopy->otherinfo,
security/keys/dh.c:					    req->dst_len + kdfcopy->otherinfolen,
security/keys/dh.c:					    outlen - req->dst_len);
security/keys/dh.c:	} else if (copy_to_user(buffer, outbuf, req->dst_len) == 0) {
security/keys/dh.c:		ret = req->dst_len;
security/selinux/hooks.c:	u16 family = req->rsk_ops->family;
security/selinux/hooks.c:	req->secid = connsid;
security/selinux/hooks.c:	req->peer_secid = peersid;
security/selinux/hooks.c:	newsksec->sid = req->secid;
security/selinux/hooks.c:	newsksec->peer_sid = req->peer_secid;
security/selinux/hooks.c:	selinux_netlbl_inet_csk_clone(newsk, req->rsk_ops->family);
security/selinux/hooks.c:	flic->flowic_secid = req->secid;
security/selinux/netlabel.c:	rc = security_netlbl_sid_to_secattr(&selinux_state, req->secid,
tools/tracing/latency/latency-collector.c:	req->ticket = r;
tools/tracing/latency/latency-collector.c:	req->ticket_completed_ref = printstate.ticket_completed;
tools/tracing/latency/latency-collector.c:	if (req->ticket > printstate.ticket_completed)
tools/tracing/latency/latency-collector.c:		printstate.ticket_completed = req->ticket;
tools/tracing/latency/latency-collector.c:	return (printstate.ticket_counter != req->ticket);
tools/tracing/latency/latency-collector.c:	return (printstate.ticket_completed != req->ticket_completed_ref);
tools/tracing/latency/latency-collector.c:	int diff = req->ticket - req->ticket_completed_ref;
tools/tracing/latency/latency-collector.c:			     sec, us, req->ticket, str);
tools/tracing/latency/latency-collector.c:			    sec, us, req->ticket);
tools/tracing/latency/latency-collector.c:				 sec, us, req->ticket, slept_ms);
tools/tracing/latency/latency-collector.c:				 us, req->ticket);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_min = msr_perf_2_ratio((((msr) >> 0) & 0xff));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_max = msr_perf_2_ratio((((msr) >> 8) & 0xff));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_desired = msr_perf_2_ratio((((msr) >> 16) & 0xff));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_epp = (((msr) >> 24) & 0xff);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_window = (((msr) >> 32) & 0x3ff);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	hwp_req->hwp_use_pkg = (((msr) >> 42) & 0x1);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			cpu, hwp_req->hwp_min, hwp_req->hwp_max,
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			hwp_req->hwp_desired, hwp_req->hwp_epp,
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			hwp_req->hwp_window, hwp_req->hwp_use_pkg);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_MIN_PERF(ratio_2_msr_perf(hwp_req->hwp_min));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_MAX_PERF(ratio_2_msr_perf(hwp_req->hwp_max));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_DESIRED_PERF(ratio_2_msr_perf(hwp_req->hwp_desired));
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_ENERGY_PERF_PREFERENCE(hwp_req->hwp_epp);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_ACTIVITY_WINDOW(hwp_req->hwp_window);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	msr |= HWP_PACKAGE_CONTROL(hwp_req->hwp_use_pkg);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	if (req->hwp_min > req->hwp_max) {
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			cpu, req->hwp_min, req->hwp_max);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	if (req->hwp_desired && (req->hwp_desired > req->hwp_max)) {
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			cpu, req->hwp_desired, req->hwp_max);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	if (req->hwp_desired && (req->hwp_desired < req->hwp_min)) {
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			cpu, req->hwp_desired, req->hwp_min);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_max > cap->highest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_max, cap->highest);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_max < cap->lowest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_max, cap->lowest);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_min > cap->highest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_min, cap->highest);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_min < cap->lowest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_min, cap->lowest);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	if (update_hwp_min && update_hwp_max && (req->hwp_min > req->hwp_max))
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:			cpu, req->hwp_min, req->hwp_max);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:	if (update_hwp_desired && req->hwp_desired) {
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_desired > req->hwp_max)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_desired, req->hwp_max);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_desired < req->hwp_min)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_desired, req->hwp_min);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_desired < cap->lowest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_desired, cap->lowest);
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:		if (req->hwp_desired > cap->highest)
tools/power/x86/x86_energy_perf_policy/x86_energy_perf_policy.c:				cpu, req->hwp_desired, cap->highest);
tools/power/x86/intel-speed-select/isst-display.c:	snprintf(header, sizeof(header), "speed-select-base-freq-properties");
tools/power/x86/intel-speed-select/isst-display.c:	snprintf(header, sizeof(header), "speed-select-turbo-freq-properties");
tools/power/x86/intel-speed-select/isst-display.c:		 "speed-select-turbo-freq-clip-frequencies");
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:31
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:63
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:151
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:161
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:163
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:164
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:177
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:178
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:181
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:184
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:211
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:213
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:219
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:230
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:241
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:247
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:256
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:269
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:280
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:282
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:286
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:293
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:296
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:304
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:472
tools/power/cpupower/po/cs.po:msgstr "Užití: cpufreq-info [přepínače]\n"
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:473 utils/cpufreq-set.c:26 utils/cpupower-set.c:23
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:474
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:475
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:477
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:479
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:480
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:481
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:482
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:483
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:484
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:486
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:487
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:488
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:489
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:491
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:492 utils/cpuidle-info.c:152
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:495
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:497
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:580
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:596
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:600 utils/cpufreq-set.c:82 utils/cpupower-set.c:42
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:617
tools/power/cpupower/po/cs.po:#: utils/cpufreq-info.c:620 utils/cpupower-info.c:142
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:25
tools/power/cpupower/po/cs.po:msgstr "Užití: cpufreq-set [přepínače]\n"
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:27
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:28
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:29
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:30
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:32
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:33 utils/cpupower-set.c:28 utils/cpupower-info.c:27
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:35
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:37
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:57
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:170
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:302
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:308
tools/power/cpupower/po/cs.po:#: utils/cpufreq-set.c:347
tools/power/cpupower/po/cs.po:msgstr "Užití: cpufreq-info [přepínače]\n"
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:31
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:63
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:151
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:161
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:163
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:164
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:177
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:178
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:181
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:184
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:211
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:213
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:219
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:230
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:241
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:247
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:256
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:269
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:280
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:282
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:286
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:293
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:296
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:304
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:472
tools/power/cpupower/po/fr.po:msgstr "Usage : cpufreq-info [options]\n"
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:473 utils/cpufreq-set.c:26 utils/cpupower-set.c:23
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:474
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:475
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:477
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:479
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:480
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:481
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:482
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:483
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:484
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:486
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:487
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:488
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:489
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:491
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:492 utils/cpuidle-info.c:152
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:495
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:497
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:580
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:596
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:600 utils/cpufreq-set.c:82 utils/cpupower-set.c:42
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:617
tools/power/cpupower/po/fr.po:#: utils/cpufreq-info.c:620 utils/cpupower-info.c:142
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:25
tools/power/cpupower/po/fr.po:msgstr "Usage : cpufreq-set [options]\n"
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:27
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:28
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:29
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:30
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:32
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:33 utils/cpupower-set.c:28 utils/cpupower-info.c:27
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:35
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:37
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:57
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:170
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:302
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:308
tools/power/cpupower/po/fr.po:#: utils/cpufreq-set.c:347
tools/power/cpupower/po/fr.po:msgstr "Usage : cpufreq-info [options]\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:31
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:63
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:151
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:161
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:163
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:164
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:177
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:178
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:181
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:184
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:211
tools/power/cpupower/po/de.po:msgstr "  kein oder ein unbekannter cpufreq-Treiber ist auf dieser CPU aktiv\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:213
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:219
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:230
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:241
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:247
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:256
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:269
tools/power/cpupower/po/de.po:msgstr "  verfügbare cpufreq-Regler: "
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:280
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:282
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:286
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:293
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:296
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:304
tools/power/cpupower/po/de.po:msgstr "  cpufreq-Statistiken: "
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:472
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:473 utils/cpufreq-set.c:26 utils/cpupower-set.c:23
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:474
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:475
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:477
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:479
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:480
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:481
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:482
tools/power/cpupower/po/de.po:msgstr "  -g, --governors      Ermittelt verfügbare cpufreq-Regler *\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:483
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:484
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:486
tools/power/cpupower/po/de.po:msgstr "  -s, --stats          Zeigt cpufreq-Statistiken an, falls vorhanden\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:487
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:488
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:489
tools/power/cpupower/po/de.po:"                       der /proc/cpufreq-Datei in 2.4. und frühen 2.6.\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:491
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:492 utils/cpuidle-info.c:152
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:495
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:497
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:580
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:596
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:600 utils/cpufreq-set.c:82 utils/cpupower-set.c:42
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:617
tools/power/cpupower/po/de.po:#: utils/cpufreq-info.c:620 utils/cpupower-info.c:142
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:25
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:27
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:28
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:29
tools/power/cpupower/po/de.po:msgstr "  -g GOV, --governors GOV   neuer cpufreq-Regler\n"
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:30
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:32
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:33 utils/cpupower-set.c:28 utils/cpupower-info.c:27
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:35
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:37
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:57
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:170
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:302
tools/power/cpupower/po/de.po:"Der -f bzw. --freq-Parameter kann nicht mit den Parametern -d/--min, "
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:308
tools/power/cpupower/po/de.po:#: utils/cpufreq-set.c:347
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:31
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:63
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:151
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:161
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:163
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:164
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:177
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:178
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:181
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:184
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:211
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:213
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:219
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:230
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:241
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:247
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:256
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:269
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:280
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:282
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:286
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:293
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:296
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:304
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:472
tools/power/cpupower/po/it.po:msgstr "Uso: cpufreq-info [opzioni]\n"
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:473 utils/cpufreq-set.c:26 utils/cpupower-set.c:23
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:474
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:475
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:477
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:479
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:480
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:481
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:482
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:483
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:484
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:486
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:487
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:488
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:489
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:491
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:492 utils/cpuidle-info.c:152
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:495
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:497
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:580
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:596
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:600 utils/cpufreq-set.c:82 utils/cpupower-set.c:42
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:617
tools/power/cpupower/po/it.po:#: utils/cpufreq-info.c:620 utils/cpupower-info.c:142
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:25
tools/power/cpupower/po/it.po:msgstr "Uso: cpufreq-set [opzioni]\n"
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:27
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:28
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:29
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:30
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:32
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:33 utils/cpupower-set.c:28 utils/cpupower-info.c:27
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:35
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:37
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:57
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:170
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:302
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:308
tools/power/cpupower/po/it.po:#: utils/cpufreq-set.c:347
tools/power/cpupower/po/it.po:msgstr "Uso: cpufreq-info [opzioni]\n"
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:31
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:63
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:151
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:161
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:163
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:163 utils/cpufreq-info.c:164
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:164
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:177
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:178
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:181
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:184
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:211
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:213
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:219
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:230
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:241
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:247
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:256
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:269
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:280
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:282
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:286
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:293
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:296
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:304
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:472
tools/power/cpupower/po/pt.po:msgstr "Uso: cpufreq-info [opções]\n"
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:473 utils/cpufreq-set.c:26 utils/cpupower-set.c:23
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:474
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:475
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:477
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:479
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:480
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:481
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:482
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:483
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:484
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:486
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:487
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:488
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:489
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:491
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:492 utils/cpuidle-info.c:152
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:495
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:497
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:580
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:596
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:600 utils/cpufreq-set.c:82 utils/cpupower-set.c:42
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:617
tools/power/cpupower/po/pt.po:#: utils/cpufreq-info.c:620 utils/cpupower-info.c:142
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:25
tools/power/cpupower/po/pt.po:msgstr "Uso: cpufreq-set [opções]\n"
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:27
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:28
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:29
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:30
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:32
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:33 utils/cpupower-set.c:28 utils/cpupower-info.c:27
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:35
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:37
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:57
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:170
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:302
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:308
tools/power/cpupower/po/pt.po:#: utils/cpufreq-set.c:347
tools/power/cpupower/po/pt.po:msgstr "Uso: cpufreq-info [opções]\n"
tools/power/cpupower/Makefile:# cpufreq-bench benchmarking tool
tools/power/cpupower/Makefile:	utils/cpupower.o utils/cpufreq-info.o utils/cpufreq-set.o \
tools/power/cpupower/.gitignore:cpufreq-info
tools/power/cpupower/.gitignore:cpufreq-set
tools/power/cpupower/.gitignore:cpufreq-aperf
tools/power/cpupower/.gitignore:utils/cpufreq-info.o
tools/power/cpupower/.gitignore:utils/cpufreq-set.o
tools/power/cpupower/.gitignore:utils/cpufreq-aperf.o
tools/power/cpupower/.gitignore:bench/cpufreq-bench
tools/power/cpupower/bench/parse.c:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/Makefile:CFLAGS += -D_GNU_SOURCE -I../lib -DDEFAULT_CONFIG_FILE=\"$(confdir)/cpufreq-bench.conf\"
tools/power/cpupower/bench/Makefile:$(OUTPUT)cpufreq-bench: $(OBJS)
tools/power/cpupower/bench/Makefile:all: $(OUTPUT)cpufreq-bench
tools/power/cpupower/bench/Makefile:install: $(OUTPUT)cpufreq-bench
tools/power/cpupower/bench/Makefile:	install -m 755 $(OUTPUT)cpufreq-bench $(DESTDIR)/$(sbindir)/cpufreq-bench
tools/power/cpupower/bench/Makefile:	install -m 755 cpufreq-bench_plot.sh $(DESTDIR)/$(bindir)/cpufreq-bench_plot.sh
tools/power/cpupower/bench/Makefile:	install -m 755 cpufreq-bench_script.sh $(DESTDIR)/$(docdir)/cpufreq-bench_script.sh
tools/power/cpupower/bench/Makefile:	install -m 644 example.cfg $(DESTDIR)/$(confdir)/cpufreq-bench.conf
tools/power/cpupower/bench/Makefile:	rm -f $(OUTPUT)cpufreq-bench
tools/power/cpupower/bench/main.c:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/config.h:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/cpufreq-bench_plot.sh:# Helper script to easily create nice plots of your cpufreq-bench results
tools/power/cpupower/bench/cpufreq-bench_plot.sh:output_file="cpufreq-bench.png"
tools/power/cpupower/bench/cpufreq-bench_plot.sh:global_title="cpufreq-bench plot"
tools/power/cpupower/bench/cpufreq-bench_plot.sh:    echo "cpufreq-bench_plot.sh [OPTIONS] logfile [measure_title] [logfile [measure_title]] ...]"
tools/power/cpupower/bench/benchmark.c:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/parse.h:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/benchmark.h:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/system.h:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/README-BENCH:This is cpufreq-bench, a microbenchmark for the cpufreq framework.
tools/power/cpupower/bench/README-BENCH:cpufreq-bench helps to test the condition of a given cpufreq governor.
tools/power/cpupower/bench/README-BENCH:trigger of the cpufreq-bench, you will see no performance loss (compare with
tools/power/cpupower/bench/README-BENCH:cpufreq-bench Command Usage
tools/power/cpupower/bench/system.c:/*  cpufreq-bench CPUFreq microbenchmark
tools/power/cpupower/bench/example.cfg:output = /var/log/cpufreq-bench
tools/power/cpupower/bench/cpufreq-bench_script.sh:# Ondemand up_threshold and sampling rate test script for cpufreq-bench
tools/power/cpupower/bench/cpufreq-bench_script.sh:	    cpufreq-bench -o /var/log/cpufreq-bench/up_threshold_${up_threshold}_sampling_rate_${sampling_rate}
tools/power/cpupower/bench/cpufreq-bench_script.sh:	command="cpufreq-bench_plot.sh -o \"sampling_rate_${SAMPLING_RATE}_up_threshold_${up_threshold}\" -t \"Ondemand sampling_rate: ${SAMPLING_RATE} comparison - Up_threshold: $up_threshold %\""
tools/power/cpupower/bench/cpufreq-bench_script.sh:	    command="${command} /var/log/cpufreq-bench/up_threshold_${up_threshold}_sampling_rate_${sampling_rate}/* \"sampling_rate = $sampling_rate\""
tools/power/cpupower/bench/cpufreq-bench_script.sh:	command="cpufreq-bench_plot.sh -o \"up_threshold_${UP_THRESHOLD}_sampling_rate_${sampling_rate}\" -t \"Ondemand up_threshold: ${UP_THRESHOLD} % comparison - sampling_rate: $sampling_rate\""
tools/power/cpupower/bench/cpufreq-bench_script.sh:	    command="${command} /var/log/cpufreq-bench/up_threshold_${up_threshold}_sampling_rate_${sampling_rate}/* \"up_threshold = $up_threshold\""
tools/power/cpupower/bench/cpufreq-bench_script.sh:    command="cpufreq-bench_plot.sh -o \"up_threshold_${UP_THRESHOLD}_sampling_rate_${SAMPLING_RATE}\" -t \"Ondemand up_threshold: ${UP_THRESHOLD} and sampling_rate ${SAMPLING_RATE} comparison\""
tools/power/cpupower/bench/cpufreq-bench_script.sh:	    command="${command} /var/log/cpufreq-bench/up_threshold_${up_threshold}_sampling_rate_${sampling_rate}/* \"up_threshold = $up_threshold - sampling_rate = $sampling_rate\""
tools/power/cpupower/README:/usr/lib; cpupower, cpufreq-bench_plot.sh to put in /usr/bin; and
tools/power/cpupower/README:cpufreq-bench to put in /usr/sbin. If you want to set up the paths
tools/power/cpupower/debug/kernel/Makefile:  obj-m	 += cpufreq-test_tsc.o
tools/testing/selftests/timers/Makefile:		      skew_consistency clocksource-switch freq-step leap-a-day \
tools/testing/selftests/timers/.gitignore:freq-step
tools/testing/selftests/cpufreq/module.sh:# $1: cpufreq-driver module to insert
tools/testing/selftests/cpufreq/module.sh:# $1: cpufreq-driver module to insert
tools/testing/selftests/cpufreq/module.sh:# $1: cpufreq-governor module to insert
tools/testing/selftests/bpf/progs/bpf_iter_tcp4.c:	struct inet_request_sock *irsk = &treq->req;
tools/testing/selftests/bpf/progs/bpf_iter_tcp4.c:	ttd = req->rsk_timer.expires - bpf_jiffies64();
tools/testing/selftests/bpf/progs/bpf_iter_tcp4.c:		       req->num_timeout, uid, 0, 0, 0, req);
tools/testing/selftests/bpf/progs/bpf_iter_tcp6.c:	struct inet_request_sock *irsk = &treq->req;
tools/testing/selftests/bpf/progs/bpf_iter_tcp6.c:	ttd = req->rsk_timer.expires - bpf_jiffies64();
tools/testing/selftests/bpf/progs/bpf_iter_tcp6.c:		       req->num_timeout, uid, 0, 0, 0, req);
tools/testing/nvdimm/test/iomap.c:				if (req->res.start == start) {
tools/testing/nvdimm/test/iomap.c:					res = &req->res;
tools/testing/nvdimm/test/iomap.c:					list_del(&req->list);
tools/testing/nvdimm/test/iomap.c:				if (start == req->res.start) {
tools/testing/nvdimm/test/iomap.c:					res = &req->res;
tools/testing/nvdimm/test/iomap.c:			INIT_LIST_HEAD(&req->list);
tools/testing/nvdimm/test/iomap.c:			res = &req->res;
tools/testing/nvdimm/test/iomap.c:			list_add(&req->list, &nfit_res->requests);
lib/test_firmware.c:		if (req->fw)
lib/test_firmware.c:			release_firmware(req->fw);
lib/test_firmware.c:			req->rc = request_partial_firmware_into_buf
lib/test_firmware.c:						(&req->fw,
lib/test_firmware.c:						 req->name,
lib/test_firmware.c:						 req->dev,
lib/test_firmware.c:			req->rc = request_firmware_into_buf
lib/test_firmware.c:						(&req->fw,
lib/test_firmware.c:						 req->name,
lib/test_firmware.c:						 req->dev,
lib/test_firmware.c:		if (!req->fw)
lib/test_firmware.c:		req->rc = test_fw_config->req_firmware(&req->fw,
lib/test_firmware.c:						       req->name,
lib/test_firmware.c:						       req->dev);
lib/test_firmware.c:	if (req->rc) {
lib/test_firmware.c:			req->idx, req->rc);
lib/test_firmware.c:			test_fw_config->test_result = req->rc;
lib/test_firmware.c:	} else if (req->fw) {
lib/test_firmware.c:		req->sent = true;
lib/test_firmware.c:			req->idx, req->fw->size);
lib/test_firmware.c:	complete(&req->completion);
lib/test_firmware.c:	req->task = NULL;
lib/test_firmware.c:		req->fw = NULL;
lib/test_firmware.c:		req->idx = i;
lib/test_firmware.c:		req->name = test_fw_config->name;
lib/test_firmware.c:		req->dev = dev;
lib/test_firmware.c:		init_completion(&req->completion);
lib/test_firmware.c:		req->task = kthread_run(test_fw_run_batch_request, req,
lib/test_firmware.c:					     "%s-%u", KBUILD_MODNAME, req->idx);
lib/test_firmware.c:		if (!req->task || IS_ERR(req->task)) {
lib/test_firmware.c:			pr_err("Setting up thread %u failed\n", req->idx);
lib/test_firmware.c:			req->task = NULL;
lib/test_firmware.c:		if (req->task || req->sent)
lib/test_firmware.c:			wait_for_completion(&req->completion);
lib/test_firmware.c:	if (!req->idx)
lib/test_firmware.c:	req->fw = fw;
lib/test_firmware.c:	complete(&req->completion);
lib/test_firmware.c:		req->name = test_fw_config->name;
lib/test_firmware.c:		req->fw = NULL;
lib/test_firmware.c:		req->idx = i;
lib/test_firmware.c:		init_completion(&req->completion);
lib/test_firmware.c:					     req->name,
lib/test_firmware.c:			req->rc = rc;
lib/test_firmware.c:			req->sent = true;
lib/test_firmware.c:		if (req->sent)
lib/test_firmware.c:			wait_for_completion(&req->completion);
lib/test_firmware.c:	if (!req->fw) {
lib/test_firmware.c:	pr_info("#%u: loaded %zu\n", idx, req->fw->size);
lib/test_firmware.c:	if (req->fw->size > PAGE_SIZE) {
lib/test_firmware.c:	memcpy(buf, req->fw->data, req->fw->size);
lib/test_firmware.c:	rc = req->fw->size;
arch/arm64/crypto/aes-glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/arm64/crypto/aes-glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/arm64/crypto/aes-glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/arm64/crypto/aes-glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm64/crypto/aes-glue.c:					   req->iv);
arch/arm64/crypto/aes-glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/arm64/crypto/aes-glue.c:		if (req->dst != req->src)
arch/arm64/crypto/aes-glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/arm64/crypto/aes-glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/arm64/crypto/aes-glue.c:				   req->iv);
arch/arm64/crypto/aes-glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/arm64/crypto/aes-glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/arm64/crypto/aes-glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/arm64/crypto/aes-glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm64/crypto/aes-glue.c:					   req->iv);
arch/arm64/crypto/aes-glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/arm64/crypto/aes-glue.c:		if (req->dst != req->src)
arch/arm64/crypto/aes-glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/arm64/crypto/aes-glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/arm64/crypto/aes-glue.c:				   req->iv);
arch/arm64/crypto/aes-glue.c:				      req->iv, ctx->key2.key_enc);
arch/arm64/crypto/aes-glue.c:				      req->iv, ctx->key2.key_enc);
arch/arm64/crypto/aes-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/arm64/crypto/aes-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		int xts_blocks = DIV_ROUND_UP(req->cryptlen,
arch/arm64/crypto/aes-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm64/crypto/aes-glue.c:					   req->iv);
arch/arm64/crypto/aes-glue.c:	dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/arm64/crypto/aes-glue.c:	if (req->dst != req->src)
arch/arm64/crypto/aes-glue.c:		dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/arm64/crypto/aes-glue.c:				   req->iv);
arch/arm64/crypto/aes-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/arm64/crypto/aes-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm64/crypto/aes-glue.c:		int xts_blocks = DIV_ROUND_UP(req->cryptlen,
arch/arm64/crypto/aes-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm64/crypto/aes-glue.c:					   req->iv);
arch/arm64/crypto/aes-glue.c:	dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/arm64/crypto/aes-glue.c:	if (req->dst != req->src)
arch/arm64/crypto/aes-glue.c:		dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/arm64/crypto/aes-glue.c:				   req->iv);
arch/arm64/crypto/aes-neonbs-glue.c:	int tail = req->cryptlen % (8 * AES_BLOCK_SIZE);
arch/arm64/crypto/aes-neonbs-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm64/crypto/aes-neonbs-glue.c:		int xts_blocks = DIV_ROUND_UP(req->cryptlen,
arch/arm64/crypto/aes-neonbs-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm64/crypto/aes-neonbs-glue.c:					   req->iv);
arch/arm64/crypto/aes-neonbs-glue.c:	dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/arm64/crypto/aes-neonbs-glue.c:	if (req->dst != req->src)
arch/arm64/crypto/aes-neonbs-glue.c:		dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/arm64/crypto/aes-neonbs-glue.c:				   req->iv);
arch/arm64/crypto/chacha-neon-glue.c:	return chacha_neon_stream_xor(req, ctx, req->iv);
arch/arm64/crypto/chacha-neon-glue.c:	chacha_init_generic(state, ctx->key, req->iv);
arch/arm64/crypto/chacha-neon-glue.c:	memcpy(&real_iv[0], req->iv + 24, 8);
arch/arm64/crypto/chacha-neon-glue.c:	memcpy(&real_iv[8], req->iv + 16, 8);
arch/arm64/crypto/aes-ce-ccm-glue.c:	u32 l = req->iv[0] + 1;
arch/arm64/crypto/aes-ce-ccm-glue.c:	memcpy(maciv, req->iv, AES_BLOCK_SIZE - l);
arch/arm64/crypto/aes-ce-ccm-glue.c:	if (req->assoclen)
arch/arm64/crypto/aes-ce-ccm-glue.c:	memset(&req->iv[AES_BLOCK_SIZE - l], 0, l);
arch/arm64/crypto/aes-ce-ccm-glue.c:	u32 len = req->assoclen;
arch/arm64/crypto/aes-ce-ccm-glue.c:	scatterwalk_start(&walk, req->src);
arch/arm64/crypto/aes-ce-ccm-glue.c:	u32 len = req->cryptlen;
arch/arm64/crypto/aes-ce-ccm-glue.c:	if (req->assoclen)
arch/arm64/crypto/aes-ce-ccm-glue.c:	memcpy(buf, req->iv, AES_BLOCK_SIZE);
arch/arm64/crypto/aes-ce-ccm-glue.c:	scatterwalk_map_and_copy(mac, req->dst, req->assoclen + req->cryptlen,
arch/arm64/crypto/aes-ce-ccm-glue.c:	u32 len = req->cryptlen - authsize;
arch/arm64/crypto/aes-ce-ccm-glue.c:	if (req->assoclen)
arch/arm64/crypto/aes-ce-ccm-glue.c:	memcpy(buf, req->iv, AES_BLOCK_SIZE);
arch/arm64/crypto/aes-ce-ccm-glue.c:	scatterwalk_map_and_copy(buf, req->src,
arch/arm64/crypto/aes-ce-ccm-glue.c:				 req->assoclen + req->cryptlen - authsize,
arch/arm64/crypto/ghash-ce-glue.c:	u32 len = req->assoclen;
arch/arm64/crypto/ghash-ce-glue.c:	scatterwalk_start(&walk, req->src);
arch/arm64/crypto/ghash-ce-glue.c:	lengths.a = cpu_to_be64(req->assoclen * 8);
arch/arm64/crypto/ghash-ce-glue.c:	lengths.b = cpu_to_be64(req->cryptlen * 8);
arch/arm64/crypto/ghash-ce-glue.c:	if (req->assoclen)
arch/arm64/crypto/ghash-ce-glue.c:	memcpy(iv, req->iv, GCM_IV_SIZE);
arch/arm64/crypto/ghash-ce-glue.c:	scatterwalk_map_and_copy(tag, req->dst, req->assoclen + req->cryptlen,
arch/arm64/crypto/ghash-ce-glue.c:	lengths.a = cpu_to_be64(req->assoclen * 8);
arch/arm64/crypto/ghash-ce-glue.c:	lengths.b = cpu_to_be64((req->cryptlen - authsize) * 8);
arch/arm64/crypto/ghash-ce-glue.c:	if (req->assoclen)
arch/arm64/crypto/ghash-ce-glue.c:	memcpy(iv, req->iv, GCM_IV_SIZE);
arch/arm64/crypto/ghash-ce-glue.c:	scatterwalk_map_and_copy(otag, req->src,
arch/arm64/crypto/ghash-ce-glue.c:				 req->assoclen + req->cryptlen - authsize,
arch/arm64/boot/dts/qcom/msm8998.dtsi:			freq-table-hz =
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			qcom,freq-domain = <&cpufreq_hw 2>;
arch/arm64/boot/dts/qcom/sm8150.dtsi:			freq-table-hz =
arch/arm64/boot/dts/qcom/sm8150.dtsi:			compatible = "qcom,cpufreq-hw";
arch/arm64/boot/dts/qcom/sm8150.dtsi:			reg-names = "freq-domain0", "freq-domain1",
arch/arm64/boot/dts/qcom/sm8150.dtsi:				    "freq-domain2";
arch/arm64/boot/dts/qcom/sm8150.dtsi:			#freq-domain-cells = <1>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sdm845.dtsi:			freq-table-hz =
arch/arm64/boot/dts/qcom/sdm845.dtsi:			compatible = "qcom,cpufreq-hw";
arch/arm64/boot/dts/qcom/sdm845.dtsi:			reg-names = "freq-domain0", "freq-domain1";
arch/arm64/boot/dts/qcom/sdm845.dtsi:			#freq-domain-cells = <1>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			qcom,freq-domain = <&cpufreq_hw 2>;
arch/arm64/boot/dts/qcom/sm8250.dtsi:			freq-table-hz =
arch/arm64/boot/dts/qcom/sm8250.dtsi:			compatible = "qcom,sm8250-cpufreq-epss", "qcom,cpufreq-epss";
arch/arm64/boot/dts/qcom/sm8250.dtsi:			reg-names = "freq-domain0", "freq-domain1",
arch/arm64/boot/dts/qcom/sm8250.dtsi:				    "freq-domain2";
arch/arm64/boot/dts/qcom/sm8250.dtsi:			#freq-domain-cells = <1>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 0>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			qcom,freq-domain = <&cpufreq_hw 1>;
arch/arm64/boot/dts/qcom/sc7180.dtsi:			compatible = "qcom,cpufreq-hw";
arch/arm64/boot/dts/qcom/sc7180.dtsi:			reg-names = "freq-domain0", "freq-domain1";
arch/arm64/boot/dts/qcom/sc7180.dtsi:			#freq-domain-cells = <1>;
arch/arm64/boot/dts/qcom/msm8996.dtsi:			freq-table-hz =
arch/arm64/boot/dts/nvidia/tegra210-p2894.dtsi:		nvidia,core-power-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-p2894.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm64/boot/dts/nvidia/tegra132-norrin.dts:		nvidia,core-power-req-active-high;
arch/arm64/boot/dts/nvidia/tegra132-norrin.dts:		nvidia,sys-clock-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-p2180.dtsi:		nvidia,core-power-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-p2180.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-p3450-0000.dts:		nvidia,core-power-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-p3450-0000.dts:		nvidia,sys-clock-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-smaug.dts:		nvidia,core-power-req-active-high;
arch/arm64/boot/dts/nvidia/tegra210-smaug.dts:		nvidia,sys-clock-req-active-high;
arch/arm64/boot/dts/hisilicon/hi3660.dtsi:			freq-table-hz = <0 0
arch/arm64/boot/dts/hisilicon/hi3670.dtsi:			freq-table-hz = <0 0
arch/arm64/boot/dts/exynos/exynos5433-tm2-common.dtsi:	devfreq-events = <&ppmu_event0_d0_general>, <&ppmu_event0_d1_general>;
arch/arm64/boot/dts/exynos/exynos7.dtsi:			freq-table-hz = <0 0>, <0 0>;
arch/arm64/boot/dts/arm/vexpress-v2f-1xv7-ca53x2.dts:			freq-range = <40000000 40000000>;
arch/arm64/boot/dts/arm/rtsm_ve-motherboard.dtsi:			freq-range = <23750000 63500000>;
arch/arm64/boot/dts/ti/k3-j721e-main.dtsi:			freq-table-hz = <250000000 250000000>, <19200000 19200000>, <19200000 19200000>;
arch/arm64/boot/dts/marvell/armada-37xx.dtsi:				pcie_clkreq_pins: pcie-clkreq-pins {
arch/arm/crypto/aes-neonbs-glue.c:	skcipher_request_set_crypt(subreq, req->src, req->dst,
arch/arm/crypto/aes-neonbs-glue.c:				   req->cryptlen, req->iv);
arch/arm/crypto/aes-neonbs-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/arm/crypto/aes-neonbs-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm/crypto/aes-neonbs-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm/crypto/aes-neonbs-glue.c:					   req->cryptlen - tail, req->iv);
arch/arm/crypto/aes-neonbs-glue.c:	scatterwalk_map_and_copy(buf, req->dst, req->cryptlen - AES_BLOCK_SIZE,
arch/arm/crypto/aes-neonbs-glue.c:	scatterwalk_map_and_copy(buf, req->src, req->cryptlen, tail, 0);
arch/arm/crypto/aes-neonbs-glue.c:	crypto_xor(buf, req->iv, AES_BLOCK_SIZE);
arch/arm/crypto/aes-neonbs-glue.c:	crypto_xor(buf, req->iv, AES_BLOCK_SIZE);
arch/arm/crypto/aes-neonbs-glue.c:	scatterwalk_map_and_copy(buf, req->dst, req->cryptlen - AES_BLOCK_SIZE,
arch/arm/crypto/chacha-glue.c:	return chacha_stream_xor(req, ctx, req->iv, neon);
arch/arm/crypto/chacha-glue.c:	chacha_init_generic(state, ctx->key, req->iv);
arch/arm/crypto/chacha-glue.c:	memcpy(&real_iv[0], req->iv + 24, 8);
arch/arm/crypto/chacha-glue.c:	memcpy(&real_iv[8], req->iv + 16, 8);
arch/arm/crypto/curve25519-glue.c:	if (req->src) {
arch/arm/crypto/curve25519-glue.c:		copied = sg_copy_to_buffer(req->src,
arch/arm/crypto/curve25519-glue.c:					   sg_nents_for_len(req->src,
arch/arm/crypto/curve25519-glue.c:	nbytes = min_t(size_t, CURVE25519_KEY_SIZE, req->dst_len);
arch/arm/crypto/curve25519-glue.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst,
arch/arm/crypto/ghash-ce-glue.c:		return crypto_shash_final(desc, req->result);
arch/arm/crypto/aes-ce-glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/arm/crypto/aes-ce-glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/arm/crypto/aes-ce-glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/arm/crypto/aes-ce-glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm/crypto/aes-ce-glue.c:					   req->iv);
arch/arm/crypto/aes-ce-glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/arm/crypto/aes-ce-glue.c:		if (req->dst != req->src)
arch/arm/crypto/aes-ce-glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/arm/crypto/aes-ce-glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/arm/crypto/aes-ce-glue.c:				   req->iv);
arch/arm/crypto/aes-ce-glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/arm/crypto/aes-ce-glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/arm/crypto/aes-ce-glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/arm/crypto/aes-ce-glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm/crypto/aes-ce-glue.c:					   req->iv);
arch/arm/crypto/aes-ce-glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/arm/crypto/aes-ce-glue.c:		if (req->dst != req->src)
arch/arm/crypto/aes-ce-glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/arm/crypto/aes-ce-glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/arm/crypto/aes-ce-glue.c:				   req->iv);
arch/arm/crypto/aes-ce-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/arm/crypto/aes-ce-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		int xts_blocks = DIV_ROUND_UP(req->cryptlen,
arch/arm/crypto/aes-ce-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm/crypto/aes-ce-glue.c:					   req->iv);
arch/arm/crypto/aes-ce-glue.c:	dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/arm/crypto/aes-ce-glue.c:	if (req->dst != req->src)
arch/arm/crypto/aes-ce-glue.c:		dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/arm/crypto/aes-ce-glue.c:				   req->iv);
arch/arm/crypto/aes-ce-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/arm/crypto/aes-ce-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/arm/crypto/aes-ce-glue.c:		int xts_blocks = DIV_ROUND_UP(req->cryptlen,
arch/arm/crypto/aes-ce-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/arm/crypto/aes-ce-glue.c:					   req->iv);
arch/arm/crypto/aes-ce-glue.c:	dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/arm/crypto/aes-ce-glue.c:	if (req->dst != req->src)
arch/arm/crypto/aes-ce-glue.c:		dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/arm/crypto/aes-ce-glue.c:				   req->iv);
arch/arm/mach-pxa/viper.c:		if (freq->old < freq->new) {
arch/arm/mach-pxa/viper.c:			viper_set_core_cpu_voltage(freq->new, 0);
arch/arm/mach-pxa/viper.c:		if (freq->old > freq->new) {
arch/arm/mach-pxa/viper.c:			viper_set_core_cpu_voltage(freq->new, 0);
arch/arm/kernel/smp.c:	struct cpumask *cpus = freq->policy->cpus;
arch/arm/kernel/smp.c:	if (freq->flags & CPUFREQ_CONST_LOOPS)
arch/arm/kernel/smp.c:			per_cpu(l_p_j_ref_freq, cpu) = freq->old;
arch/arm/kernel/smp.c:			global_l_p_j_ref_freq = freq->old;
arch/arm/kernel/smp.c:	if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
arch/arm/kernel/smp.c:	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new)) {
arch/arm/kernel/smp.c:						freq->new);
arch/arm/kernel/smp.c:				    per_cpu(l_p_j_ref_freq, first), freq->new);
arch/arm/mach-rpc/ecard.c:	struct expansion_card *ec = req->ec;
arch/arm/mach-rpc/ecard.c:	struct expansion_card *ec = req->ec;
arch/arm/mach-rpc/ecard.c:	unsigned char *buf = req->buffer;
arch/arm/mach-rpc/ecard.c:	unsigned int len = req->length;
arch/arm/mach-rpc/ecard.c:	unsigned int off = req->address;
arch/arm/mach-rpc/ecard.c:		if (!req->use_loader || !ec->loader) {
arch/arm/mach-rpc/ecard.c:			req->fn(req);
arch/arm/mach-rpc/ecard.c:			complete(req->complete);
arch/arm/mach-rpc/ecard.c:	req->complete = &completion;
arch/arm/mach-imx/mach-imx7d.c:		platform_device_register_simple("imx-cpufreq-dt", -1, NULL, 0);
arch/arm/mach-imx/mach-imx7ulp.c:		platform_device_register_simple("imx-cpufreq-dt", -1, NULL, 0);
arch/arm/boot/dts/exynos4412-itop-scp-core.dtsi:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/exynos4412-itop-scp-core.dtsi:	devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
arch/arm/boot/dts/exynos4412-p4note.dtsi:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/exynos4412-p4note.dtsi:	devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
arch/arm/boot/dts/tegra124-jetson-tk1.dts:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra124-jetson-tk1.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/spear13xx.dtsi:		compatible = "st,cpufreq-spear";
arch/arm/boot/dts/tegra30-apalis.dtsi:			clk1-req-pee2 {
arch/arm/boot/dts/tegra30-apalis.dtsi:			clk2-req-pcc5 {
arch/arm/boot/dts/tegra30-apalis.dtsi:			pex-l0-clkreq-n-pdd2 {
arch/arm/boot/dts/tegra30-apalis.dtsi:			sys-clk-req-pz5 {
arch/arm/boot/dts/tegra30-apalis.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-apalis.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-colibri.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-seaboard.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra30-asus-nexus7-grouper-maxim-pmic.dtsi:			cpu-pwr-req-hog {
arch/arm/boot/dts/exynos4412-midas.dtsi:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/exynos4412-midas.dtsi:	devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <50000000 60000000>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <20000000 40000000>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <23750000 165000000>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <20000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <20000000 60000000>;
arch/arm/boot/dts/vexpress-v2p-ca15-tc1.dts:			freq-range = <40000000 40000000>;
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:			clk1-req-pee2 {
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:			clk2-req-pcc5 {
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:			pex-l0-clkreq-n-pdd2 {
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:			sys-clk-req-pz5 {
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-apalis-v1.1.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/armada-388-clearfog.dtsi:		pcie1-0-clkreq-hog {
arch/arm/boot/dts/exynos4412-odroid-common.dtsi:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/exynos4412-odroid-common.dtsi:	devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
arch/arm/boot/dts/exynos3250-monk.dts:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/tegra30-ouya.dts:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-ouya.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/exynos5422-odroid-core.dtsi:	devfreq-events = <&nocp_mem0_0>, <&nocp_mem0_1>,
arch/arm/boot/dts/exynos5422-odroid-core.dtsi:	devfreq-events = <&ppmu_event3_dmc0_0>,	<&ppmu_event3_dmc0_1>,
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:			pex-l0-clkreq-n-pdd2 {
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:			pex-l1-clkreq-n-pdd6 {
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:			clk2-req-pcc5 { /* D4 GPIO */
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:			clk3-req-pee1 { /* NC */
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:			dap-mclk1-req-pee2 { /* NC */
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra124-apalis-v1.2.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/vexpress-v2p-ca9.dts:			freq-range = <30000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca9.dts:			freq-range = <10000000 80000000>;
arch/arm/boot/dts/vexpress-v2p-ca9.dts:			freq-range = <33000000 100000000>;
arch/arm/boot/dts/tegra30-colibri.dtsi:			pex-l0-clkreq-n-pdd2 {
arch/arm/boot/dts/tegra30-colibri.dtsi:			clk1-req-pee2 {
arch/arm/boot/dts/tegra30-colibri.dtsi:			clk2-req-pcc5 {
arch/arm/boot/dts/tegra30-colibri.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-colibri.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra124-apalis.dtsi:			pex-l0-clkreq-n-pdd2 {
arch/arm/boot/dts/tegra124-apalis.dtsi:			pex-l1-clkreq-n-pdd6 {
arch/arm/boot/dts/tegra124-apalis.dtsi:			clk2-req-pcc5 { /* D4 GPIO */
arch/arm/boot/dts/tegra124-apalis.dtsi:			clk3-req-pee1 { /* NC */
arch/arm/boot/dts/tegra124-apalis.dtsi:			dap-mclk1-req-pee2 { /* NC */
arch/arm/boot/dts/tegra124-apalis.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra124-apalis.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-trimslice.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/bcm4709-netgear-r8000.dts:			ieee80211-freq-limit = <5735000 5835000>;
arch/arm/boot/dts/bcm4709-netgear-r8000.dts:					ieee80211-freq-limit = <5170000 5730000>;
arch/arm/boot/dts/armada-388-clearfog.dts:	pcie2-0-clkreq-hog {
arch/arm/boot/dts/tegra30-beaver.dts:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-beaver.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-harmony.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-tamonten.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/vexpress-v2m.dtsi:					freq-range = <25000000 60000000>;
arch/arm/boot/dts/vexpress-v2m.dtsi:					freq-range = <23750000 65000000>;
arch/arm/boot/dts/vexpress-v2m.dtsi:					freq-range = <24000000 24000000>;
arch/arm/boot/dts/tegra124-venice2.dts:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra124-venice2.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/vexpress-v2m-rs1.dtsi:						freq-range = <25000000 60000000>;
arch/arm/boot/dts/vexpress-v2m-rs1.dtsi:						freq-range = <23750000 65000000>;
arch/arm/boot/dts/vexpress-v2m-rs1.dtsi:						freq-range = <24000000 24000000>;
arch/arm/boot/dts/tegra20-paz00.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra20-ventana.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/exynos3250-rinato.dts:	devfreq-events = <&ppmu_dmc0_3>, <&ppmu_dmc1_3>;
arch/arm/boot/dts/exynos3250-rinato.dts:	devfreq-events = <&ppmu_leftbus_3>, <&ppmu_rightbus_3>;
arch/arm/boot/dts/tegra20-acer-a500-picasso.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra114-dalmore.dts:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra114-dalmore.dts:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra124-nyan.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra124-nyan.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/tegra30-cardhu.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-cardhu.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/nuvoton-common-npcm7xx.dtsi:		clkreq_pins: clkreq-pins {
arch/arm/boot/dts/tegra30-asus-nexus7-grouper-common.dtsi:		nvidia,core-power-req-active-high;
arch/arm/boot/dts/tegra30-asus-nexus7-grouper-common.dtsi:		nvidia,sys-clock-req-active-high;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <50000000 100000000>;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <5000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <80000000 120000000>;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <23750000 165000000>;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <80000000 80000000>;
arch/arm/boot/dts/vexpress-v2p-ca5s.dts:			freq-range = <25000000 60000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <17000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <17000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <17000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <17000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <20000000 40000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <23750000 165000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <20000000 40000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <17000000 50000000>;
arch/arm/boot/dts/vexpress-v2p-ca15_a7.dts:			freq-range = <20000000 50000000>;
arch/arm/mach-s3c/cpufreq-utils-s3c24xx.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-s3c/iotiming-s3c2410.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-s3c/pll-s3c2440-12000000.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-s3c/Makefile.s3c24xx:obj-$(CONFIG_ARM_S3C24XX_CPUFREQ) += cpufreq-utils-s3c24xx.o
arch/arm/mach-s3c/iotiming-s3c2412.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-s3c/pll-s3c2410.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-s3c/pll-s3c2440-16934400.c:#include <linux/soc/samsung/s3c-cpufreq-core.h>
arch/arm/mach-davinci/da850.c:	.name			= "cpufreq-davinci",
arch/sparc/kernel/time_64.c:	for_each_cpu(cpu, freq->policy->cpus) {
arch/sparc/kernel/time_64.c:			ft->ref_freq = freq->old;
arch/sparc/kernel/time_64.c:		if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
arch/sparc/kernel/time_64.c:		    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new)) {
arch/sparc/kernel/time_64.c:					      freq->new);
arch/mips/pci/pci-lantiq.c:	req_mask = of_get_property(node, "req-mask", NULL);
arch/mips/crypto/chacha-glue.c:	return chacha_mips_stream_xor(req, ctx, req->iv);
arch/mips/crypto/chacha-glue.c:	chacha_init_generic(state, ctx->key, req->iv);
arch/mips/crypto/chacha-glue.c:	memcpy(&real_iv[0], req->iv + 24, 8);
arch/mips/crypto/chacha-glue.c:	memcpy(&real_iv[8], req->iv + 16, 8);
arch/mips/kernel/time.c:	struct cpumask *cpus = freq->policy->cpus;
arch/mips/kernel/time.c:	if (freq->flags & CPUFREQ_CONST_LOOPS)
arch/mips/kernel/time.c:		glb_lpj_ref_freq = freq->old;
arch/mips/kernel/time.c:			per_cpu(pcp_lpj_ref_freq, cpu) = freq->old;
arch/mips/kernel/time.c:	if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
arch/mips/kernel/time.c:	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new)) {
arch/mips/kernel/time.c:						freq->new);
arch/mips/kernel/time.c:					    freq->new);
arch/mips/kernel/cevt-r4k.c:		mips_ref_freq = freq->old;
arch/mips/kernel/cevt-r4k.c:				     freq->new);
arch/mips/kernel/cevt-r4k.c:		for_each_cpu(cpu, freq->policy->cpus) {
arch/mips/boot/dts/lantiq/easy50712.dts:			req-mask = <0x1>;		/* GNT1 */
arch/mips/alchemy/common/clock.c:		if (pr < req->rate)
arch/mips/alchemy/common/clock.c:		tdv = alchemy_calc_div(req->rate, pr, scale, maxdiv, NULL);
arch/mips/alchemy/common/clock.c:		diff = req->rate - nr;
arch/mips/alchemy/common/clock.c:		if (nr > req->rate)
arch/mips/alchemy/common/clock.c:			tpr = req->rate * j;
arch/mips/alchemy/common/clock.c:			tdv = alchemy_calc_div(req->rate, pr, scale, maxdiv,
arch/mips/alchemy/common/clock.c:			diff = req->rate - nr;
arch/mips/alchemy/common/clock.c:			if (nr > req->rate)
arch/mips/alchemy/common/clock.c:	req->best_parent_rate = bpr;
arch/mips/alchemy/common/clock.c:	req->best_parent_hw = bpc;
arch/mips/alchemy/common/clock.c:	req->rate = br;
arch/x86/kvm/x86.c:		khz = freq->new;
arch/x86/kvm/x86.c:	if (freq->old < freq->new && send_ipi) {
arch/x86/kvm/x86.c:	if (val == CPUFREQ_PRECHANGE && freq->old > freq->new)
arch/x86/kvm/x86.c:	if (val == CPUFREQ_POSTCHANGE && freq->old < freq->new)
arch/x86/kvm/x86.c:	for_each_cpu(cpu, freq->policy->cpus)
arch/x86/crypto/aegis128-aesni-glue.c:	crypto_aegis128_aesni_init(&state, ctx->key.bytes, req->iv);
arch/x86/crypto/aegis128-aesni-glue.c:	crypto_aegis128_aesni_process_ad(&state, req->src, req->assoclen);
arch/x86/crypto/aegis128-aesni-glue.c:	crypto_aegis128_aesni_final(&state, tag_xor, req->assoclen, cryptlen);
arch/x86/crypto/aegis128-aesni-glue.c:	unsigned int cryptlen = req->cryptlen;
arch/x86/crypto/aegis128-aesni-glue.c:	scatterwalk_map_and_copy(tag.bytes, req->dst,
arch/x86/crypto/aegis128-aesni-glue.c:				 req->assoclen + cryptlen, authsize, 1);
arch/x86/crypto/aegis128-aesni-glue.c:	unsigned int cryptlen = req->cryptlen - authsize;
arch/x86/crypto/aegis128-aesni-glue.c:	scatterwalk_map_and_copy(tag.bytes, req->src,
arch/x86/crypto/aegis128-aesni-glue.c:				 req->assoclen + cryptlen, authsize, 0);
arch/x86/crypto/aesni-intel_glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/x86/crypto/aesni-intel_glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/x86/crypto/aesni-intel_glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/x86/crypto/aesni-intel_glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/x86/crypto/aesni-intel_glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/x86/crypto/aesni-intel_glue.c:					   req->iv);
arch/x86/crypto/aesni-intel_glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/x86/crypto/aesni-intel_glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/x86/crypto/aesni-intel_glue.c:		if (req->dst != req->src)
arch/x86/crypto/aesni-intel_glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/x86/crypto/aesni-intel_glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/x86/crypto/aesni-intel_glue.c:				   req->iv);
arch/x86/crypto/aesni-intel_glue.c:	int cbc_blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/x86/crypto/aesni-intel_glue.c:	struct scatterlist *src = req->src, *dst = req->dst;
arch/x86/crypto/aesni-intel_glue.c:	if (req->cryptlen <= AES_BLOCK_SIZE) {
arch/x86/crypto/aesni-intel_glue.c:		if (req->cryptlen < AES_BLOCK_SIZE)
arch/x86/crypto/aesni-intel_glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/x86/crypto/aesni-intel_glue.c:					   req->iv);
arch/x86/crypto/aesni-intel_glue.c:		if (req->cryptlen == AES_BLOCK_SIZE)
arch/x86/crypto/aesni-intel_glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, subreq.cryptlen);
arch/x86/crypto/aesni-intel_glue.c:		if (req->dst != req->src)
arch/x86/crypto/aesni-intel_glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst,
arch/x86/crypto/aesni-intel_glue.c:				   req->cryptlen - cbc_blocks * AES_BLOCK_SIZE,
arch/x86/crypto/aesni-intel_glue.c:				   req->iv);
arch/x86/crypto/aesni-intel_glue.c:	unsigned long left = req->cryptlen;
arch/x86/crypto/aesni-intel_glue.c:	if (req->src->length >= assoclen && req->src->length) {
arch/x86/crypto/aesni-intel_glue.c:		scatterwalk_start(&assoc_sg_walk, req->src);
arch/x86/crypto/aesni-intel_glue.c:		gfp_t flags = (req->base.flags & CRYPTO_TFM_REQ_MAY_SLEEP) ?
arch/x86/crypto/aesni-intel_glue.c:		scatterwalk_map_and_copy(assoc, req->src, 0, assoclen, 0);
arch/x86/crypto/aesni-intel_glue.c:	scatterwalk_map_and_copy(auth_tag, req->dst,
arch/x86/crypto/aesni-intel_glue.c:				 req->assoclen + req->cryptlen,
arch/x86/crypto/aesni-intel_glue.c:	scatterwalk_map_and_copy(auth_tag_msg, req->src,
arch/x86/crypto/aesni-intel_glue.c:				 req->assoclen + req->cryptlen - auth_tag_len,
arch/x86/crypto/aesni-intel_glue.c:	if (unlikely(req->assoclen != 16 && req->assoclen != 20))
arch/x86/crypto/aesni-intel_glue.c:		*(iv+4+i) = req->iv[i];
arch/x86/crypto/aesni-intel_glue.c:	return gcmaes_encrypt(req, req->assoclen - 8, ctx->hash_subkey, iv,
arch/x86/crypto/aesni-intel_glue.c:	if (unlikely(req->assoclen != 16 && req->assoclen != 20))
arch/x86/crypto/aesni-intel_glue.c:		*(iv+4+i) = req->iv[i];
arch/x86/crypto/aesni-intel_glue.c:	return gcmaes_decrypt(req, req->assoclen - 8, ctx->hash_subkey, iv,
arch/x86/crypto/aesni-intel_glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/x86/crypto/aesni-intel_glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/x86/crypto/aesni-intel_glue.c:		int blocks = DIV_ROUND_UP(req->cryptlen, AES_BLOCK_SIZE) - 2;
arch/x86/crypto/aesni-intel_glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/x86/crypto/aesni-intel_glue.c:					   blocks * AES_BLOCK_SIZE, req->iv);
arch/x86/crypto/aesni-intel_glue.c:		dst = src = scatterwalk_ffwd(sg_src, req->src, req->cryptlen);
arch/x86/crypto/aesni-intel_glue.c:		if (req->dst != req->src)
arch/x86/crypto/aesni-intel_glue.c:			dst = scatterwalk_ffwd(sg_dst, req->dst, req->cryptlen);
arch/x86/crypto/aesni-intel_glue.c:					   req->iv);
arch/x86/crypto/aesni-intel_glue.c:	memcpy(iv, req->iv, 12);
arch/x86/crypto/aesni-intel_glue.c:	return gcmaes_encrypt(req, req->assoclen, ctx->hash_subkey, iv,
arch/x86/crypto/aesni-intel_glue.c:	memcpy(iv, req->iv, 12);
arch/x86/crypto/aesni-intel_glue.c:	return gcmaes_decrypt(req, req->assoclen, ctx->hash_subkey, iv,
arch/x86/crypto/ghash-clmulni-intel_glue.c:		return crypto_shash_final(desc, req->result);
arch/x86/crypto/chacha_glue.c:	return chacha_simd_stream_xor(req, ctx, req->iv);
arch/x86/crypto/chacha_glue.c:	chacha_init_generic(state, ctx->key, req->iv);
arch/x86/crypto/chacha_glue.c:	if (req->cryptlen > CHACHA_BLOCK_SIZE && crypto_simd_usable()) {
arch/x86/crypto/chacha_glue.c:	memcpy(&real_iv[0], req->iv + 24, 8);
arch/x86/crypto/chacha_glue.c:	memcpy(&real_iv[8], req->iv + 16, 8);
arch/x86/crypto/curve25519-x86_64.c:	if (req->src)
arch/x86/crypto/curve25519-x86_64.c:	nbytes = min_t(size_t, CURVE25519_KEY_SIZE, req->dst_len);
arch/x86/crypto/curve25519-x86_64.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst,
arch/x86/crypto/curve25519-x86_64.c:	if (!req->src)
arch/x86/crypto/curve25519-x86_64.c:	copied = sg_copy_to_buffer(req->src,
arch/x86/crypto/curve25519-x86_64.c:				   sg_nents_for_len(req->src,
arch/x86/crypto/curve25519-x86_64.c:	nbytes = min_t(size_t, CURVE25519_KEY_SIZE, req->dst_len);
arch/x86/crypto/curve25519-x86_64.c:	copied = sg_copy_from_buffer(req->dst, sg_nents_for_len(req->dst,
arch/x86/platform/ce4100/falconfalls.dts:					freq-reg = <0x26>;
arch/x86/kernel/tsc.c:		ref_freq = freq->old;
arch/x86/kernel/tsc.c:	if ((val == CPUFREQ_PRECHANGE  && freq->old < freq->new) ||
arch/x86/kernel/tsc.c:	    (val == CPUFREQ_POSTCHANGE && freq->old > freq->new)) {
arch/x86/kernel/tsc.c:			cpufreq_scale(loops_per_jiffy_ref, ref_freq, freq->new);
arch/x86/kernel/tsc.c:		tsc_khz = cpufreq_scale(tsc_khz_ref, ref_freq, freq->new);
arch/x86/kernel/tsc.c:		if (!(freq->flags & CPUFREQ_CONST_LOOPS))
arch/x86/kernel/tsc.c:		set_cyc2ns_scale(tsc_khz, freq->policy->cpu, rdtsc());
arch/x86/kernel/cpu/resctrl/pseudo_lock.c:		dev_pm_qos_remove_request(&pm_req->req);
arch/x86/kernel/cpu/resctrl/pseudo_lock.c:		list_del(&pm_req->list);
arch/x86/kernel/cpu/resctrl/pseudo_lock.c:					     &pm_req->req,
arch/x86/kernel/cpu/resctrl/pseudo_lock.c:		list_add(&pm_req->list, &plr->pm_reqs);
arch/powerpc/crypto/aes-spe-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/powerpc/crypto/aes-spe-glue.c:	int offset = req->cryptlen - tail - AES_BLOCK_SIZE;
arch/powerpc/crypto/aes-spe-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/powerpc/crypto/aes-spe-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/powerpc/crypto/aes-spe-glue.c:					   req->cryptlen - tail, req->iv);
arch/powerpc/crypto/aes-spe-glue.c:	scatterwalk_map_and_copy(b[0], req->dst, offset, AES_BLOCK_SIZE, 0);
arch/powerpc/crypto/aes-spe-glue.c:	scatterwalk_map_and_copy(b[0], req->src, offset + AES_BLOCK_SIZE, tail, 0);
arch/powerpc/crypto/aes-spe-glue.c:			req->iv, NULL);
arch/powerpc/crypto/aes-spe-glue.c:	scatterwalk_map_and_copy(b[0], req->dst, offset, AES_BLOCK_SIZE + tail, 1);
arch/powerpc/crypto/aes-spe-glue.c:	int tail = req->cryptlen % AES_BLOCK_SIZE;
arch/powerpc/crypto/aes-spe-glue.c:	int offset = req->cryptlen - tail - AES_BLOCK_SIZE;
arch/powerpc/crypto/aes-spe-glue.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/powerpc/crypto/aes-spe-glue.c:		skcipher_request_set_crypt(&subreq, req->src, req->dst,
arch/powerpc/crypto/aes-spe-glue.c:					   offset, req->iv);
arch/powerpc/crypto/aes-spe-glue.c:	scatterwalk_map_and_copy(b[1], req->src, offset, AES_BLOCK_SIZE + tail, 0);
arch/powerpc/crypto/aes-spe-glue.c:		ppc_encrypt_ecb(req->iv, req->iv, ctx->key_twk, ctx->rounds,
arch/powerpc/crypto/aes-spe-glue.c:	gf128mul_x_ble(&twk, (le128 *)req->iv);
arch/powerpc/crypto/aes-spe-glue.c:			req->iv, NULL);
arch/powerpc/crypto/aes-spe-glue.c:	scatterwalk_map_and_copy(b[0], req->dst, offset, AES_BLOCK_SIZE + tail, 1);
arch/powerpc/perf/req-gen/_begin.h:#define REQ_GEN_PREFIX req-gen
arch/powerpc/perf/hv-gpci-requests.h:#include "req-gen/_begin.h"
arch/powerpc/perf/hv-gpci-requests.h:#include "req-gen/_end.h"
arch/powerpc/perf/hv-gpci.h:#include "req-gen/perf.h"
arch/powerpc/perf/hv-24x7.c:				      req->performance_domain, req->data_offset,
arch/powerpc/perf/hv-24x7.c:				      req->starting_ix, req->starting_lpar_ix,
arch/powerpc/perf/hv-24x7.c:	req->performance_domain = event_get_domain(event);
arch/powerpc/perf/hv-24x7.c:	req->data_size = cpu_to_be16(8);
arch/powerpc/perf/hv-24x7.c:	req->data_offset = cpu_to_be32(event_get_offset(event));
arch/powerpc/perf/hv-24x7.c:	req->starting_lpar_ix = cpu_to_be16(event_get_lpar(event));
arch/powerpc/perf/hv-24x7.c:	req->max_num_lpars = cpu_to_be16(1);
arch/powerpc/perf/hv-24x7.c:	req->starting_ix = cpu_to_be16(idx);
arch/powerpc/perf/hv-24x7.c:	req->max_ix = cpu_to_be16(1);
arch/powerpc/perf/hv-24x7.c:		if (domain_needs_aggregation(req->performance_domain))
arch/powerpc/perf/hv-24x7.c:			req->max_num_thread_groups = -1;
arch/powerpc/perf/hv-24x7.c:		else if (req->performance_domain != HV_PERF_DOMAIN_PHYS_CHIP) {
arch/powerpc/perf/hv-24x7.c:			req->starting_thread_group_ix = idx % 2;
arch/powerpc/perf/hv-24x7.c:			req->max_num_thread_groups = 1;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	size_t transfer_size = req->size - req->pos;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	int dma = !(req->flags & MPC52XX_LPBFIFO_FLAG_NO_DMA);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	int write = req->flags & MPC52XX_LPBFIFO_FLAG_WRITE;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	int poll_dma = req->flags & MPC52XX_LPBFIFO_FLAG_POLL_DMA;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:			data = req->data + req->pos;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		bd->data[0] = req->data_phys + req->pos;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		 req->offset + req->pos);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	bit_fields = req->cs << 24 | 0x000008;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (!lpbfifo.req->defer_xfer_start)
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	dma = !(req->flags & MPC52XX_LPBFIFO_FLAG_NO_DMA);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	write = req->flags & MPC52XX_LPBFIFO_FLAG_WRITE;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	poll_dma = req->flags & MPC52XX_LPBFIFO_FLAG_POLL_DMA;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		data = req->data + req->pos;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->pos += count;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (req->size - req->pos)
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->last_byte = ((u8 *)req->data)[req->size - 1];
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		req->irq_count++;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->irq_ticks += mftb() - ts;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (do_callback && req->callback)
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		req->callback(req);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (!req || (req->flags & MPC52XX_LPBFIFO_FLAG_NO_DMA)) {
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		req->irq_count++;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		req->buffer_not_done_cnt++;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		if ((req->buffer_not_done_cnt % 1000) == 0)
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->last_byte = ((u8 *)req->data)[req->size - 1];
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->pos = status & 0x00ffffff;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->irq_ticks += mftb() - ts;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (req->callback)
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:		req->callback(req);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	int dma = !(req->flags & MPC52XX_LPBFIFO_FLAG_NO_DMA);
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	int write = req->flags & MPC52XX_LPBFIFO_FLAG_WRITE;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->irq_count = 0;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->irq_ticks = 0;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->buffer_not_done_cnt = 0;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	req->pos = 0;
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	if (lpbfifo.req && !lpbfifo.req->defer_xfer_start) {
arch/powerpc/platforms/52xx/mpc52xx_lpbfifo.c:	    lpbfifo.req->defer_xfer_start) {
arch/powerpc/platforms/powermac/nvram.c:	if (req->arg)
arch/powerpc/platforms/powermac/nvram.c:		complete((struct completion *)req->arg);
arch/powerpc/platforms/powermac/low_i2c.c:	complete(req->arg);
arch/powerpc/platforms/powermac/low_i2c.c:	struct pmu_i2c_hdr *hdr = (struct pmu_i2c_hdr *)&req->data[1];
arch/powerpc/platforms/powermac/low_i2c.c:		req->data[0] = PMU_I2C_CMD;
arch/powerpc/platforms/powermac/low_i2c.c:		req->reply[0] = 0xff;
arch/powerpc/platforms/powermac/low_i2c.c:		req->nbytes = sizeof(struct pmu_i2c_hdr) + 1;
arch/powerpc/platforms/powermac/low_i2c.c:		req->done = pmu_i2c_complete;
arch/powerpc/platforms/powermac/low_i2c.c:		req->arg = &comp;
arch/powerpc/platforms/powermac/low_i2c.c:			req->nbytes += len;
arch/powerpc/platforms/powermac/low_i2c.c:		if (req->reply[0] == PMU_I2C_STATUS_OK)
arch/powerpc/platforms/powermac/low_i2c.c:	if (req->reply[0] != PMU_I2C_STATUS_OK)
arch/powerpc/platforms/powermac/low_i2c.c:		req->data[0] = PMU_I2C_CMD;
arch/powerpc/platforms/powermac/low_i2c.c:		req->reply[0] = 0xff;
arch/powerpc/platforms/powermac/low_i2c.c:		req->nbytes = 2;
arch/powerpc/platforms/powermac/low_i2c.c:		req->done = pmu_i2c_complete;
arch/powerpc/platforms/powermac/low_i2c.c:		req->arg = &comp;
arch/powerpc/platforms/powermac/low_i2c.c:		if (req->reply[0] == PMU_I2C_STATUS_OK && !read)
arch/powerpc/platforms/powermac/low_i2c.c:		if (req->reply[0] == PMU_I2C_STATUS_DATAREAD && read) {
arch/powerpc/platforms/powermac/low_i2c.c:			int rlen = req->reply_len - 1;
arch/powerpc/platforms/powermac/low_i2c.c:				memcpy(data, &req->reply[1], len);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (!req || req->dir == MPC512X_LPBFIFO_REQ_DIR_READ) {
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (req->callback)
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		req->callback(req);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (req->dir == MPC512X_LPBFIFO_REQ_DIR_WRITE)
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:			lpbfifo.ram_bus_addr, req->size, dir);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		if (req->callback)
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:			req->callback(req);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (lpbfifo.req->size == 0 || !IS_ALIGNED(lpbfifo.req->size, 4))
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (lpbfifo.req->portsize != LPB_DEV_PORTSIZE_UNDEFINED) {
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		bpt = lpbfifo.req->portsize;
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		if (IS_ALIGNED(lpbfifo.req->dev_phys_addr, min(bpt, 0x8u)) &&
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:					IS_ALIGNED(lpbfifo.req->size, bpt)) {
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		phys_addr_t access_start = lpbfifo.req->dev_phys_addr;
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:		phys_addr_t access_end = access_start + lpbfifo.req->size;
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (lpbfifo.req->dir == MPC512X_LPBFIFO_REQ_DIR_WRITE) {
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:			lpbfifo.req->ram_virt_addr, lpbfifo.req->size, dir);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	sg_dma_len(&sg) = lpbfifo.req->size;
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	out_be32(&lpbfifo.regs->start_addr, lpbfifo.req->dev_phys_addr);
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (lpbfifo.req->dir == MPC512X_LPBFIFO_REQ_DIR_READ)
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	if (lpbfifo.req->dir == MPC512X_LPBFIFO_REQ_DIR_WRITE)
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:	bits = lpbfifo.req->size | MPC512X_SCLPC_START;
arch/powerpc/platforms/512x/mpc512x_lpbfifo.c:						lpbfifo.req->size, dir);
arch/um/drivers/mconsole_user.c:	msg.msg_name = &(req->origin);
arch/um/drivers/mconsole_user.c:	msg.msg_namelen = req->originlen;
arch/um/drivers/mconsole_user.c:	return sendmsg(req->originating_fd, &msg, 0);
arch/um/drivers/mconsole_user.c:		if (!strncmp(req->request.data, cmd->command,
arch/um/drivers/mconsole_user.c:	req->originlen = sizeof(req->origin);
arch/um/drivers/mconsole_user.c:	req->len = recvfrom(fd, &req->request, sizeof(req->request), 0,
arch/um/drivers/mconsole_user.c:			    (struct sockaddr *) req->origin, &req->originlen);
arch/um/drivers/mconsole_user.c:	if (req->len < 0)
arch/um/drivers/mconsole_user.c:	req->originating_fd = fd;
arch/um/drivers/mconsole_user.c:	if (req->request.magic != MCONSOLE_MAGIC) {
arch/um/drivers/mconsole_user.c:		len = MIN(sizeof(req->request.data) - 1,
arch/um/drivers/mconsole_user.c:			  strlen((char *) &req->request));
arch/um/drivers/mconsole_user.c:		memmove(req->request.data, &req->request, len);
arch/um/drivers/mconsole_user.c:		req->request.data[len] = '\0';
arch/um/drivers/mconsole_user.c:		req->request.magic = MCONSOLE_MAGIC;
arch/um/drivers/mconsole_user.c:		req->request.version = 0;
arch/um/drivers/mconsole_user.c:		req->request.len = len;
arch/um/drivers/mconsole_user.c:	if (req->request.len >= MCONSOLE_MAX_DATA) {
arch/um/drivers/mconsole_user.c:	if (req->request.version != MCONSOLE_VERSION) {
arch/um/drivers/mconsole_user.c:	req->request.data[req->request.len] = '\0';
arch/um/drivers/mconsole_user.c:	req->cmd = mconsole_parse(req);
arch/um/drivers/mconsole_user.c:	if (req->cmd == NULL) {
arch/um/drivers/mconsole_user.c:		n = sendto(req->originating_fd, &reply, len, 0,
arch/um/drivers/mconsole_user.c:			   (struct sockaddr *) req->origin, req->originlen);
arch/um/drivers/mconsole_kern.c:		list_del(&req->list);
arch/um/drivers/mconsole_kern.c:		req->request.cmd->handler(&req->request);
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data;
arch/um/drivers/mconsole_kern.c:	len = req->len - (ptr - req->request.data);
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data;
arch/um/drivers/mconsole_kern.c:	deactivate_fd(req->originating_fd, MCONSOLE_IRQ);
arch/um/drivers/mconsole_kern.c:	os_set_fd_block(req->originating_fd, 1);
arch/um/drivers/mconsole_kern.c:		if (!mconsole_get_request(req->originating_fd, req))
arch/um/drivers/mconsole_kern.c:		if (req->cmd->handler == mconsole_go)
arch/um/drivers/mconsole_kern.c:		if (req->cmd->handler == mconsole_stop) {
arch/um/drivers/mconsole_kern.c:		if (req->cmd->handler == mconsole_sysrq) {
arch/um/drivers/mconsole_kern.c:			old_regs = set_irq_regs((struct pt_regs *)&req->regs);
arch/um/drivers/mconsole_kern.c:		(*req->cmd->handler)(req);
arch/um/drivers/mconsole_kern.c:	os_set_fd_block(req->originating_fd, 0);
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data, *name, *error_string = "";
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data, *err_msg = "";
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data;
arch/um/drivers/mconsole_kern.c:	char *ptr = req->request.data;
arch/um/drivers/ubd_kern.c:			if ((io_req->error == BLK_STS_NOTSUPP) && (req_op(io_req->req) == REQ_OP_DISCARD)) {
arch/um/drivers/ubd_kern.c:				blk_queue_max_discard_sectors(io_req->req->q, 0);
arch/um/drivers/ubd_kern.c:				blk_queue_max_write_zeroes_sectors(io_req->req->q, 0);
arch/um/drivers/ubd_kern.c:				blk_queue_flag_clear(QUEUE_FLAG_DISCARD, io_req->req->q);
arch/um/drivers/ubd_kern.c:			blk_mq_end_request(io_req->req, io_req->error);
arch/um/drivers/ubd_kern.c:	if (req_op(req->req) == REQ_OP_READ) {
arch/um/drivers/ubd_kern.c:	unsigned long byte_offset = io_req->offset;
arch/um/drivers/ubd_kern.c:		io_req->io_desc[0].buffer = NULL;
arch/um/drivers/ubd_kern.c:		io_req->io_desc[0].length = blk_rq_bytes(req);
arch/um/drivers/ubd_kern.c:			BUG_ON(i >= io_req->desc_cnt);
arch/um/drivers/ubd_kern.c:			io_req->io_desc[i].buffer =
arch/um/drivers/ubd_kern.c:			io_req->io_desc[i].length = bvec.bv_len;
arch/um/drivers/ubd_kern.c:		for (i = 0; i < io_req->desc_cnt; i++) {
arch/um/drivers/ubd_kern.c:			cowify_req(io_req, &io_req->io_desc[i], byte_offset,
arch/um/drivers/ubd_kern.c:			byte_offset += io_req->io_desc[i].length;
arch/um/drivers/ubd_kern.c:	io_req->req = req;
arch/um/drivers/ubd_kern.c:		io_req->fds[0] = dev->cow.fd;
arch/um/drivers/ubd_kern.c:		io_req->fds[0] = dev->fd;
arch/um/drivers/ubd_kern.c:	io_req->error = 0;
arch/um/drivers/ubd_kern.c:	io_req->sectorsize = SECTOR_SIZE;
arch/um/drivers/ubd_kern.c:	io_req->fds[1] = dev->fd;
arch/um/drivers/ubd_kern.c:	io_req->offset = (u64) blk_rq_pos(req) << SECTOR_SHIFT;
arch/um/drivers/ubd_kern.c:	io_req->offsets[0] = 0;
arch/um/drivers/ubd_kern.c:	io_req->offsets[1] = dev->cow.data_offset;
arch/um/drivers/ubd_kern.c:		io_req->io_desc[i].sector_mask = 0;
arch/um/drivers/ubd_kern.c:		io_req->io_desc[i].cow_offset = -1;
arch/um/drivers/ubd_kern.c:	io_req->desc_cnt = segs;
arch/um/drivers/ubd_kern.c:	n = os_pwrite_file(req->fds[1], &segment->bitmap_words,
arch/um/drivers/ubd_kern.c:	if (req_op(req->req) == REQ_OP_FLUSH) {
arch/um/drivers/ubd_kern.c:		req->error = map_error(-os_sync_file(req->fds[0]));
arch/um/drivers/ubd_kern.c:	nsectors = desc->length / req->sectorsize;
arch/um/drivers/ubd_kern.c:		off = req->offset + req->offsets[bit] +
arch/um/drivers/ubd_kern.c:			start * req->sectorsize;
arch/um/drivers/ubd_kern.c:		len = (end - start) * req->sectorsize;
arch/um/drivers/ubd_kern.c:			buf = &desc->buffer[start * req->sectorsize];
arch/um/drivers/ubd_kern.c:		switch (req_op(req->req)) {
arch/um/drivers/ubd_kern.c:				n = os_pread_file(req->fds[bit], buf, len, off);
arch/um/drivers/ubd_kern.c:					req->error = map_error(-n);
arch/um/drivers/ubd_kern.c:			n = os_pwrite_file(req->fds[bit], buf, len, off);
arch/um/drivers/ubd_kern.c:				req->error = map_error(-n);
arch/um/drivers/ubd_kern.c:			n = os_falloc_punch(req->fds[bit], off, len);
arch/um/drivers/ubd_kern.c:				req->error = map_error(-n);
arch/um/drivers/ubd_kern.c:			req->error = BLK_STS_NOTSUPP;
arch/um/drivers/ubd_kern.c:	req->offset += len;
arch/um/drivers/ubd_kern.c:	req->error = update_bitmap(req, desc);
arch/um/drivers/ubd_kern.c:			for (i = 0; !req->error && i < req->desc_cnt; i++)
arch/um/drivers/ubd_kern.c:				do_io(req, &(req->io_desc[i]));
arch/s390/pci/pci_clp.c:	if (req->lps != 0 && req->lps != 2)
arch/s390/pci/pci_clp.c:	uptr = (void __force __user *)(unsigned long) req->data_p;
arch/s390/pci/pci_clp.c:	switch (req->lps) {
arch/s390/pci/pci_clp.c:	if (req->cmd > 1 || clp_get_ilp(&ilp) != 0)
arch/s390/pci/pci_clp.c:	uptr = (void __force __user *)(unsigned long) req->data_p;
arch/s390/pci/pci_clp.c:	if (req->cmd == 0) {
arch/s390/pci/pci_clp.c:		exists = test_bit_inv(req->lps, &ilp);
arch/s390/crypto/aes_s390.c:	if (req->cryptlen < AES_BLOCK_SIZE)
arch/s390/crypto/aes_s390.c:	if (unlikely(!xts_ctx->fc || (req->cryptlen % AES_BLOCK_SIZE) != 0)) {
arch/s390/crypto/aes_s390.c:	unsigned int aadlen = req->assoclen;
arch/s390/crypto/aes_s390.c:	unsigned int pclen = req->cryptlen;
arch/s390/crypto/aes_s390.c:	 *   req->src: aad||plaintext
arch/s390/crypto/aes_s390.c:	 *   req->dst: aad||ciphertext||tag
arch/s390/crypto/aes_s390.c:	 *   req->src: aad||ciphertext||tag
arch/s390/crypto/aes_s390.c:	 *   req->dst: aad||plaintext, return 0 or -EBADMSG
arch/s390/crypto/aes_s390.c:	memcpy(param.j0, req->iv, ivsize);
arch/s390/crypto/aes_s390.c:	gcm_walk_start(&gw_in, req->src, len);
arch/s390/crypto/aes_s390.c:	gcm_walk_start(&gw_out, req->dst, len);
arch/s390/crypto/aes_s390.c:		scatterwalk_map_and_copy(tag, req->src, len, taglen, 0);
arch/s390/crypto/aes_s390.c:		scatterwalk_map_and_copy(param.t, req->dst, len, taglen, 1);
block/blk-merge.c:	return bio_will_gap(req->q, req, req->biotail, bio);
block/blk-merge.c:	return bio_will_gap(req->q, NULL, bio, req->bio);
block/blk-merge.c:	if (req->nr_phys_segments + nr_phys_segs > blk_rq_get_max_segments(req))
block/blk-merge.c:	if (blk_integrity_merge_bio(req->q, req, bio) == false)
block/blk-merge.c:	req->nr_phys_segments += nr_phys_segs;
block/blk-merge.c:	req_set_nomerge(req->q, req);
block/blk-merge.c:		req_set_nomerge(req->q, req);
block/blk-merge.c:		req_set_nomerge(req->q, req);
block/blk-merge.c:	req->nr_phys_segments = segments + blk_rq_nr_discard_segments(next);
block/blk-merge.c:	total_phys_segments = req->nr_phys_segments + next->nr_phys_segments;
block/blk-merge.c:	req->nr_phys_segments = total_phys_segments;
block/blk-merge.c:		part_stat_inc(req->part, merges[op_stat_group(req_op(req))]);
block/blk-merge.c:	    queue_max_discard_segments(req->q) > 1)
block/blk-merge.c:	    || req->rq_disk != next->rq_disk)
block/blk-merge.c:	    !blk_write_same_mergeable(req->bio, next->bio))
block/blk-merge.c:	if (req->write_hint != next->write_hint)
block/blk-merge.c:	if (req->ioprio != next->ioprio)
block/blk-merge.c:	if (((req->rq_flags | next->rq_flags) & RQF_MIXED_MERGE) ||
block/blk-merge.c:	    (req->cmd_flags & REQ_FAILFAST_MASK) !=
block/blk-merge.c:	if (next->start_time_ns < req->start_time_ns)
block/blk-merge.c:		req->start_time_ns = next->start_time_ns;
block/blk-merge.c:	req->biotail->bi_next = next->bio;
block/blk-merge.c:	req->biotail = next->biotail;
block/blk-merge.c:	req->__data_len += blk_rq_bytes(next);
block/blk-merge.c:	part_stat_inc(req->part, merges[op_stat_group(req_op(req))]);
block/blk-merge.c:	rq_qos_merge(req->q, req, bio);
block/blk-merge.c:	if ((req->cmd_flags & REQ_FAILFAST_MASK) != ff)
block/blk-merge.c:	req->biotail->bi_next = bio;
block/blk-merge.c:	req->biotail = bio;
block/blk-merge.c:	req->__data_len += bio->bi_iter.bi_size;
block/blk-merge.c:	rq_qos_merge(req->q, req, bio);
block/blk-merge.c:	if ((req->cmd_flags & REQ_FAILFAST_MASK) != ff)
block/blk-merge.c:	bio->bi_next = req->bio;
block/blk-merge.c:	req->bio = bio;
block/blk-merge.c:	req->__sector = bio->bi_iter.bi_sector;
block/blk-merge.c:	req->__data_len += bio->bi_iter.bi_size;
block/blk-merge.c:	req->biotail->bi_next = bio;
block/blk-merge.c:	req->biotail = bio;
block/blk-merge.c:	req->__data_len += bio->bi_iter.bi_size;
block/blk-merge.c:	req->nr_phys_segments = segments + 1;
block/blk-core.c:		req->rq_disk ? req->rq_disk->disk_name : "?",
block/blk-core.c:		req->cmd_flags & ~REQ_OP_MASK,
block/blk-core.c:		req->nr_phys_segments,
block/blk-core.c:		IOPRIO_PRIO_CLASS(req->ioprio));
block/blk-core.c:	if (req->part && blk_do_io_stat(req)) {
block/blk-core.c:		part_stat_add(req->part, sectors[sgrp], bytes >> 9);
block/blk-core.c:	if (req->part && blk_do_io_stat(req) &&
block/blk-core.c:	    !(req->rq_flags & RQF_FLUSH_SEQ)) {
block/blk-core.c:		update_io_ticks(req->part, jiffies, true);
block/blk-core.c:		part_stat_inc(req->part, ios[sgrp]);
block/blk-core.c:		part_stat_add(req->part, nsecs[sgrp], now - req->start_time_ns);
block/blk-core.c:	if (!req->bio)
block/blk-core.c:		req->q->integrity.profile->complete_fn(req, nr_bytes);
block/blk-core.c:		     !(req->rq_flags & RQF_QUIET)))
block/blk-core.c:	while (req->bio) {
block/blk-core.c:		struct bio *bio = req->bio;
block/blk-core.c:			req->bio = bio->bi_next;
block/blk-core.c:	if (!req->bio) {
block/blk-core.c:		req->__data_len = 0;
block/blk-core.c:	req->__data_len -= total_bytes;
block/blk-core.c:		req->__sector += total_bytes >> 9;
block/blk-core.c:	if (req->rq_flags & RQF_MIXED_MERGE) {
block/blk-core.c:		req->cmd_flags &= ~REQ_FAILFAST_MASK;
block/blk-core.c:		req->cmd_flags |= req->bio->bi_opf & REQ_FAILFAST_MASK;
block/blk-core.c:	if (!(req->rq_flags & RQF_SPECIAL_PAYLOAD)) {
block/blk-core.c:			req->__data_len = blk_rq_cur_bytes(req);
block/blk-core.c:		req->nr_phys_segments = blk_recalc_rq_segments(req);
block/bsg-lib.c:	size_t sz = (sizeof(struct scatterlist) * req->nr_phys_segments);
block/bsg-lib.c:	BUG_ON(!req->nr_phys_segments);
block/bsg-lib.c:	sg_init_table(buf->sg_list, req->nr_phys_segments);
block/bsg-lib.c:	buf->sg_cnt = blk_rq_map_sg(req->q, req, buf->sg_list);
block/bsg-lib.c:	job->timeout = req->timeout;
block/bsg-lib.c:	if (req->bio) {
Binary file block/.blk-mq.c.swo matches
block/blk-mq.c:	req->rq_flags |= RQF_TIMED_OUT;
block/blk-mq.c:	if (req->q->mq_ops->timeout) {
block/blk-mq.c:		ret = req->q->mq_ops->timeout(req, reserved);
block/scsi_ioctl.c:	if (copy_from_user(req->cmd, hdr->cmdp, hdr->cmd_len))
block/scsi_ioctl.c:	if (blk_verify_command(req->cmd, mode))
block/scsi_ioctl.c:	req->cmd_len = hdr->cmd_len;
block/scsi_ioctl.c:	hdr->status = req->result & 0xff;
block/scsi_ioctl.c:	hdr->masked_status = status_byte(req->result);
block/scsi_ioctl.c:	hdr->msg_status = msg_byte(req->result);
block/scsi_ioctl.c:	hdr->host_status = host_byte(req->result);
block/scsi_ioctl.c:	hdr->driver_status = driver_byte(req->result);
block/scsi_ioctl.c:	hdr->resid = req->resid_len;
block/scsi_ioctl.c:	if (req->sense_len && hdr->sbp) {
block/scsi_ioctl.c:		int len = min((unsigned int) hdr->mx_sb_len, req->sense_len);
block/scsi_ioctl.c:		if (!copy_to_user(hdr->sbp, req->sense, len))
block/scsi_ioctl.c:		req->cmd = kzalloc(hdr->cmd_len, GFP_KERNEL);
block/scsi_ioctl.c:		if (!req->cmd)
block/scsi_ioctl.c:	req->retries = 0;
block/scsi_ioctl.c:	req->cmd_len = cmdlen;
block/scsi_ioctl.c:	if (copy_from_user(req->cmd, sic->data, cmdlen))
block/scsi_ioctl.c:	err = blk_verify_command(req->cmd, mode);
block/scsi_ioctl.c:	req->retries = 5;
block/scsi_ioctl.c:		req->retries = 1;
block/scsi_ioctl.c:		req->retries = 1;
block/scsi_ioctl.c:	err = req->result & 0xff;	/* only 8 bit SCSI status */
block/scsi_ioctl.c:		if (req->sense_len && req->sense) {
block/scsi_ioctl.c:			bytes = (OMAX_SB_LEN > req->sense_len) ?
block/scsi_ioctl.c:				req->sense_len : OMAX_SB_LEN;
block/scsi_ioctl.c:			if (copy_to_user(sic->data, req->sense, bytes))
block/scsi_ioctl.c:	memset(req->__cmd, 0, sizeof(req->__cmd));
block/scsi_ioctl.c:	req->cmd = req->__cmd;
block/scsi_ioctl.c:	req->cmd_len = BLK_MAX_CDB;
block/scsi_ioctl.c:	req->sense_len = 0;
block/bsg.c:	sreq->cmd_len = hdr->request_len;
block/bsg.c:	if (sreq->cmd_len > BLK_MAX_CDB) {
block/bsg.c:		sreq->cmd = kzalloc(sreq->cmd_len, GFP_KERNEL);
block/bsg.c:		if (!sreq->cmd)
block/bsg.c:	if (copy_from_user(sreq->cmd, uptr64(hdr->request), sreq->cmd_len))
block/bsg.c:	if (blk_verify_command(sreq->cmd, mode))
block/bsg.c:	hdr->device_status = sreq->result & 0xff;
block/bsg.c:	hdr->transport_status = host_byte(sreq->result);
block/bsg.c:	hdr->driver_status = driver_byte(sreq->result);
block/bsg.c:	if (sreq->sense_len && hdr->response) {
block/bsg.c:					sreq->sense_len);
block/bsg.c:		if (copy_to_user(uptr64(hdr->response), sreq->sense, len))
block/bsg.c:		hdr->din_resid = sreq->resid_len;
block/bsg.c:		hdr->dout_resid = sreq->resid_len;
block/blk-crypto-internal.h:	return bio_crypt_ctx_mergeable(req->crypt_ctx, blk_rq_bytes(req),
block/blk-crypto-internal.h:				       bio->bi_iter.bi_size, req->crypt_ctx);
block/blk-crypto-internal.h:	return bio_crypt_ctx_mergeable(req->crypt_ctx, blk_rq_bytes(req),
block/blk-timeout.c:	WRITE_ONCE(req->deadline, jiffies);
block/blk-timeout.c:	kblockd_schedule_work(&req->q->timeout_work);
block/blk-timeout.c:	struct request_queue *q = req->q;
block/blk-timeout.c:	if (!req->timeout)
block/blk-timeout.c:		req->timeout = q->rq_timeout;
block/blk-timeout.c:	req->rq_flags &= ~RQF_TIMED_OUT;
block/blk-timeout.c:	expiry = jiffies + req->timeout;
block/blk-timeout.c:	WRITE_ONCE(req->deadline, expiry);
block/mq-deadline.c:	if (!list_empty(&req->queuelist) && !list_empty(&next->queuelist)) {
block/mq-deadline.c:				(unsigned long)req->fifo_time)) {
block/mq-deadline.c:			list_move(&req->queuelist, &next->queuelist);
block/mq-deadline.c:			req->fifo_time = next->fifo_time;
block/blk-integrity.c:	if (bio_integrity(req->bio)->bip_flags !=
block/blk-integrity.c:	if (req->nr_integrity_segments + next->nr_integrity_segments >
block/blk-integrity.c:	if (bio_integrity(req->bio)->bip_flags != bio_integrity(bio)->bip_flags)
block/blk-integrity.c:	if (req->nr_integrity_segments + nr_integrity_segs >
block/blk-integrity.c:	req->nr_integrity_segments += nr_integrity_segs;
block/blk.h:	struct bio_integrity_payload *bip = bio_integrity(req->bio);
block/blk.h:	return bvec_gap_to_prev(req->q, &bip->bip_vec[bip->bip_vcnt - 1],
block/blk.h:	struct bio_integrity_payload *bip_next = bio_integrity(req->bio);
block/blk.h:	return bvec_gap_to_prev(req->q, &bip->bip_vec[bip->bip_vcnt - 1],
block/blk.h:	req->cmd_flags |= REQ_NOMERGE;
block/bfq-iosched.c:	    rb_prev(&req->rb_node) &&
block/bfq-iosched.c:	    blk_rq_pos(container_of(rb_prev(&req->rb_node),
include/media/v4l2-subdev.h: *		 freq->type must be filled in. Normally done by video_ioctl2()
include/media/videobuf2-core.h: * If req->count is 0, all the memory will be freed instead.
include/media/media-request.h:	spin_lock_irqsave(&req->lock, flags);
include/media/media-request.h:	if (req->state == MEDIA_REQUEST_STATE_COMPLETE) {
include/media/media-request.h:		req->access_count++;
include/media/media-request.h:	spin_unlock_irqrestore(&req->lock, flags);
include/media/media-request.h:	spin_lock_irqsave(&req->lock, flags);
include/media/media-request.h:	if (!WARN_ON(!req->access_count))
include/media/media-request.h:		req->access_count--;
include/media/media-request.h:	spin_unlock_irqrestore(&req->lock, flags);
include/media/media-request.h:	spin_lock_irqsave(&req->lock, flags);
include/media/media-request.h:	if (req->state == MEDIA_REQUEST_STATE_IDLE ||
include/media/media-request.h:	    req->state == MEDIA_REQUEST_STATE_UPDATING) {
include/media/media-request.h:		req->state = MEDIA_REQUEST_STATE_UPDATING;
include/media/media-request.h:		req->updating_count++;
include/media/media-request.h:	spin_unlock_irqrestore(&req->lock, flags);
include/media/media-request.h:	spin_lock_irqsave(&req->lock, flags);
include/media/media-request.h:	WARN_ON(req->updating_count <= 0);
include/media/media-request.h:	if (!--req->updating_count)
include/media/media-request.h:		req->state = MEDIA_REQUEST_STATE_IDLE;
include/media/media-request.h:	spin_unlock_irqrestore(&req->lock, flags);
include/media/media-request.h:	kref_get(&req->kref);
include/media/media-request.h: * @kref: Reference count of the object, acquire before releasing req->lock
include/media/media-request.h: * the @req->lock spin lock to make this safe.
include/media/dvb_vb2.h: * free previously requested buffers, is ``req->count`` is zero.
include/crypto/internal/skcipher.h:	req->base.complete(&req->base, err);
include/crypto/internal/skcipher.h:	return req->__ctx;
include/crypto/internal/skcipher.h:	return req->base.flags;
include/crypto/internal/acompress.h:	return req->__ctx;
include/crypto/internal/acompress.h:	req->base.complete(&req->base, err);
include/crypto/internal/hash.h:	req->base.complete(&req->base, err);
include/crypto/internal/hash.h:	return req->base.flags;
include/crypto/internal/kpp.h:	return req->__ctx;
include/crypto/internal/kpp.h:	req->base.complete(&req->base, err);
include/crypto/internal/aead.h:	return req->__ctx;
include/crypto/internal/aead.h:	req->base.complete(&req->base, err);
include/crypto/internal/aead.h:	return req->base.flags;
include/crypto/internal/akcipher.h:	return req->__ctx;
include/crypto/internal/akcipher.h:	req->base.complete(&req->base, err);
include/crypto/skcipher.h:	return __crypto_skcipher_cast(req->base.tfm);
include/crypto/skcipher.h:	req->base.tfm = crypto_skcipher_tfm(tfm);
include/crypto/skcipher.h:	req->base.complete = compl;
include/crypto/skcipher.h:	req->base.data = data;
include/crypto/skcipher.h:	req->base.flags = flags;
include/crypto/skcipher.h:	req->src = src;
include/crypto/skcipher.h:	req->dst = dst;
include/crypto/skcipher.h:	req->cryptlen = cryptlen;
include/crypto/skcipher.h:	req->iv = iv;
include/crypto/acompress.h:	req->base.tfm = crypto_acomp_tfm(tfm);
include/crypto/acompress.h:	return __crypto_acomp_tfm(req->base.tfm);
include/crypto/acompress.h:	req->base.complete = cmpl;
include/crypto/acompress.h:	req->base.data = data;
include/crypto/acompress.h:	req->base.flags = flgs;
include/crypto/acompress.h:	req->src = src;
include/crypto/acompress.h:	req->dst = dst;
include/crypto/acompress.h:	req->slen = slen;
include/crypto/acompress.h:	req->dlen = dlen;
include/crypto/acompress.h:	if (!req->dst)
include/crypto/acompress.h:		req->flags |= CRYPTO_ACOMP_ALLOC_OUTPUT;
include/crypto/acompress.h:	unsigned int slen = req->slen;
include/crypto/acompress.h:	unsigned int slen = req->slen;
include/crypto/hash.h: *	  implementation must not use req->result.
include/crypto/hash.h: *	   req->result.
include/crypto/hash.h: *	    happens at this point. Driver must not use req->result.
include/crypto/hash.h: *	    req->result.
include/crypto/hash.h:	return __crypto_ahash_cast(req->base.tfm);
include/crypto/hash.h:	return req->__ctx;
include/crypto/hash.h:	unsigned int nbytes = req->nbytes;
include/crypto/hash.h:	req->base.tfm = crypto_ahash_tfm(tfm);
include/crypto/hash.h:	req->base.complete = compl;
include/crypto/hash.h:	req->base.data = data;
include/crypto/hash.h:	req->base.flags = flags;
include/crypto/hash.h:	req->src = src;
include/crypto/hash.h:	req->nbytes = nbytes;
include/crypto/hash.h:	req->result = result;
include/crypto/kpp.h: *			enough req->dst_len will be updated to the size
include/crypto/kpp.h: *			req->dst_len will be updated to the size required
include/crypto/kpp.h:	req->base.tfm = crypto_kpp_tfm(tfm);
include/crypto/kpp.h:	return __crypto_kpp_tfm(req->base.tfm);
include/crypto/kpp.h:	req->base.complete = cmpl;
include/crypto/kpp.h:	req->base.data = data;
include/crypto/kpp.h:	req->base.flags = flgs;
include/crypto/kpp.h:	req->src = input;
include/crypto/kpp.h:	req->src_len = input_len;
include/crypto/kpp.h:	req->dst = output;
include/crypto/kpp.h:	req->dst_len = output_len;
include/crypto/pcrypt.h:	return req->__ctx;
include/crypto/pcrypt.h:	return &req->padata;
include/crypto/aead.h:	return __crypto_aead_cast(req->base.tfm);
include/crypto/aead.h:	req->base.tfm = crypto_aead_tfm(tfm);
include/crypto/aead.h:	req->base.complete = compl;
include/crypto/aead.h:	req->base.data = data;
include/crypto/aead.h:	req->base.flags = flags;
include/crypto/aead.h:	req->src = src;
include/crypto/aead.h:	req->dst = dst;
include/crypto/aead.h:	req->cryptlen = cryptlen;
include/crypto/aead.h:	req->iv = iv;
include/crypto/aead.h:	req->assoclen = assoclen;
include/crypto/akcipher.h: *		the req->dst_len will be updated to the size required for the
include/crypto/akcipher.h: *		the req->dst_len will be updated to the size required for the
include/crypto/akcipher.h: *		the req->dst_len will be updated to the size required for the
include/crypto/akcipher.h:	req->base.tfm = crypto_akcipher_tfm(tfm);
include/crypto/akcipher.h:	return __crypto_akcipher_tfm(req->base.tfm);
include/crypto/akcipher.h:	req->base.complete = cmpl;
include/crypto/akcipher.h:	req->base.data = data;
include/crypto/akcipher.h:	req->base.flags = flgs;
include/crypto/akcipher.h:	req->src = src;
include/crypto/akcipher.h:	req->dst = dst;
include/crypto/akcipher.h:	req->src_len = src_len;
include/crypto/akcipher.h:	req->dst_len = dst_len;
include/crypto/akcipher.h:	unsigned int src_len = req->src_len;
include/crypto/akcipher.h:	unsigned int src_len = req->src_len;
include/crypto/akcipher.h: * Note: req->dst should be NULL, req->src should point to SG of size
include/crypto/akcipher.h: * (req->src_size + req->dst_size), containing signature (of req->src_size
include/crypto/akcipher.h: * length) with appended digest (of req->dst_size length).
include/target/iscsi/iscsi_target_core.h:/* struct iscsi_datain_req->dr_complete */
include/target/iscsi/iscsi_target_core.h:/* struct iscsi_datain_req->recovery */
include/linux/pm_qos.h:	return req->dev != NULL;
include/linux/pm_qos.h:	return dev->power.qos->resume_latency_req->data.pnode.prio;
include/linux/pm_qos.h:	return dev->power.qos->flags_req->data.flr.flags;
include/linux/pm_qos.h:	return !IS_ERR_OR_NULL(req->qos);
include/linux/tcp.h:	tp->saved_syn = req->saved_syn;
include/linux/tcp.h:	req->saved_syn = NULL;
include/linux/nfs_page.h:	return !test_and_set_bit(PG_BUSY, &req->wb_flags);
include/linux/nfs_page.h:	list_add_tail(&req->wb_list, head);
include/linux/nfs_page.h:	list_move_tail(&req->wb_list, head);
include/linux/nfs_page.h:	if (list_empty(&req->wb_list))
include/linux/nfs_page.h:	list_del_init(&req->wb_list);
include/linux/nfs_page.h:	return (((loff_t)req->wb_index) << PAGE_SHIFT) + req->wb_offset;
include/linux/nfs_page.h:	return req->wb_lock_context->open_context;
include/linux/devfreq.h: *			has registered devfreq->nb at a notifier-head,
include/linux/mtd/nand.h:	iter->req.mode = req->mode;
include/linux/mtd/nand.h:	iter->req.ooboffs = req->ooboffs;
include/linux/mtd/nand.h:	iter->dataleft = req->len;
include/linux/mtd/nand.h:	iter->oobleft = req->ooblen;
include/linux/mtd/nand.h:	iter->req.databuf.in = req->datbuf;
include/linux/mtd/nand.h:	iter->req.oobbuf.in = req->oobbuf;
include/linux/mtd/mtd.h: * This function will adjust @req->addr and @req->len to align them on
include/linux/mtd/mtd.h:	mod = mtd_mod_by_eb(req->addr, mtd);
include/linux/mtd/mtd.h:		req->addr -= mod;
include/linux/mtd/mtd.h:		req->len += mod;
include/linux/mtd/mtd.h:	mod = mtd_mod_by_eb(req->addr + req->len, mtd);
include/linux/mtd/mtd.h:		req->len += mtd->erasesize - mod;
include/linux/cpufreq.h:	/* cpufreq-stats */
include/linux/cpufreq.h: * frequency present in freq-table exposed by the driver. For these drivers if
include/linux/cpufreq.h:/* Works only on sorted freq-tables */
include/linux/cpufreq.h:/* Works only on sorted freq-tables */
include/linux/cpufreq.h:/* Works only on sorted freq-tables */
include/linux/blkdev.h:	return req->ioprio;
include/linux/ceph/osd_client.h:	BUG_ON(__whch >= __oreq->r_num_ops);				\
include/linux/ceph/osd_client.h:	&__oreq->r_ops[__whch].typ.fld;					\
include/linux/devfreq-event.h: * devfreq-event: a framework to provide raw data and events of devfreq devices
include/linux/devfreq-event.h: * struct devfreq_event_dev - the devfreq-event device
include/linux/devfreq-event.h: * @node	: Contain the devfreq-event device that have been registered.
include/linux/devfreq-event.h: * @dev		: the device registered by devfreq-event class. dev.parent is
include/linux/devfreq-event.h: *		  the device using devfreq-event.
include/linux/devfreq-event.h: * @lock	: a mutex to protect accessing devfreq-event.
include/linux/devfreq-event.h: * @desc	: the description for devfreq-event device.
include/linux/devfreq-event.h: * This structure contains devfreq-event device information.
include/linux/devfreq-event.h: * struct devfreq_event_data - the devfreq-event data
include/linux/devfreq-event.h: * @load_count	: load count of devfreq-event device for the given period.
include/linux/devfreq-event.h: * @total_count	: total count of devfreq-event device for the given period.
include/linux/devfreq-event.h: * This structure contains the data of devfreq-event device for polling period.
include/linux/devfreq-event.h: * struct devfreq_event_ops - the operations of devfreq-event device
include/linux/devfreq-event.h: * @enable	: Enable the devfreq-event device.
include/linux/devfreq-event.h: * @disable	: Disable the devfreq-event device.
include/linux/devfreq-event.h: * @reset	: Reset all setting of the devfreq-event device.
include/linux/devfreq-event.h: * @set_event	: Set the specific event type for the devfreq-event device.
include/linux/devfreq-event.h: * @get_event	: Get the result of the devfreq-event devie with specific
include/linux/devfreq-event.h: * This structure contains devfreq-event device operations which can be
include/linux/devfreq-event.h: * implemented by devfreq-event device drivers.
include/linux/devfreq-event.h: * struct devfreq_event_desc - the descriptor of devfreq-event device
include/linux/devfreq-event.h: * @name	: the name of devfreq-event device.
include/linux/devfreq-event.h: * @driver_data	: the private data for devfreq-event driver.
include/linux/devfreq-event.h: * @ops		: the operation to control devfreq-event device.
include/linux/devfreq-event.h: * Each devfreq-event device is described with a this structure.
include/linux/devfreq-event.h: * This structure contains the various data for devfreq-event device.
include/linux/sunrpc/xprt.h:	return test_bit(RPC_BC_PA_IN_USE, &req->rq_bc_pa_state);
include/net/request_sock.h:	req->rsk_listener = NULL;
include/net/request_sock.h:		req->rsk_listener = sk_listener;
include/net/request_sock.h:	req->rsk_ops = ops;
include/net/request_sock.h:	req->saved_syn = NULL;
include/net/request_sock.h:	req->num_timeout = 0;
include/net/request_sock.h:	req->num_retrans = 0;
include/net/request_sock.h:	req->sk = NULL;
include/net/request_sock.h:	refcount_set(&req->rsk_refcnt, 0);
include/net/request_sock.h:	req->rsk_ops->destructor(req);
include/net/request_sock.h:	if (req->rsk_listener)
include/net/request_sock.h:		sock_put(req->rsk_listener);
include/net/request_sock.h:	kfree(req->saved_syn);
include/net/request_sock.h:	kmem_cache_free(req->rsk_ops->slab, req);
include/net/request_sock.h:	WARN_ON_ONCE(refcount_read(&req->rsk_refcnt) != 0);
include/net/request_sock.h:	if (refcount_dec_and_test(&req->rsk_refcnt))
include/net/request_sock.h:		WRITE_ONCE(queue->rskq_accept_head, req->dl_next);
include/net/request_sock.h:	if (req->num_timeout == 0)
include/xen/interface/io/displif.h: * /local/domain/1/device/vdispl/0/0/req-ring-ref = "2832"
include/xen/interface/io/displif.h: * /local/domain/1/device/vdispl/0/0/req-event-channel = "15"
include/xen/interface/io/displif.h: * /local/domain/1/device/vdispl/0/1/req-ring-ref = "2833"
include/xen/interface/io/displif.h: * /local/domain/1/device/vdispl/0/1/req-event-channel = "17"
include/xen/interface/io/displif.h: * req-event-channel
include/xen/interface/io/displif.h: * req-ring-ref
include/xen/interface/io/displif.h:#define XENDISPL_FIELD_REQ_RING_REF	"req-ring-ref"
include/xen/interface/io/displif.h:#define XENDISPL_FIELD_REQ_CHANNEL	"req-event-channel"
include/xen/interface/io/displif.h: *   /local/domain/<dom-id>/device/vdispl/<dev-id>/0/req-ring-ref
include/xen/interface/io/displif.h: *   /local/domain/<dom-id>/device/vdispl/<dev-id>/0/req-ring-ref
include/xen/interface/io/displif.h: *   /local/domain/<dom-id>/device/vdispl/<dev-id>/0/req-ring-ref
include/xen/interface/io/displif.h: *   /local/domain/<dom-id>/device/vdispl/<dev-id>/0/req-ring-ref
include/xen/interface/io/displif.h: *   /local/domain/<dom-id>/device/vdispl/<dev-id>/0/req-ring-ref
include/scsi/scsi_request.h:	if (req->cmd != req->__cmd)
include/scsi/scsi_request.h:		kfree(req->cmd);
include/trace/events/rpcrdma.h:		const struct rpc_task *task = req->rl_slot.rq_task;
include/trace/events/rpcrdma.h:		const struct rpc_rqst *rqst = &req->rl_slot;
include/trace/events/rpcrdma.h:		const struct rpc_rqst *rqst = &req->rl_slot;
include/trace/events/rpcrdma.h:		__entry->hdrlen = req->rl_hdrbuf.len;
include/trace/events/rpcrdma.h:		const struct rpc_rqst *rqst = &req->rl_slot;
include/trace/events/rpcrdma.h:		const struct rpcrdma_sendctx *sc = req->rl_sendctx;
include/trace/events/rpcrdma.h:		__entry->num_sge = req->rl_wr.num_sge;
include/trace/events/rpcrdma.h:		__entry->signaled = req->rl_wr.send_flags & IB_SEND_SIGNALED;
include/trace/events/rpcrdma.h:		const struct rpc_task *task = req->rl_slot.rq_task;
include/trace/events/ib_mad.h:			__entry->mgmt_class = agent->reg_req->mgmt_class;
include/trace/events/ib_mad.h:				agent->reg_req->mgmt_class_version;
include/trace/events/tcp.h:		__entry->sport = ireq->ir_num;
include/trace/events/tcp.h:		__entry->dport = ntohs(ireq->ir_rmt_port);
include/trace/events/tcp.h:		*p32 = ireq->ir_loc_addr;
include/trace/events/tcp.h:		*p32 = ireq->ir_rmt_addr;
include/trace/events/tcp.h:		TP_STORE_ADDRS(__entry, ireq->ir_loc_addr, ireq->ir_rmt_addr,
include/trace/events/tcp.h:			      ireq->ir_v6_loc_addr, ireq->ir_v6_rmt_addr);
include/trace/events/devfreq.h:		__string(dev_name, dev_name(&devfreq->dev))
include/trace/events/devfreq.h:		__assign_str(dev_name, dev_name(&devfreq->dev));
include/trace/events/devfreq.h:		__entry->busy_time = devfreq->last_status.busy_time;
include/trace/events/devfreq.h:		__entry->total_time = devfreq->last_status.total_time;
include/trace/events/devfreq.h:		__string(dev_name, dev_name(&devfreq->dev))
include/trace/events/devfreq.h:		__entry->freq = devfreq->previous_freq;
include/trace/events/devfreq.h:		__entry->busy_time = devfreq->last_status.busy_time;
include/trace/events/devfreq.h:		__entry->total_time = devfreq->last_status.total_time;
include/trace/events/devfreq.h:		__entry->polling_ms = devfreq->profile->polling_ms;
include/trace/events/devfreq.h:		__assign_str(dev_name, dev_name(&devfreq->dev));
sound/pci/maestro3.c:		freq--;
sound/pci/mixart/mixart_hwdep.c:	audio_info_req->line_max_level = MIXART_FLOAT_P_22_0_TO_HEX;
sound/pci/mixart/mixart_hwdep.c:	audio_info_req->micro_max_level = MIXART_FLOAT_M_20_0_TO_HEX;
sound/pci/mixart/mixart_hwdep.c:	audio_info_req->cd_max_level = MIXART_FLOAT____0_0_TO_HEX;
sound/xen/xen_snd_front.c:	req->operation = operation;
sound/xen/xen_snd_front.c:	req->id = evtchnl->evt_next_id++;
sound/xen/xen_snd_front.c:	evtchnl->evt_id = req->id;
sound/xen/xen_snd_front.c:	req->op.hw_param = *hw_param_req;
sound/xen/xen_snd_front.c:	req->op.open.pcm_format = format;
sound/xen/xen_snd_front.c:	req->op.open.pcm_channels = channels;
sound/xen/xen_snd_front.c:	req->op.open.pcm_rate = rate;
sound/xen/xen_snd_front.c:	req->op.open.buffer_sz = buffer_sz;
sound/xen/xen_snd_front.c:	req->op.open.period_sz = period_sz;
sound/xen/xen_snd_front.c:	req->op.open.gref_directory =
sound/xen/xen_snd_front.c:	req->op.rw.length = count;
sound/xen/xen_snd_front.c:	req->op.rw.offset = pos;
sound/xen/xen_snd_front.c:	req->op.rw.length = count;
sound/xen/xen_snd_front.c:	req->op.rw.offset = pos;
sound/xen/xen_snd_front.c:	req->op.trigger.type = type;
sound/soc/codecs/cs42l52.c:				"cirrus,chgfreq-divisor", &val32) >= 0)
sound/soc/codecs/cs43130.c:	cs43130->clk_req--;
sound/soc/codecs/cs43130.c:	cs43130->clk_req--;
sound/soc/codecs/cs42l56.c:	if (of_property_read_u32(np, "cirrus,chgfreq-divisor", &val32) >= 0)
sound/soc/tegra/tegra20_spdif.c:	spdif->playback_dma_data.slave_id = dmareq->start;
sound/usb/mixer_scarlett_gen2.c:	req->cmd = cpu_to_le32(cmd);
sound/usb/mixer_scarlett_gen2.c:	req->size = cpu_to_le16(req_size);
sound/usb/mixer_scarlett_gen2.c:	req->seq = cpu_to_le16(seq);
sound/usb/mixer_scarlett_gen2.c:	req->error = 0;
sound/usb/mixer_scarlett_gen2.c:	req->pad = 0;
sound/usb/mixer_scarlett_gen2.c:		memcpy(req->data, req_data, req_size);
sound/usb/mixer_scarlett_gen2.c:	if (resp->cmd != req->cmd ||
sound/usb/mixer_scarlett_gen2.c:	    resp->seq != req->seq ||
sound/usb/mixer_scarlett_gen2.c:			le32_to_cpu(req->cmd), le32_to_cpu(resp->cmd),
sound/usb/mixer_scarlett_gen2.c:			le16_to_cpu(req->seq), le16_to_cpu(resp->seq),
tags:APQ8096SG	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	APQ8096SG = 0x138ul,$/;"	e	enum:_msm_id	file:
tags:APQ8096V3	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	APQ8096V3 = 0x123ul,$/;"	e	enum:_msm_id	file:
tags:ARM	drivers/cpufreq/imx-cpufreq-dt.c	/^	ARM,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:CLK_HW_DIV	drivers/cpufreq/qcom-cpufreq-hw.c	22;"	d	file:
tags:CORE	drivers/cpufreq/imx-cpufreq-dt.c	/^	CORE,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:FIRC	drivers/cpufreq/imx-cpufreq-dt.c	/^	FIRC,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:HSRUN_CORE	drivers/cpufreq/imx-cpufreq-dt.c	/^	HSRUN_CORE,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:HSRUN_SCS_SEL	drivers/cpufreq/imx-cpufreq-dt.c	/^	HSRUN_SCS_SEL,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:IMX7ULP_CPUFREQ_CLKS	drivers/cpufreq/imx-cpufreq-dt.c	/^enum IMX7ULP_CPUFREQ_CLKS {$/;"	g	file:
tags:IMX7ULP_MAX_RUN_FREQ	drivers/cpufreq/imx-cpufreq-dt.c	30;"	d	file:
tags:IMX8MN_OCOTP_CFG3_SPEED_GRADE_MASK	drivers/cpufreq/imx-cpufreq-dt.c	24;"	d	file:
tags:IMX8MP_OCOTP_CFG3_MKT_SEGMENT_MASK	drivers/cpufreq/imx-cpufreq-dt.c	28;"	d	file:
tags:IMX8MP_OCOTP_CFG3_MKT_SEGMENT_SHIFT	drivers/cpufreq/imx-cpufreq-dt.c	27;"	d	file:
tags:LUT_CORE_COUNT	drivers/cpufreq/qcom-cpufreq-hw.c	20;"	d	file:
tags:LUT_L_VAL	drivers/cpufreq/qcom-cpufreq-hw.c	19;"	d	file:
tags:LUT_MAX_ENTRIES	drivers/cpufreq/qcom-cpufreq-hw.c	17;"	d	file:
tags:LUT_SRC	drivers/cpufreq/qcom-cpufreq-hw.c	18;"	d	file:
tags:LUT_TURBO_IND	drivers/cpufreq/qcom-cpufreq-hw.c	23;"	d	file:
tags:LUT_VOLT	drivers/cpufreq/qcom-cpufreq-hw.c	21;"	d	file:
tags:MAX_BANKS	include/linux/soc/samsung/s3c-cpufreq-core.h	16;"	d
tags:MAX_NAME_LEN	drivers/cpufreq/sun50i-cpufreq-nvmem.c	20;"	d	file:
tags:MSM8996SG	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	MSM8996SG = 0x131ul,$/;"	e	enum:_msm_id	file:
tags:MSM8996V3	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	MSM8996V3 = 0xF6ul,$/;"	e	enum:_msm_id	file:
tags:MSM8996_SG	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	MSM8996_SG,$/;"	e	enum:_msm8996_version	file:
tags:MSM8996_V3	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	MSM8996_V3,$/;"	e	enum:_msm8996_version	file:
tags:MSM_ID_SMEM	drivers/cpufreq/qcom-cpufreq-nvmem.c	32;"	d	file:
tags:NFORCE2_BOOTFSB	drivers/cpufreq/cpufreq-nforce2.c	21;"	d	file:
tags:NFORCE2_MIN_FSB	drivers/cpufreq/cpufreq-nforce2.c	27;"	d	file:
tags:NFORCE2_PLL	drivers/cpufreq/cpufreq-nforce2.c	25;"	d	file:
tags:NFORCE2_PLLADR	drivers/cpufreq/cpufreq-nforce2.c	24;"	d	file:
tags:NFORCE2_PLLENABLE	drivers/cpufreq/cpufreq-nforce2.c	22;"	d	file:
tags:NFORCE2_PLLREG	drivers/cpufreq/cpufreq-nforce2.c	23;"	d	file:
tags:NFORCE2_SAFE_DISTANCE	drivers/cpufreq/cpufreq-nforce2.c	28;"	d	file:
tags:NFORCE2_XTAL	drivers/cpufreq/cpufreq-nforce2.c	20;"	d	file:
tags:NUM_OF_MSM8996_VERSIONS	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	NUM_OF_MSM8996_VERSIONS,$/;"	e	enum:_msm8996_version	file:
tags:NVMEM_MASK	drivers/cpufreq/sun50i-cpufreq-nvmem.c	22;"	d	file:
tags:NVMEM_SHIFT	drivers/cpufreq/sun50i-cpufreq-nvmem.c	23;"	d	file:
tags:OCOTP_CFG3_MKT_SEGMENT_MASK	drivers/cpufreq/imx-cpufreq-dt.c	26;"	d	file:
tags:OCOTP_CFG3_MKT_SEGMENT_SHIFT	drivers/cpufreq/imx-cpufreq-dt.c	25;"	d	file:
tags:OCOTP_CFG3_SPEED_GRADE_MASK	drivers/cpufreq/imx-cpufreq-dt.c	23;"	d	file:
tags:OCOTP_CFG3_SPEED_GRADE_SHIFT	drivers/cpufreq/imx-cpufreq-dt.c	22;"	d	file:
tags:S3C2412_MAX_IO	include/linux/soc/samsung/s3c-cpufreq-core.h	17;"	d
tags:SCS_SEL	drivers/cpufreq/imx-cpufreq-dt.c	/^	SCS_SEL,$/;"	e	enum:IMX7ULP_CPUFREQ_CLKS	file:
tags:__CPUFREQ_DT_H__	drivers/cpufreq/cpufreq-dt.h	8;"	d
tags:__LINUX_DEVFREQ_EVENT_H__	include/linux/devfreq-event.h	10;"	d
tags:__LINUX_SOC_SAMSUNG_S3C_CPUFREQ_CORE_H	include/linux/soc/samsung/s3c-cpufreq-core.h	10;"	d
tags:_msm8996_version	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^enum _msm8996_version {$/;"	g	file:
tags:_msm_id	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^enum _msm_id {$/;"	g	file:
tags:bank	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	union s3c_iobank	bank[MAX_BANKS];$/;"	m	struct:s3c_iotimings	typeref:union:s3c_iotimings::s3c_iobank	access:public
tags:bankcon	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned long	bankcon;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:base	drivers/cpufreq/qcom-cpufreq-hw.c	/^	void __iomem *base;$/;"	m	struct:qcom_cpufreq_data	file:	access:public
tags:blacklist	drivers/cpufreq/cpufreq-dt-platdev.c	/^static const struct of_device_id blacklist[] __initconst = {$/;"	v	typeref:struct:of_device_id
tags:board	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^DEFINE_SHOW_ATTRIBUTE(board);$/;"	v
tags:board	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_cpufreq_board *board;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_cpufreq_board	access:public
tags:board_show	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static int board_show(struct seq_file *seq, void *p)$/;"	f	signature:(struct seq_file *seq, void *p)
tags:calc_divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_divs)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:calc_freqtable	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_freqtable)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:calc_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:cpu0_node_has_opp_v2_prop	drivers/cpufreq/cpufreq-dt-platdev.c	/^static bool __init cpu0_node_has_opp_v2_prop(void)$/;"	f	signature:(void)
tags:cpu_dev	drivers/cpufreq/cpufreq-dt.c	/^	struct device *cpu_dev;$/;"	m	struct:private_data	typeref:struct:private_data::device	file:	access:public
tags:cpu_dev	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct device *cpu_dev;$/;"	v	typeref:struct:device
tags:cpu_hw_rate	drivers/cpufreq/qcom-cpufreq-hw.c	/^static unsigned long cpu_hw_rate, xo_rate;$/;"	v
tags:cpufreq-dt-platdev.c	drivers/cpufreq/cpufreq-dt-platdev.c	1;"	F
tags:cpufreq-dt.c	drivers/cpufreq/cpufreq-dt.c	1;"	F
tags:cpufreq-dt.h	drivers/cpufreq/cpufreq-dt.h	1;"	F
tags:cpufreq-nforce2.c	drivers/cpufreq/cpufreq-nforce2.c	1;"	F
tags:cpufreq_dt_attr	drivers/cpufreq/cpufreq-dt.c	/^static struct freq_attr *cpufreq_dt_attr[] = {$/;"	v	typeref:struct:freq_attr
tags:cpufreq_dt_find_data	drivers/cpufreq/cpufreq-dt.c	/^static struct private_data *cpufreq_dt_find_data(int cpu)$/;"	f	signature:(int cpu)
tags:cpufreq_dt_pdev	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct platform_device *cpufreq_dt_pdev;$/;"	v	typeref:struct:platform_device
tags:cpufreq_dt_pdev	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static struct platform_device *cpufreq_dt_pdev, *cpufreq_pdev;$/;"	v	typeref:struct:platform_device
tags:cpufreq_dt_pdev	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static struct platform_device *cpufreq_dt_pdev, *sun50i_cpufreq_pdev;$/;"	v	typeref:struct:platform_device
tags:cpufreq_dt_platdev_init	drivers/cpufreq/cpufreq-dt-platdev.c	/^core_initcall(cpufreq_dt_platdev_init);$/;"	v
tags:cpufreq_dt_platdev_init	drivers/cpufreq/cpufreq-dt-platdev.c	/^static int __init cpufreq_dt_platdev_init(void)$/;"	f	signature:(void)
tags:cpufreq_dt_platform_data	drivers/cpufreq/cpufreq-dt.h	/^struct cpufreq_dt_platform_data {$/;"	s
tags:cpufreq_dt_platform_data::get_intermediate	drivers/cpufreq/cpufreq-dt.h	/^	unsigned int	(*get_intermediate)(struct cpufreq_policy *policy,$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:cpufreq_dt_platform_data::have_governor_per_policy	drivers/cpufreq/cpufreq-dt.h	/^	bool have_governor_per_policy;$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:cpufreq_dt_platform_data::resume	drivers/cpufreq/cpufreq-dt.h	/^	int (*resume)(struct cpufreq_policy *policy);$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:cpufreq_dt_platform_data::suspend	drivers/cpufreq/cpufreq-dt.h	/^	int (*suspend)(struct cpufreq_policy *policy);$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:cpufreq_dt_platform_data::target_intermediate	drivers/cpufreq/cpufreq-dt.h	/^	int		(*target_intermediate)(struct cpufreq_policy *policy,$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:cpufreq_exit	drivers/cpufreq/cpufreq-dt.c	/^static int cpufreq_exit(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:cpufreq_init	drivers/cpufreq/cpufreq-dt.c	/^static int cpufreq_init(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:cpufreq_offline	drivers/cpufreq/cpufreq-dt.c	/^static int cpufreq_offline(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:cpufreq_online	drivers/cpufreq/cpufreq-dt.c	/^static int cpufreq_online(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:cpufreq_opp_table	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct opp_table *cpufreq_opp_table;$/;"	v	typeref:struct:opp_table
tags:cpufreq_pdev	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static struct platform_device *cpufreq_dt_pdev, *cpufreq_pdev;$/;"	v	typeref:struct:
tags:cpufreq_qcom_hw_driver	drivers/cpufreq/qcom-cpufreq-hw.c	/^static struct cpufreq_driver cpufreq_qcom_hw_driver = {$/;"	v	typeref:struct:cpufreq_driver
tags:cpus	drivers/cpufreq/cpufreq-dt.c	/^	cpumask_var_t cpus;$/;"	m	struct:private_data	file:	access:public
tags:data	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	const struct qcom_cpufreq_match_data *data;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::qcom_cpufreq_match_data	file:	access:public
tags:data_index	drivers/macintosh/via-macii.c	/^static int data_index;      \/* index of the next byte to send from req->data *\/$/;"	v
tags:dbgfs_file_board	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static struct dentry *dbgfs_file_board;$/;"	v	typeref:struct:dentry
tags:dbgfs_file_info	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static struct dentry *dbgfs_file_info;$/;"	v	typeref:struct:dentry
tags:dbgfs_file_io	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static struct dentry *dbgfs_file_io;$/;"	v	typeref:struct:dentry
tags:dbgfs_root	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static struct dentry *dbgfs_root;$/;"	v	typeref:struct:dentry
tags:debug_io_show	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*debug_io_show)(struct seq_file *seq,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:desc	include/linux/devfreq-event.h	/^	const struct devfreq_event_desc *desc;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::devfreq_event_desc	access:public
tags:dev	include/linux/devfreq-event.h	/^	struct device dev;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::device	access:public
tags:dev_attr_enable_count	drivers/devfreq/devfreq-event.c	/^static DEVICE_ATTR_RO(enable_count);$/;"	r
tags:dev_attr_name	drivers/devfreq/devfreq-event.c	/^static DEVICE_ATTR_RO(name);$/;"	r
tags:devfreq-event.c	drivers/devfreq/devfreq-event.c	1;"	F
tags:devfreq-event.h	include/linux/devfreq-event.h	1;"	F
tags:devfreq_event	drivers/devfreq/devfreq-event.c	/^ATTRIBUTE_GROUPS(devfreq_event);$/;"	v
tags:devfreq_event_add_edev	drivers/devfreq/devfreq-event.c	/^struct devfreq_event_dev *devfreq_event_add_edev(struct device *dev,$/;"	f	signature:(struct device *dev, struct devfreq_event_desc *desc)
tags:devfreq_event_add_edev	include/linux/devfreq-event.h	/^extern struct devfreq_event_dev *devfreq_event_add_edev(struct device *dev,$/;"	p	signature:(struct device *dev, struct devfreq_event_desc *desc)
tags:devfreq_event_add_edev	include/linux/devfreq-event.h	/^static inline struct devfreq_event_dev *devfreq_event_add_edev(struct device *dev,$/;"	f	signature:(struct device *dev, struct devfreq_event_desc *desc)
tags:devfreq_event_attrs	drivers/devfreq/devfreq-event.c	/^static struct attribute *devfreq_event_attrs[] = {$/;"	v	typeref:struct:attribute
tags:devfreq_event_class	drivers/devfreq/devfreq-event.c	/^static struct class *devfreq_event_class;$/;"	v	typeref:struct:class
tags:devfreq_event_data	include/linux/devfreq-event.h	/^struct devfreq_event_data {$/;"	s
tags:devfreq_event_data::load_count	include/linux/devfreq-event.h	/^	unsigned long load_count;$/;"	m	struct:devfreq_event_data	access:public
tags:devfreq_event_data::total_count	include/linux/devfreq-event.h	/^	unsigned long total_count;$/;"	m	struct:devfreq_event_data	access:public
tags:devfreq_event_desc	include/linux/devfreq-event.h	/^struct devfreq_event_desc {$/;"	s
tags:devfreq_event_desc::driver_data	include/linux/devfreq-event.h	/^	void *driver_data;$/;"	m	struct:devfreq_event_desc	access:public
tags:devfreq_event_desc::event_type	include/linux/devfreq-event.h	/^	u32 event_type;$/;"	m	struct:devfreq_event_desc	access:public
tags:devfreq_event_desc::name	include/linux/devfreq-event.h	/^	const char *name;$/;"	m	struct:devfreq_event_desc	access:public
tags:devfreq_event_desc::ops	include/linux/devfreq-event.h	/^	const struct devfreq_event_ops *ops;$/;"	m	struct:devfreq_event_desc	typeref:struct:devfreq_event_desc::devfreq_event_ops	access:public
tags:devfreq_event_dev	include/linux/devfreq-event.h	/^struct devfreq_event_dev {$/;"	s
tags:devfreq_event_dev::desc	include/linux/devfreq-event.h	/^	const struct devfreq_event_desc *desc;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::devfreq_event_desc	access:public
tags:devfreq_event_dev::dev	include/linux/devfreq-event.h	/^	struct device dev;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::device	access:public
tags:devfreq_event_dev::enable_count	include/linux/devfreq-event.h	/^	u32 enable_count;$/;"	m	struct:devfreq_event_dev	access:public
tags:devfreq_event_dev::lock	include/linux/devfreq-event.h	/^	struct mutex lock;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::mutex	access:public
tags:devfreq_event_dev::node	include/linux/devfreq-event.h	/^	struct list_head node;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::list_head	access:public
tags:devfreq_event_disable_edev	drivers/devfreq/devfreq-event.c	/^int devfreq_event_disable_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_disable_edev	include/linux/devfreq-event.h	/^extern int devfreq_event_disable_edev(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_disable_edev	include/linux/devfreq-event.h	/^static inline int devfreq_event_disable_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_enable_edev	drivers/devfreq/devfreq-event.c	/^int devfreq_event_enable_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_enable_edev	include/linux/devfreq-event.h	/^extern int devfreq_event_enable_edev(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_enable_edev	include/linux/devfreq-event.h	/^static inline int devfreq_event_enable_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_get_drvdata	include/linux/devfreq-event.h	/^static inline void *devfreq_event_get_drvdata(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_get_edev_by_phandle	drivers/devfreq/devfreq-event.c	/^struct devfreq_event_dev *devfreq_event_get_edev_by_phandle(struct device *dev,$/;"	f	signature:(struct device *dev, const char *phandle_name, int index)
tags:devfreq_event_get_edev_by_phandle	include/linux/devfreq-event.h	/^extern struct devfreq_event_dev *devfreq_event_get_edev_by_phandle($/;"	p	signature:( struct device *dev, const char *phandle_name, int index)
tags:devfreq_event_get_edev_by_phandle	include/linux/devfreq-event.h	/^static inline struct devfreq_event_dev *devfreq_event_get_edev_by_phandle($/;"	f	signature:( struct device *dev, const char *phandle_name, int index)
tags:devfreq_event_get_edev_count	drivers/devfreq/devfreq-event.c	/^int devfreq_event_get_edev_count(struct device *dev, const char *phandle_name)$/;"	f	signature:(struct device *dev, const char *phandle_name)
tags:devfreq_event_get_edev_count	include/linux/devfreq-event.h	/^extern int devfreq_event_get_edev_count(struct device *dev,$/;"	p	signature:(struct device *dev, const char *phandle_name)
tags:devfreq_event_get_edev_count	include/linux/devfreq-event.h	/^static inline int devfreq_event_get_edev_count(struct device *dev,$/;"	f	signature:(struct device *dev, const char *phandle_name)
tags:devfreq_event_get_event	drivers/devfreq/devfreq-event.c	/^int devfreq_event_get_event(struct devfreq_event_dev *edev,$/;"	f	signature:(struct devfreq_event_dev *edev, struct devfreq_event_data *edata)
tags:devfreq_event_get_event	include/linux/devfreq-event.h	/^extern int devfreq_event_get_event(struct devfreq_event_dev *edev,$/;"	p	signature:(struct devfreq_event_dev *edev, struct devfreq_event_data *edata)
tags:devfreq_event_get_event	include/linux/devfreq-event.h	/^static inline int devfreq_event_get_event(struct devfreq_event_dev *edev,$/;"	f	signature:(struct devfreq_event_dev *edev, struct devfreq_event_data *edata)
tags:devfreq_event_init	drivers/devfreq/devfreq-event.c	/^static int __init devfreq_event_init(void)$/;"	f	signature:(void)
tags:devfreq_event_init	drivers/devfreq/devfreq-event.c	/^subsys_initcall(devfreq_event_init);$/;"	v
tags:devfreq_event_is_enabled	drivers/devfreq/devfreq-event.c	/^bool devfreq_event_is_enabled(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_is_enabled	include/linux/devfreq-event.h	/^extern bool devfreq_event_is_enabled(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_is_enabled	include/linux/devfreq-event.h	/^static inline bool devfreq_event_is_enabled(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_list	drivers/devfreq/devfreq-event.c	/^static LIST_HEAD(devfreq_event_list);$/;"	v
tags:devfreq_event_list_lock	drivers/devfreq/devfreq-event.c	/^static DEFINE_MUTEX(devfreq_event_list_lock);$/;"	v
tags:devfreq_event_ops	include/linux/devfreq-event.h	/^struct devfreq_event_ops {$/;"	s
tags:devfreq_event_ops::disable	include/linux/devfreq-event.h	/^	int (*disable)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:devfreq_event_ops::enable	include/linux/devfreq-event.h	/^	int (*enable)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:devfreq_event_ops::get_event	include/linux/devfreq-event.h	/^	int (*get_event)(struct devfreq_event_dev *edev,$/;"	m	struct:devfreq_event_ops	access:public
tags:devfreq_event_ops::reset	include/linux/devfreq-event.h	/^	int (*reset)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:devfreq_event_ops::set_event	include/linux/devfreq-event.h	/^	int (*set_event)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:devfreq_event_release_edev	drivers/devfreq/devfreq-event.c	/^static void devfreq_event_release_edev(struct device *dev)$/;"	f	signature:(struct device *dev)
tags:devfreq_event_remove_edev	drivers/devfreq/devfreq-event.c	/^int devfreq_event_remove_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_remove_edev	include/linux/devfreq-event.h	/^extern int devfreq_event_remove_edev(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_remove_edev	include/linux/devfreq-event.h	/^static inline int devfreq_event_remove_edev(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_reset_event	drivers/devfreq/devfreq-event.c	/^int devfreq_event_reset_event(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_reset_event	include/linux/devfreq-event.h	/^extern int devfreq_event_reset_event(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_reset_event	include/linux/devfreq-event.h	/^static inline int devfreq_event_reset_event(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_set_event	drivers/devfreq/devfreq-event.c	/^int devfreq_event_set_event(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_set_event	include/linux/devfreq-event.h	/^extern int devfreq_event_set_event(struct devfreq_event_dev *edev);$/;"	p	signature:(struct devfreq_event_dev *edev)
tags:devfreq_event_set_event	include/linux/devfreq-event.h	/^static inline int devfreq_event_set_event(struct devfreq_event_dev *edev)$/;"	f	signature:(struct devfreq_event_dev *edev)
tags:devm_devfreq_event_add_edev	drivers/devfreq/devfreq-event.c	/^struct devfreq_event_dev *devm_devfreq_event_add_edev(struct device *dev,$/;"	f	signature:(struct device *dev, struct devfreq_event_desc *desc)
tags:devm_devfreq_event_add_edev	include/linux/devfreq-event.h	/^extern struct devfreq_event_dev *devm_devfreq_event_add_edev(struct device *dev,$/;"	p	signature:(struct device *dev, struct devfreq_event_desc *desc)
tags:devm_devfreq_event_add_edev	include/linux/devfreq-event.h	/^static inline struct devfreq_event_dev *devm_devfreq_event_add_edev($/;"	f	signature:( struct device *dev, struct devfreq_event_desc *desc)
tags:devm_devfreq_event_match	drivers/devfreq/devfreq-event.c	/^static int devm_devfreq_event_match(struct device *dev, void *res, void *data)$/;"	f	signature:(struct device *dev, void *res, void *data)
tags:devm_devfreq_event_release	drivers/devfreq/devfreq-event.c	/^static void devm_devfreq_event_release(struct device *dev, void *res)$/;"	f	signature:(struct device *dev, void *res)
tags:devm_devfreq_event_remove_edev	drivers/devfreq/devfreq-event.c	/^void devm_devfreq_event_remove_edev(struct device *dev,$/;"	f	signature:(struct device *dev, struct devfreq_event_dev *edev)
tags:devm_devfreq_event_remove_edev	include/linux/devfreq-event.h	/^extern void devm_devfreq_event_remove_edev(struct device *dev,$/;"	p	signature:(struct device *dev, struct devfreq_event_dev *edev)
tags:devm_devfreq_event_remove_edev	include/linux/devfreq-event.h	/^static inline void devm_devfreq_event_remove_edev(struct device *dev,$/;"	f	signature:(struct device *dev, struct devfreq_event_dev *edev)
tags:disable	include/linux/devfreq-event.h	/^	int (*disable)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_clkdivs	divs;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_clkdivs	access:public
tags:driver_data	include/linux/devfreq-event.h	/^	void *driver_data;$/;"	m	struct:devfreq_event_desc	access:public
tags:dt_cpufreq_driver	drivers/cpufreq/cpufreq-dt.c	/^static struct cpufreq_driver dt_cpufreq_driver = {$/;"	v	typeref:struct:cpufreq_driver
tags:dt_cpufreq_early_init	drivers/cpufreq/cpufreq-dt.c	/^static int dt_cpufreq_early_init(struct device *dev, int cpu)$/;"	f	signature:(struct device *dev, int cpu)
tags:dt_cpufreq_platdrv	drivers/cpufreq/cpufreq-dt.c	/^module_platform_driver(dt_cpufreq_platdrv);$/;"	v
tags:dt_cpufreq_platdrv	drivers/cpufreq/cpufreq-dt.c	/^static struct platform_driver dt_cpufreq_platdrv = {$/;"	v	typeref:struct:platform_driver
tags:dt_cpufreq_probe	drivers/cpufreq/cpufreq-dt.c	/^static int dt_cpufreq_probe(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:dt_cpufreq_release	drivers/cpufreq/cpufreq-dt.c	/^static void dt_cpufreq_release(void)$/;"	f	signature:(void)
tags:dt_cpufreq_remove	drivers/cpufreq/cpufreq-dt.c	/^static int dt_cpufreq_remove(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:enable	include/linux/devfreq-event.h	/^	int (*enable)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:enable_count	drivers/devfreq/devfreq-event.c	/^static DEVICE_ATTR_RO(enable_count);$/;"	v
tags:enable_count	include/linux/devfreq-event.h	/^	u32 enable_count;$/;"	m	struct:devfreq_event_dev	access:public
tags:enable_count_show	drivers/devfreq/devfreq-event.c	/^static ssize_t enable_count_show(struct device *dev,$/;"	f	signature:(struct device *dev, struct device_attribute *attr, char *buf)
tags:epss_soc_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^static const struct qcom_cpufreq_soc_data epss_soc_data = {$/;"	v	typeref:struct:qcom_cpufreq_soc_data
tags:event_type	include/linux/devfreq-event.h	/^	u32 event_type;$/;"	m	struct:devfreq_event_desc	access:public
tags:fid	drivers/cpufreq/cpufreq-nforce2.c	/^static int fid;$/;"	v
tags:find_supply_name	drivers/cpufreq/cpufreq-dt.c	/^static const char *find_supply_name(struct device *dev)$/;"	f	signature:(struct device *dev)
tags:freq	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		freq;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_freq	access:public
tags:freq_table	drivers/cpufreq/cpufreq-dt.c	/^	struct cpufreq_frequency_table *freq_table;$/;"	m	struct:private_data	typeref:struct:private_data::cpufreq_frequency_table	file:	access:public
tags:genpd_names	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	const char **genpd_names;$/;"	m	struct:qcom_cpufreq_match_data	file:	access:public
tags:genpd_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **genpd_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:get_event	include/linux/devfreq-event.h	/^	int (*get_event)(struct devfreq_event_dev *edev,$/;"	m	struct:devfreq_event_ops	access:public
tags:get_intermediate	drivers/cpufreq/cpufreq-dt.h	/^	unsigned int	(*get_intermediate)(struct cpufreq_policy *policy,$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:get_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*get_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:get_krait_bin_format_a	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static void get_krait_bin_format_a(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, int *speed, int *pvs, int *pvs_ver, struct nvmem_cell *pvs_nvmem, u8 *buf)
tags:get_krait_bin_format_b	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static void get_krait_bin_format_b(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, int *speed, int *pvs, int *pvs_ver, struct nvmem_cell *pvs_nvmem, u8 *buf)
tags:get_version	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	int (*get_version)(struct device *cpu_dev,$/;"	m	struct:qcom_cpufreq_match_data	file:	access:public
tags:have_governor_per_policy	drivers/cpufreq/cpufreq-dt.h	/^	bool have_governor_per_policy;$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:have_static_opps	drivers/cpufreq/cpufreq-dt.c	/^	bool have_static_opps;$/;"	m	struct:private_data	file:	access:public
tags:hw_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **hw_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:icc_scaling_enabled	drivers/cpufreq/qcom-cpufreq-hw.c	/^static bool icc_scaling_enabled;$/;"	v
tags:idcy	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	idcy;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:imx-cpufreq-dt.c	drivers/cpufreq/imx-cpufreq-dt.c	1;"	F
tags:imx7ulp_clks	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct clk_bulk_data imx7ulp_clks[] = {$/;"	v	typeref:struct:clk_bulk_data
tags:imx7ulp_data	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct cpufreq_dt_platform_data imx7ulp_data = {$/;"	v	typeref:struct:cpufreq_dt_platform_data
tags:imx7ulp_get_intermediate	drivers/cpufreq/imx-cpufreq-dt.c	/^static unsigned int imx7ulp_get_intermediate(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int index)
tags:imx7ulp_target_intermediate	drivers/cpufreq/imx-cpufreq-dt.c	/^static int imx7ulp_target_intermediate(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int index)
tags:imx_cpufreq_dt_driver	drivers/cpufreq/imx-cpufreq-dt.c	/^module_platform_driver(imx_cpufreq_dt_driver);$/;"	v
tags:imx_cpufreq_dt_driver	drivers/cpufreq/imx-cpufreq-dt.c	/^static struct platform_driver imx_cpufreq_dt_driver = {$/;"	v	typeref:struct:platform_driver
tags:imx_cpufreq_dt_probe	drivers/cpufreq/imx-cpufreq-dt.c	/^static int imx_cpufreq_dt_probe(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:imx_cpufreq_dt_remove	drivers/cpufreq/imx-cpufreq-dt.c	/^static int imx_cpufreq_dt_remove(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:info	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^DEFINE_SHOW_ATTRIBUTE(info);$/;"	v
tags:info	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_cpufreq_info *info;	\/* for core, not drivers *\/$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_cpufreq_info	access:public
tags:info_show	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static int info_show(struct seq_file *seq, void *p)$/;"	f	signature:(struct seq_file *seq, void *p)
tags:io	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^DEFINE_SHOW_ATTRIBUTE(io);$/;"	v
tags:io_2410	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c2410_iobank_timing	*io_2410;$/;"	m	union:s3c_iobank	typeref:struct:s3c_iobank::s3c2410_iobank_timing	access:public
tags:io_2412	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c2412_iobank_timing	*io_2412;$/;"	m	union:s3c_iobank	typeref:struct:s3c_iobank::s3c2412_iobank_timing	access:public
tags:io_show	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static int io_show(struct seq_file *seq, void *p)$/;"	f	signature:(struct seq_file *seq, void *p)
tags:latency	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		latency;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:load_count	include/linux/devfreq-event.h	/^	unsigned long load_count;$/;"	m	struct:devfreq_event_data	access:public
tags:lock	include/linux/devfreq-event.h	/^	struct mutex lock;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::mutex	access:public
tags:lock_pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	lock_pll:1;$/;"	m	struct:s3c_cpufreq_config	access:public
tags:locktime_bits	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char		locktime_bits;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:locktime_m	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		locktime_m;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:locktime_u	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		locktime_u;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:lut_row_size	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u8 lut_row_size;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:match_data_krait	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static const struct qcom_cpufreq_match_data match_data_krait = {$/;"	v	typeref:struct:qcom_cpufreq_match_data
tags:match_data_kryo	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static const struct qcom_cpufreq_match_data match_data_kryo = {$/;"	v	typeref:struct:qcom_cpufreq_match_data
tags:match_data_qcs404	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static const struct qcom_cpufreq_match_data match_data_qcs404 = {$/;"	v	typeref:struct:qcom_cpufreq_match_data
tags:max	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		max;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_freq	access:public
tags:max	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		max;$/;"	m	struct:s3c_cpufreq_info	typeref:struct:s3c_cpufreq_info::s3c_freq	access:public
tags:max_fsb	drivers/cpufreq/cpufreq-nforce2.c	/^static int max_fsb;$/;"	v
tags:min_fsb	drivers/cpufreq/cpufreq-nforce2.c	/^static int min_fsb;$/;"	v
tags:mpll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct clk		*mpll;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::clk	access:public
tags:name	drivers/devfreq/devfreq-event.c	/^static DEVICE_ATTR_RO(name);$/;"	v
tags:name	include/linux/devfreq-event.h	/^	const char *name;$/;"	m	struct:devfreq_event_desc	access:public
tags:name	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	const char		*name;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:name_show	drivers/devfreq/devfreq-event.c	/^static ssize_t name_show(struct device *dev, struct device_attribute *attr,$/;"	f	signature:(struct device *dev, struct device_attribute *attr, char *buf)
tags:names_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **names_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:need_pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		need_pll:1;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:nforce2_calc_fsb	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_calc_fsb(int pll)$/;"	f	signature:(int pll)
tags:nforce2_calc_pll	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_calc_pll(unsigned int fsb)$/;"	f	signature:(unsigned int fsb)
tags:nforce2_cpu_exit	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_cpu_exit(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:nforce2_cpu_init	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_cpu_init(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:nforce2_detect_chipset	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_detect_chipset(void)$/;"	f	signature:(void)
tags:nforce2_dev	drivers/cpufreq/cpufreq-nforce2.c	/^static struct pci_dev *nforce2_dev;$/;"	v	typeref:struct:pci_dev
tags:nforce2_driver	drivers/cpufreq/cpufreq-nforce2.c	/^static struct cpufreq_driver nforce2_driver = {$/;"	v	typeref:struct:cpufreq_driver
tags:nforce2_exit	drivers/cpufreq/cpufreq-nforce2.c	/^module_exit(nforce2_exit);$/;"	v
tags:nforce2_exit	drivers/cpufreq/cpufreq-nforce2.c	/^static void __exit nforce2_exit(void)$/;"	f	signature:(void)
tags:nforce2_fsb_read	drivers/cpufreq/cpufreq-nforce2.c	/^static unsigned int nforce2_fsb_read(int bootfsb)$/;"	f	signature:(int bootfsb)
tags:nforce2_get	drivers/cpufreq/cpufreq-nforce2.c	/^static unsigned int nforce2_get(unsigned int cpu)$/;"	f	signature:(unsigned int cpu)
tags:nforce2_ids	drivers/cpufreq/cpufreq-nforce2.c	/^static const struct pci_device_id nforce2_ids[] = {$/;"	v	typeref:struct:pci_device_id
tags:nforce2_init	drivers/cpufreq/cpufreq-nforce2.c	/^module_init(nforce2_init);$/;"	v
tags:nforce2_init	drivers/cpufreq/cpufreq-nforce2.c	/^static int __init nforce2_init(void)$/;"	f	signature:(void)
tags:nforce2_set_fsb	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_set_fsb(unsigned int fsb)$/;"	f	signature:(unsigned int fsb)
tags:nforce2_target	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_target(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int target_freq, unsigned int relation)
tags:nforce2_verify	drivers/cpufreq/cpufreq-nforce2.c	/^static int nforce2_verify(struct cpufreq_policy_data *policy)$/;"	f	signature:(struct cpufreq_policy_data *policy)
tags:nforce2_write_pll	drivers/cpufreq/cpufreq-nforce2.c	/^static void nforce2_write_pll(int pll)$/;"	f	signature:(int pll)
tags:node	drivers/cpufreq/cpufreq-dt.c	/^	struct list_head node;$/;"	m	struct:private_data	typeref:struct:private_data::list_head	file:	access:public
tags:node	include/linux/devfreq-event.h	/^	struct list_head node;$/;"	m	struct:devfreq_event_dev	typeref:struct:devfreq_event_dev::list_head	access:public
tags:nwait_en	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	nwait_en;	\/* nWait enabled for bank. *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:opp_table	drivers/cpufreq/cpufreq-dt.c	/^	struct opp_table *opp_table;$/;"	m	struct:private_data	typeref:struct:private_data::opp_table	file:	access:public
tags:ops	include/linux/devfreq-event.h	/^	const struct devfreq_event_ops *ops;$/;"	m	struct:devfreq_event_desc	typeref:struct:devfreq_event_desc::devfreq_event_ops	access:public
tags:pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct cpufreq_frequency_table pll;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::cpufreq_frequency_table	access:public
tags:pr_fmt	drivers/cpufreq/cpufreq-dt.c	9;"	d	file:
tags:pr_fmt	drivers/cpufreq/cpufreq-nforce2.c	10;"	d	file:
tags:pr_fmt	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	10;"	d	file:
tags:pr_fmt	drivers/cpufreq/sun50i-cpufreq-nvmem.c	11;"	d	file:
tags:print_ns	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	28;"	d	file:
tags:priv_list	drivers/cpufreq/cpufreq-dt.c	/^static LIST_HEAD(priv_list);$/;"	v
tags:private_data	drivers/cpufreq/cpufreq-dt.c	/^struct private_data {$/;"	s	file:
tags:private_data::cpu_dev	drivers/cpufreq/cpufreq-dt.c	/^	struct device *cpu_dev;$/;"	m	struct:private_data	typeref:struct:private_data::device	file:	access:public
tags:private_data::cpus	drivers/cpufreq/cpufreq-dt.c	/^	cpumask_var_t cpus;$/;"	m	struct:private_data	file:	access:public
tags:private_data::freq_table	drivers/cpufreq/cpufreq-dt.c	/^	struct cpufreq_frequency_table *freq_table;$/;"	m	struct:private_data	typeref:struct:private_data::cpufreq_frequency_table	file:	access:public
tags:private_data::have_static_opps	drivers/cpufreq/cpufreq-dt.c	/^	bool have_static_opps;$/;"	m	struct:private_data	file:	access:public
tags:private_data::node	drivers/cpufreq/cpufreq-dt.c	/^	struct list_head node;$/;"	m	struct:private_data	typeref:struct:private_data::list_head	file:	access:public
tags:private_data::opp_table	drivers/cpufreq/cpufreq-dt.c	/^	struct opp_table *opp_table;$/;"	m	struct:private_data	typeref:struct:private_data::opp_table	file:	access:public
tags:qcom-cpufreq-hw.c	drivers/cpufreq/qcom-cpufreq-hw.c	1;"	F
tags:qcom-cpufreq-nvmem.c	drivers/cpufreq/qcom-cpufreq-nvmem.c	1;"	F
tags:qcom_cpufreq_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^struct qcom_cpufreq_data {$/;"	s	file:
tags:qcom_cpufreq_data::base	drivers/cpufreq/qcom-cpufreq-hw.c	/^	void __iomem *base;$/;"	m	struct:qcom_cpufreq_data	file:	access:public
tags:qcom_cpufreq_data::res	drivers/cpufreq/qcom-cpufreq-hw.c	/^	struct resource *res;$/;"	m	struct:qcom_cpufreq_data	typeref:struct:qcom_cpufreq_data::resource	file:	access:public
tags:qcom_cpufreq_data::soc_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^	const struct qcom_cpufreq_soc_data *soc_data;$/;"	m	struct:qcom_cpufreq_data	typeref:struct:qcom_cpufreq_data::qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_driver	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static struct platform_driver qcom_cpufreq_driver = {$/;"	v	typeref:struct:platform_driver
tags:qcom_cpufreq_drv	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^struct qcom_cpufreq_drv {$/;"	s	file:
tags:qcom_cpufreq_drv	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^struct qcom_cpufreq_drv;$/;"	x	file:
tags:qcom_cpufreq_drv::data	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	const struct qcom_cpufreq_match_data *data;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::qcom_cpufreq_match_data	file:	access:public
tags:qcom_cpufreq_drv::genpd_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **genpd_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:qcom_cpufreq_drv::hw_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **hw_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:qcom_cpufreq_drv::names_opp_tables	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	struct opp_table **names_opp_tables;$/;"	m	struct:qcom_cpufreq_drv	typeref:struct:qcom_cpufreq_drv::opp_table	file:	access:public
tags:qcom_cpufreq_drv::versions	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	u32 versions;$/;"	m	struct:qcom_cpufreq_drv	file:	access:public
tags:qcom_cpufreq_exit	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^module_exit(qcom_cpufreq_exit);$/;"	v
tags:qcom_cpufreq_exit	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static void __exit qcom_cpufreq_exit(void)$/;"	f	signature:(void)
tags:qcom_cpufreq_get_msm_id	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static enum _msm8996_version qcom_cpufreq_get_msm_id(void)$/;"	f	signature:(void)
tags:qcom_cpufreq_hw_attr	drivers/cpufreq/qcom-cpufreq-hw.c	/^static struct freq_attr *qcom_cpufreq_hw_attr[] = {$/;"	v	typeref:struct:freq_attr
tags:qcom_cpufreq_hw_cpu_exit	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_cpu_exit(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:qcom_cpufreq_hw_cpu_init	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_cpu_init(struct cpufreq_policy *policy)$/;"	f	signature:(struct cpufreq_policy *policy)
tags:qcom_cpufreq_hw_driver	drivers/cpufreq/qcom-cpufreq-hw.c	/^static struct platform_driver qcom_cpufreq_hw_driver = {$/;"	v	typeref:struct:platform_driver
tags:qcom_cpufreq_hw_driver_probe	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_driver_probe(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:qcom_cpufreq_hw_driver_remove	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_driver_remove(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:qcom_cpufreq_hw_exit	drivers/cpufreq/qcom-cpufreq-hw.c	/^module_exit(qcom_cpufreq_hw_exit);$/;"	v
tags:qcom_cpufreq_hw_exit	drivers/cpufreq/qcom-cpufreq-hw.c	/^static void __exit qcom_cpufreq_hw_exit(void)$/;"	f	signature:(void)
tags:qcom_cpufreq_hw_fast_switch	drivers/cpufreq/qcom-cpufreq-hw.c	/^static unsigned int qcom_cpufreq_hw_fast_switch(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int target_freq)
tags:qcom_cpufreq_hw_get	drivers/cpufreq/qcom-cpufreq-hw.c	/^static unsigned int qcom_cpufreq_hw_get(unsigned int cpu)$/;"	f	signature:(unsigned int cpu)
tags:qcom_cpufreq_hw_init	drivers/cpufreq/qcom-cpufreq-hw.c	/^postcore_initcall(qcom_cpufreq_hw_init);$/;"	v
tags:qcom_cpufreq_hw_init	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int __init qcom_cpufreq_hw_init(void)$/;"	f	signature:(void)
tags:qcom_cpufreq_hw_match	drivers/cpufreq/qcom-cpufreq-hw.c	/^static const struct of_device_id qcom_cpufreq_hw_match[] = {$/;"	v	typeref:struct:of_device_id
tags:qcom_cpufreq_hw_read_lut	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_read_lut(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, struct cpufreq_policy *policy)
tags:qcom_cpufreq_hw_target_index	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_hw_target_index(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int index)
tags:qcom_cpufreq_init	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^module_init(qcom_cpufreq_init);$/;"	v
tags:qcom_cpufreq_init	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static int __init qcom_cpufreq_init(void)$/;"	f	signature:(void)
tags:qcom_cpufreq_krait_name_version	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static int qcom_cpufreq_krait_name_version(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, struct nvmem_cell *speedbin_nvmem, char **pvs_name, struct qcom_cpufreq_drv *drv)
tags:qcom_cpufreq_kryo_name_version	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static int qcom_cpufreq_kryo_name_version(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, struct nvmem_cell *speedbin_nvmem, char **pvs_name, struct qcom_cpufreq_drv *drv)
tags:qcom_cpufreq_match_data	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^struct qcom_cpufreq_match_data {$/;"	s	file:
tags:qcom_cpufreq_match_data::genpd_names	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	const char **genpd_names;$/;"	m	struct:qcom_cpufreq_match_data	file:	access:public
tags:qcom_cpufreq_match_data::get_version	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	int (*get_version)(struct device *cpu_dev,$/;"	m	struct:qcom_cpufreq_match_data	file:	access:public
tags:qcom_cpufreq_match_list	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static const struct of_device_id qcom_cpufreq_match_list[] __initconst = {$/;"	v	typeref:struct:of_device_id
tags:qcom_cpufreq_probe	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static int qcom_cpufreq_probe(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:qcom_cpufreq_remove	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static int qcom_cpufreq_remove(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:qcom_cpufreq_set_bw	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_set_bw(struct cpufreq_policy *policy,$/;"	f	signature:(struct cpufreq_policy *policy, unsigned long freq_khz)
tags:qcom_cpufreq_soc_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^struct qcom_cpufreq_soc_data {$/;"	s	file:
tags:qcom_cpufreq_soc_data::lut_row_size	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u8 lut_row_size;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_soc_data::reg_enable	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_enable;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_soc_data::reg_freq_lut	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_freq_lut;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_soc_data::reg_perf_state	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_perf_state;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_soc_data::reg_volt_lut	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_volt_lut;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:qcom_cpufreq_update_opp	drivers/cpufreq/qcom-cpufreq-hw.c	/^static int qcom_cpufreq_update_opp(struct device *cpu_dev,$/;"	f	signature:(struct device *cpu_dev, unsigned long freq_khz, unsigned long volt)
tags:qcom_get_related_cpus	drivers/cpufreq/qcom-cpufreq-hw.c	/^static void qcom_get_related_cpus(int index, struct cpumask *m)$/;"	f	signature:(int index, struct cpumask *m)
tags:qcom_soc_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^static const struct qcom_cpufreq_soc_data qcom_soc_data = {$/;"	v	typeref:struct:qcom_cpufreq_soc_data
tags:qcs404_genpd_names	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^static const char *qcs404_genpd_names[] = { "cpr", NULL };$/;"	v
tags:reading_reply	drivers/macintosh/via-macii.c	/^static bool reading_reply;       \/* store reply in reply_buf else req->reply *\/$/;"	v
tags:reg_enable	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_enable;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:reg_freq_lut	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_freq_lut;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:reg_perf_state	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_perf_state;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:reg_volt_lut	drivers/cpufreq/qcom-cpufreq-hw.c	/^	u32 reg_volt_lut;$/;"	m	struct:qcom_cpufreq_soc_data	file:	access:public
tags:reply_len	drivers/macintosh/via-macii.c	/^static int reply_len; \/* number of bytes received in reply_buf or req->reply *\/$/;"	v
tags:reply_ptr	drivers/macintosh/via-macii.c	/^static unsigned char *reply_ptr;     \/* next byte in reply_buf or req->reply *\/$/;"	v
tags:res	drivers/cpufreq/qcom-cpufreq-hw.c	/^	struct resource *res;$/;"	m	struct:qcom_cpufreq_data	typeref:struct:qcom_cpufreq_data::resource	file:	access:public
tags:reset	include/linux/devfreq-event.h	/^	int (*reset)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:resume	drivers/cpufreq/cpufreq-dt.h	/^	int (*resume)(struct cpufreq_policy *policy);$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:s3c-cpufreq-core.h	include/linux/soc/samsung/s3c-cpufreq-core.h	1;"	F
tags:s3c2410_cpufreq_setrefresh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2410_cpufreq_setrefresh(struct s3c_cpufreq_config *cfg);$/;"	p	signature:(struct s3c_cpufreq_config *cfg)
tags:s3c2410_iobank_timing	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c2410_iobank_timing {$/;"	s
tags:s3c2410_iobank_timing::bankcon	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned long	bankcon;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::nwait_en	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	nwait_en;	\/* nWait enabled for bank. *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tacc	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacc;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tacp	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacp;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tacs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacs;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tcah	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcah;		\/* Address hold after nCS *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tcoh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcoh;		\/* nCS hold after nOE\/nWE *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iobank_timing::tcos	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcos;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:s3c2410_iotiming_calc	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c2410_iotiming_calc(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *iot)
tags:s3c2410_iotiming_calc	include/linux/soc/samsung/s3c-cpufreq-core.h	231;"	d
tags:s3c2410_iotiming_debugfs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2410_iotiming_debugfs(struct seq_file *seq,$/;"	p	signature:(struct seq_file *seq, struct s3c_cpufreq_config *cfg, union s3c_iobank *iob)
tags:s3c2410_iotiming_debugfs	include/linux/soc/samsung/s3c-cpufreq-core.h	230;"	d
tags:s3c2410_iotiming_get	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c2410_iotiming_get(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *timings)
tags:s3c2410_iotiming_get	include/linux/soc/samsung/s3c-cpufreq-core.h	232;"	d
tags:s3c2410_iotiming_set	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2410_iotiming_set(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *iot)
tags:s3c2410_iotiming_set	include/linux/soc/samsung/s3c-cpufreq-core.h	233;"	d
tags:s3c2410_set_fvco	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2410_set_fvco(struct s3c_cpufreq_config *cfg);$/;"	p	signature:(struct s3c_cpufreq_config *cfg)
tags:s3c2412_cpufreq_setrefresh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2412_cpufreq_setrefresh(struct s3c_cpufreq_config *cfg);$/;"	p	signature:(struct s3c_cpufreq_config *cfg)
tags:s3c2412_iobank_timing	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c2412_iobank_timing {$/;"	s
tags:s3c2412_iobank_timing::idcy	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	idcy;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbidcyr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbidcyr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbwstbrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstbrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbwstoen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstoen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbwstrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbwstwen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstwen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::smbwstwr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstwr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::wstbrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstbrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::wstoen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstoen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::wstrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::wstwen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstwen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iobank_timing::wstwr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstwr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:s3c2412_iotiming_calc	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c2412_iotiming_calc(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *iot)
tags:s3c2412_iotiming_calc	include/linux/soc/samsung/s3c-cpufreq-core.h	254;"	d
tags:s3c2412_iotiming_debugfs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2412_iotiming_debugfs(struct seq_file *seq,$/;"	p	signature:(struct seq_file *seq, struct s3c_cpufreq_config *cfg, union s3c_iobank *iob)
tags:s3c2412_iotiming_debugfs	include/linux/soc/samsung/s3c-cpufreq-core.h	253;"	d
tags:s3c2412_iotiming_get	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c2412_iotiming_get(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *timings)
tags:s3c2412_iotiming_get	include/linux/soc/samsung/s3c-cpufreq-core.h	255;"	d
tags:s3c2412_iotiming_set	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern void s3c2412_iotiming_set(struct s3c_cpufreq_config *cfg,$/;"	p	signature:(struct s3c_cpufreq_config *cfg, struct s3c_iotimings *iot)
tags:s3c2412_iotiming_set	include/linux/soc/samsung/s3c-cpufreq-core.h	256;"	d
tags:s3c2440_read_camdivn	include/linux/soc/samsung/s3c-cpufreq-core.h	/^u32 s3c2440_read_camdivn(void);$/;"	p	signature:(void)
tags:s3c2440_write_camdivn	include/linux/soc/samsung/s3c-cpufreq-core.h	/^void s3c2440_write_camdivn(u32 camdiv);$/;"	p	signature:(u32 camdiv)
tags:s3c24xx-cpufreq-debugfs.c	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	1;"	F
tags:s3c24xx_read_clkdivn	include/linux/soc/samsung/s3c-cpufreq-core.h	/^u32 s3c24xx_read_clkdivn(void);$/;"	p	signature:(void)
tags:s3c24xx_read_mpllcon	include/linux/soc/samsung/s3c-cpufreq-core.h	/^u32 s3c24xx_read_mpllcon(void);$/;"	p	signature:(void)
tags:s3c24xx_write_clkdivn	include/linux/soc/samsung/s3c-cpufreq-core.h	/^void s3c24xx_write_clkdivn(u32 clkdiv);$/;"	p	signature:(u32 clkdiv)
tags:s3c24xx_write_locktime	include/linux/soc/samsung/s3c-cpufreq-core.h	/^void s3c24xx_write_locktime(u32 locktime);$/;"	p	signature:(u32 locktime)
tags:s3c_cpufreq_addfreq	include/linux/soc/samsung/s3c-cpufreq-core.h	/^static inline int s3c_cpufreq_addfreq(struct cpufreq_frequency_table *table,$/;"	f	signature:(struct cpufreq_frequency_table *table, int index, size_t table_size, unsigned int freq)
tags:s3c_cpufreq_clk_get	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern struct clk *s3c_cpufreq_clk_get(struct device *, const char *);$/;"	p	signature:(struct device *, const char *)
tags:s3c_cpufreq_config	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c_cpufreq_config {$/;"	s
tags:s3c_cpufreq_config::board	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_cpufreq_board *board;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_cpufreq_board	access:public
tags:s3c_cpufreq_config::divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_clkdivs	divs;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_clkdivs	access:public
tags:s3c_cpufreq_config::freq	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		freq;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_freq	access:public
tags:s3c_cpufreq_config::info	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_cpufreq_info *info;	\/* for core, not drivers *\/$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_cpufreq_info	access:public
tags:s3c_cpufreq_config::lock_pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	lock_pll:1;$/;"	m	struct:s3c_cpufreq_config	access:public
tags:s3c_cpufreq_config::max	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		max;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::s3c_freq	access:public
tags:s3c_cpufreq_config::mpll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct clk		*mpll;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::clk	access:public
tags:s3c_cpufreq_config::pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct cpufreq_frequency_table pll;$/;"	m	struct:s3c_cpufreq_config	typeref:struct:s3c_cpufreq_config::cpufreq_frequency_table	access:public
tags:s3c_cpufreq_debugfs_call	include/linux/soc/samsung/s3c-cpufreq-core.h	202;"	d
tags:s3c_cpufreq_debugfs_call	include/linux/soc/samsung/s3c-cpufreq-core.h	204;"	d
tags:s3c_cpufreq_getconfig	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern struct s3c_cpufreq_config *s3c_cpufreq_getconfig(void);$/;"	p	signature:(void)
tags:s3c_cpufreq_getiotimings	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern struct s3c_iotimings *s3c_cpufreq_getiotimings(void);$/;"	p	signature:(void)
tags:s3c_cpufreq_info	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c_cpufreq_info {$/;"	s
tags:s3c_cpufreq_info::calc_divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_divs)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::calc_freqtable	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_freqtable)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::calc_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*calc_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::debug_io_show	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*debug_io_show)(struct seq_file *seq,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::get_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int		(*get_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::latency	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		latency;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::locktime_bits	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char		locktime_bits;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::locktime_m	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		locktime_m;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::locktime_u	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		locktime_u;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::max	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_freq		max;$/;"	m	struct:s3c_cpufreq_info	typeref:struct:s3c_cpufreq_info::s3c_freq	access:public
tags:s3c_cpufreq_info::name	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	const char		*name;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::need_pll	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int		need_pll:1;$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::set_divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_divs)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::set_fvco	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_fvco)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::set_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_info::set_refresh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_refresh)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:s3c_cpufreq_register	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c_cpufreq_register(struct s3c_cpufreq_info *info);$/;"	p	signature:(struct s3c_cpufreq_info *info)
tags:s3c_freq_dbg	include/linux/soc/samsung/s3c-cpufreq-core.h	260;"	d
tags:s3c_freq_dbg	include/linux/soc/samsung/s3c-cpufreq-core.h	262;"	d
tags:s3c_freq_debugfs_init	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^late_initcall(s3c_freq_debugfs_init);$/;"	v
tags:s3c_freq_debugfs_init	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static int __init s3c_freq_debugfs_init(void)$/;"	f	signature:(void)
tags:s3c_freq_iodbg	include/linux/soc/samsung/s3c-cpufreq-core.h	266;"	d
tags:s3c_freq_iodbg	include/linux/soc/samsung/s3c-cpufreq-core.h	268;"	d
tags:s3c_iobank	include/linux/soc/samsung/s3c-cpufreq-core.h	/^union s3c_iobank {$/;"	u
tags:s3c_iobank::io_2410	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c2410_iobank_timing	*io_2410;$/;"	m	union:s3c_iobank	typeref:struct:s3c_iobank::s3c2410_iobank_timing	access:public
tags:s3c_iobank::io_2412	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c2412_iobank_timing	*io_2412;$/;"	m	union:s3c_iobank	typeref:struct:s3c_iobank::s3c2412_iobank_timing	access:public
tags:s3c_iotimings	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c_iotimings {$/;"	s
tags:s3c_iotimings::bank	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	union s3c_iobank	bank[MAX_BANKS];$/;"	m	struct:s3c_iotimings	typeref:union:s3c_iotimings::s3c_iobank	access:public
tags:s3c_plltab	include/linux/soc/samsung/s3c-cpufreq-core.h	/^struct s3c_plltab {$/;"	s
tags:s3c_plltab::size	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int			 size;$/;"	m	struct:s3c_plltab	access:public
tags:s3c_plltab::vals	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_pllval	*vals;$/;"	m	struct:s3c_plltab	typeref:struct:s3c_plltab::s3c_pllval	access:public
tags:s3c_plltab_register	include/linux/soc/samsung/s3c-cpufreq-core.h	/^extern int s3c_plltab_register(struct cpufreq_frequency_table *plls,$/;"	p	signature:(struct cpufreq_frequency_table *plls, unsigned int plls_no)
tags:set_divs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_divs)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:set_event	include/linux/devfreq-event.h	/^	int (*set_event)(struct devfreq_event_dev *edev);$/;"	m	struct:devfreq_event_ops	access:public
tags:set_fvco	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_fvco)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:set_iotiming	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_iotiming)(struct s3c_cpufreq_config *cfg,$/;"	m	struct:s3c_cpufreq_info	access:public
tags:set_refresh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	void		(*set_refresh)(struct s3c_cpufreq_config *cfg);$/;"	m	struct:s3c_cpufreq_info	access:public
tags:set_target	drivers/cpufreq/cpufreq-dt.c	/^static int set_target(struct cpufreq_policy *policy, unsigned int index)$/;"	f	signature:(struct cpufreq_policy *policy, unsigned int index)
tags:show_max	drivers/cpufreq/s3c24xx-cpufreq-debugfs.c	/^static void show_max(struct seq_file *seq, struct s3c_freq *f)$/;"	f	signature:(struct seq_file *seq, struct s3c_freq *f)
tags:size	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	int			 size;$/;"	m	struct:s3c_plltab	access:public
tags:smbidcyr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbidcyr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:smbwstbrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstbrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:smbwstoen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstoen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:smbwstrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:smbwstwen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstwen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:smbwstwr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned char	smbwstwr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:soc_data	drivers/cpufreq/qcom-cpufreq-hw.c	/^	const struct qcom_cpufreq_soc_data *soc_data;$/;"	m	struct:qcom_cpufreq_data	typeref:struct:qcom_cpufreq_data::qcom_cpufreq_soc_data	file:	access:public
tags:sun50i-cpufreq-nvmem.c	drivers/cpufreq/sun50i-cpufreq-nvmem.c	1;"	F
tags:sun50i_cpufreq_driver	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static struct platform_driver sun50i_cpufreq_driver = {$/;"	v	typeref:struct:platform_driver
tags:sun50i_cpufreq_exit	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^module_exit(sun50i_cpufreq_exit);$/;"	v
tags:sun50i_cpufreq_exit	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static void __exit sun50i_cpufreq_exit(void)$/;"	f	signature:(void)
tags:sun50i_cpufreq_get_efuse	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static int sun50i_cpufreq_get_efuse(u32 *versions)$/;"	f	signature:(u32 *versions)
tags:sun50i_cpufreq_init	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^module_init(sun50i_cpufreq_init);$/;"	v
tags:sun50i_cpufreq_init	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static int __init sun50i_cpufreq_init(void)$/;"	f	signature:(void)
tags:sun50i_cpufreq_match_list	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static const struct of_device_id sun50i_cpufreq_match_list[] = {$/;"	v	typeref:struct:of_device_id
tags:sun50i_cpufreq_match_node	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static const struct of_device_id *sun50i_cpufreq_match_node(void)$/;"	f	signature:(void)
tags:sun50i_cpufreq_nvmem_probe	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static int sun50i_cpufreq_nvmem_probe(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:sun50i_cpufreq_nvmem_remove	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static int sun50i_cpufreq_nvmem_remove(struct platform_device *pdev)$/;"	f	signature:(struct platform_device *pdev)
tags:sun50i_cpufreq_pdev	drivers/cpufreq/sun50i-cpufreq-nvmem.c	/^static struct platform_device *cpufreq_dt_pdev, *sun50i_cpufreq_pdev;$/;"	v	typeref:struct:
tags:suspend	drivers/cpufreq/cpufreq-dt.h	/^	int (*suspend)(struct cpufreq_policy *policy);$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:tacc	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacc;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:tacp	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacp;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:tacs	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tacs;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:target_intermediate	drivers/cpufreq/cpufreq-dt.h	/^	int		(*target_intermediate)(struct cpufreq_policy *policy,$/;"	m	struct:cpufreq_dt_platform_data	access:public
tags:tcah	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcah;		\/* Address hold after nCS *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:tcoh	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcoh;		\/* nCS hold after nOE\/nWE *\/$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:tcos	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	tcos;$/;"	m	struct:s3c2410_iobank_timing	access:public
tags:to_devfreq_event	drivers/devfreq/devfreq-event.c	26;"	d	file:
tags:total_count	include/linux/devfreq-event.h	/^	unsigned long total_count;$/;"	m	struct:devfreq_event_data	access:public
tags:vals	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	struct s3c_pllval	*vals;$/;"	m	struct:s3c_plltab	typeref:struct:s3c_plltab::s3c_pllval	access:public
tags:versions	drivers/cpufreq/qcom-cpufreq-nvmem.c	/^	u32 versions;$/;"	m	struct:qcom_cpufreq_drv	file:	access:public
tags:whitelist	drivers/cpufreq/cpufreq-dt-platdev.c	/^static const struct of_device_id whitelist[] __initconst = {$/;"	v	typeref:struct:of_device_id
tags:wstbrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstbrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:wstoen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstoen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:wstrd	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstrd;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:wstwen	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstwen;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:wstwr	include/linux/soc/samsung/s3c-cpufreq-core.h	/^	unsigned int	wstwr;$/;"	m	struct:s3c2412_iobank_timing	access:public
tags:xo_rate	drivers/cpufreq/qcom-cpufreq-hw.c	/^static unsigned long cpu_hw_rate, xo_rate;$/;"	v
